corpusid,section,subsection,section_pos_in_pct,text
2423505,2/23,1.0,0.087,"As mentioned in the introduction, the shortage of labeled **data** is a fundamental problem for applied machine learning. It is important enough that several areas of research is devoted to various aspects of this problem. In the active learning paradigm, labels are acquired in an interactive fashion to maximize the benefit of each new label [Kapoor et al., 2007]. Related approaches include [Branson et al., 2011], where a 'human-in-the-loop' determines which labels to update, thus making the 'most' out of the acquired labels. Crowd sourcing through, e.g. Amazon mechanical turk (mTurk), allows for rapid collection of large amounts of labels, and much research is devoted to the efficient distribution of tasks and the interpretation and weighting of retrieved labels [Welinder et al., 2010]. Further areas include weakly supervised method, e.g. multiple instance learning [Dietterich et al., 1997] or latent structureal SVMs [Yu and Joachims, 2009] where the level of supervision is lower than the given task demands. Other approaches include semi-supervised learning that make use of small amounts of labelled **data** together with large amounts of unlabeled data. Notably the concept of co-training [Blum and Mitchell, 1998] is a popular approach."
246337567,1/70,2.0,0.014,"LD that is published under an open license is known as linked open **data** (LOD) (Berners-Lee 2006). LOD is classified according to a Five Star rating system, and to be considered Five Star, a LD dataset must contain interlinks to related **data** (Berners-Lee 2006;Kim and Hausenblas 2015). The purpose of these LD interlinks is to enhance the knowledge associated with a specific entity (Papaleo et al. 2014). These interlinks have the potential to transform the Web into a globally linked and searchable database, rather than a disparate collection of documents (W3C 2015). Many metadata standards used in libraries, archives, and museums (LAMs) cannot be processed by Web search engines; thus a significant amount of relevant content is not visible in Web search results (Guerrini and Possemato 2016;Pesch and Miller 2016). Metadata published as RDF, however, are easily processed by SW search engines (Schilling 2012)enhancing **data** discoverability and visibility. Cross-institutional metadata interlinking would allow for easier, more efficient querying and discovery of LAM materials (Alemu et al. 2012;Coyle 2013;Seeman and Goddard 2015)."
249538382,7/22,1.0,0.318,"To create high-quality ERP system **data** and increase rigor, we develop requirements for our **data** based on prior work. We follow Baader et al. [4], who find several requirements for both their developed **data** generator and the resulting data. We also draw additional requirements from previously conducted design science research that aims to develop a fraud detection system in the ERP domain. Here, Fuchs et al. [7] aggregate requirements for detection systems that are able to highlight fraud in ERP systems. Some of their requirements describe design decisions that need to be respected during implementation of the fraud detection approach and are unaffected by the studied **data** (e.g. requiring adaptable or intelligent logic). Other requirements, however, describe scenarios in which fraud detection approaches should yield satisfying performance (e.g. detection of outliers in values). We argue that **data** should be created such that the performance of fraud detection approaches can be validated in these scenarios, and therefore identify these requirements as directly relevant for our **data** generation process. Figure 1 gives an overview of the requirements in the preliminary work of Baader et al. [4] as well as the requirements we identify as relevant to our **data** generation process from Fuchs et al. [7]. We additionally note the resulting measures we take in our proposed **data** generation scheme to satisfy these requirements."
55648852,20/40,7.0,0.5,"The Italian OBS **data** available at the time of this report are only those recorded by the broadband OBSs. These **data** are saved in SAC files and therefore easy to handle. The procedure was the same as for the rest of data, obtaining .mat files as the final format.  "
233705419,1/53,1.0,0.019,"In this paper, the focus is on the formalization of expert knowledge and its use for test design and integration into different machine learning (ML) algorithms. The formalization of expert knowledge from different domains (e.g., expertise regarding plant mechanical Processes 2021, 9, 515 2 of 12 processes and knowledge about thermo-chemical and other physical mechanisms of chemical processes) is particularly challenging and reveals the uniqueness of the presented approach. Due to the lack of data, deep neuronal networks cannot always be trained, and other ML algorithms must be combined to quantify and expand expert knowledge from different domains. Figure 1 shows the continuous learning procedure and the interaction between the different parts of an AI-based hybrid model, i.e., **data** measurement, expert knowledge, and ML algorithms with special metrics for automated evaluation (autoML) [5]. With this procedure, expert knowledge can be continuously quantified, and the understanding of the plant and chemical processes can be expanded."
146010542,11/17,1.0,0.647,"""Man in the middle"" (MITM/MIM) is a kind of malware which relies on SSL/TSL protocol weakness, being correspondent in communication between two network users (Čekerevac et al., 2017;Mallik et al., 2019). In such a case, downloading of important **data** occurs while users can rarely detect it. 7."
245105154,9/25,1.0,0.36,"The chosen simulation scenario represented a simple sensing application where end devices sense and transmit **data** to the gateway at 1-h intervals. This type of application was relevant enough for the researchers to use to collect performance **data** about the different algorithms. In this research experiment, this application involved the end devices sending 20-byte packets to the gateways every 1 h. The end devices and the gateway adhered to the 1% duty cycle required by applications operating in the European ISM band [14]. All simulation scenarios mentioned lasted for one week and were executed ten times as in [8]."
119479526,1/29,1.0,0.034,"High quality thermodynamic property models are the key to calculating numerous other properties and predicting complex material behaviors. Researchers construct these models through a process called assessment [1] whereby experimental and computational information regarding material properties is used to evaluate the optimal mathematical forms that relate properties to parameters such as temperature, pressure and composition. Thermodynamic assessments present numerous challenges: the presence of outliers, missing or underestimated errors in datasets and systematic errors are commonplace. Furthermore, it is critical to select model forms that match the trends in the **data** and are based on the physics and chemistry of the material. These complex judgments are the sole responsibility of the practitioner and are rarely quantitatively expressed in the final models. Bayesian statistical methods provide an opportunity to address each of these challenges in a robust and comprehensive manner."
232380196,1/28,1.0,0.036,"In the real world, the image classes are normally presented in a long-tailed distribution [25]. While some common classes (head classes) can have sufficient image samples, some uncommon or rare categories (tail classes) can be underrepresented by limited samples. The **data** imbalance poses great challenge to learning unbiased classifiers."
52141668,11/16,1.0,0.688,"Figure 1 :
1Proportion of **data** used for experiment
"
184487142,14/47,1.0,0.298,"Empirical defenses are empirically robust to existing adversarial attacks, and the best empirical defense so far is adversarial training [20,25]. In this kind of defense, a neural network is trained to minimize the worst-case loss over a neighborhood around the input. Although such defenses seem powerful, nothing guarantees that a more powerful, not yet known, attack would not break them; the most that can be said is that known attacks are unable to find adversarial examples around the **data** points. In fact, most empirical defenses proposed in the literature were later ""broken"" by stronger adversaries [4,2,35,1]. To stop this arms race between defenders and attackers, a number of work tried to focus on building certified defenses which enjoy formal robustness guarantees."
246337567,4/70,2.0,0.057,"Data provenance is a record describing the origin of a piece of **data** and can include information on the date/time, people, institutions, and processes involved in its creation. Given that any individual can publish to the SW, LD provenance is crucial in establishing the trustworthiness and quality of the **data** (Dezani-Ciancaglini et al. 2012). In the LAM domain, The Open Archival Information System (OAIS) (CCSDS 2019) and Preservation Metadata: Implementation Strategies (PREMIS) (PREMIS Editorial Committee 2015), are both widely accepted standards for digital preservation that require the provision of provenance information when archiving digital resources."
225532842,4/17,1.0,0.235,"Within initial phase, the node of the sensor transmits information towards the nodes of the master type (outer nodes as well as on-body ones). In the other one, OMN tests the taken information for determining if it was taken correctly; after that the OMN transfers an ACK positive in the reverse direction, besides OBN comes the information off which was taken out of a sensor, just like it is displayed in Figure 3. If not, the OMN transfers NACK towards the OBN, that re-transfers the information which was taken from the sensor towards the OMN and after that merges the information of the signal of the _rst and other phases by MRC which is Maximal Ratio Combining. The goals of the achievement can be briefed as mentioned below [2]: 
‫ܥܦ‬ ൌ ܶ ௧௩ ܶ ௌ ሺ1 ܲ‫ܴܧ‬ሻ ሺ1ሻ
where ܶ ௧௩ is the RF activity time, which is given as [9]:
ܶ ௧௩ ൌ ܶ ܶ ௐ ܶ ௗ௧ ܶ 2ܶ ௌூிௌ 2ܶ ఈ ሺ2ሻ
ܶ ௐ is average contention time and it is given as:
ܶ ௐ ൌ 0.5 ‫ܹܥ‬ . ܶ ௦
(3) The required time to send a **data** is given as [9]:
ܶ ் ൌ ܶ ܶ ு ܶ ெ ܶ ை ܶ ிௌ . ሺ4ሻ
The acknowledgment sending time is given by:
ܶ ൌ ܶ ܶ ு ܶ ெ ܶ ிௌ . ሺ5ሻ
The average probability of error at the packet level at each hop is given as [10][11]:
‫ܴܧܲ‬ ൌ 1 െ ሺ1 െ ‫‪ܴሻ‬ܧܤ‬ ሺ6ሻ
The DC is given as [2]:
‫ܥܦ‬ ൌ ܶ ܶ ௐ ܶ ௗ௧ ܶ 2ܶ ௌூிௌ 2ߙ. ܶ ௦ ൈ ൫2 െ ሺ1 െ ‫‪ܴሻ‬ܧܤ‬ ൯ ሺ7ሻ
The factor,ሺ2 െ ሺ1 െ ‫‪ܴሻ‬ܧܤ‬ ሻ, is taken into account, which shows how the BER influences DC. DC and the average transmission power are affected directly by the factor ሺ2 െ ሺ1 െ ‫‪ܴሻ‬ܧܤ‬ ሻ."
246337567,3/70,2.0,0.043,LD interlinking describes the task of determining whether a named resource (an entity identified by a URI) can be linked to another named resource in order to indicate that they both describe the same thing or that they are related in some capacity (Ferrara et al. 2011). The purpose of LD interlinks is to provide additional information about an entity in order to improve **data** discovery (Kim and Hausenblas 2015).
54704771,11/11,1.0,1.0,"Profit split method 
If there is no **data** for application 
of traditional methods 
Profit split method 
Indirect use "
565361,17/29,2.0,0.586,"With the increasing use of digital imagery that is independent of TV, new methods are continually being introduced. Just as in halftoning, coding schemes that exploit the lowpass spatial response of the eye have been suggested for image coding. In subband coding [313], the image is split into orthogonal subbands with varying frequency content. The subbands are then quantized with fewer bits allocated to higher frequency components. VQ techniques, similar to those described in the earlier section on palettization, can be used for the quantization. Known anisotropy in the eye's spatial response can also be utilized. The lower sensitivity of the eye along the 45 angle, permits fewer bits to be allocated to frequency bands located on the diagonal. This idea is easily extended to color images. However, complete **data** on the spatial frequency response of the eye to spatial color (chromatic) frequencies has only recently been published. The combination of subband coding with color spatial frequency response was presented in [314] and [315]."
27068907,2/25,1.0,0.08,"Often deployed in refrigeration houses and cars, wireless sensor nodes are mainly targeted at collecting and processing temperature signals, and sending the processed signals to the monitoring terminal. The **data** is sent through the radio frequency mode."
236522469,5/33,1.0,0.152,"The neural network learns the patterns from the input **data** by reading the input **data** set and applying different computations to it. However, the neural network does not just do this once; it learns repeatedly using the input **data** set and also the results of previous tests. Each step in learning from the input **data** set is called an epoch. That is, an epoch refers to one cycle in the entire training **data** set [48,49]. Initially, CNN were trained with a large number of epochs or steps (iterations) to ensure that the smallest loss would be within that step range. After the first training, we determined an ideal number of steps to obtain the least loss to optimize the analyses and repetitions that would be performed; this test served fundamentally to know how many epochs would be necessary for the final At the end of the sample selection process, the software provides a file in .csv format, containing filename, height, width, class, xmin, xmax, ymin, and ymax [47]. From the Labelimg .csv file, it was possible to create two sets of samples randomly: Training (70%; 1706 samples) and Test (30%; 731 samples); these samples formed from the Training and Test images were fed into the CNN as input parameters. For validation, 487 images were separated from the training samples to be applied in the validation, guaranteeing that the model did not present overfitting ( Table 2)."
236196766,22/47,2.0,0.468,"When compared to these tools, GrimoireLab is in general more diverse in terms of **data** sources supported with a common interface: all of them can be retrieved using the Perceval API. For all of them raw and enriched indexes are produced with a similar structure, all of them can be retrieved and analyzed automatically with the same Mordred configuration. Most of the tools mentioned above support one, or a small number, of different **data** sources, and in general are not designed to produce uniform **data** that can be later queried for further analysis in a uniform way. GrimoireLab also provides identity management for all of these **data** sources, and a common way of visualizing and reporting data. However, the main difference is probably the fact that GrimoireLab tools can be used, if needed, in isolation, and that the **data** is stored in a way that allows for many different kinds of further analysis."
225958729,2/13,1.0,0.154,"In essence, cloud computing is a computing model, which mainly relies on distributed computing, grid computing, and parallel computing. The ultimate purpose of cloud computing is to provide users with comfortable and convenient services. For cloud computing functions, convenience is a big feature, such as the storage of data. Besides, cloud computing has the characteristics and advantages of a timesharing system, mainly reflected in three aspects: first, different devices can also achieve the purpose 2 of network **data** sharing; Second, it has complete computing function and storage function; Third, the operation of the application is quite convenient, especially for users, whose terminal equipment are not high. As for the processing of **data** in cloud computing, it mainly covers two aspects: the collation work after **data** collection, and the search work within the system. If only from the **data** collection after the collation of the work, it includes **data** analysis and the results of the return. Overall, cloud computing is dedicated to providing a good experience for users. "
246337567,5/70,2.0,0.071,"These LD services have been summarised in Table 1 where it can be seen that, on average, the **data** was interlinked to five external datasets-primarily authority files and controlled vocabularies as well as datahubs such as DBpedia 11 and Wikidata. 12 Although interlinking with authority files and controlled vocabularies is extremely useful, this type of linking predates LD. Additionally, while linking to large-scale datahubs, such as DBpedia and Wikidata, is useful, these datasets do not fall within the LAM domain. Additionally, only two services, Europeana and the BNB, appeared to provide LD provenance information. Finally, the majority of interlinks created by the projects were identity links-leaving vast potential for LAMs to create provenance-rich relationship interlinks that provide additional information and context for a given entity."
232380196,3/28,4.0,0.107,"Loss re-weighting Apart from the aforementioned databased re-balance strategies, another line of studies propose to mitigate the negative effects of **data** imbalance by modifying the loss functions. Loss re-weighting is one of the simple but effective ways to tailor the loss function for imbalanced classification, where the basic idea is to upweight the tailed samples and downweight the head samples in the loss function [17]. The existing solutions differ mainly in how to define the weights for different classes. In classsensitive cross-entropy loss [14], the weight assigned to each class is inversely proportional to the number of samples. In class-balanced loss [7], the authors decide the re-weighting coefficients based on the real volumes of different classes, named effective numbers. In the work [30], the weights to the training examples are optimized to minimize the loss of a held-out evaluation set."
246165803,15/45,1.0,0.333,"Two models were proposed for the classification system, based on the type of **data** provided by the accelerometer: the K-nearest neighbor algorithm and an Artificial Neural Network. Even though both algorithms classify data, they are opposite approaches. The KNN algorithm is more practical and easier to train than the ANN, and ANN is a more sophisticated and likely better approach. However, considering the amount of experimental **data** obtained, the KNN could be better suited."
17966235,8/35,1.0,0.229,"In the indoor environments, however, due to the limited range, the assumption of pseudowired is not reasonable [63], [64]. On the other hand, owing to the explosive growth of mobile **data** demands as well as to overcome the limited range of mmWave communications, in a practical mmWave communication system, the number of deployed APs over both public and private areas increases tremendously. For example, a large number of APs must be deployed in scenarios such as enterprise cubicles and conference rooms to provide seamless coverage. In this case, the interference in the network can be divided into two portions: interference within each BSS, and interference among different BSSs [65]. As shown in Fig. 3, when the two links in BSS1 and BSS2 are communicating in the same slot t, since AP1 directs its beam towards the laptop, AP1 will have interference to the laptop. If the distance between them is short, the service of the laptop will be degraded significantly."
2765985,6/7,1.0,0.857,The source routing is not a mandatory function. It is called only if it is selected by the originator of PDU. The source routing function allows a network entity to specify the path that a generated PDU shall take [2]. Then it will examine the route in the parameter value that defined by the network entity where the PDU constructed. The source route function will give the forward PDU function the **data** packet and the address of the next network entity where the packet needs to be transmitted. Source route analysis divided into complete source route analysis and partial source route analysis.
246165803,14/45,2.0,0.311,"Additional **data** were acquired since the ANN model needs labeled **data** for training. This also obtained **data** for comparison. With new **data** on a less troubled street, the algorithms' manual labeling of the anomalies and cleaner training **data** can be provided to the algorithm for a better performance."
249538382,12/22,1.0,0.545,"Within our proposed **data** generation scheme, we conducted five separate runs of the ERPsim serious game with both exclusively normal and partially fraudulent business operation. In Table 2 we report some financial characteristics of the simulated company over the conducted runs, with each run lasting one fiscal year. When comparing purchasing costs and turnover costs, we observe that all companies were capable of achieving a considerable added value through the procurement, production, and sales strategies employed by the **data** generation participants. Our first participant group was capable of achieving higher added values within their runs normal 1 and fraud 1, which can be attributed to a largely differing business strategy compared to our second group. While our second group specifically targeted large resellers in their runs (normal 2, fraud 2, fraud 3) through producing exclusively large product sizes and was capable of serving the market of the 71 large resellers within ERPsim, our first group produces additional small product sizes that are sold also to smaller retails which left them with a higher number of customers. This also explains the high turnover volume in comparison to the purchasing volume of run normal 1, as turnover volume here also included smaller packaging. Overall, we find that the different participant groups indeed generated **data** with varying characteristics through the choice of different business strategies."
5803875,30/49,1.0,0.612,"There is an increasing need, fueled by new national regulations in Europe and Australia, for ISPs to ensure that personal information belonging to their users does not leave the country. It is unclear whether such regulations cover **data** in transit as well as storage, but **data** can certainly be sniffed while in transit, violating the original intent. Such regulations may place a substantial burden on ISPs to prove that such **data** remains within a country for its entire lifetime, even when it moves. It is still far from clear what the implications are on ISP operations. Currently we do not have the tools to monitor **data** in transit and state with confidence that **data** has not left a country, even briefly."
240460078,37/40,1.0,0.925,"Direct transfer 
of **data** to 
programme 
convenor/tutor "
248392338,1/27,1.0,0.037,"The digitization of our daily lives has ushered opportunities for the collection of personal **data** on those activities, which up to recently, were private. Moreover, automated **data** collection has become almost impossible to escape (Auxier et al., 2019). This **data** is used in ways that can impact our reality (Slavkovik et al., 2021). Regulations are increasingly put in place to protect our interests. Examples include the European Union's General Data Protection Regulation (GDPR) (Parlament and Council, 2016) and the California Consumer Privacy Act (CCPA) (Infromation, 2018). One of the goals of these regulations is to enforce the practice to inform and obtain consent from users about the use of **data** processing and **data** trackers . In Europe, the most tangible effect of these regulations has been the appearance, and ubiquity, of consent banners on webpages. Cookie banners appear because, according to the GDPR and the ePrivacy Directive (ePD) (the Council of the European Union, 2009), websites, regardless of where they are based, must inform users located in the EU about personal **data** collection and obtain their consent for certain purposes 1 ."
119247546,1/46,1.0,0.022,"One of the main advantages of the use of conformal geodesics in the construction of gauge (and coordinate) systems in a vacuum spacetime is that they provide an a priori conformal factor which can be read off directly from the **data** one has specified to generate the congruence of conformal geodesics. Hence, one has a canonical procedure to generate a conformal extension of the spacetime in question. In addition, gauge systems based on conformal geodesics give rise to a fairly straightforward hyperbolic reduction of the conformal Einstein field equations in which most of the evolution equations are, in fact, transport equations -see e.g. [12,14]."
246165803,26/45,3.0,0.578,"During the **data** acquisition process, the vehicle did not experience unevenness with great height differences, nor did it pass through tunnels, bridges, traffic lights, or other typical situations for a city road. Thus, this limited its ability to differentiate common cases of healthy streets and anomalies such as bumps, potholes, or any other type. Therefore, it is necessary to include all kinds of daily situations that do not represent a problem for the road in the training."
236196766,13/47,13.0,0.277,"Mordred orchestrates all the process, according to the information in its configuration files, deciding which repositories to retrieve, how enriched indexes are produced, when **data** should be updated, etc."
252484412,4/5,2.0,0.8,"As I have argued previously ( §3), the very idea of being in good health, i.e., one of Nussbaum's ten fundamental capabilities, has been transformed by big **data** and the AIpowered techniques used to analyze such data. With more information, faster ways to process it, and more efficient methods for finding significant patterns and trends, the standards for being in good health have significantly shifted. However, consider the case of someone belonging to an ethnic minority who is recommended by their AI-informed doctor to follow a therapy that was proven very effective according to the statistics calculated by the machine. Having the possibility to access the demographic information contained in the database the machine used to issue its recommendation, as well as to gain some general knowledge of algorithmic bias and its risks, seems in this case necessary in order for the good health capability to be granted to that patient. Indeed, the AI-transformed capability for good health requires that a patient is put in a position to either choose to trust and follow the machine's recommendations or refrain from consulting the machine altogether. As for the bike case, these two alternative options are granted only if the patient is put in a position to gain practical and intellectual access to the machine and its processes. The possibility to gain knowledge (both theoretical and practical) must be there regardless, to guarantee that the patient makes an informed, free, and autonomous decision even when opting out."
17966235,21/35,1.0,0.6,"Efficient and intelligent network control are based on accurate and comprehensive network state information obtained by efficient measurement mechanisms. There already exist some work on the measurement of network state information. Ning et al. [130] considered the process of neighbor discovery in 60 GHz indoor wireless networks, and examine direct discovery and gossip-based discovery, from which the up-todate network topology or node location information can be obtained. Kim et al. [131] analyzed the directional neighbor discovery process based on the IEEE 802.15.3c standard. Park et al. [132] proposed a multi-band directional neighbor discovery scheme, where management procedures are carried out in the 2.4 GHz band with the omni-directional antennas while **data** transmissions are performed in the 60 GHz band with directional antennas, to reduce the neighbor discovery time and energy consumption. Chen et al. [   Reflection or NLOS transmission [80], [81], [82], [83], [84] PHY/MAC Relaying [34], [85], [86], [87], [89] MAC Multi-AP diversity [88] MAC multipath routing [90] Routing Fig. 8. Heterogeneous networks consisting of macrocells, microcells, WLANs, and picocells in the 60 GHz band forming training results among clients that can be established at the AP."
239039030,8/23,2.0,0.348,"The size of the uplink and downlink frames depends on the size of the input image and the number of detected objects in the image, respectively. Based on our preliminary experiments, we found that the size of the downlink frame is relatively small (i.e., M UL i M DL i ) than that of the uplink frame, indicating that the last term in (3) is negligible. In addition, d q,i can be treated as a constant based on the assumption that the object detection workloads are static and the edge server always operates at maximum performance. Therefore, the offloading delay D OFF i at the ith mobile edge device depends on the uplink **data** rates r U L i and the queueing delay d q,i incurred at the remote edge server. The queueing delay d q,i in (3) is obtained by the number of offloading requests stored in the queue of the edge server and the remaining time for the ongoing offloading service, which are unknown in advance. It implies that the queueing delay can be treated as a random variable with bounded support, that is, 0 ≤ d q,i ≤ (N OFF − 1)d OFF p , in which N OFF is the number of mobile edge devices offloading object detection workloads."
236196766,15/47,2.0,0.319,"In addition to some of the visualization panels provided by Sigils, Cauldron offers also more than 50 different Kibana visualizations, and a summary of more than 40 metrics as charts produced with JavaScript, using **data** provided by a Django API that queries directly the Elasticsearch enriched indexes produced by GrimoireLab. The main view for a project in Cauldron (see Fig. 21) includes four of these visualizations, showing the extensibility of GrimoireLab, in this case to interface to external visualization services."
245105154,7/25,8.0,0.28,"The last two algorithms considered in this paper are presented by Cuomo et al. [7]. In their quest to find a way to improve the ADR, Cuomo et al. [7] exposed that in some cases, forcing an end device to use a lower **data** rate can reduce collisions in a LoRa net-work. Accordingly, they proposed two implementations of the ADR. The simpler of the two, EXPLoRa-SF, was built to reduce network collisions by segregating end devices into channels based on their distance from the gateway. The second approach, EXPLoRa-AT, was built on the functionalities of EXPLoRa-SF and included an intelligence mechanism to equalize airtimes for all traffic in different transmission channels and to enforce channel usage fairness. Both algorithms were implemented and tested using LoRaSim and compared against the native ADR algorithm in terms of throughput and **data** extraction rate. The simulation environment was a network operating in the European ISM band consisting of 500 to 2000 end devices each transmitting a 160-byte packet every 5 to 3600 s. The overall results showed superior performances of both algorithms over the native ADR."
3640435,13/47,1.0,0.277,"A common criticism of neural networks is that they are hard to engineer, hence this section attempts to provide insights on how good MLP architectures may be designed for our problem, as well as intuition regarding the amount of training **data** necessary to achieve good performance. We used matrix multiplication for our analysis, but the same qualitative behavior was observed in convolutions. Table 2 shows the cross-validation MSE of several MLP architectures, as measured on a fixed set of 10, 000 data-points separate from the 200, 000 samples used for training. Unsurprisingly, deeper networks seem to perform much better than shallower one (given a fixed amount of parameters). The accuracy of the network can be adjusted by adding (moderately wider) layers, at the cost of longer training and higher runtime latency. We emphasize the importance of the logarithmic feature transformation exposed in the previous subsection, without which our system would converge to much worse solutions -if at all.  Figure 5 shows the evolution of our most accurate MLP's accuracy as the amount of training **data** available grows. As expected, collecting more **data** does not seem to provide much benefits beyond a certain point (150,000 samples for GEMM, or ∼ 6 hours of **data** collection).  "
249258070,61/119,1.0,0.513,"The current inquiry adds to the body of knowledge in this area by exploring potential changes to both reactive and proactive officer activities brought on by the pandemic using CFS **data** from Houston, Texas collected from January 1, 2018 through December 31, 2020. This study is informed by routine activity theory and perspectives on proactive policing. Trends are examined for seven different call types: violent crime, property offenses, disorder incidents, suspicious incidents, traffic-related activities, service-related activities, and non-crime events. In doing so, observed trends can be compared to the other large jurisdictions to further our understanding of how the pandemic has impacted demands for police services (e.g., Ashby, 2020). We also examine trends in officer proactivity through officer-initiated activities identified in the CFS **data** performed by three units: patrol, specialized crime investigation units, and the department's specialized response unit. This provides a unique look into how COVID-19 may have influenced officer-initiated activities."
247084475,2/17,1.0,0.118,"To overcome the Mean Teacher based CRNN model limitations, we propose the Couple Learning method to provide more useful information during model training. Specifically, the commonly used PLG model extracts information from raw **data** by generating pseudo-labels, but it introduces noise that negatively impacts the training process. Moreover, the Mean Teacher method involves only the noise suppression mechanism. However, a consistency cost can reduce the noise impact in the pseudo-labels due to detection errors by maintaining an exponential moving average of the label predictions on each training example and penalizing predictions inconsistent with this target. Therefore, the contribution of the proposed Couple Learning method is utilizing the information in the compound **data** more effectively. From this perspective, we couple the Mean Teacher method and the PLG model."
233705419,7/53,1.0,0.132,"Frequently, **data** that can be measured in principle cannot be captured for design reasons. In a thermo-chemical process, it is often not possible to directly measure and record all of the parameters relevant for control and monitoring. These parameters include local high temperatures and pressures, or concentrations of unstable intermediate products."
236196766,13/47,14.0,0.277,"In all the cases when Kibana is used for interactively visualizing **data** (see Fig. 15), Sigils provides a set of ready-to-use visualizations and dashboards. See examples of a summary dashboard provided by Sigils in Figs. 18 and 19. The use of Arthur is optional: users can write their own schedulers, if they prefer."
52141668,5/16,1.0,0.312,"As the attempt of automatically detecting deception in people, we try to explore deception cues within the choices of words when lying to others. In this experiment, we use Linguistic Inquiry and Word Count (LIWC) (Pennebaker et al., 2007) and Whissell's Dictionary of Affect in Language (DAL) (Whissell, 2009) in order to determine the psychological scores for each sentence. Using LIWC, we extract 72 features which comprise of word class scores and also scores for non-word elements of the sentence such as punctuations and parenthesis. From IDC, we use 9:1 of all **data** as learning **data** and the rest of them as testing data. For the learning experiment, we use 8:1 of all learning **data** as training **data** and developing **data** as can be seen in Figure 1. We use three classifiers, Random Forest, linear Support Vector Machine (SVM), and Neural Networks."
134689280,14/20,1.0,0.7,"The inhabitant's perspective stands in contrast to the 'god's view' (Morton et al. 2014) or the god trick (Aitken and Craine 2006;Wood 1992;Monmonier 1996) of mapping from an impossibly high or distanced viewpoint and visualising and analysing **data** from a totalising perspective. Maps excel at giving **data** overviews and I do not argue against this. What I propose is that we should 'people the past' (or any material evidence) using a variety of dynamic spatial methods (see Morton et al. 2014) and create static **data** renderings which allow us ways towards understanding spatial situations from an inhabitant's perspective. It is not an argument for exact replication of experience, as indeed, in contemporary lives, we can never attain a complete replication of even our direct neighbour's perspective. Understanding the other and their time-space specific and social position and situation is inevitably always based on part projected fabrication; such is the artificiality of analysis."
236196766,7/47,2.0,0.149,"Manuscripts is a tool that queries enriched indexes, providing analytics results such as summary tables, built from templates. Tables are produced in CSV format, thus they can be imported into spreadsheets or other programs. It can also produce reports as PDF documents, including a part of the information in those tables, with some textual explanations. Manuscripts therefore produces a certain kind of report for a set of repositories, but can also be used as a template to produce customized reports. For assisting in the creation and presentation of interactive visualizations, GrimoireLab provides three components: Sigils, a set of predefined widgets (visualizations and charts); Kidash, which loads Sigils widgets to Kibiter, and Kibiter, a soft-fork of Kibana 4 ) which provides web-based actionable dashboards (users can interact with the **data** shown, by filtering, bucketing, drilling down, etc.)."
245986448,22/45,1.0,0.489,"We have demonstrated the development of a method to obtain quantitative density **data** from pre-existing Schlieren images through the use of Gaussian processes. The central novelty with this method lies in the fact that it does not require any pre-calibration or special set-up as required by existing methods discussed in Section I B, and is widely applicable-even if only one knife-edge orientation is available. Our workflow is not intended to upend or subvert the modern practicalities of BOS, but rather complement it, by enabling scientists to be able to retrospectively reconstruct density fields from the plethora of schlieren images that exist in literature."
246165803,25/45,3.0,0.556,"Geospatial visualization was carried out to compare and choose a better model for classifying anomalies on the city's streets. The main reason why KNN was a better fit was that it did not require **data** scaling for its inputs. Thus, the KNN accurately handled a street with deep potholes, speed bumps without any paint or signaling, and a generally more chaotic avenue that generated bigger sensor signals."
249258070,8/119,1.0,0.067,"Despite the mounting research related to COVID-19 and police activities, there remain several gaps in the current body of literature. First, there is a lack of focus on proactivity and self-initiated activities-a salient aspect of policing. Second, several studies on CFS changes were published shortly after the emergence of COVID-19 and were unable to account for long-term trends and potential impacts outside of a few weeks or months. Lastly, results across studies suggest substantial variation in the effect of COVID-19 on police activities. Studies have noted differences in either perceived changes across departments (Maskály et al., 2021) or CFS trends across various cities and/or call types (Ashby, 2020;Dai et al., 2021;Mohler et al., 2020;. In reflecting on his own research findings, Ashby (2020) noted, ""[o]ne important finding from this study is that there is unlikely to be a single universal experience of coronavirus among police departments: different agencies may experience different changes. This means that the availability of **data** from multiple agencies will be crucial in developing our understanding of reactive patrol policing during a major public health emergency"" (p. 1070). Overall, there remains a need for additional research to better understand the impact of COVID-19 on police activities (see also Lum, Maupin, & Stoltz, 2020a)."
52064012,15/16,2.0,0.938,"At the project level, an initiative seeking to better integrate these different designations and provide essential new knowledge of North Atlantic ecosystems through **data** gathering and synthesis is the EU ATLAS Horizon 2020 project (www.eu-atlas.org). The project aims to propose a marine spatial planning framework for sustainable blue growth and conservation in the deep North Atlantic, scenario testing, using 12 trans-Atlantic case studies, five of which are in ABNJ. It will provide 'scaled-up' information including basin-scale oceanography (flux, trajectories and thresholds); models predicting changes to ecosystem functioning; biodiversity hotspots and marine genetics. Case studies will then 'scale down' this information for regional management. The intention is to integrate EBSAs, MPAs and VMEs. If appropriate, proposals for APEIs and PSSAs will be included."
210839501,1/2,1.0,0.5,"Muhamed Amin* [a, b, c] and Jochen Küpper* [a, d, e] Using a new semi-empirical method for calculating molecular polarizabilities and the ClausiusÀ Mossotti relation, we calculated the static dielectric constants of dry proteins for all structures in the protein **data** bank (PDB). The mean dielectric constant of more than 150,000 proteins is e r ¼ 3:23 with a standard deviation of 0.04, which agrees well with previous measurement for dry proteins. The small standard deviation results from the strong correlation between the molecular polarizability and the volume of the proteins. We note that nonamino acid cofactors such as Chlorophyll may alter the dielectric environment significantly. Furthermore, our model shows anisotropies of the dielectric constant within the same molecule according to the constituents amino acids and cofactors. Finally, by changing the amino acid protonation states, we show that a change of pH does not have a significant effect on the dielectric constants of proteins."
22512771,8/24,2.0,0.333,"F. 2. Motion trajectory for patient 3, based on the center of volume of individual GTVs. Figure 3 presents the dependencies on precalculated **data** in the steps of the dose reconstruction algorithm. The activity diagram in the online dose reconstruction loop box shows how dose is accumulated during delivery. The dashed arrows relate the precomputed **data** to the online step. For each received MLC aperture, (1) its dose contribution has to be computed by converting the aperture to beamlet weights and subsequently multiplying with the dose-influence **data** for the respective beam and phase. (2) The energy from the dose contribution is then computed using the precomputed high-resolution DVFs and the electron density of the respective phase. (3) The energy then needs to be divided by the deformed mass of the respective phase. (4) Finally, the dose can be accumulated to the previously delivered dose."
17966235,12/35,2.0,0.343,"Ghosh et al. [101] made a case for using mmWave bands, in particular the 28, 38, 71-76 and 81-86 GHz bands for the 5G enhanced local area (eLA) access. With huge bandwidth, the eLA system is able to achieve peak **data** rates in excess of 10 Gbps and edge **data** rates of more than 100 Mbps. Singh et al. [104] presented an mmWave system for supporting uncompressed high-definition (HD) video up to 3 Gb/s. Wu et al. [105] defined and evaluated important metrics to characterize multimedia QoS, and designed a QoSaware multimedia scheduling scheme to achieve the trade-off between performance and complexity."
16180771,5/6,5.0,0.833,"User-system interaction **data** analysis consists in analysis of **data** from the interaction between the fully implemented system and real users, either in controlled experiments with selected users and scenarios which they have to perform, or in field studies where the SLDS or component is being exposed to uncontrolled user interaction. User-system interaction **data** is useful or even necessary in many cases, i.e. when too little is known in advance about the phenomena that will be present in the deployed application. This data, if comprehensive, has high reliability because of deriving from a test corpus of sufficient size and realism wrt. task and user behaviour. Unfortunately, the **data** cannot be obtained until late in the development of the system. Usersystem interaction **data** analysis, if performed extensively rather than cursorily, is costly. This kind of analysis can be partly replaced by Wizard of Oz **data** analysis which is costly as well but which happens early enough in the life-cycle to enable prevention of gross errors. Since there is significant cost in both cases, cost which is only offset by corresponding risks, this is where (early) design support tools are most desirable."
3640435,2/47,1.0,0.043,"This paper aims at offering a new perspective on automatic performance tuning. We present a system, ISAAC, which does not produce a fixed set of tuning parameters per se, but rather a function that maps input characteristics to such parameters. We show that this function can be automatically learned from empirical benchmarking **data** using standard machine learning techniques (i.e., multi-layer perceptron), and propose a simple statistical method to speed-up the synthesis of a proper training dataset. An important addition of our framework is the use of a relatively low-level intermediate language (i.e., NVIDIA PTX), as opposed to higher-level alternatives typically used in similar systems (i.e., C, CUDA or OpenCL). While this is not strictly necessary and restricts our numerical experiments to NVIDIA GPUs only, this strategic choice leads to (1) better code generation, (2) faster compilation, and (3) more accurate performance models (due to simpler instruction selection heuristics)."
22512771,8/24,1.0,0.333,"DynaTrack was extended to compute the respiratory phase of each acquired target position in real-time. The phasebinning algorithm is based on previous work by Lu et al. 29 but was modified to allow for online binning. Bins are defined relative to the automatically detected extremal respiratory positions (""peaks"" and ""valleys"") in each respiratory cycle. During real-time motion acquisition and binning, future **data** points are not available after acquiring the current **data** point making it impossible to use the current respiratory branch for binning. Instead the **data** point is phase shifted by one respiratory cycle, and binned relative to the last fully acquired exhalation or inhalation branch. The respiratory period is calculated from the last 20 s worth of motion **data** using Fourier analysis."
134689280,18/20,1.0,0.9,"It is only following this elaborate philosophical and theoretical preamble that we can confidently turn to GIS as a toolkit in aid of social interpretations of spatial **data** (here: built environments). Verhagen (2018, this volume) glances over 30 years of GIS applications in archaeology and emphasises the apprehension with which the more theoretically and interpretively inclined archaeologists have received it. The lack of direct theoretical engagement with GIS is still lamented during many CAA conferences (Computer Applications and Quantitative Methods in Archaeology). The outlook of this chapter is not for the archaeological 'spatial turn' to generate theory, but to generate theory for the 'spatial turn'. Though archaeological evidence is necessarily spatial, we should not allow spatial empiricism to become the driver of social insights. In this light it might be a fallacy to desire the integration of native GIS concepts in archaeological theory and interpretation. Yes, GIS could (and probably should) be part of a mixed multimethod approach, but when we dedicate ourselves to direct theoretical engagement with the spatial **data** GIS relies on, it becomes apparent we have to reconceptualise our **data** in GIS. Since we now have a concept of interpretive data, we should devise ways to appropriate GIS formats to become commensurable with the understanding packed into these data. This strategy towards GIS is not an instant proponent of an eclectic use of spatial analytical tools (Hacιgüzeller 2012;Hacιgüzeller and Thaler 2014; but also in qualitative GIS: Cope and Elwood 2009). Constructive and defensible eclecticism requires a solid, that is, coherent and consistent, fundamental framework of the research process and knowledge production in which it is placed. How else can we evaluate the contribution and validity of its results? However, as material boundaries are but one aspect or operation in the constitution of built environments and used here to contribute to just one mode of understanding, this strategy does support pluralism in perspectives. What this strategy requires first, before even considering mixing and matching methods and ideas, is to work through the consequences of reconciling GIS as a toolkit with interpreting archaeological evidence. That is because the implications of following a fundamental theoretical route into GIS [as propagated by Wheatley and Gillings (2000), Gillings (2012), Hacιgüzeller (2012), McEwan and Millican (2012), Kosiba and Bauer (2013), Wheatley (2014); and following the lead of critique developed in Geographical Information Science by Schwanen (2009), Leszczynski (2009)] are much more profound."
12790199,9/21,4.0,0.429,"Translation processes convert interaction history **data** to another form, such as a conversion from visual 2-D **data** to 3-D coordinates for the arm to target, or from continuous color information to a discrete color category."
16180771,5/6,3.0,0.833,"A glassbox test is a test in which the internal system representation can be inspected. The evaluator should ensure that reasonable test suites, i.e. **data** sets, can be constructed that will activate all loops and conditions of the program being tested."
57697459,3/29,1.0,0.103,"Congestion control. The TCP has a certain capacity called transfer window. If we want to send **data** from Point A to Point B we load **data** into the transfer window and wait for an acknowledgement. Point B will send an acknowledge signal telling Point A that all those packets have been received. If we're successful, then the TCP becomes optimistic in the sense that it widens the transfer window so that it can send more **data** at the same time. If the transfer failed for whatever reason, then the transfer window shortens. This produces a slower traffic. TCP makes use of sequence numbering, congestion window and retransmission timer mechanisms to achieve less congestion and reliable service. TCP sender assigns sequence number for every packet sent and expects an acknowledgement before proceeding with further **data** transfer. Congestion window is used to perform congestion control, which keeps track of the number of packets that can be sent by the sender without being acknowledged by the receiving side. Basically, congestion control window decides whether TCP sender is allowed to send packets at any particular instance. TCP accomplishes reliable **data** delivery by deploying retransmission timer mechanism which detects packet loss and retransmits them. If an acknowledgement is not received before the expiry of the retransmission timer, TCP retransmits the packet and triggers congestion control."
249258070,21/119,1.0,0.176,"The current inquiry adds to the body of knowledge in this area by exploring potential changes to both reactive and proactive officer activities brought on by the pandemic using CFS **data** from Houston, Texas collected from January 1, 2018 through December 31, 2020. This study is informed by routine activity theory and perspectives on proactive policing. Trends are examined for seven different call types: violent crime, property offenses, disorder incidents, suspicious incidents, traffic-related activities, service-related activities, and non-crime events. In doing so, observed trends can be compared to the other large jurisdictions to further our understanding of how the pandemic has impacted demands for police services (e.g., Ashby, 2020). We also examine trends in officer proactivity through officer-initiated activities identified in the CFS **data** performed by three units: patrol, specialized crime investigation units, and the department's specialized response unit. This provides a unique look into how COVID-19 may have influenced officer-initiated activities."
236196766,2/47,2.0,0.043,"**data** source: any system providing retrieval mechanisms (usually, an API) to access **data** related to software development: source code management, issue tracking, code review, synchronous or asynchronous communication, testing, collaborative documentation writing, Q/A forums, etc. Examples of a **data** source are a Git server, a Bugzilla instance, a Mailman archive, or some Slack instance. kind of **data** source: all **data** sources with the same retrieval API. Examples of kinds of **data** sources are ""Git"", ""Bugzilla"", ""Mailman"", or ""Slack"". repository: a part of a **data** source, usually corresponding to the **data** managed for a certain project. Examples of repositories are a Git repository, a Bugzilla issue tracker, a mailing list archive in a Mailman instance, or a Slack channel. index: all **data** corresponding to a certain kind of **data** source, as it is stored in the GrimoireLab database. Indexes may be raw, with **data** as similar as possible to the one provided by the **data** sources, or enriched, which are tailored to easy visualization and reporting."
154663855,19/21,1.0,0.905,"MNEs also need to make Miller's fifth strategy (i.e., ""flexibility"") a strategic priority. What this means will vary from industry to industry. For global manufacturers it may involve diversification of suppliers, inventory management, and contingency transportation planning (Sheffi, 2005). For hotel chains like Marriott, flexibility involves attention to business continuity planning (BCP), namely, devising specific guidelines for managing a crisis. BCP may involve everything from mirroring **data** to maximizing guest comfort and convenience and pursuing profits. Nevertheless, as Gunaratna points out, unless there is a ""paradigm shift"" in the way hotels around the world conceive of and manage this new and rapidly evolving threat, the lives of their guests and employees, their reputations, and indeed their long-term economic viability will be at risk."
15294885,2/25,3.0,0.08,"The results in [8], [10], [11], however, have considered only the real passband or, equivalently, the complex baseband transmission of a proper-complex **data** sequence. Hence, these results are not directly applicable to, e.g., the real passband transmission of a BPSK **data** sequence, which is an impropercomplex **data** sequence in complex baseband. Recall that complex-valued random variables, vectors, and processes are called proper if their complementary covariance, complementary covariance matrix, and complementary auto-covariance function (a.k.a. pseudo-covariance, pseudo-covariance matrix, and pseudocovariance function) vanish, respectively [12]. Otherwise, they are called improper [13]. Although the complex envelopes of the majority of digitally modulated signals are proper, there still remain other digitally modulated signals whose complex envelopes have non-vanishing complementary auto-covariance functions [13]. For example, the complex envelopes of PAM, vestigial sideband PAM, unbalanced QAM, offset quaternary phase-shift keying (OQPSK), and Gaussian minimum shift keying are improper."
59514737,5/8,1.0,0.625,"When tracking targets and multiple interfering targets enter site of the detector at the same time, even if the 2.1 decision condition is used, a large number of candidate trajectories remain, which requires the real-time infrared image processing system to provide large memory and computational overhead. This method relies too much on current **data** and ignores the use of other image sequence information. At the same time, in the process of track association, there may be several situations such as trajectory bifurcation and trajectory crossing. When multiple measuring points fall into the **data** association area of a certain trajectory, the trajectory bifurcation occurs; When a measured **data** falls within a **data** association region of multiple trajectories, the trajectory crossing will occur. When a single independent **data** point appears, a new track may occur. This process is shown in Figure 2. "
245105154,7/25,2.0,0.28,The proposed algorithm used the gradient projection method to determine distribution ratios that minimize contention in each **data** rate and maximizes network throughput.
238719786,13/14,1.0,0.929,"
SIE block plays a vital role in transmitting as well as receiving the **data** with USB interface. SIE block acts as an intermediate between the central processing unit of a computer and the universal transceiver macro cell interface (UTMI). InAlgorithm 
{ 
Input: 
Binary signal 
Output: 
Transmission signal (Code word) 
Intermediate Results: 
Transmitter polynomial 
01: 
The message signal in binary form need to be 
converted into polynomial form F(x) 
02: 
Multiply F(x) with M(x) 
// B(x)= F(x) * M(x) 
03: 
B(x) which is in polynomial form need to be 
converted into binary form 
// i.e. B[0111010110110110] 
} 
Fig. 1. Algorithm for BCH encoder "
57697459,12/29,3.0,0.414,"The first idea that comes to mind when implementing this is to create separate service for each type of multimedia unit. But we can abstract this and transform it into a single service with generic **data** types. The ISendService<T> interface, where T is a service type, from Figure 7 shows us how the abstraction was realized. The generic parameter T represents the Service type. The Service Type is nothing more than then service contracts exposed by the web-services that the peer hosts. The T parameter is used by the implementation of the ISendService<T> to establish the type cast of the ChannelFactory and when the Initialize method is called, the peer endpoint is known and a channel can be open between the two peers so that the streaming can begin."
12790199,3/21,1.0,0.143,"The system is capable of responding rapidly to certain sensory triggers, by moving away from sensed collisions and also using knowledge of collisions to adjust grasping targets. The object schemas serve to coordinate visual, touch, and motor-related **data** in such cases."
233705419,14/53,1.0,0.264,"In this step, the defined test design has to be filled with **data** to train the hybrid model. These **data** can be collected either from a database or from new experiments."
22512771,1/24,2.0,0.042,"Moreover, this method is based on 3D image data, although 4D image **data** are usually available. Glitzner et al. 21 have proposed a 4D dose reconstruction pipeline for kidney based on online MR imaging and generation of a pseudo 4DCT. They use deformable vector fields (DVFs) to map dose from each phase to a reference phase. Their dose calculation algorithm takes 15 s/MLC aperture and hence cannot be utilized in an online dose reconstruction scenario."
27068907,14/25,1.0,0.56,"Appropriate test environment should be chosen to ensure the accuracy of the results. Normally, the test is carried out in an open space outdoors. The tester should select a certain number of nodes, which have the same straight-line distance from the terminal, and carries out the test at the straight-line distance of 20m, 40m, 60m, 80m, 100m, 120m, 150m, and 200m. The nodes at each distance should be set into a group. Each group of nodes should be tested continuously for 3h and measured three times. The measured results should be averaged and the loss of **data** packets should be summed up. Table 4 displays the final results. "
5803875,29/49,1.0,0.592,"We make the geolocation and detours detection **data** available to the community via a public RESTful API interface. The motivation to do so is as follows. 1) Network operators can easily query our database and check if their prefix suffered a detour. 2) Internet measurement researchers can use this information to study various BGP anomalies such as route leaks, detecting malicious ASes, etc. Our results on AS and prefix geolocation are available at http://geoinfo.bgpmon.io and detours results can be accessed at http://detours. bgpmon.io."
15294885,19/25,1.0,0.76,"A
Tx and an Rx operate over a real passband to transmit a **data** sequence {b[l]} l∈Z . Fig. 1 shows the system block diagram in complex baseband. The **data** sequence {b[l]} l∈Z is assumed well modeled by a zero-mean improper-complex SOS random process with auto-covariance and complementary autocovariance functions given, respectively, by m[k] E{b[k + l]b[l] * } andm[k] E{b[k + l]b[l]}, where the superscript * denotes complex conjugation. By applying the discrete-time Fourier transform (DTFT) operations to m[k] andm[k], the PSD M(f ) and the complementary PSDM(f ) of the **data** sequence {b[l]} l∈Z are derived, respectively, as M"
236196766,6/47,2.0,0.128,"In the usual pipeline, GrimoireELK feeds SortingHat with identities found in raw data, which deals with merging and tagging according to its configuration, and sends them back to be added to the enriched data. For doing its job, SortingHat maintains a relational database with identities and related data, including the origin of each identity, for traceability. SortingHat may also automatically read identities-related **data** in some formats: Gitdm, MailMap, Stackalytics, and the formats used by Eclipse and Mozilla projects. The overall design of SortingHat is summarized in Fig. 10. The conceptual schema of the SortingHat database is shown in Fig. 11. More details are described in (Moreno et al., 2019)."
246337567,50/70,1.0,0.714,"NAISC-L advances the state-of-the-art by presenting an interlinking framework that facilitates the creation of relationship and identity links, and that is accessible via a GUI designed to support IPs. It is envisaged that the NAISC-L framework will have an impact on the adoption of LD in LAMs by facilitating IPs to create LD interlinks with greater ease and efficacy than existing LD tooling allows. NAISC-L is complementary to existing interlinking frameworks as it supports the creation of relationship links through an interlinking process that encourages the application of domain expert knowledge. Facilitating the application of domain expertise allows IPs to use their specialist knowledge of particular subject areas, as well as their tacit knowledge of the needs and interests of LAM users, for the creation of useful, interesting and creative interlinks. Additionally, the provision of provenance data, detailing IPs as the creators and curators of these interlinks, increases user trustworthiness. In sum, LAM metadata that has been enriched with authoritative interlinks, created by IPs, would improve **data** discovery and promote increased use of LAM resources by allowing users to navigate seamlessly between related entities held in internal and external datasets."
24456035,3/42,2.0,0.071,"Regression methods fit a model to the historical **data** which is used to predict the baseline [13] [14]. They can potentially overcome biases incurred by averaging methods [12]. They often require considerable historical **data** for acceptable accuracy, and the models may be too simple to capture the complex behavior of individual agents."
251040404,1/15,2.0,0.067,"In this letter, we aim to integrate PAS with HARQ. When applying IR-HARQ, simply performing the sequential puncturing may cause potential distribution distortion in retransmissions. As such, we propose a symbol-wise puncturing scheme to preserve the shaping distribution and realize the promised gain of PAS. First, we consider the standard PAS structure [7] and adopt the constant composition distribution matcher (CCDM) proposed in [17] as a DM to transform the input bits into amplitude symbols. Then, they are represented by their binary labels with a desired probability distribution, while the binary labels are termed as amplitude bits. After FEC encoding, the information bits excluding the amplitude bits and all the parity bits are called sign bits. We apply IR-HARQ in our work, i.e., transmitting **data** packet that is self-decodable for the first transmission and the redundant information for retransmissions. In this case, the traditional sequential puncturing will cause retransmissions with only the sign bits, which brings severe distribution distortion. To address this issue, we pair the amplitude bits and sign bits into a label sequence of shaped modulation symbols. Then, we perform symbol-wise puncturing on the label sequence. In our scheme, a certain proportion of the amplitude bits and sign bits are sent in each transmission to ensure the probability distribution. At the receiver, the a-priori information of the amplitude bits that have not be transmitted is calculated to enhance FEC decoding. Our simulation results indicate that our proposed symbol-wise puncturing can obtain stable shaping gain across the signal-to-noise ratio (SNR) on the throughput over both AWGN and multiple-input multiple-output (MIMO) Rayleigh fading channels and realize the desired probability distribution with only little distortion in each transmission, while the gain of the sequential puncturing drops rapidly with the increase of retransmission times and the distribution of the sequential puncturing in retransmissions tends to be uniform. Note that for type-I and type-III HARQ, since the **data** packets in each transmission are self-decodable, there are enough amplitude bits to preserve the probability distribution. In other words, the conventional PAS would still work when it is integrated with these two types of HARQ. Therefore, we only consider IR-HARQ in our work."
57697459,10/29,2.0,0.345,"Thus we can observe an abstraction layer can be created that ensures extensibility and maintainability, but we will talk about this subject in more depth when we'll present the architecture of the SDK. A proxy server is created for each existing web service. The proxy servers act as senders. They have the responsibility of sending whatever **data** they receive, and nothing more. As we'd expect, all the proxy servers need to run in the same time, in parallel to offer high transmission throughput."
236196766,24/47,1.0,0.511,"Several Docker container images are also provided to run pre-configured versions of GrimoireLab, with all services already pre-installed. They can produce complete dashboards, with raw and enriched **data** for all repositories, just by running the container with the appropriate configuration data. They can also be used with official container images for services, via docker-compose (see the companion dataset, described in Section ""A companion package and other information"", for an example of running the toolset this way, including configuration files). Docker images for GrimoireLab are stored in DockerHub, so that they can be recovered later (for any GrimoireLab release). They are also produced from Dockerfile configuration files, publicly available from GrimoireLab repositories."
236522469,5/33,2.0,0.152,"The neural network learns the patterns from the input **data** by reading the input **data** set and applying different computations to it. However, the neural network does not just do this once; it learns repeatedly using the input **data** set and also the results of previous tests. Each step in learning from the input **data** set is called an epoch. That is, an epoch refers to one cycle in the entire training **data** set [48,49]. Initially, CNN were trained with a large number of epochs or steps (iterations) to ensure that the smallest loss would be within that step range. After the first training, we determined an ideal number of steps to obtain the least loss to optimize the analyses and repetitions that would be performed; this test served fundamentally to know how many epochs would be necessary for the final model fit; this step was essential because an excessive number of epochs leads the model to overfitting, i.e., in this case, it will present results with very good statistical metrics, but with erroneous identification of species."
236196766,11/47,1.0,0.234,"GrimoireLab components and procedure: The main component in this scenario is Perceval, which will retrieve **data** from the **data** sources API. If source code metrics are to be obtained, Graal will also be involved. All of them will produce collections of JSON documents that will be stored for further processing. Those JSON documents will be stored and published for reproducibility of the study, and used as the **data** set for the analysis."
17966235,5/35,1.0,0.143,"A. IEEE 802.11ad IEEE 802.11ad specifies the physical layer and MAC layer in 60GHz band to support multi-gigabit wireless applications including instant wireless sync, wireless display of high definition (HD) streams, cordless computing, and internet access [9]. In the physical layer, two operating modes are defined, the orthogonal frequency division multiplexing (OFDM) mode for high performance applications (e.g. high **data** rate), and the single carrier (SC) mode for low power and low complexity implementation."
252484412,3/5,1.0,0.6,"I will use this last capability to say more about how AI is transforming or has already transformed the definition and the conditions of possession and realization of (some) capabilities in ways that are not all positive. I want to draw attention to the fact that AI technology can, in addition to expanding and making capabilities easier to possess and realize, also make them harder to possess and realize, due to the dangers that inevitably accompany a family of technologies that we do not (yet) fully understand or control. As much as AI has re-defined the conditions of possession and realization of at least some central capabilities, it has also re-defined the ways in which those capabilities can be taken away. To give one example, the advent of big **data** analysis has made seeking and obtaining employment a more standardized process (most first-round selections are done by algorithms based on keywords and other information contained in digital resumes). Although this process has the potential to increase objectivity and to pair employers and employees more effectively, it might make it easier to ""get away with"" (voluntary or involuntary) discrimination. Because of how advanced natural language processing is today, algorithms have the power to retrieve information about a potential hire's personal life, race, cultural and religious background, sexual orientation, and more that might be implicitly present in one's application documents."
249538382,11/22,3.0,0.5,"In this fraud, products were ordered regularly, but the delivery address was changed for the PO (3) to a private address. Larceny 6 (O2C) Similar to larceny 5, but in the O2C process. The delivery address in the master **data** of a customer in the order was changed (9), so that the delivery of a corresponding customer order was delivered to the wrong address. The address was changed back afterwards. Corporate Injury 1 (P2P) This fraud represents extensively large purchases by changing the Sales Planning (6), leading to company damages through high spending and potential waste and overstocking of warehouses. Structurally, this fraud results in anomalous extreme values in POs. Corporate Injury 2 (O2C)"
249258070,23/119,1.0,0.193,"Law enforcement executives have noted the impact of the pandemic on police activities. Based on survey **data** collected from 989 US and Canadian executive officers who are members of the IACP, Lum et al. (2020a) noted several reported changes in police operations during the initial months of the pandemic. By March 23, 2020, 43% of responding agencies stopped or significantly changed their responses to CFS, 57% reported a decline in CFS, 61% implemented policies to reduce proactive stops, and 73% limited community policing activities. As of May 10, 2020, a second survey wave indicated that 53% of the responding agencies continued to have policies that limited proactivity, and 64% were still limiting community-oriented policing activities-both slight decreases from wave 1 (Lum, Maupin, & Stoltz, 2020b)."
15704680,1/22,1.0,0.045,"Finally, in order to evaluate the efficiency of our method, we apply it on **data** annotated according to the formalism of the categorial dependency grammar. The **data** consists on a treebank containing both projective and non-projective trees associated with sentences of French."
249258070,37/119,1.0,0.311,"The purpose of the current study was to examine changes in both reactive and proactive police activities since the onset of the COVID-19 pandemic when compared to previous years. Specifically, **data** from Houston, Texas were analyzed across seven reactive categories and selfinitiated activities across three units (patrol, crime investigations, and DRT) from January 1, 2018 to December 31, 2020. The results indicated that COVID-19 had notable impacts on four of the reactive measures and all three self-initiated activities. Three key findings emerged from the observed trends and are highlighted here."
6811986,2/20,1.0,0.1,Related Work. Two different communities have studied the problem of de-termining the information that can be inferred from complete access to **data** in a subset of the relations in a relational schema using constraints that relate the subset to the full vocabulary.
249538382,9/22,1.0,0.409,"As determined through our requirements analysis in Section 2.1, **data** for ERP fraud detection requires a large variety of realistic fraud cases. To create realistic fraud cases that translate well to different companies, we focus on creating frauds within two standardized business processes that are simulated within our **data** generator. First, we select the widely used purchase-to-pay (P2P) process that has been the focus of previous **data** generation approaches [22,4,3]. In the P2P scenario, illustrated in Figure 2, a demand is created by the user's forecast. By performing the Material Requirement Planning (MRP) run, the user creates a purchase requisition (PR) for each demand. A buying agent then converts each PR into a purchase order (PO). As in the real world, saving a PO starts transferring the PO to the given supplier, where it gets converted into a customer order. While these steps are usually implemented via electronic **data** interchange between two ERP systems, in ERPsim the simulation middle-ware receives the PO and virtually ships the ordered goods after a random time within a defined time-frame. After this, the incoming goods need to be received at the production plant with a goods receipt (GR), and paid for by recording and clearing the invoice (INV)."
41857677,2/41,1.0,0.049,Multiple Distributed Internet Gateways (MDIG) is proposed to offload the network from Internet **data** packets and leave the network backbone ideal to trunk different virtual network packets.
249538382,11/22,4.0,0.5,"Here, the employee committing fraud drastically lowered sales prices (7) to damage the company. Selling Kickback 1 (O2C) This fraud case was conducted by manipulating sales conditions (8) for specific customers, which allowed the customers to purchase products with lowered order prices via discounts. Selling Kickback 2 (O2C) Similar to Selling Kickback 1, the order prices are manipulated. In this case, beneficial sales conditions were given to a specific customer in the sales order document itself (9). of committed frauds should be realistic. Schreyer et al. [17] argue that real audit scenarios have highly unbalanced class distribution between very few anomalous and vast amounts of regular entries. Judging the real number of occupational fraud cases that are expected to lie within a company's data, however, is challenging, since the number of employees engaging in fraud is unknown and even in detected frauds the large majority of cases contains active attempts to hide the fraudulent activity [1]. To limit the amount of frauds included within our **data** and obtain a heavily unbalanced class distribution, we therefore limit our fraudster to conducting two fraud cases per simulated month of operation."
55648852,20/40,4.0,0.5,"The **data** extracted from the broadband stations are in MiniSeed format; therefore not further conversion is needed, only into .mat files. In this case we followed the same procedure as for the Cubes, we took the time **data** of each explosion to cut the MiniSeed file 30 s before it and 60 s after it and save it in Matlab files. The only problem we addressed in this step was that the coordinates of the broadband stations were daily calculated and differ from one day to another in some decimals. In order to have a final station coordinates we calculated the mean of all these daily GPS coordinates."
53708053,3/3,2.0,1.0,"Quantitative policy evaluation can benefit from a rich set of econometric methods for analyzing count **data** Keywords: Poisson regression, negative binomial distribution, zero-inflation, hurdle model Pros Count **data** regressions provide an appropriate, rich, and flexible modeling environment for nonnegative integers, 0, 1, 2, etc. Poisson regression is the workhorse model for estimating constant relative policy effects. Hurdle and related models allow distinguishing between extensive margin effects (outcome probability of a zero) and intensive margin effects (probability of one or more counts). With count data, policy evaluations can move beyond the consideration of mean effects and determine the effect on the entire distribution of outcomes instead."
249258070,48/119,1.0,0.403,"Despite the mounting research related to COVID-19 and police activities, there remain several gaps in the current body of literature. First, there is a lack of focus on proactivity and self-initiated activities-a salient aspect of policing. Second, several studies on CFS changes were published shortly after the emergence of COVID-19 and were unable to account for long-term trends and potential impacts outside of a few weeks or months. Lastly, results across studies suggest substantial variation in the effect of COVID-19 on police activities. Studies have noted differences in either perceived changes across departments (Maskály et al., 2021) or CFS trends across various cities and/or call types (Ashby, 2020;Dai et al., 2021;Mohler et al., 2020;. In reflecting on his own research findings, Ashby (2020) noted, ""[o]ne important finding from this study is that there is unlikely to be a single universal experience of coronavirus among police departments: different agencies may experience different changes. This means that the availability of **data** from multiple agencies will be crucial in developing our understanding of reactive patrol policing during a major public health emergency"" (p. 1070). Overall, there remains a need for additional research to better understand the impact of COVID-19 on police activities (see also Lum, Maupin, & Stoltz, 2020a)."
52141668,10/16,1.0,0.625,"In this paper, we have described the explorations on analyzing deception in Indonesian transcribed interviews using the **data** collected from IDC. Seeing that the experiments give promising results, we can use the lexical approach as an initial step for detecting deception in people. Besides, we can also combine the lexical approach with using acoustic/prosodic features. In future works, we plan to combine the lexical features along with other speech related features for identifying deception as it can give broader information about the data. We will also take into consideration the correlation between the previous sentence and also the following sentence that the subjects say.
"
245986448,15/45,1.0,0.333,"One approach to reduce computational cost is through the use sparse GPs that approximate (between the gradient and function sampling), the gradient inputs may be sampled from an image in a grid format, however the addition of the function observations disrupts the required format to take advantage of Kronecker products directly, without any masking of regions. Since this paper is purely focused on the methodology of obtaining quantitative **data** from schlieren images, only some of these approaches have been considered to make the method tractable."
236196766,6/47,1.0,0.128,"Modules in the Identities Management area manage **data** about personal identities. This allows analysis in which contributor identities and related information (tags), such as team/organization affiliations, are needed. SortingHat and HatStall are the components in this area. The first one deals with identities management itself, receiving new identities found, grouping them in unique (merged) identities, etc. HatStall provides a web-based interface so that users can manually mage identities when needed, thus complementing the algorithmic procedures that SortingHat follows. HatStall does no management on its own: for any operation on identities, it uses SortingHat services. For understanding why identities management is convenient in GrimoireLab, it is important to notice how personal identities are found in **data** sources. Depending on the **data** source, identities come in different formats: commit signatures (e.g., full names and email addresses) in Git repositories, email addresses, GitHub or Slack usernames, etc. Any person may use several identities even in the same repository, and certainly in different **data** sources. In some cases, an identity can be shared by several contributors (e.g., support email addresses in forums). Finally, identities may need to be linked to other information, in a process we call ""tagging"", for certain analysis. For example, affiliation **data** can be extracted from domains in email addresses, or from other sources, and used to tag unique (merged) identities, so that affiliation information becomes available for actions for the corresponding person even in **data** sources where the **data** was not originally available."
233705419,12/53,2.0,0.226,"The capture, evaluation, and quantification of expert knowledge with the generated data, and visualization of the **data** model for the decision-making process are used in the AI-based hybrid model procedure in the following steps:"
249258070,71/119,1.0,0.597,"This study relies on CFS **data** provided by the Houston Police Department (HPD) based on records from their Computer Aided Dispatch (CAD) system. While CFS **data** may not capture all activity an officer engages in, these **data** are one of the best resources available to understand both conventional police activities and officer proactivity (Lum, Koper, et al., 2020;Wu & Lum, 2017;Zhang and Zhao, 2021)."
57697459,12/29,6.0,0.414,"It is worth mentioning that the genericity with which the send and receive services have been built offers extensibility in the sense that if future types of services are needed, we only need to create and use their **data** types. With the reduction of duplicate code maintainability is assured and by not creating a separate class for each individual service, the code coverage is highly increased together with the cohesion of the classes. And finally, due to the fact that the project uses an IOC container, the instantiation of the services is easy because uniformity is guaranteed and the reuse is 24 A First Design Approach to a Multimedia SDK Based on a Hybrid P2P Architecture self-evident because the whole module, as well as the whole system, relies on abstraction which facilitates dependency injection."
12790199,9/21,1.0,0.429,"At the core of the system's sensorimotor coordination are concurrently-running interaction processes. An interaction process writes **data** derived from its execution to an interaction history, which is kept in shared memory to be read by related processes. During each cycle, an interaction process reads from various interaction histories, performs some processing, and writes to its own interaction history."
119303658,3/22,1.0,0.136,"Before proceeding to a **data** example, we also note that we extract the ICME track from STEREO-A/HI images in the same plane (the ecliptic) as the main in situ observing spacecraft (STEREO-B ) is situated. In this way we avoid any effects based on observations and positions yielding from different latitudes."
249258070,81/119,1.0,0.681,"The current inquiry adds to the body of knowledge in this area by exploring potential changes to both reactive and proactive officer activities brought on by the pandemic using CFS **data** from Houston, Texas collected from January 1, 2018 through December 31, 2020. This study is informed by routine activity theory and perspectives on proactive policing. Trends are examined for seven different call types: violent crime, property offenses, disorder incidents, suspicious incidents, traffic-related activities, service-related activities, and non-crime events. In doing so, observed trends can be compared to the other large jurisdictions to further our understanding of how the pandemic has impacted demands for police services (e.g., Ashby, 2020). We also examine trends in officer proactivity through officer-initiated activities identified in the CFS **data** performed by three units: patrol, specialized crime investigation units, and the department's specialized response unit. This provides a unique look into how COVID-19 may have influenced officer-initiated activities."
134689280,6/20,3.0,0.3,"First, what appears to be a truncation is not necessarily truncated. The features could be intentionally constructed, i.e. actually preserved and originally finished that way. This is arguably the most important distinction: do we see the representation of the finished article thanks to decent preservation or is the shape of this feature a representation of something broken? If the latter, there are still many options. Was the feature destroyed and, if so, when, by whom, and how? Did it deteriorate over time and, if so, by gradual dilapidation of the original feature after disuse or due to other site formation processes? Was it damaged by modification, reuse, or reappropriation in the ancient or recent past? Did it suffer from decay of perishable building materials or decay due to the perishing of originally incorporated natural elements (such as trees and plants)? Was (part of) the feature removed by either animals or humans after disuse or abandonment? Without a symbology for line ends, when conditions of archaeological recording allow for it, the end user will once again rely on rules of thumb to carry out the conjectures. Fortunately this can be done in critical and archaeologically knowledgeable and sensible ways (see Vis, under review, 2014b). Once the metadata of the project as well as spatial **data** and analogous information from historic and cultural proximity have been exhausted, one can still apply visual and morphological contrast when constructing complementary data, document the applied rules of thumb, and mark up **data** for easy separation of these conjectures from retentions of originally acquired spatial data."
57697459,11/29,3.0,0.379,"Entity Model Layer. The Repository is built in a very similar way to the DataService from the Domain Model. It is built having in mind extensibility, reusability and maintainability. The Repository takes advantages of the generics that the .NET Framework offers, to avoid duplicate code. It uses the DBContext generated by Entity Framework to implement the CRUD operations generically, for each entity. Throughout the **data** model, the Repository is never instantiated, but it is registered within the Unity container and resolved wherever it is needed. This way of working ensures flexibility and it prepares the code for future changes. If, for instance, the ORM would be replaced, a new repository will have to be created, but due to the fact that component layer relies on abstraction, the replacement of the old component with the new component is very easy, the affected places in the Domain model layer being reduced to only one line of code. The Domain model is a simple one because this is not a database centric application. However, we need to consider the key points of the **data** model that are likely to change and try to encapsulate them right from the database. Thus, the few the changes are at the database level, the smaller is the impact on the entity layer. To achieve this, we needed to make an educated guess about what are the regions of the database that are likely to change. Of course, in the pessimistic case, the whole structure of the database may change leading to major modifications at the entity layer."
246165803,16/45,1.0,0.356,"The KNN algorithm is a classifier that considered N different kinds of neighbors to the sample, with a uniform weight consideration. This means that all points in each neighborhood are weighted equally. For this work, we built a KNN algorithm using Python's library Sci-Kit Learn, considering four neighbors to our **data** input and receiving four output classes."
17966235,19/35,1.0,0.543,"Roh et al. [117] cellular hybrid beamforming supporting outdoor and indoor coverage of a few hundred meters with more than 500 Mb/s **data** rate Ayach et al. [118] cellular hybrid beamforming exploit the spatial structure of channels to design precoders Alkhateeb et al. [119] cellular hybrid beamforming exploit the poor scattering nature to estimate the channel Singh et al. [120] cellular hybrid beamforming with multiple arrays beamforming independently, and codebook-based"
236196766,13/47,18.0,0.277,"Also in Table 2, it can be seen how the performance is close to the maximum allowed by the GitHub API token rate: 5,000 calls per hour, or about 83 calls per minute. Using two tokens, that maximum would amount to 163 calls per minute. Processing of Git commits is much faster, since it does not involve API rates, and is limited only by the Git server response time, download time, and git processing. Enrichment processes for git are much faster than for GitHub because they are also lighter: in the GitHub case they include the computing of some duration metrics, based on the **data** in the raw index, which is a bit longer to retrieve."
59624,14/19,1.0,0.737,"Merely all the error models previously identified can be applied for human error analysis. Common errors are the occurrence of an action of the actor not belonging to the planned interaction (error E.1), the execution of actions in a wrong order (E.2), and the omission of an action during an interaction (E.3). It is also possible to note human errors such as E.6, E.7 and E.8 consisting in furnishing bad **data** to the system. For instance, a user can type a letter whereas the system is waiting for a number (E.6), or he/she can tune a pressure valve too high for the system (E.8). The error E.4 is rather rare in human error analysis because it implies that the object for the interface is absent. The error E.5 depends on the time constraints a system can have, and is based on non functional requirements as for the error E.10. The error model E.9 which concerns response of a message (return values) is really useful for software or electronic components analysis. In case of the human component this is equal to E.6, E.7 and E.8, for message coming from the system."
248392338,12/27,1.0,0.444,"Policy and legal implications. Any AI computational system aiming to detect dark patterns should align to detectable issues that are already deemed illegal by authoritative sources. But there are only few (mandatory) legal rules in Europe constraining the use of dark patterns, and enforcement is slow in holding websites accountable. The only mandatory decision ascertaining any UI based aspect is dated of 2019 forbidding the use of pre-ticked boxes (of Justice of the European Union, 2019). From Article 7(3) of the GDPR (""it shall be as easy to withdraw as to give consent"", it can be interpreted that privacy choices should be equal (e.g. parity in accept, reject and revoke choices) Nouwens et al., 2020b). Parity feature entails i) equal widgets, ii) equal number of times to either accept/reject/revoke consent, iii) across modalities (web, mobile and app setting levels) (Johanna Gunawan, 2021). This reasoning on feature parity needs still to be held definitive by court decisions as well for consistency in all EU. The ePrivacy Regulation draft 14 , being discussed in the European Council, as of today, is absent on the definition of dark patterns or UI features, even accepting the use of cookie walls (Council's version), considered as an onstructive dark pattern (Kretschmer et al., 2021;Gray et al., 2021). Such weak enforcement and the high rate of consent optimization enhanced by using faulty designs in cookie banners (Hils et al., 2020; at scale, facilitated by the use of consent management platforms, explain the recurrent use of dark patterns in cookie banners. In the future, we need to see a more serious approach to enforcement, either by courts, or by decisions issued by **data** protection authorities. That is the only way to ensure that automated systems can rely on the necessary legal certainty in identifying dark patterns by identifying concrete characteristics of design."
15294885,2/25,4.0,0.08,"Among these improper-complex signals, we focus in this paper on a linear modulation of an impropercomplex **data** sequence using only one transmit waveform. In particular, we consider an improper-complex **data** sequence that is well modeled by a zero-mean improper-complex second-order stationary (SOS) random process for which the auto-covariance and the complementary auto-covariance functions depend only on the time difference [13]. This results in an improper-complex second-order cyclostationary (SOCS) transmitted signal. For example, PAM, vestigial sideband PAM, and unbalanced QAM fall into this category. It is assumed that such an improper-complex SOCS signal is transmitted over a strictly bandlimited frequency-selective linear time-invariant (LTI) channel whose output is corrupted by an additive proper-complex SOCS random process. As already mentioned, proper-complex SOCS random processes well model the complex envelopes of the majority of digitally modulated signals as well as the complex envelope of an additive Gaussian noise."
236447646,6/11,1.0,0.545,"We also used the ASMD Python API to select the proper datasets for our experiments. To avoid over-fitting during the evaluation stage, we did not use the Maestro [24] and MusicNet [22] datasets because the AMT models were trained on them. Instead, we used the ""Saarland Music Dataset"" [25] for evaluating piano A2SA. It consists of 50 piano audio recordings along with the associated MIDI performances, recorded with high-quality piano equipped with MIDI transducers. As regards to multi-instrument music, we relied on another well known dataset: the ""Bach10"" [23] dataset, which includes 10 different Bach chorales synthesized with virtual chamber instruments. Even though Bach10 dataset provides non-aligned scores, we used our artificially misaligned **data** to obtain results comparable with the other datasets."
213583867,2/4,1.0,0.5,"Merupakan suatu konsep yang memperluas konektivitas integrasi penggunaan internet secara terus-menerus, terhubung pada perangkat hardware yang digunakan manusia. Menurut [8]pemanfaatan internet sebagai media dalam penyampaian **data** informasi serta mengendalikan perangkat keras atau sensor merupakan konsep dari IoT. Contohnya seperti mesin produksi, pompa air, relay saklar, sensor, dan semua benda yang terhubung pada jaringan intranet maupun internet global. Penerapan komunikasi dalam proses monitoring dengan IoT mempermudah seluruh aktivitas dengan integrasi smartphone [9]."
229722484,5/39,2.0,0.128,"In this paper, we are interested in uploading operations from smartphones, as we consider the **data** collection as reference task. We want to exploit the available hardware as much as we can, hence also allowing the file transfer via multiple interfaces, that is splitting the file into chunks that are distributed among the available connections. Approaches related to this aim have been considered in [10,11], even though the lack of technical details allows little room for reproduciblity. For instance, even the specification of which devices have been tested for the experimentation is missing, or the way energy consumption has been measured."
5803875,3/49,1.0,0.061,"In [9] authors focus on routing policies and point out cases where routing decisions taken by ASes do not conform to expected behavior. There are complex AS relationships, such as, hybrid or partial transit which impact routing. Such relationships may lead to false positives in our results. However, the paper points out that most violations of expected routing behavior caused by complex AS relationships are very few and most violations were caused by major content providers. Our work identifies detours for variety of ASes, including both large content providers and small institutions. Moreover, in [24] authors argue that such incongruities are caused due to incorrect IP to AS mappings. About 60% of mismatches occur due to IP sharing between adjacent ASes. Authors here show that 63% to 88% of paths observed in control plane are valid in **data** plane as well. The work in [14] also analyzes the control plane (RIBs and AS paths) to construct a network topology and then uses traceroute to construct country-level paths. The goal of this work was to understand the role of different countries that act as hubs in cross-country Internet paths. Their results show that western countries are important players in country level internet connectivity."
59624,12/19,1.0,0.632,"The error models been specified, their effects on system harm risk have to be studied. To handle this activity, we tuned the FMECA array [10] (originally devoted to functional analysis). This section proposes to introduce the following elements into the FMECA array for a message failure mode analysis (see figure 7): the interaction or the message name, the failure modes or the errors identified thanks to the previous error models, the causes of those failure modes, the effects at a local, higher or system level, the **data** to estimate the risk (severity is the harm seriousness, and failure mode occurrence is noted as probability), the on-line means to detect failure modes and their effects, the possible means for risk prevention and protection and other pieces of information."
232291095,3/24,1.0,0.125,Data collection and external **data** linkage
246165803,14/45,1.0,0.311,"The experiment took place in different stages. First, for every route, the Access Points and RSU were placed according to Figure 4, respectively, and multiple laps were run for each route. Table 3 shows the summary of the **data** obtained by each experiment and the percentage of the route covered by the APs reached. This **data** were stored in the RSU for further processing. The packet error rate of the proposed V2I network resulted in results of an average 2.47% PER, with a maximum of 8% in the worst configuration possible and unexpected anomalies in the communications, including interference, partial or complete obstruction in the line of sight, or unexpected weather conditions."
236196766,13/47,16.0,0.277,"Use case: one-time analysis of a collection of repositories Requirements: One-time retrieval of all the **data** from two kinds of **data** sources (Git and GitHub) for a medium sized list of repositories, all of them related to IoT (Internet of Things)."
246337567,19/70,2.0,0.271,"NAISC-L users and are completed when users actively update the Interlink Graph with the additions, deletions or revisions they have made to the linkset. A linkset has only one named graph that contains all of its active interlinks. This design allows for simple and efficient querying of the interlinks. 2. Provenance graph: This is a named graph, in the form of a prov:Bundle, that contains the provenance **data** of the links in an Interlink Graph. Multiple provenance graphs can be associated with one Interlink Graph, as a new provenance graph is created for every interlinking session. A Provenance Graph contains the origin **data** of the interlinks created during an interlinking session, as well as the origin **data** for the linkset itself. It also provides a history of the interlink deletion and revision activities that occurred during an interlinking session. These descriptions are provided using RDF Reification (Manola and Miller 2004). 3. Relationship graph: This is a named graph containing a set of statements linking an Interlink Graph with its Provenance Graphs using the property prov:has_ Provenance. This property, which is part of PROV-AQ: Provenance Access and Query 17 (Moreau et al. 2013), specifies how to obtain a provenance record associated with a resource."
248392338,20/27,1.0,0.741,C Description of the **data** repository
248392338,6/27,7.0,0.222,10. Does the website work after rejecting all Cookies (iteworkafterrejectingcoookies) -whether the site works after all cookie purposes are rejected (it is binary **data** with some comments);
233705419,17/53,1.0,0.321,"Based on the collected measurement **data** and the formalized expert knowledge, the implemented AI-based algorithm can be used to quantify and intuitively visualize the relationships in the measurement data."
236196766,25/47,4.0,0.532,"Easy deployment as a complete system using Docker or docker-compose, with a single command, but at the same time can be custom-installed using pypi packages. It can be used as a complete toolset, but most of its tools can be also used by themselves, as modules, integrated with user-implemented software. Tested in real-world (both industrial and research) cases, including systems running continuously for months, retrieving **data** from thousands of repositories."
199379465,4/14,1.0,0.286,"The second model is the InferSent Model, Figure 1: The Infersent Architecture adopted for NLI task which is a sentence embedding method that provides semantic representations for English sentences. As shown in Figure 1, the architecture centralizes on the idea that two sentences (premise input and hypothesis input) will be transformed by sentence encoder (same weights). After that, it leverages three matching methods to recognize relations between premise input and hypothesis input. The three matching methods are: concatenation of two vectors, product two vectors element-wise and absolute difference of two vectors. Conneau et al. (2017) proposed the model which is trained using GloVe word embeddings (Pennington et al., 2014). In our work, we used the MedNLI (Romanov and Shivade, 2018;Goldberger et al., 2000) along with different word embeddings such as 300D GloVe embeddings, MIMIC clinic **data** embeddings (Johnson et al., 2016), Wikipedia (english) embeddings, the combination of Wikipedia english and MIMIC clinical **data** embeddings and even with the combination of 300D GloVe with BioASQ (Tsatsaronis et al., 2015) and MIMIC embeddings. All the techniques were set with number of training epochs as 100 and were trained on GPUs."
249258070,117/119,1.0,0.983,"The purpose of the current study was to examine changes in both reactive and proactive police activities since the onset of the COVID-19 pandemic when compared to previous years. Specifically, **data** from Houston, Texas were analyzed across seven reactive categories and selfinitiated activities across three units (patrol, crime investigations, and DRT) from January 1, 2018 to December 31, 2020. The results indicated that COVID-19 had notable impacts on four of the reactive measures and all three self-initiated activities. Three key findings emerged from the observed trends and are highlighted here."
246165803,21/45,1.0,0.467,"Data were scaling. In the case of the artificial neural network, additional scaling was performed to improve the training process using a min-max scaler from 0 to 1. This process is because scaled **data** tend to improve training, given the high number of matrix multiplications by the nature of the artificial neural network. This characteristic is the main difference between the input of both models. On the other hand, the KNN algorithm classifies information based on different types of distances: Euclidean distance, cosine squared distance, etc. Moreover, the scaling of **data** does not represent any difference."
2482529,1/37,1.0,0.027,"In general, the training **data** do not determine a unique concept. Frequently there are an infinite number of concepts that are consistent with the data. Any factors other than the training **data** that determine the concept selected by the learning algorithm are called the bias of the algorithm (Utgoff and Mitchell, 1982;Utgoff, 1986;Rendell, 1986;Haussler, 1988; Gordon and desJardins, 1995). For example, it is common to build learning algorithms that have a bias towards simpler concepts, even when simpler concepts have lower accuracy on the training **data** than more complex concepts."
14054650,6/13,1.0,0.462,"If our goal is to promote progress towards highquality MT, we should investigate the creation of more expressive cross-lingual representations. The challenge is, then, to do so without compromising the undeniable strength of surface-based SMT. One of its strongest points is its robust descriptive nature that learns as much as possible from **data** while imposing only very few and general a priori constraints. Rather than advocating transfer systems based on specific linguistic theories, we believe that this philosophy should be upheld as much as possible as we explore more expressive transfer representations."
249258070,28/119,1.0,0.235,"Despite the mounting research related to COVID-19 and police activities, there remain several gaps in the current body of literature. First, there is a lack of focus on proactivity and self-initiated activities-a salient aspect of policing. Second, several studies on CFS changes were published shortly after the emergence of COVID-19 and were unable to account for long-term trends and potential impacts outside of a few weeks or months. Lastly, results across studies suggest substantial variation in the effect of COVID-19 on police activities. Studies have noted differences in either perceived changes across departments (Maskály et al., 2021) or CFS trends across various cities and/or call types (Ashby, 2020;Dai et al., 2021;Mohler et al., 2020;. In reflecting on his own research findings, Ashby (2020) noted, ""[o]ne important finding from this study is that there is unlikely to be a single universal experience of coronavirus among police departments: different agencies may experience different changes. This means that the availability of **data** from multiple agencies will be crucial in developing our understanding of reactive patrol policing during a major public health emergency"" (p. 1070). Overall, there remains a need for additional research to better understand the impact of COVID-19 on police activities (see also Lum, Maupin, & Stoltz, 2020a)."
225958729,10/13,1.0,0.769,"In the legal society, laws and regulations have a strong binding force, which can effectively regulate individual behaviors and ideas. Compared with western developed countries, China starts late in the application of cloud computing. Although relevant departments in China have issued the corresponding legal system, the laws and regulations on cloud computing network security are not sound enough. There are big loopholes so that some criminals can take advantage of, leading to the loss of **data** and important information in the computer. According to the current legal system, for illegal means to steal **data** information, damage user **data** and other acts, the punishment is relatively low. Facing with huge remuneration, it will lead to all kinds of illegal acts and incidents."
245986448,1/45,1.0,0.022,"The utility of a schlieren image lies in the fact that the refractive index is dependent on the density of the medium it passes through. Knowledge of this relationship permits one to obtain quantitative **data** from such images. To make this lucid, let ρ (x, y) be the spatially varying density of a fluid surrounding an object of interest; it is expressed as a scalar-field with a horizontal coordinate x and a vertical coordinate y. It has a linear relationship with the refractive index n (x, y),"
134689280,16/20,1.0,0.8,"There is nothing new about having to negotiate these limitations. However, to arrive at an 'interpretive GIS' and applying associate analytical tools, we must fully understand the extent of the opportunity for social interpretation. Many of the problems discussed so far tend to disappear into the background of 'archaeological evidencing'. It can be appreciated just how much influence the treatment of archaeological evidence has on exactly which kind of interpretive and analytical work is supported by it. At this stage we can ask, so why does it matter that our **data** best approximates a would-be inhabited built environment? What is its value, its contribution, its relevance? From the outset I placed the arguments in this chapter in the context of social interpretation, but until now virtually all effort has gone into preparing and seeing built environment **data** as material boundaries. What is the social interpretation of material boundaries? With social interpretation of material evidence, I seek to place the material as a fundamental part of social science. This is not an attempt to reformulate the many guises of social archaeology (see Preucel and Meskell 2007) under a new heading. It should be seen as part of recent calls for archaeology to act as a social science and to contribute to pertinent societal issues Kintigh et al. 2014;Smith 2015). In archaeology as a social science, it could be said that 'we are no longer concerned with how these materials can be interpreted; instead we are interested in how these materials intra-acted with past people' (Meirion Jones 2015: 336), specifying our interpretive process and purpose. From this vantage point, the difference between the purviews of archaeology and social science is all but gone. The synchronous mode of analysis of spatially determinant characteristics further emphasises these equal terms of operation."
199379465,1/14,1.0,0.071,"Recent studies have shown that patient-specific **data** can be utilized for the development of intelligent Healthcare Information Management Systems (HIMS), that support a wide range of supporting applications that enhance healthcare delivery platforms. The application of natural language processing, sophisticated **data** modeling, and predictive algorithms make it a highly interesting area of research. Patient **data** is continuously generated in large volume and variety, given the multiple modalities, it is available in (e.g., discharge summaries, physician's notes, clinical reports, lab reports etc). With an abundance of such diverse information sources available in the medical domain, sophisticated solutions that can adapt to the heterogeneity and specific manifold nature of health-related information are a critical requirement for HIMS development."
57697459,10/29,3.0,0.345,"Once again, another layer of abstraction can be observed; all the proxy servers do the same thing, but with different **data** types. By adding this abstraction layer, we minimize the future impact of adding another streaming functionality to the application like screen sharing or file transfer. The gains in this case are self-evident. Both the web servers and proxy servers rely on abstraction to form a common way of working, facilitating the adding of new features. All of them in concept behave the same but, one of them acts different at a lower level. The Signaling web-server and proxy server, as the name suggests, is responsible of for the initialization and for the termination of a connection."
196543150,1/17,2.0,0.059,"The connectome estimated using functional or effective connectivity algorithms contains a large amount of data, which can complicate the biophysical interpretation. The connectome is composed of values indicating the relatedness of each regionby-region combination. In addition, each of these values can be estimated optionally for defined time-windows and/or frequency ranges. That is, the final result may characterize the **data** in up to four dimensions: region × region × time × frequency. In order to reduce the dimensionality of these complex **data** and to extract meaningful patterns, topological graph analysis can be performed. The importance of specific nodes and the general architecture can be characterized by local and global network characteristics (21). Local indices identify important information hubs, which distribute or merge information to a large number of other nodes, or select so-called rich-clubs of highly interconnected nodes. Global indices measure the organization of the network into small worlds where only neighboring regions exchange information, or whether the network is organized in a centralized way. Regions with high outflow are considered drivers of information transfer in the network. Efficient information transfer across the network is measured by efficiency or path length. Segregation characterized by groups of highly connected regions for specialization can be measured by the clustering coefficient (22). The clear advantage of deriving network characteristics is that it reduces the statistical challenge posed by the multidimensional problem in terms of multiple comparisons. High dimensional **data** can lead to false discoveries when the statistical approach does not deal adequately with the high dimensionality. However, a large degree of integration can obscure localized phenomena. Therefore, the degree of integration needs to be chosen carefully in line with the current clinical problem or research question."
146010542,8/17,1.0,0.471,"Also, in the summer of 2017,""Svitzer"" company was a victim of **data** theft -over 5,000 e-mails with personal **data** were redirected to outside addresses. More than 400 employees were endangered. The problem arose 10 months before it was discovered and then fixed within 5 hours. The investigation confirmed that messages had been redirected to the outside addresses but, when the mailboxes become full, the e-mails were returning as non-delivered (Bogle, 2018). 9."
233705419,7/53,2.0,0.132,"Frequently, **data** that can be measured in principle cannot be captured for design reasons. In contrast, relevant status **data** can be calculated or predicted from simple measurable parameters using valid simulation models or based on expert knowledge. The acquisition of such parameters can be referred to as a soft sensor supporting the AI algorithms, which can then be trained with a larger and technically more meaningful database and be calibrated for prediction [6,7]."
5524852,2/6,1.0,0.333,"The very complex **data** organization is usable by specialists but not by ordinary users. That is why we have been interested by the realization of a flexible and intelligent system, which allows the consultation and comparaison of the two languages lexicongrammars (which are at the present day romance languages lexicon-grammars), and which includes the correspondance notion we have just presented. Its use will not need any knowledge neither of the **data** organization nor of computer science."
22512771,19/24,1.0,0.792,"We have successfully implemented online 4D dose reconstruction in our research treatment planning and delivery platform. The tracking solution can be used on a conventional linac. The tracking and delivery software DynaTrack runs on a computer in the linac control room, while the workstation running DynaPlan can be placed anywhere, as long as a lowlatency network connection is available. The algorithms for dose calculation and accumulation reach a high memory bandwidth of 50-70 GB/s on the workstation used in this study. Although the runtimes are reasonably stable, Windows is not a real-time operating system. Hence there might always be an unexpected lag, resulting in individual outlier runtimes for a few scattered instances. The mean computation time per MLC aperture ranged from 21.3 to 34.5 ms which was well below 40 ms. Hence, a computation rate of 25 Hz can be maintained. If latency builds up nonetheless, it can be compensated during beam-off periods, when no accumulation has to be performed. For the patient **data** in this study, the runtimes scale with the size of the dose-influence data. On computers with less memory bandwidth or computational power, the number of slices to calculate and accumulate dose for could be decreased (e.g., to the target region-of-interest only, instead of the whole lung volume)."
249258070,17/119,1.0,0.143,"The purpose of the current study was to examine changes in both reactive and proactive police activities since the onset of the COVID-19 pandemic when compared to previous years. Specifically, **data** from Houston, Texas were analyzed across seven reactive categories and selfinitiated activities across three units (patrol, crime investigations, and DRT) from January 1, 2018 to December 31, 2020. The results indicated that COVID-19 had notable impacts on four of the reactive measures and all three self-initiated activities. Three key findings emerged from the observed trends and are highlighted here."
236196766,1/47,1.0,0.021,"Software development, and in particular open source software development, relies on an increasing number of support tools (Dabbish et al., 2012;Storey et al., 2010;Lanubile et al., 2010). Each of them maintain **data** about the software development process, the Extra functionality. Built-in functionality for addressing common problems in realworld **data** retrieval, storage and analysis: fault-tolerance, incremental retrieval, extensibility, facilities for **data** curation, identity management (including tracking of identities in different **data** sources), **data** persistence, traceability and uniform access to the data."
236196766,13/47,9.0,0.277,"In some cases it is convenient to schedule the retrieval as a collection of tasks that can run in parallel. This happens for example when we can benefit from several nodes analyzing different Git repositories in parallel, or when several nodes can consume a certain API quicker than a single one. In these cases we can add Arthur, which will schedule Perceval and Graal jobs taking into account aspects such as availability of tokens to access **data** sources, or refresh periods (how often **data** will be retrieved incrementally from repositories). Arthur uses a Redis database to manage jobs and batches of retrieved items (see Fig. 17)."
235829209,1/47,3.0,0.021,"Surrogate models have been widely used in studying nonlinear dynamical systems [3,4,5,6,7,8], including charged particle motion in modern accelerators [9,10,11,12,13,14,15]. These models are obtained by training on either simulated **data** or experimental data, which have a high computational demand or require complicated experimental processing. If models can predict the dynamical system properties accurately with reduced resource requirements, they can be used for more efficient applications, such as optimization problems. Improving the prediction accuracy is the highest priority in these applications. In contrast to these existing approaches, the main advantage of using data-driven chaos indicators is that the requirement on the absolute accuracy of surrogate models is less demanding, and therefore can be structured with less complexity and data."
22512771,22/24,1.0,0.917,"We have implemented and evaluated a software platform for 4D online dose reconstruction. We have shown that dose can be calculated and accumulated in real-time at 25 Hz for the whole lung volume using a clinical voxel resolution utilizing precalculated dose-influenced **data** and DVFs. We could demonstrate for a limited patient cohort how decreased PTV margins lead to inadequate target coverage during untracked delivery for patients with substantial motion. Moreover, we observed that MLC centroid tracking successfully recovers the GTV target dose for these patients. OAR doses were consistently reduced by reducing PTV margins. "
228063906,1/53,1.0,0.019,"The classical model of communication complexity was introduced by Yao [Yao79], who also subsequently introduced its quantum analogue [Yao93]. Communication complexity has important applications in several disciplines, in particular for lower bounds on circuits, **data** structures, streaming algorithms, and many other complexity measures (see, for example, [KN97] and the references therein). denotes the function corresponding to the communication problem in which Alice is given input X = (X 1 , . . . , X n ) ∈ {−1, 1} nj , Bob is given Y = (Y 1 , . . . , Y n ) ∈ {−1, 1} nk , and their task is to compute F (X, Y ) = f (G(X 1 , Y 1 ), . . . , G(X n , Y n )). Many well-known functions in communication complexity are derived in this way, such as Set-Disjointness (DISJ n := NOR n •AND 2 ), Inner Product (IP n := PARITY n • AND 2 ) and Equality (EQ n := NOR n • XOR 2 ). A natural approach to obtain efficient quantum communication protocols for f • G is to ""simulate"" a quantum query algorithm for f , where a query to the ith input bit of f is simulated by a communication protocol that computes G(X i , Y i ). Buhrman, Cleve and Wigderson [BCW98] observed that such a simulation is indeed possible if G is bitwise AND or XOR. Here Q(f ) denotes the bounded-error quantum query complexity of f , and Q cc (f • ) denotes the bounded-error quantum communication complexity for computing f • . Throughout this paper, we refer to Theorem 1.1 as the BCW simulation. [BCW98] used this, for instance, to show that the bounded-error quantum communication complexity of the Set-Disjointness function is O( √ n log n),"
184487142,5/47,1.0,0.106,"We now wish to use our new attack to boost the adversarial robustness of smoothed classifiers. We do so using the well-studied adversarial training framework [20,25]. In adversarial training, given a current set of model weights w t and a labeled **data** point (x t , y t ), one finds an adversarial perturbation x t of x t for the current model w t , and then takes a gradient step for the model parameters, evaluated at the point (x t , y t ). Intuitively, this encourages the network to learn to minimize the worst-case loss over a neighborhood around the input."
236196766,25/47,3.0,0.532,"Flexibility and configurability of the tool, even for large-scale analysis (10,000 s of repositories). The storage model, with raw **data** mimicking the original API, kept for further analysis, and enriched, identity-merged **data** for visualization. Identity merging is unique (or at least at the level of the best of other tools)."
236196766,6/47,3.0,0.128,"SortingHat uses a very conservative approach to merging identities: it uses algorithms that are quite likely to only merge identities that really correspond with the same person. This approach is used because in production environments, experience has shown how erroneously merging identities causes much more problems than failing to merge some identities, and because it can more easily be complemented with manual curation of the data. For example, the naive algorithm of ""merge two identities if the email address is present in both, and it is exactly equal"", fails in large datasets for common cases such as ""root@localhost"", merging for example ""John Smith <root@localhost>"" with ""Mary Williams <root@localhost>"". SortingHat provides this algorithm, which can be activated, but we had to include a deny list with common addresses such as this ""root@localhost"" to make it useful. SortingHat periodically merges identities using these conservative algorithms, that can also be activated (or not) in its configuration. If more detail is needed, ingestion of identities **data** from reliable sources (such as company records, or FOSS Foundation **data** about its developers), or manual curation (usually via HatStall) can be used. However, since SortingHat offers an API to manage the identities it stores, more aggressive automatic algorithms for merging them could be easily implemented."
236196766,5/47,2.0,0.106,"The Analytics area is covered by two components, GrimoireELK and Cereslib. The first one implements the core GrimoireLab pipeline: obtaining JSON items from the Data Retrieval components, storing them with persistence in ""raw indexes"", enriching those indexes by producing items more suitable for visualization and reporting, and storing them in persistent ""enriched indexes"". In the process, GrimoireELK also uses SortingHat, in the Identities Management area, for identifying new identities, and finding the corresponding unique (merged) identities. Since both raw and enriched indexes are Elasticsearch indexes, they are basically collections of JSON items (named ""documents"" in Elasticsearch). All usual operations on noSQL databases are possible on those indexes: retrieving one or more items given some constraints, aggregating values for certain fields for a certain selection of items, updating items matching certain values, etc. The other component, Cereslib, is a library providing an API with useful functionality for certain kinds of specialized functionality. The Cereslib API is invoked by GrimoireELK to run ""studies"", which produces some specific enriched indexes. Studies are specialized preanalysis, producing items with a specific aim in mind. For example, one of them, ""Areas of code"", produces commit **data** at the file level (each item consists of commit metadata for each revision of each file), which is useful to analyze how different areas of code evolve."
116736295,1/7,1.0,0.143,"This study investigated whether Software Project Managers in Iran assess risks in software projects. It also looked at risk assessment approaches and methodologies used in software projects risk management, means of storing risk **data** and their reuse and the possible reasons as to why software projects fail to meet performance, cost and schedule requirements. These reasons include major threats in software project that Software Project Managers experience in Iran. The main intention for this research was to obtain facts on the state of the art of risks assessment practice in Iran, develop a risk assessment framework and its supporting tool based on these facts also known as study findings and the existing software project management acceptable practices surveyed in the existing literature."
246165803,1/45,6.0,0.022,"Some of the applications of short-range technologies vary from localization to warning signaling. One example of application in short-range ultra-wideband (UWB) technologies provides estimated ranges to track the vehicle's position in an outdoor environment. Martin et al. built an accurate and reliable positioning solution based on the combination of UWB varying estimates and inertial and odometry **data** of the vehicle [16]. As it has a low cost and a long battery life, ZigBee technology Vehicle Identification is possible. One proposed application is the classification of vehicles and communication through the 802.15.4 protocol. In addition, Zigbee technologies can be useful in V2V communications under certain conditions for Collision warnings [15,17]. Other applications could include the communication of sensors in Wireless Personal Area Networks (WPAN) and low-energy, BLE-based fingerprint localization [18]."
248392338,6/27,4.0,0.222,"3. ""Not yes"" (nameofnotyes) -the text within the first UI element (link or button) that only eventually leads to an opt out from tracking (semistructured text); 4. Location of the pop up (location) -the location of the cookie pop up on the website (this is a description in the form of semi-structured text); 5. Does the cookie banner disable the website (contentblocking) -whether the website is accessible and scrollable while the pop up is active. It is yes/no (binary) **data** with some comments;"
249258070,77/119,1.0,0.647,"The purpose of the current study was to examine changes in both reactive and proactive police activities since the onset of the COVID-19 pandemic when compared to previous years. Specifically, **data** from Houston, Texas were analyzed across seven reactive categories and selfinitiated activities across three units (patrol, crime investigations, and DRT) from January 1, 2018 to December 31, 2020. The results indicated that COVID-19 had notable impacts on four of the reactive measures and all three self-initiated activities. Three key findings emerged from the observed trends and are highlighted here."
40828380,1/13,1.0,0.077,"In order to process the packages (received at a package delivery company) more efficiently at the initial stages of routing, the company may classify the arrivals of packages into two categories: one containing (usually small) packages that require individual attention such as marking codes, posting special care, if any, and routing information; the other may involve packages that are destined to go in only one route or in one vehicle. These packages can be processed in groups of one or more. In computer communications, suppose the incoming jobs are grouped into two types"" one type requiring access to a common **data** base and the other type needing the use of common input/output device such as a laser printer or color plotter. The central processor can process all the jobs of each type in groups. Another example is in load balancing using probing in distributed processing. When jobs arrive into the dispatcher, it probes the distributed system for the type of load (heavy, moderate or light) and accordingly the jobs are distributed to balance the load among various processors. In all the above applications, we see that the jobs that require processing of general type can be processed in groups of varying sizes, which motivates the need for the type of service mechanism considered in this paper. For economic reasons, it is better to have a minimum number of jobs to form a batch before they are processed. The maximum number of jobs that can be processed at a time is the size of the buffer, which is given by K."
27068907,11/25,1.0,0.44,"The terminal software mainly consists of the main program, the RF transceiver subprogram, the touch screen communication subprogram and others. Under terminal control, the master and slave control mode is selected and the **data** is transmitted via the MODBUS protocol. The touch screen triggers the SCM for a certain period of time, sends the acquisition command to the acquisition unit, and stores the received **data** in the set address for **data** processing. In the meantime, it analyzes the **data** returned from the nodes. In the case of failure, the touch screen serves as a protection and sends the alarm information to the monitoring center. See Figure 4 for the specific workflow of the terminal.  "
234850341,19/23,1.0,0.826,"In the current times, technology plays a crucial role in identification and detection of fake news. Most social media are turning to use this methodology to curb the fake news. The basic concepts used are **data** mining techniques with algorithms like feature selection, Natural language processing, Document-term-matrix construction."
244631546,6/16,1.0,0.375,"The **data** used in this paper are selected from the official websites of The Guardian, The New York Times, The Economist, The Atlantic, News Week, etc. The **data** contain articles on domains of economics, technologies, and humanities. We take the **data** crawling from The Guardian as the example to show the training result of the model (Table 1). In this experiment, 8 paragraphs are summarized with the model. We checked the results and found that 3 paragraphs are effective and available, the precision is 37.5% ( Table 2)."
5803875,25/49,1.0,0.51,"To characterize detours we define two metrics:    Before using the above metrics to characterize the detours, we perform **data** pruning to avoid skewing of **data** towards ASes that have more peers that provide BGP feeds to RouteViews and RIPE RIS. Also, ASes with multiple peers and similar views can contribute duplicate detours to our dataset. We follow a simple approach to deal with this problem: if an AS contains more than one peer we select the peer that saw the most detours as the representative of that AS. This may potentially undercount detours since some peers in same AS may see different detours. After selecting a representative we are left with 36 (out of 79) peers. We now continue our characterization of detours by looking at detour dynamics. Specifically we focus on flap rate and duty cycle, defined as follows:"
146010542,7/17,1.0,0.412,"A group of students successfully proved weaknesses and imperfections of Global Positioning System (GPS). In 2013 they hacked the GPS signal on a private yacht and distributed false position **data** to navigational equipment. As the track-pilot was active, automatic correction of course had been initiated in order to put the yacht back on route (Vaas, 2013)."
12790199,2/21,1.0,0.095,"The object schemas act as discrete entities for the purposes of language and planning. Organizing continuous processes into object schemas allows incoming sensory **data** to be readily sorted for rapid interaction with language and planning, and vice versa. It should be noted that the term ""schema"" is used here in a psychological sense, as used by Piaget [25], or  Figure 1: Simplified block diagram of the system, showing **data** flow between the five parts of the system. Note that most of the **data** flow occurs by virtue of object schemas and plan trees being composed of interaction processes, which is not depicted. computationally by Drescher [14] or Roy [28], in that incoming continuous sensory percepts are organized into discrete structures. In this case, incoming sensory **data** is regarded as being signs of objects in the environment. Our object schemas are an implementation based on our interpretation of the term in this context."
119479526,1/29,2.0,0.034,"This Bayesian framework naturally accommodates ancillary methods to address issues commonly seen in real computational and experimental data, including the presence of outliers, systematic errors and inaccurate error bars. Our novel approach optimally leverages specific heat and enthalpy **data** (as well as entropies and Gibbs free energies if available) to construct self-consistent thermodynamic models. One major advantage of this approach versus previous attempts is that it does not incur the errors associated with the conversion of all **data** to the same property basis (e.g. fitting and then differentiating enthalpy **data** to convert to specific heat). Furthermore, the framework can naturally incorporate the relative weighting of various datasets and provides significant insight into the relative importance of each dataset to the model. We demonstrate the strengths of the framework through the construction of a thermodynamic property model for Hafnium metal from a diverse collection of experimental measurements of heat capacity and enthalpy for the alpha, beta and liquid phases. Hafnium metal is a good candidate for this study as the available measurements exhibit the previously mentioned issues due to the difficulty of obtaining Hafnium samples without Zirconium content, the potential for oxygen contamination, and the extreme temperatures at which the beta and liquid phases are stable (Hafnium melts at ∼2500K and vaporizes at 4900K) [17]."
22512771,21/24,1.0,0.875,"Sonke et al. 39 have shown that although the shape of the tumor trajectory was found to be stable interfractionally, baseline shifts might invalidate the 4DCT planning dataset. Although MLC tracking is expected to cope with these shifts (depending on the motion acquisition method), this might result in a mismatch with the dose-influence data. Therefore, to apply the proposed online 4D dose reconstruction method, the validity of the dose-influence **data** should be assessed prior to each fraction. To allow for dose reconstruction on anatomy not captured on 4DCT, patient models could be utilized. 40 Innovations in image-guided radiation therapy technology like the MR-linac 41 may ultimately bring 4D online-imaging and have the potential to continuously update a patient model, robust to baseline shifts and other anatomy changes. Extending this work to volumetric arc therapy (VMAT) is hindered by the substantial increase in dose-influence data. We are currently investigating the trade-off between the number of beam angles and the dosimetric accuracy for online dose reconstruction of VMAT deliveries. Generating dose-influence **data** on the fly is currently too slow and we therefore envision future online 4D dose calculation directly, based on the patient model geometry and a real-time Monte Carlo dose calculation."
12790199,11/21,1.0,0.524,"This process-centered representation provides a convenient means of organizing sensorimotor **data** and processes such that changes in one active process can immediately affect another process in that object schema. For instance, a moving visual region can rapidly change the target location for a grasp-related process. Likewise, a failed grasp can lead to doubt that a physical object actually exists at that location, leading in turn to reevaluation of the visual regions. This representation also provides a single point of connection for affordance-based terms, such as ""liftable"" or ""graspable."""
229722484,5/39,3.0,0.128,"In D'Angelo et al. [28] and in Audrito et al. [29], the authors study the bandwidth constraint problem. This concerns flow on multi-interface networks. In these papers, each interface is associated with a specific bandwidth. The Maximum Flow and Minimum Cost Flow problems aim at finding a connection between two nodes by considering the bandwidth constraints. The Maximum Flow problem aims at maximising the bandwidth between the two nodes. All the network interfaces are assumed to be active. In this way all the permitted connections can be established. In this context, a flow function that guarantees the maximum communication bandwidth between the two nodes has been studied. This problem is a generalisation of the Maximum Flow problem for standard networks. The Minimum Cost Flow problem aims at finding a communication sub-network between two nodes that has a minimum energy consumption cost and ensures at least a given communication bandwidth B. More precisely, the problem finds the set of active interfaces that has minimum cost and ensures that a certain node s can exchange **data** with another node t with a bandwidth not smaller than B. Although the solution can be a path between s and t, a more complex graph can be required. This has nodes with active interfaces that depend on the network topology. This problem is a generalisation of the Minimum Cost Flow problem for standard networks."
232380196,3/28,1.0,0.107,"Long-tailed classification is a long-standing research problem in machine learning, where the key is to overcome the **data** imbalance issue [21,16]. Given the great success deep neural networks have achieved in balanced classification tasks, increasing attention is being shifted to proposing neural networks based solutions for long-tailed classification. In this work, we mainly focus on the neural networks based approaches, which can be roughly divided into the following categories."
36060542,6/18,1.0,0.333,"Deep neural networks addressing computer vision tasks commonly push the input visual **data** through a sequence of operations. A common trend of this sequential processing is that the input **data** is internally resampled until reaching the desired prediction space. As mentioned in Sec. 2, methods aiming at interpretation/explanation start from an internal point in the network and go backwards until reaching the input space -producing a heatmap. However, due to the resampling process, heatmaps generated by the backwards process tend to display grid-like artifacts. More precisely, we find that this grid effect is caused by the internal resampling introduced by network operations with stride larger than one (S>1). To alleviate this effect, in the backwards pass, we set the stride S=1 and compensate this change by modifying the input accordingly. As a result, the backwards process can be executed while maintaining the network structure."
246337567,17/70,3.0,0.243,The framework should provide provenance **data** for the interlinks generated. 
246165803,8/45,3.0,0.178,"Several access points were distributed and connected through vendor-specific protocols to ensure communication between an OBU and an RSU. The OBU has three sensors and an external antenna device to acquire **data** from its surroundings and the data's position. Then, through socket communications, it can send information to the RSU device. Thus, the RSU device handled both the server-side of the communication channel and the **data** preprocessing."
249538382,1/22,3.0,0.045,"Previous works on ERP system fraud detection may be divided into approaches that rely on entirely private **data** and frauds, private **data** with synthetically injected frauds, or entirely synthetic **data** and frauds. While there have been works that use real ERP system **data** to develop and evaluate fraud detection systems [18,17,12], details about the **data** and the **data** itself are kept under wraps to avoid revealing company trade secrets and privacy information. For scenarios where real frauds are not available, Islam et al. [8] generate synthetic fraud cases within private ERP system **data** through randomly creating changes to normal transactions while limiting changes and timings with given intervals. While this generates anomalous transactions through not yet observed peaks in single entries, the generated anomalies have no inherent meaning or interpretation with respect to real-life occurrences or fraud."
246337567,8/70,1.0,0.114,"In terms of domain specialisation, only OpenRefine has extensions specifically developed for LAMs. Additionally, none of the reviewed tools has published user-testing **data** for their GUIs and none publish interlink provenance data. Thus, there is scope for a LD interlinking framework designed specifically for the LAM domain that provides rich **data** provenance for LD interlinks and that has a userfriendly GUI that has been tested by the tool's targeted users."
232404548,3/32,1.0,0.094,"Our goal is to synthesize a novel view I t , given target camera parameters K t , R t , T t , from a set of input images, I s i , i = 1, 2, ..., N . We assume there is sufficient overlap between the source views such that correspondences can be established. We estimate source view camera intrinsic and extrinsic by a well-established structure-from-motion (SfM) pipeline, e.g.COLMAP [26]. Fig. 2 illustrates the situation. Mathematically, we formulate this problem as:
I t * = argmax I t p I t |I s 1 , I s 2 , ..., I s N ,(1)
where p(·) is a probability function. Due to the expensive accessibility of 3D **data** (e.g., depths) and a limited number of input views, it is hard to compute accurate 3D geometry from input source views. Therefore, our intuition is to develop an end-to-end framework that combines geometry estimation and image synthesis, to eliminate the error propagation issue. We achieve this goal by estimating target-view depth and source-view visibility for target pixels directly under the target view."
2423505,23/23,1.0,1.0,"Figure 1 .
1Say we have labeled **data** X from the source domain corresponding to two classes + and ×, and unlabeled dataX from the target domain belonging to class ×. Instead of assuming some relevant features or transformations between the domains, we characterize the domain shift between X andX by drawing motivation from incremental learning. By viewing the generative subspaces S 1 and S 2 of the source and target as points on a Grassmann manifold G N,d (green and red dots respectively), we first sample points along the geodesic between them (dashed lines) to obtain 'meaningful' intermediate subspaces (yellow dots). We then analyze projections of labeled ×, + (green) and unlabeled × (red) onto these subspaces to perform classification. (All figures are best viewed in color).
"
249538382,1/22,5.0,0.045,"Baader et al. [4] partially alleviate the need of expert knowledge by modeling normal and fraudulent behavior directly within an ERP system, thus being able to automate parts of the generation process that would be carried out by the ERP system in a real world scenario. Remaining business decisions that are not taken over by the ERP system such as procurement quantities or sales prices are simulated through random distributions. Baader and Krcmar [3] extend the approach in additional work, where, instead of generating fraud cases through random distributions, they obtain fraud scenarios through user participation with the white-collar hacking contest [15], a serious game developed to teach players the abuse of an ERP system and the detection thereof. While the resulting frauds may model realistic scenarios, they are modeled into an existing database in post, potentially causing unwanted divergence between normal and fraudulent **data** characteristics. Further, in contrast to other research areas that utilise synthetic **data** such as intrusion detection [14], all published synthetic ERP **data** generation methods to our knowledge do not publish their code and data, making reproducible and incremental research in ERP fraud detection difficult due to missing comparability."
246165803,22/45,1.0,0.489,All the **data** obtained during the experimentation phases underwent this treatment before moving on to the training and testing phase of the machine learning algorithms. 
229722484,2/39,1.0,0.051,• Can we optimise **data** rate as well as energy consumption?
208637417,1/23,1.0,0.043,"Since its initial founding in the 1990s, the field of topological **data** analysis (TDA) has matured in several directions: through the development of rigorous mathematical foundations, powerful computational algorithms, and increasingly sophisticated tools. Recent years have seen the introduction of a new class of TDA tools: topological transforms. These are parametrized families of topological invariants that enjoy injectivity properties not found in single persistence diagrams. The first to be studied were the Persistent Homology Transform and Euler Characteristic Transform of Turner, Mukherjee, and Boyer [TMB14], which apply to shapes embedded in Euclidean space. Later, in [DSW15], Dey et. al. defined a topological transform for abstract metric graphs, and studied its stability and computability. This was complemented by work of Oudot and Solomon [OS17], who provided a variety of injectivity results for this intrinsic transform."
246165803,8/45,2.0,0.178,"The proposed solution is that a V2I-Fog computing architecture that integrates different sensors in vehicles, and through fog computing and machine learning, detects problems in the state of the streets, will boost smart urban mobility solutions in terms of affordability, effectiveness, attractiveness, and sustainability. This solution needs to be broken down into several parts: Communications, RSU-OBU system, Machine Learning, and **data** visualization."
184487142,12/47,2.0,0.255,"Semi-supervised learning Carmon et al. [5] recently showed that using unlabelled **data** can improve the adversarial robustness as well. They employ a simple, yet effective, semi-supervised learning technique called self-training to improve the robustness of CIFAR-10 classifiers. We employ this idea in our framework and we train our CIFAR-10 smoothed classifiers via self-training using the unlabelled dataset used in Carmon et al. [5]. Details can be found in Appendix E.2."
17966235,3/35,1.0,0.086,"There have been considerable work on mmWave propagation at the 60 GHz band [5], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29]. The free space propagation loss is proportional to the square of the carrier frequency. With a wavelength of about 5 mm, the free space propagation loss at 60 GHz is 28 decibels (dB) more than at 2.4 GHz [14].  Besides, the Oxygen absorption in the 60 GHz band has a peak, ranging from 15 to 30 dB/km [30]. The channel characterization in [31] shows that the non-line-of-sight (NLOS) channel suffers from higher attenuation than the line-of-sight (LOS) channel. The large scale fading F (d) can be modeled as follows.
F (d) = P L(d 0 ) + 10nlog 10 d d 0 − S σ ,(1)
where P L(d 0 ) is the path loss at reference distance d 0 , n is the path loss exponent, and S σ is the showing loss. σ is the standard deviation of S σ . In table I, we list the statistical parameters of the path loss model obtained in a corridor, a LOS hall, and a NLOS hall [31]. We can observe that the path loss exponent in the LOS hall is 2.17, while the path loss exponent in the NLOS hall is 3.01. To combat severe propagation loss, directional antennas are employed at both transmitter and receiver to achieve a high antenna gain. For the small-scale propagation effects in the 60 GHz band, it is found that the multipath effect is not obvious with directional antennas. By using circular polarization and receiving antennas of narrow beam width, multipath reflection can be suppressed [32], [33]. In the LOS channel model in the conference room environment proposed in IEEE 802.11ad [9], the direct path contains almost all the energy, and nearly no other multipath components exist. In this case, the channel can be regarded as the Additive White Gaussian Noise (AWGN) channel. In the NLOS channel, there is no direct path, and the number of paths with significant energy is small. To achieve high **data** rate and maximize the power efficiency [34], mmWave communications mainly rely on the LOS transmission."
254275294,8/12,1.0,0.667,"Compared with the standard KBC setting, the performance of canonical KBC systems (i.e., TransE, RotatE, and StAR) drops dramatically under zero-shot entity or relation setting, demonstrating the difficulty of our proposed dataset. ZeroB is the most challenging setting since both entities and relations in test **data** are unseen during training. Additionally, StAR can encode the semantics of text descriptions more efficiently, which significantly outperforms TransE and RotatE across knowledge graph genres and zero-shot settings. It indicates the importance of considering textual semantics in zero-shot KBC and points to the future direction about how to design an efficient approach that can take descriptive information into consideration to solve Zero-KBC problems. In our experiments, we also observe that graph properties of knowledge bases can affect models' generalization capabilities. For example, compared with WN18RR and FB15K237, ATOMIC has a much sparser graph structure (only 1% of the entities act as both the head and tail, while the percentage for WN18RR and FB15K237 are 80% and 88%, respectively). As a result, the models that only leverage the graph structures suffer from the largest performance drop from the standard setting to zero-shot ones, while the model (i.e., StAR) utilize it could generalize better to unseen entities and relations. We also include complete experimental results on all ZeroKBC scenarios in Table IV. VII. CONCLUSION This work systematically examines different zero-shot KBC scenarios and develops a comprehensive benchmark named ZeroKBC, which covers these scenarios with three types of knowledge sources. Experimental results show that canonical and state-of-the-art KBC systems suffer great performance degradation on this challenging yet practical benchmark. We further present several important observations and promising future directions based on our system output analysis.  
"
245864793,12/42,1.0,0.286,"Based on this data, the ""play"" module counts the movements done by the patient (by comparing them against the reference, i.e., the stored exercise template). It further sends the counter **data** to the VR game and to the ""exoskeleton-as-keyboard"" module. The VR game uses this **data** to visually correlate the avatar movements with the actual patient movements. If an external game is used as a motivator within a rehab level, the ""exoskeleton-askeyboard"" module translates this **data** to virtual key presses that, in turn, control the external game (e.g., executing jumps, left or right turns)."
233705419,9/53,1.0,0.17,"The EDI hive IoT framework is a cloud system based on the latest microservices architecture, which allows for a flexible orchestration of resources. This means that many user groups with large amounts of **data** can access the platform for different applications without performance restrictions. For **data** safety purposes, the platform can be operated as a private cloud on-or off-premises [9]. In addition to general use, role/rights, measurement **data** from management functions (e.g., aggregated measurement data), etc., the EDI hive offers other generic applications that can be used to optimize and control processes ( Figure 3). In particular, the ""EDI hive Cause-and-Effect Chain Editor"" can be employed to formalize existing expert knowledge and use it for the calibration of AI-based models [10]. With the EDI hive standard names application, the system and system parameter names in the EDI hive can be semantically networked with regard to different languages. Furthermore, specific and frequently abbreviated control and measurement system channel names can be translated into different languages."
55648852,20/40,6.0,0.5,"The Spanish OBS **data** are provided in RAW binary format. The tools for conversion permit to obtain an output format known as PascalSegy. This **data** files were, then, organized in the common .mat files for their analysis."
24456035,20/42,1.0,0.476,"Remark 10. We have assumed that agent utility functions (and resulting true baseline consumption b k ) are deterministic. However, b k depends on (exogenous) random parameters such as temperature and occupancy. For example, A more realistic model would accommodate dependence on exogenous random processes such as temperature and occupancy. This might result, for example, in a baseline consumption of the form b k = b k +a k |θ−θ 0 |. Here, θ is the realized temperature during the DR event, and θ 0 is the predicted temperature. In this case, agents can be required to report their best-effort forecast b k of their baseline consumption along with the temperature sensitivity a k . Historical consumption **data** can be used to assist agents in making these reports. The SRBM mechanism can be easily extended to incorporate these more complex reporting scenarios. The most general scenarios with uncertain utility functions that explicitly depend on exogenous random processes θ is challenging and is an ongoing work."
236447646,5/11,1.0,0.455,"Unfortunately, there is not a great variety of datasets providing exact matches between score and midi performances. Thus, we used a systematic approach to generate misaligned sequences of notes as similar as possible to a musical score. The drawback of our method is that the resulting evaluation will not produce reliable values for real-world applications. However, it ensures that **data** does not contain manual annotation errors regarding matching notes. Moreover, here we are interested in the comparison of the considered approaches and leave the perceptual assessment of a performance on realworld score for future work."
2765985,7/7,1.0,1.0,"PDU composition occurs when a packet arrives from the transport layer. First, the route of the packet to the destination address is determined by the routing mechanism. The routing mechanism in CLNP is described in the section 4.3 above. The routing **data** is then included in the options part of the CLNP header. After that, the PDU composition is performed by attaching CLNP header to the packet."
251040404,2/15,1.0,0.133,"The block diagram of the proposed symbol-wise puncturing system with PAS and HARQ is shown in Fig. 1. For the first transmission, the source generates a random binary **data** block. Then, the **data** block is mapped to the shaped bits by a PS encoder while an LDPC encoder is performed for FEC encoding subsequently. After symbol-wise puncturing the encoded codeword, the punctured bits are modulated into QAM symbols and transmitted over the channel. On the other hand, at the receiver, the soft demodulator adopts the received noisy symbols to calculate the log-likelihood ratios (LLRs). Then, the received encoded codeword is recovered by inverse puncturing and feed the intermediate results to the LDPC decoder. Subsequently, the PS decoder transforms the decoded bits back to the **data** block. If there is no error, the error detection returns an acknowledgment (ACK) and the transmitter sends the next **data** block. However, if the **data** block cannot be correctly decoded, it returns a negative acknowledgment (NACK) to request a retransmission. Futhermore, if the **data** cannot be successfully recovered after reaching the maximum number of transmissions, it is dropped and an ACK is fed back."
236196766,13/47,12.0,0.277,"GrimoireELK interacts with SortingHat to store new identities in its database and be informed about merged identities and their tags. Using **data** from raw indexes and SortingHat, GrimoireELK produces enriched indexes in Elasticsearch. These indexes (and raw indexes, when convenient) can be analyzed with scripts."
236196766,6/47,4.0,0.128,"HatStall complements the automatic processes followed by SortingHat, by providing a web interface that can be used to manually manage identities. That interface permits, for example, manually merging, or adding affiliation **data** to identities. HatStall has proven to be very useful to fix by hand some errors that automatic procedures may cause in complex situations, or to manually complement **data** related to identities when there are informal sources of knowledge."
236196766,8/47,3.0,0.17,"Mordred instructs GrimoireELK about when to poll based on its configuration, and GrimoireELK constructs the corresponding queries (to **data** sources, via Perceval, or to raw indexes) using metadata (in raw indexes or in enriched indexes, respectively). When Arthur is used, Mordred instructs it directly about polling frequencies."
236196766,14/47,1.0,0.298,"Requirements: Continuous analysis of all relevant repositories, from several **data** sources, of a large project (all software promoted by Wikimedia Foundation). Magnitudes: See Table 3. GrimoireLab setup: The setup corresponds to the description of the research scenario ""Large-scale, continuously updated dataset"", described in Subsection ""Research scenario: Large-scale, continuously updated dataset"" (Fig. 16), including continuous update and identity management."
236196766,13/47,2.0,0.277,"GrimoireLab components and procedure: For these kind of studies, GrimoireLab enriched indexes would be convenient, and could be complemented, if needed, with GrimoireLab raw indexes that will be produced anyway. Using GrimoireELK for the **data** collection and enrichment ensures that the indexes will be properly stored in Elasticsearch databases. SortingHat will be used when identity merging is important for the study (as in the second example above). Kibana can be used to visualize the indexes in the enriched database, which can be useful for the exploratory study. For example, Kibana can easily show the activity of a single person in all **data** sources over time."
57697459,9/29,2.0,0.31,"Besides the high throughput and performance that it can offer, it can be easily integrated with Entity Framework, and furthermore, the development environment facilitates the integration between the two. Automapper is used to facilitate the transformation on entity objects to **data** transfer objects."
247318640,2/12,2.0,0.167,"The average execution time of the SQUANDER package significantly exceeds QFAST in most cases, being similar to the average time of successful decompositions of the QSearch package. The execution time of the QISKIT package took only several second, thus we omit these **data** from the table. The increased execution time of the adaptive decomposing algorithm can be explained by the sequentially repeated iterations of the circuit compression process, similarly to QSearch traversing a decomposition tree and expanding the synthesised quantum circuit from iteration to iteration. Though, the success rate of the SQUANDER package turned to be much reliable than QSearch: roughly in half of our numerical experiments we did not received any result from the QSearch package in the 12h time limit. These cases are labeled by dashes in Table 1. Unfortunately, the large scale of our numerical experiments did not allow us to give more attempts to relaunch these unsuccessful gate synthesis attempts."
5648146,1/18,2.0,0.056,"In this study, a metric of the human standing balance ability based on the MLLE is proposed. The dynamic multivariate **data** of ankle, knee, and hip can be measured by three joint angle sensors. Thirty-six normal people of different ages took part in the test, and the multivariate largest Lyapunov exponent was calculated from their time series. In order to statistically analyse and compare the proposed approach and the traditional method, the single variety LLE from the COP was also calculated. The results show that the MLLE is advantaged in differentiating balance under eyes-closed conditions; sway **data** are analysed especially under the eyes-closed condition, and this approach based on multidimensional time series confers significant advantages."
52064012,8/16,1.0,0.5,"As of 2016, sixteen of these designations have been adopted by the IMO, all proposed by a State or States in national waters, the most recent being Jomard Entrance in Papua New Guinea. Roberts et al. [62] discuss possible application in the high seas but as yet no proposal for Areas Beyond National Jurisdiction (ABNJ) has been forthcoming. Four further areas are currently under consideration within IMO as proposed respectively by the Philippines (Tubbataha Reefs), Malaysia (Pulau Kukup and Tanjung Piai), Indonesia (Lombok Strait including Gili Islands and Nusa Penida Islands) and Mauritania (Banc D'Arguin and adjacent sea area). The Banc d'Arguin proposal is of note in the context of this paper having drawn **data** from the CBD EBSA described for the area (CBD COP 12, 2014). Banc d'Arguin National Park and an adjacent zone of the Atlantic (Gulf d'Arguin) can be described as an ecologically inter-connected region of global significance situated at the junction of two biogeographic realms, hosting the largest concentration of wintering wading birds in the world (the area is a core component of the East Atlantic Flyway) and one of the most diversified communities of piscivorous birds. The National Park has been listed as a World Heritage Site since 1989 (UNESCO 13COM XV.A) and UNESCO's World Heritage Committee has taken a keen interest in 2014, requesting the State Party (Mauritania) to submit the request to designate Banc d'Arguin region as a PSSA (UNESCO 38COM 7B. 62)."
15294885,2/25,1.0,0.08,"One of the classical problems related to the processing of WSCS random processes is a joint optimization of the transmitter (Tx) and receiver (Rx) in a communication system. In [4]- [7], real-baseband pulse amplitude modulation (PAM) of a wide-sense stationary (WSS) real-valued **data** symbol sequence is considered with a linear Rx for use over an additive WSS colored noise channel. Under the minimum mean-squared error (MMSE) optimality criterion and the average transmit power constraint, the jointly optimal transmit and receive waveforms are derived. It is shown that, interestingly, the waveforms have nonzero spectral values only on a generalized Nyquist interval [6] with length equal to the minimum bandwidth required to satisfy the Nyquist condition for zero intersymbol interference (ISI) [1]."
235829209,25/47,1.0,0.532,"Consider a different scenario: an unknown nonlinear dynamical system is encapsulated into a blackbox and only an ensemble of trajectories (input and output data) are available. Comparing actual trajectories to interpolated trajectories is one way to gauge chaos. A typical method to interpolate from known trajectories is to build a surrogate model with machine learning techniques. A surrogate model needs to be established first, then predictions can be made by evaluating trajectories with given initial conditions. This procedure is known as ""supervised learning"" [2]. To validate the model, the **data** is often randomly split into two clusters: a large training set and a small testing set. A model is then constructed from the training set. The performance of the model, i.e., the prediction accuracy, is measured by comparing the testing **data** against its prediction. The performance of the model depends on the type and complexity of the model, the volume of training data, the algorithm used for training, etc."
14392421,7/15,1.0,0.467,"White and Smyth [13] showed that optimizing the modularity measure Q can be reformulated as a spectral relaxation problem and proposed spectral clustering algorithms that seek to maximize Q. By eigendecomposing a related matrix, these methods can map graph **data** points into Euclidean space, the clustering problem on which space is of equivalence to that on the original graph."
134689280,7/20,1.0,0.35,"While conjecturing is not as strong a process as fully fledged reconstruction, there is a risk of getting caught in the fallacy of perfection. In archaeological reconstruction, there is the tendency of reconstructing everything to an absolutely pristine and clean state. Buildings and surfaces are all fully functional and, in outstanding condition, their environments devoid of any form of pollution. One could argue this striving for perfection is a kind of hyperrealism. The reconstructed situation is not one that likely ever existed. A true reconstruction of the past should account for areas laying fallow and buildings in disuse or disrepair. Such occurrences would have been part and parcel of a built environment in flux. Beyond the visual impression, the critical social interpretive importance of perfection generated by conjecture or reconstruction can vary. This depends on the purpose of analysis or interpretation, i.e. what is the newly constructed **data** supposed to comment on or contribute to? To illustrate this, let me err on the spatial side of the analytical spectrum. The reliability of population estimates based on buildings heavily depends on knowledge or assumptions that determine which were occupied and which had only occasional, shared, intermittent, or partial use (introducing degrees of spatial duplication or redundancy). However, a general understanding of the functional structure or spatial experience and opportunities for inhabitants does not rely on information about which house was occupied at each specific moment in time or its state of repair. From our own experience, we can accept that when a house is unoccupied, would we always know? And when it is dilapidated, it is still recognisable as a house and still poses a physical impediment to access that space. The building still has potential to be a household or to be repurposed. The space and the experience of that space is still structured in roughly the same way, even if the affective and sociocultural context may differ from particular case to particular case. The point is to alert us to the fact that when the notion of occupiable space (to understand how boundaries compose built environments) requires us to conjecture, we create an approximation of a situation in the past, not a reconstruction of any particular situation in the past. A sufficiently critical research design will be aware of both the social interpretive limitations and opportunities this offers."
246165803,8/45,4.0,0.178,"The third part corresponds to classification through Machine Learning. Machine learning algorithms have been proven to be the best alternative to usefully process information. Therefore, it is necessary to develop useful models that correctly classify the **data** obtained via the OBU. The last part corresponds to the visualization of the processed data, showing useful information regarding the conditions of the city's streets and avenues. Once both MLAs have been tested and implemented, the algorithms will quantatively compare two streets to determine which road is the most troubled in terms of anomalies."
184487142,12/47,1.0,0.255,"We explore using more **data** to improve the robustness of smoothed classifiers. Specifically, we pursue two ideas: 1) pre-training similar to [17], and 2) semi-supervised learning as in [5]."
236196766,18/47,2.0,0.383,"Bugs. Researchers using GrimoireLab become dependent on it producing **data** correctly. This makes their studies subject to bugs or errors in GrimoireLab or its configuration. Experience shows that it is more likely that a single researcher writing code makes mistakes causing bugs, than a software used in many different scenarios by many different people. GrimoireLab uses unit testing to prevent new bugs and regressions, with relatively high test coverage (Graal: 99%, Perceval: 98%, SortingHat: 93%, GrimoireELK: 82%, Mordred: 63%). But still, if there are bugs in some component, those could cause wrong **data** to entire datasets. Therefore, **data** checking should still be an important part of any research using GrimoireLab. Adaptability. If a study is designed as a function of what can be done with GrimoireLab, or what can be done easily with it, there is a risk of focusing on what the toolset can do, and being limited by it. Researchers should confront the GrimoireLab model, designing new components when needed, or realizing when it is not well suited for a certain kind of study. Evolution and poor documentation. Even when GrimoireLab features extensive documentation, including a tutorial, and specific documentation for modules, it is not always easy to know what it can do, or how to tailor it to specific needs. This, together with the fact that GrimoireLab is for now a moving target, continuously evolving, may make it complex to use in some cases. Its community is already working on improving documentation, and keeping it updated, but still this may be an issue."
196543150,1/17,1.0,0.059,"The most classical measures for functional connectivity are correlation and coherence, which reflects the similarity between signals in the time and frequency domain, respectively. Intuitively speaking, coherence is a correlation of two signals in the frequency domain (15). Other connectivity measures consider the phase of the oscillations in the electrophysiological signals, the so-called measures of synchronization. The phase indicates whether the oscillation is at a specific time point t at a peak, trough, or transitions between these two states (such as for instance, zero crossings). If two signals exhibit the same phases at the same point in time, they are said to oscillate synchronously. Determining the phase of two signals allows calculating the difference in phase, the phase lag, which in turn may inform us about propagation effects, if the one signal exhibits a later phase than the other signal. The phase lag is suggested to reflect signal propagation and can be studied to examine effective connectivity. In addition to bivariate measures that consider pairs of signals, multivariate measures are designed in order to remove shared properties between multiple signals, such as, for example, partial coherence (16). Most measures of effective connectivity are described under the umbrella term Granger causality (17). This concept considers two signals X and Y and examines whether the activity at time point t of signal X can be predicted (statistically) by the activity at the earlier time points t-k of signal Y. Among them, partial directed coherence (18) and directed transfer function (19) are commonly used to study epilepsy. Next to these **data** driven analysis approaches, effective connectivity can also be estimated based on underlying biophysical models with a priori assumptions about the organization of the network as in Dynamic Causal Modeling (DCM) and other neural mass models. DCM in EEG or MEG takes biologically plausibility of causal models into account, and thus yields an informed estimate of connectivity (20)."
55648852,9/40,1.0,0.225,"We have used also the **data** recorded by the INGV permanent network operated by the Osservatorio Etneo (the INGV Etna Observatory; Figure 7). Seismic stations of this network are broadband three-component Nanometrics Trillium seismometers. These sensors have a period of 40 s, a flat frequency response from 0.025 Hz and a sensitivity of 1553 V/M/S. They register with a sample frequency of 100 Hz by a Nanometrics Trident digital system (24 bits). For TOMO-ETNA experiment we used the **data** registered in 71 seismic stations. The dataset is provided in DMX format, which is a simplified type of SUDS format. In this case, careful **data** processing was needed to transform DMX to a SAC format."
246165803,1/45,2.0,0.022,"Main V2I applications found in the literature revolve around: traffic solutions, secure communications for **data** privacy, and **data** processing. Traffic signal algorithms to control flow traffic have been studied [8], where simulations have shown a decrease in waiting time to almost 80% and reductions in travel time of 15%, compared to non-connected vehicle scenarios."
157096864,46/80,1.0,0.575,"Moscow is, no doubt, capable of launching a gray-zone or ambiguous conflict, but Ukraine indicates that it may be unable to control the course of such a war, particularly in the short term. It is impossible to say if Russian leaders will conclude that the attempts at political warfare and irregular warfare in Ukraine were ill-conceived or poorly executed-possibly both. If the purpose was to avoid escalation to a conventional war, then the operation failed. Moscow may conclude that repeating such an operation is too fraught with risk and unpredictability. However, Russia more likely will use the lessons from Ukraine to refine how it goes about political warfare, particularly where use of conventional force is prohibitive. Undoubtedly, the Ukraine case offers a significant amount of **data** and experience for Russia's military and civilian intelligence services: GRU, FSB, and SVR."
245105154,13/25,2.0,0.52,"Surprisingly, at the largest network size (of 2000 end devices) the proposed algorithm managed to achieve a DER above 0.5 and still maintain a 40% superior performance over the rest of the algorithms. This appealing performance of the proposed algorithm in dense network settings is owed to how it performs **data** rate optimization. The algorithm keeps track of the congestion statuses of each SF. And when optimizing the **data** rate for an end device, it uses the congestion statuses to find out which of the computed optimized **data** 6. Discussion"
2765985,2/7,1.0,0.286,"Rio et al explains the structure and organization of the networking code of Linux kernel 2.4.20 [2]. They explain the main **data** structure, the sub-IP layer, the IP layer, and two transport layers: TCP and UDP. This paper contributes our understanding of how the CLNP module can be integrated inside the Linux kernel, just like the IP module integrated in the same Linux kernel."
244631546,4/16,1.0,0.25,"This article uses a model that combines the seq2seq model with the attention mechanism. This model is very good at solving problems such as repetition and incompatibility in the generation of words and sentences. And the quality of abstract generation has been improved [8]. 1) seq2seq model The seq2seq model can be applied to tasks such as part-of-speech tagging, text summarization, translation, etc. The main research of this article is a text Summarization, the correspondence between the input sequence and the output sequence is not obvious. So the model in this article is built by two RNN (recurrent neural networks). An RNN is an encoder, it is responsible for encoding the input sequence X, convert the input sequence
1 2 3 X , , , , n x x x x = < … > into a
fixed-length semantic vector C, this process is a non-linear change. [6] Another RNN is decoder, It is responsible for generating the y-i to be generated at time I, it according to the semantic vector C and the generated information y 1 , y 2 , y 3 , …, y i-1 . Finally generated sequence ( )
1 2 3 C F , , , , n x x x x = … (1) ( ) 1 2 3 1 C, , , , , i i y G y y y y − = … (2)
The end-to-end process of this model combines semantic understanding and text generation. But in the coding stage, regardless of the length of the input sequence, the length of the output semantic vector C is fixed. This leads to **data** loss when generating sequences. Therefore, we introduce an attention mechanism in the seq2seq model to solve the problem [9]."
245105154,7/25,5.0,0.28,The authors used mathematical modelling to derive the fairest **data** rate distribution ratios and set up the ADR to use these ratios to make **data** rate optimization decisions.
245105154,7/25,6.0,0.28,"Kim and Yoo [9] discovered that the native ADR algorithm performed poorly under large LoRa network conditions. They found that the algorithm reduced the network's overall throughput. To mitigate this problem, the authors proposed a contention-aware approach to the ADR. The solution used the gradient projection method to compute optimized **data** rate distributions that optimized throughput for each **data** rate group. This in turn reduced network contention and optimized the overall network throughput. The solution was evaluated using simulation representing the European ISM band with a one per cent duty cycle. The simulation networks consisted of 5 to 10,000 end devices each transmitting 50 to 100 bytes of data. The evaluation was based on throughput and its effectiveness was compared against the traditional ADR algorithm and to a version of the ADR with a balanced number of end devices (NEDs) in each **data** rate group. The proposed solution outperformed the traditional ADR algorithm in terms of overall network throughput, however, the solution performed poorly in terms of end device transmission success rate. Hence, in terms of transmission reliability, the solution still needs to be improved."
252835989,4/53,1.0,0.075,"The complete automation of smart farming is achieved by ISO 7798-2 security specifica tions-heterogeneous swarms are used in cloud middleware to operate drones, autonomous vehicles, etc. Autonomous-vehicle secure connectivity using IoT devices and key management framework is demonstrated by Jha S. et al. [22]. The vehicular network authentication is performed by blockchain based on hash graphs that can perform thousands of transactions per second and a framework designed using batch rekeying and logical key hierarchy (LKH). The 5G cooperative autonomous connectedness and driving is presented by Bagheri H. et al. [23]. This system uses 5G-based extensive authentication protocol (EAP) supporting 3GPP and non-3GPP communication networks, independent access, and mobility management function with session management function. The autonomous communication within the P2P network is demonstrated by Rahmani L. et al. [24]. A distributed hash table for agent lookup is shared by all the communicating agents and uses public-key cryptography for secure P2P communication with end-to-end encryption. An IoT mutual authentication protocol for Things-To-Things (T2T) is presented by Lounis K. et al. [25]. The T2T protocol uses physical unclonable functions (PUFs) with dual-level-challenge response pairs for the IoT authentication. V2X communication-based efficient authentication for protection against DDOS is demonstrated by Ko T. et al. [26]. The V2X system uses a security credential management system (SCMS), which classifies multiple similar messages in different categories for authentication and uses advanced verify-on-demand (AVoD) for signature verification with threat analysis. An improved isolation forest method for autonomous-vehicles-attack detection is presented by X. Duan et al. [27]. The detection of data-tampering attack is performed here using **data** mass and scoring for anomaly detection as a part of intrusion detection. An autonomous vehicle smart-parking system with the fog-blockchain architecture is presented by Shahzad A. et al. [28]. Smart parking helps to recognize the parking location with the help of fog nodes to IoT, the proof-of-concept by lightweight blockchain and a cryptographic module is utilized. Blockchain-based autonomous vehicle platoon management in 5G is demonstrated by Wu B. et al. [29]. This real-time system improves traffic management with public-key cryptography and 5Genabled revocable attribute-based encryption (RABE) with key distribution and revocation. P2P drone communication using blockchain is presented by Kumar M.S. et al. [30]. The drone base communication uses blockchain with GPS coordinates to avoid spoofing attacks and keeps the blacklisted database."
246337567,64/70,1.0,0.914,"Transform bib-
liographic and 
authority **data** "
233705419,18/53,1.0,0.34,"Based on the collected measurement **data** and the formalized expert knowledge, the implemented AI-based algorithm can be used to quantify and intuitively visualize the relationships in the measurement data."
135401293,1/16,1.0,0.062,"The methyl or ethyl esters of fatty acids are commonly termed as ""biodiesel"". The biodiesels made from vegetable oils, because of good property and quality, can be adequately used in diesel engines [1]. Biodiesel has been considered as an ideal alternative for diesel fuel because of its environmental friendly property and it has huge potential to provide comparable engine performance results. Biogas and Natural gases can be the better substitute fuel for gasoline engine and diesel engine engines [2,3]. Many research **data** propose that it is achievable to enhance the compression ratio of biogas fuelled engine when CO2 is present in biogas [4,5]. When bio fuels are used, it releases only fractional amount of carbon in its emission [6], so that biogas can be used for heating purposes, power generation etc. [7,8]. Usage of biogas in engine promote the engine efficiency because of complete combustion in the engine cylinder [9]."
233705419,1/53,2.0,0.019,"Processes 2021, 9, x FOR PEER REVIEW 2 of 13 In this paper, the focus is on the formalization of expert knowledge and its use for test design and integration into different machine learning (ML) algorithms. The formalization of expert knowledge from different domains (e.g., expertise regarding plant mechanical processes and knowledge about thermo-chemical and other physical mechanisms of chemical processes) is particularly challenging and reveals the uniqueness of the presented approach. Due to the lack of data, deep neuronal networks cannot always be trained, and other ML algorithms must be combined to quantify and expand expert knowledge from different domains. Figure 1 shows the continuous learning procedure and the interaction between the different parts of an AI-based hybrid model, i.e., **data** measurement, expert knowledge, and ML algorithms with special metrics for automated evaluation (autoML) [5]. With this procedure, expert knowledge can be continuously quantified, and the understanding of the plant and chemical processes can be expanded. Along with a cloud-based IT solution from Engineering Data Intelligence (EDI Ltd., Pfinztal-Berghausen, Germany) called the ""EDI hive Internet of things (IoT) Framework"" (short EDI hive), the process of capturing expert knowledge and the integration of process engineering fundamentals, AI-based modeling, and the subsequent application of the AIbased hybrid model in power plant operation can be achieved. In this paper, the advantages of AI-based hybrid models in industrial applications are discussed, the experimental results are presented together with the modeling results, and the continuous software-based support of this process through EDI hive is demonstrated."
249258070,43/119,1.0,0.361,"Law enforcement executives have noted the impact of the pandemic on police activities. Based on survey **data** collected from 989 US and Canadian executive officers who are members of the IACP, Lum et al. (2020a) noted several reported changes in police operations during the initial months of the pandemic. By March 23, 2020, 43% of responding agencies stopped or significantly changed their responses to CFS, 57% reported a decline in CFS, 61% implemented policies to reduce proactive stops, and 73% limited community policing activities. As of May 10, 2020, a second survey wave indicated that 53% of the responding agencies continued to have policies that limited proactivity, and 64% were still limiting community-oriented policing activities-both slight decreases from wave 1 (Lum, Maupin, & Stoltz, 2020b)."
239039030,6/23,1.0,0.261,"The proposed framework is working on the edge computing architecture consisting of three entities: the mobile edge devices, remote edge server, and wireless AP. In mobile edge devices, the image **data** are captured using a camera module attached to the edge device. Subsequently, it is resized and normalized to fit the predefined input shape of the object detection DNN model. Then, the DNN inference, which can be executed using two methods, is performed to detect the location and classification of the objects included in the image. First, the edge devices are capable of offloading the DNN inference tasks to the edge server, which is called DNN offloading. Second, edge devices are capable of processing the DNN inference tasks under the assumption that the edge devices are equipped with a lightweight GPU hardware."
246337567,17/70,1.0,0.243,"NAISC-L **data** is stored in a relational database (RDB) and is uplifted to RDF using R2RML, a W3C Recommendation used to express mappings from RDBs to RDF (Das et al. 2012). NAISC-L's Knowledge Organisation, detailed in Sect. 4.4.1, consists of three named graphs-an interlink graph, a provenance graph and a relationship graph. The **data** for each graph are uplifted to RDF using a separate R2RML mapping. These mappings were created using the JUMA mapping tool (Crotti et al. 2018). The graphs can be viewed and downloaded in different RDF serialisation formats. The graphs can also be explored via interactive visualisations generated using GoJS. 16 The interlinking framework should facilitate the creaƟon of idenƟty and relaƟonship links."
249538382,11/22,5.0,0.5,"In this setting, we conduct multiple **data** generation runs in the SAPs R/3 on HANA ERP system together with ERPsim R11.2 with a group of 5 research participants. We let the group play the game twice, obtaining a run of exclusively normal operation (normal 1) as well as a run that has fraudulent activities incorporated next to normal business processes (fraud 1). To obtain differing company characteristics such as varying business strategies and user behavior, we additionally select a second group of participants to generate data. Our second group of participants generate one run of normal operation (normal 2) and two individual runs containing different fraud cases (fraud 2, 3), resulting in 3 datasets, each simulating one financial year."
246165803,10/45,1.0,0.222,"The RSU was built using a raspberry Pi, with the server's software built-in with Python. Before the **data** were processed, they were saved in CSV format, with the latitude and longitude of each packet and a timestamp for future reference. "
27068907,9/25,2.0,0.36,"In a single reception and transmission, the **data** frame is only 8 bytes. See Table 3 for the format of the **data** frame. Specifically, the first two bytes are respectively the **data** head and the command code, and the last byte is the end-of-string identifier 0xaa. As for the sent **data** frame, the meaning of the first two bytes remain the same, while the third byte is different from that of the received **data** frame.    Each reading and writing via SPI contains 16 bits: 1 bit for the select bit, 7 bits for the address and 8 bits for the data. The R/W select bit is used to identify the reading and writing operations. 1 stands for reading, and 0 stands for writing."
249538382,11/22,1.0,0.5,"Using our proposed **data** generation process and the collected frauds, we conduct multiple runs of the ERPsim game to generate ERP system data, with each run generating **data** of one fiscal year of operation. Runs are played by five research participants with an information systems background. Participants are instructed on the business process specifics of the company modeled within ERPsim and adopt the roles described in Section 2.2."
229483030,9/10,1.0,0.9,"Pilot projects provide a means to test and disseminate future solutions, but an understanding of places as something more than where performance **data** can be extracted is essential [22]. Analysing the stories that are told about Lø can help us to understand what kind of support is needed in the early stages of a project. This case highlights the importance of the early establishment of forums for engagement and information exchange where new solutions appear realistic and relevant for the citizens and the local context. The most important goal of such forums would be to synchronize the various stories told about the future zero emission neighbourhood. At Lø, the ZEN centre could have worked much more actively to inscribe itself into the site's ongoing story. In addition, the future occupants should have been included as actors in the pilot story -from early on -instead as passive recipients. It will always be possible to tell different stories about a specific building or neighbourhood development. But if two central stories are allowed to drift too far apart, one of them will have an unhappy ending."
225958729,9/13,1.0,0.692,"In the cloud computing environment, once the emergence of computer network problems happen, users will be directly affected . To avoid user **data** theft, damage and other situations, it is necessary to strengthen the user awareness of prevention optimization. Through training, publicity and other forms of education can gradually enhance the user's computer security awareness. By raising the awareness of precaution, it can ensure the correctness of operation, reduce the occurrence of all kinds of security problems comprehensively, and maintain the stable operation of the computer."
549001,2/36,2.0,0.056,"At the end of the computation, machines collectively output the solution. The **data** output by each machine has to fit in its local memory. Hence again, each machine can output at most S words."
216374957,4/27,1.0,0.148,Key parameters of tunnel cross passages can be determined in 4 steps: collect basic **data** on the tunnel; preliminarily determine design parameters of cross passages; evaluate safety risks of tunnel evacuation; and analyze risk evaluation results. The flowchart is given in Fig. 1.
236196766,7/47,3.0,0.149,"Contributors growth (shown as illustration in Fig. 12 6 ): total number of contributors, active contributors over time, contributors growth by repository, difference with average of active contributors over time. This panel is offered for most of the **data** sources (Git, GitHub issues, GitHub pull requests, Gerrit, Bugzilla, Jira, mailing lists, etc), and in each case ""contributor"" is defined accordingly to the actions in that kind of repository (for Git, it is commit authors, for Bugzilla it is issue reporters, for GitHub pull requests is the pull requester, etc.). Bugzilla timing 7 : median and 80% percentile of open time, evolution of the status of issues over time, issues by resolution and issues by severity, evolution of the number of issue submitters over time, table with main submitters, table with latest issues, etc. Similar panels are provided for other issue tracking systems and code review systems. Gerrit efficiency 8 : review efficiency index (number of closed divided by open changesets), average and median time to merge, over time. Similar panels are provided for other code review systems. Jenkins jobs 9 : total number of builds, jobs, active nodes; proportion of build results; evolution of jobs over time: table with builds, durations, success status per job."
2423505,14/23,1.0,0.609,"• We then utilize the information that these subspaces convey on the labeled X, and learn a discriminative classifier to predict the labels ofX. Furthermore, we illustrate the capability of our method for handling multiple source and target domains, and in accommodating labeled **data** in the target, if any."
85554746,1/19,2.0,0.053,(i) to highlight the need for an integrated RI to provide GHG and related environmental **data** with enhanced coverage across Africa;
248858280,24/24,2.0,1.0,"Theta range for **data** collection 
1.40 to 27.48˚. "
246337567,18/70,1.0,0.257,"The NAISC-L Tool consists of an approach to knowledge organisation, a provenance **data** model and a GUI, all of which are detailed below."
236196766,25/47,5.0,0.532,"GrimoireLab is managed as an open free, open source software project, with a public roadmap, and all contributions managed through pull requests in GitHub. The project documents how to contribute to it, and in fact some important contributions (such as partial support for some **data** sources) have been received by the core team of developers. Researchers and developers of any kind are welcome to propose their patches fixing errors or providing new features."
236196766,13/47,6.0,0.277,"Dataset about all the projects hosted by the Apache Foundation Research objective: To produce a dataset that may help to better understand software development processes used in Apache projects. Example of RQ: Which ones are the different patterns of joining and leaving Apache projects? Method: Obtain the description of all the Apache projects, maintained by the Apache Foundation. Since this description includes links to all **data** sources (and repositories) used by those projects, produce a comprehensive list of all repositories that should be visited to maintain the dataset. Then, do a first retrieval of **data** from all of them, update it by frequent periodic visits, and dump it in a file that can be easily shared with researchers. Apache projects use, in different projects, Git repositories, GitHub projects for issues and pull requests, Bugzilla for issues, and change requests, mailing lists, and some other kinds of **data** sources, thus all of them need to be mined."
12790199,10/21,1.0,0.476,"The belief context consists of interaction processes, their interaction histories, and associated expectation **data** (discussed further at the end of this section), organized into object schemas. Each object schema's contents represent a set of beliefs that is probably about a real physical object. For instance, a visual tracker and its history **data** manages and contains a set of beliefs that include the location, color, and shape of an object. Similarly, an inactive action process for performing a grasp is associated with an expected success likelihood, which constitutes a belief about the graspability of the object."
12790199,12/21,1.0,0.571,"robot's fingers frequently, leading to a low success expectation for future lifting of heavy objects (sometimes we handpick the instances to be stored by the system, to prevent persistent sensorimotor failures from skewing success expectations). These statistics in turn affect the planning system's decision-making, and allow attributes to be directly linked to the affordances of each object, rather than merely being static **data** used for labeling purposes. Object schemas provide a discrete organization scheme for these statistics, which are then used by the planning system."
238719786,1/14,1.0,0.071,"The universal serial bus (USB) interface is used as a standard type of interface in many different kinds of devices for the transmission of data. The **data** transfer rate, low power and ease to use are the key features that made USB as an industry standard **data** transmission interface. Hot plugging can be achieved automatically in USB interface. Without shutting down the system, USB can connect the computer with electronic devices. A RS232 dependent system can be easily portable to USB interface by using embedded RS232 to USB converter. To bridge the difference in **data** rates among the 2 interfaces first-in first-out (FIFO) logic is used. The study of USB protocol with an FPGA development board is important. The USB standard interface broadly has 2 units, Parallel interface engine (PIE) and USB transceiver macro cell interface (UTMI). PIE is accountable for packet extraction or construction and also responsible for the communication with the peripherals. UTMI is connected to USB cables and are used for transmission of serial **data** and for synchronization of time frames. The serial interface engine (SIE) has two sub-blocks, Endpoint Logic sub-block and SIE control sub-block. The endpoint logic block has, FIFO, FIFO logic and endpoint number recognition. The SIE block has sequencing logic for USB packets and transactions managing, logic of address recognition and USB product identification logic (PID). SIE blocks lies in between the processing unit of computer and UTMI. It receives the **data** from the computer processor and transmits to the UTMI. The UTMI unit does clock synchronization, clock recovery, bit stuffing, **data** serialization and deserialization. UTMI uses differential signals to transmit **data** from one USB to other USB compactable device."
249258070,1/119,1.0,0.008,"The current inquiry adds to the body of knowledge in this area by exploring potential changes to both reactive and proactive officer activities brought on by the pandemic using CFS **data** from Houston, Texas collected from January 1, 2018 through December 31, 2020. This study is informed by routine activity theory and perspectives on proactive policing. Trends are examined for seven different call types: violent crime, property offenses, disorder incidents, suspicious incidents, traffic-related activities, service-related activities, and non-crime events. In doing so, observed trends can be compared to the other large jurisdictions to further our understanding of how the pandemic has impacted demands for police services (e.g., Ashby, 2020). We also examine trends in officer proactivity through officer-initiated activities identified in the CFS **data** performed by three units: patrol, specialized crime investigation units, and the department's specialized response unit. This provides a unique look into how COVID-19 may have influenced officer-initiated activities."
248392338,7/27,3.0,0.259,"Example of pre-processing. For illustration purposes, we convey an example on clustering of the ""not yes"" option text feature. During the **data** collection, the text that indicates an alternative to accepting consent was collected as a separate text feature regardless of whether the text appeared on a button or as link."
238019744,2/8,1.0,0.25,"Comparing the optimization results in Table 1 with those in Fig. 4, we find that the optimal sleep parameters obtained by the improved FA are consistent with the global optimal points observed in Fig. 4. Therefore, we can verify that for the cloud computing system considered in this paper, the optimal results obtained by the improved FA are the global optimal values. 7. Conclusion. In this paper, we evaluated and optimized the energy-saving mechanism considering the correlation in cloud traffic. We considered the correlated arrival of cloud **data** requests affected by the random cloud environment to follow a Markovian Arrival Process (MAP), and established a MAP/M/N /N +K queue with a synchronous multi-vacation accordingly to analyze the system performance. Based on the system analysis in the steady state, two performance measures, namely, the energy saving rate of the system and the average latency of tasks with the energysaving mechanism were derived. For the correlated traffic in a random cloud environment, numerical experiments were carried out to illustrate the change trends for the average latency for tasks and the energy saving rate of the system. A cost function taking sleep parameters as an argument was constructed to balance different performance measures. Furthermore, we designed an improved FA to optimize the energy-saving mechanism. Optimization results show that an appropriate increase in the VM-number deployed in a PM will minimize the system cost."
249258070,83/119,2.0,0.697,"Additionally, Maskály et al. (2021) collected survey **data** from police executives in 27 countries around the world to assess the effects of COVID-19 on police organizations and activities. Their findings indicated that, by summer 2020, responding organizations experienced at least some changes to problem-solving or community policing activities (83%), patrol strategies (78.3%), traffic stops (68.2%), officer-initiated activities (60.9%), special operations teams' activities (54.1%), handling CFS (43.4%), and use of tactical teams (34.8%). Collectively, these results demonstrate that routine police activities have been impacted by the COVID-19 pandemic. Such changes have also led to empirical investigations of how police activities have changed since the start of the pandemic."
55648852,20/40,1.0,0.5,"The first step was the unification of the **data** formats, because all the seismic **data** are recorded in a dif- ferent formats depending on the station features (shortperiod, broadband, OBS, etc.). This procedure is not as easy as it may seem, since it is a very sensitive procedure. In the following paragraphs the different original formats and their conversion are detailed. Our preferred format to work with is .mat (matlab) so that we can process the **data** in a less time-consuming way."
54551628,15/17,1.0,0.882,"Krakauer and colleagues bolstered their experimental fi ndings by comparing them with a statistical model of movements of the arm and wrist. The model uses a Bayesian approach, where previous experience and new **data** are combined to form a new parameter estimate. A key aspect of this approach is that greater uncertainty about the parameter leads to faster learning. Crucially, in their model, the investigators assumed that the majority of movements with the arm also include moving the wrist, but not vice versa. This led to a situation where the uncertainty in the parameter estimate-the imposed rotationdepended not only on the current limb context but also on the history of training in previous limb contexts. The model was able to reproduce most of the effects they saw in the experiments, such as the fi nding that learning would transfer from arm to wrist, but not vice versa, and blocking of generalization."
248392338,1/27,5.0,0.037,"We discuss why attempts at automated dark patterns detection such as ours are still insufficient. While our attempt exposes many limitations to the automated detection of dark patterns, it also offers valuable lessons on how we can make progress. Towards this goal, we have made our code, prediction models and **data** available for anyone to build upon our efforts. We argue that the automatic detection of dark patterns requires not only machine learning, but also refinement of the concept of dark patterns and consequently improvements in regulatory initiatives."
244631546,4/16,2.0,0.25,"First step, define an information element in the output sequence of the decoder as ""Query"", the sequence information in the encoder input sequence as a    ""key"". The ""value"" usually represents the sequence information with the same key (it is the semantic code corresponding to each word in the input sentence). That is to say, the input sequence is composed of ""key-value"" **data** pairs. The second step is to calculate the attention weight coefficient. First calculate the similarity of key and value. Then normalize the calculated similarity. The final result is the normalized coefficient, which is the weight coefficient i a ."
24456035,3/42,1.0,0.071,"Averaging methods determine baselines by averaging the consumption on past days that are similar (ex: in temperature or workday) to the event day. There are many variants such as weighted averaging and using an adjustment factor to account for variations between the event day and prior similar days. A detailed comparison of different averaging methods in offered in [8] [9] [10]. While averaging methods are attractive because of their simplicity, they suffer from estimation biases that can be substantial [10] [11]. Also, these methods require significant **data** access, especially for residential DR programs [12]."
59624,12/19,2.0,0.632,"Note that the goal in these arrays is not to proceed to a deep analysis of each of the mentioned points; in particular, the aim is not to consider the causes of the causes but to synthesize the main **data** in order to obtain a system analysis."
14392421,11/15,1.0,0.733,"For hard partitions, nodes in small communities are simply partitioned into their ""closest"" detected cluster, which will certainly result in a loss of accuracy for the final results. Credal partitions make cautious decisions by clustering nodes which we are uncertain into imprecise communities. The introduced imprecise clusters can avoid the risk to group a node into a specific class without strong belief. In other words, a **data** pair can be clustered into the same specific group only when we are quite confident and thus the misclassification rate will be reduced. "
236196766,4/47,9.0,0.085,"Full-size  DOI: 10.7717/peerj-cs.601/ fig-6 writers, making it possible to live-stream **data** or serialize it to database management systems. See an overview of the structure of Arthur in Fig. 7."
49293274,1/14,1.0,0.071,"In online (digital) advertising, ""third-party"" **data** vendors provide streams of anonymized unique user identifiers (UUID) along with their alleged attributes for use in deciding which users to buy advertisements for."
146120626,1/8,1.0,0.125,"The consequences of using the current h values for the historic ones at the time of a paper's publication when calculating h α are, in fact, poorly understood and closely related to the time dependence of h for individual scientists. In the present work, we show that historical h values can be readily calculated using retrievable **data** from Web of Science and we study the time dependence of h for a large number of condensed matter physicists. We show that the average of h over a larger population does indeed show a roughly linear time dependence, but this does not hold on the level of individual scientists. Given the relative ease of calculating historical h values, the definition of h α could thus be modified such that the α-author is determined at the time of a paper's publication. However, a more severe practical problem with h α is that it is extremely difficult to calculate due to (co-)author name disambiguation. arXiv:1905.01943v1 [cs.DL] 6 May 2019"
119335883,1/26,1.0,0.038,"Irregularly shaped districts have long been a hallmark of gerrymandering in American democracy. Unfortunately, determining which shapes are justifiable and appropriate is surprisingly nuanced (see, for example, [3]). Furthermore, the fine-grained demographic **data** available to modern mapmakers enables them to achieve partisan aims even when constrained to reasonable shapes. There is still a need for robust tools capable of measuring how fair or unfair a redistricting plan is in terms of its partisan effects."
246165803,11/45,1.0,0.244,"We carried out concurrent programming to ensure a better data-collection rate, and a buffer was implemented to obtain a significant amount of **data** while handovers or a wireless disconnection occurred."
134689280,4/20,1.0,0.2,"More elaborate use of symbology may exist to distinguish kinds of lines, but predominantly the occurrence and shape of archaeological traces of spatial transformations are visually represented by lines. Thus, the end user or interpretive analyst would likely encounter archaeological evidence of built space as lines on maps when acquiring spatial data. This confronts us with a twofold heuristic challenge: First, how much do we actually know about the empirical (physical) reality these lines convey as archaeological evidence? Second, how do we get to the entities shaped by linked-up boundaries on the human scale of occupiable spatial subdivisions? This will highlight limitations to the usability of information contained in archaeological spatial **data** which are not necessarily new, but are seldomly made explicit. The first consideration regards the physical characteristics and condition behind the classification that is implied by any line mapped as archaeological evidence. We can commonsensically acknowledge the heterogeneity of any construction in both the technique and materials used (e.g. bricks and mortar). Even cyclopean masonry (e.g. Mycenaean and Inca architecture) does not render a constant surface. Yet, a line suggests that the physical characteristics along its course remain the same. Especially when architecture is concerned, it invokes the impression of the regular and constant vertical faces of modern construction we are used to, obscuring any specification of the physical characteristics that may afford human beings a different relationship with that spatial distinction. Lines also suggest a parity of physical conditions that applies along all full lengths. The same visual style of line can be used from archaeological feature to archaeological feature, whereas we know that preservation is rarely equal throughout a site. Beyond environmental forces and historical events acting on spatial constructions, the original characteristics of building and engineering may have influenced how spatial constructions appear as an archaeological trace. On top of this ambiguity, which is by and large intrinsic to archaeological evidence, very often the same style line can be used for multiple conditions and situations within a single plan."
249538382,1/22,1.0,0.045,"The association of certified fraud examiners defines occupational fraud as abusing one's occupation through the deliberate abuse of an employing organization's assets, and estimates that currently companies lose 5% of their revenue to this type of fraud [1]. To reduce the loss of revenue to occupational fraud, researchers have in the past suggested to use the **data** contained within ERP systems to detect fraudulent activity [18,17,12]. ERP systems are a core component for managing the flows of cash, materials, production and other resources within companies. They represent a large market with 37, 679.26 Mio. USD worldwide revenue in 2020, and support most medium-sized and large companies in their daily work [6,20]."
249538382,14/22,1.0,0.636,"With companies keeping a lock on ERP system **data** due to privacy and trade secrets concerns, researchers in the area of occupational fraud detection have in the past turned to synthetic **data** generation for validating their work. Previous works in this area however did not provide **data** to the public, limiting open and reproducible research on detecting fraud in ERP systems."
236196766,5/47,3.0,0.106,"GrimoireELK is the main actor of this area, interacting with the database. Its design is shown in Fig. 8. A feeder collects JSON documents produced by the **data** retrieval, storing them as the raw database (in an Elasticsearch index). Dumps of this raw **data** can be easily created to make any analysis reproducible, or to analyze directly with third party tools."
248392338,20/27,4.0,0.741,"
Features. The used dataset of Soe et al. (2020) contains many interesting and potentially relevant features for dark pattern detection. The list of available features in the Soe et al. (2020) dataset and their **data** types are: 1. Site ID (siteid) -the identifying name of the website;
"
236196766,43/47,1.0,0.915,"Table 2
2Main stages of **data** collection and enrichment for the IoT repositories case.Elapsed time "
146010542,12/17,1.0,0.706,Identification is a process of identification OF internal and external weaknesses or risks. It contains knowledge about: personnel and their abilities to recognize risks; systems; **data** and other elements that can cause a risk due to disruption of normal IT process within the company.
52064012,9/16,1.0,0.562,"In  [69]. They are large precautionary areas, each 400 km 2 with an inner core zone and surrounding buffer intended to protect the core, and minimum viable population sizes, from any sediment plume caused by mining. The nine APEIs allow for biogeographic representation based on three north-south and three east-west strata, reflecting strong productivity-driven gradients, in the absence of detailed **data** on the composition and distribution of benthic communities [78]. The APEIs also recognize high diversity of fragile fauna that will be very slow to recover from any mining impacts [3]. [39] highlight the fact that 'whilst contractors gather environmental and technical information on an annual basis, and report to ISA for the purposes of constructing a common baseline within their license areas, an 'Achilles heel' of the CCZ-EMP is that there is no requirement or incentive for contractors to carry out similar surveys in APEI's. Further to an interim preliminary evaluation report [68], in 2016 the ISA Legal and Technical Commission (LTC) also undertook an initial review of the current status of management implementation of the CCZ-EMP (ISBA/ 22/LTC/12). Other than workshops convened to consider specific taxa, implementation measures (such as **data** standardization and taxonomic inter-calibration and contractor plans and measures to ensure habitat and faunal recovery) have not been undertaken. LTC recommended the creation of two additional APEIs, workshops on APEI effectiveness and Impact Reference Zones 25 /Preservation Reference Zones 26 and the 25 Impact Reference Zones are ""Areas which are representative of the environmental characteristics of a particular region to be used for assessing the effect of activities in that region on the marine environment."" (ISA, < https://www.isa.org.jm/impact-referencezone >). 26 Preservation Reference Zones are ""Areas representative of the mine site in which no mining shall occur to ensure representative and stable biota of the seabed in order to assess any changes in the flora and fauna of the marine environment caused by mining activities."" (ISA, < https://www.isa.org.jm/preservation-reference-zone >)."
2423505,17/23,1.0,0.739,"In this section, we discuss the concept of multi-modal learning. In this setting, correspondences are assumed to be on instance, rather then category, level. Also, here it is commonly assumed ample train **data** is available in both domains. Similarly to Sec. 5, the common goal of most methods is to estimate transformations L t nad L s so that P s ((X T L s = x|Y = k) = P t (X T L t = x|Y = k). This can be done by letting e.g. L s = I, thus mapping the target domain to the source domain, or vice versa. One could also consider mapping both spaces into a common space. We will begin this section by reviewing Canonical Correlation Analysis, Principal Component Analysis, Linear Discriminant Analysis. We then consider recent work utilizing these methods [Sharma et al., 2012]."
249258070,3/119,1.0,0.025,"Law enforcement executives have noted the impact of the pandemic on police activities. Based on survey **data** collected from 989 US and Canadian executive officers who are members of the IACP, Lum et al. (2020a) noted several reported changes in police operations during the initial months of the pandemic. By March 23, 2020, 43% of responding agencies stopped or significantly changed their responses to CFS, 57% reported a decline in CFS, 61% implemented policies to reduce proactive stops, and 73% limited community policing activities. As of May 10, 2020, a second survey wave indicated that 53% of the responding agencies continued to have policies that limited proactivity, and 64% were still limiting community-oriented policing activities-both slight decreases from wave 1 (Lum, Maupin, & Stoltz, 2020b)."
249258070,3/119,2.0,0.025,"Additionally, Maskály et al. (2021) collected survey **data** from police executives in 27 countries around the world to assess the effects of COVID-19 on police organizations and activities. Their findings indicated that, by summer 2020, responding organizations experienced at least some changes to problem-solving or community policing activities (83%), patrol strategies (78.3%), traffic stops (68.2%), officer-initiated activities (60.9%), special operations teams' activities (54.1%), handling CFS (43.4%), and use of tactical teams (34.8%). Collectively, these results demonstrate that routine police activities have been impacted by the COVID-19 pandemic. Such changes have also led to empirical investigations of how police activities have changed since the start of the pandemic."
246165803,25/45,4.0,0.556,"The KNN classifier's most common issue was mislabeling other classes, or neighbors, into curves. However, with only one physical example, **data** with a more varied power spectrum were more likely to fall into that category. The ANN classifier failed to accurately detect much of the **data** without distinction. One of the main problems of the classifier could be the sensitivity to scaling."
565361,11/29,1.0,0.379,"For colorimeters and color cameras, the stimulus is normally a luminous object or an object illuminated by an illuminant external to the device. For these devices, the product, (or its equivalent), defines the spectral radiance whose color is to be recorded. From the model in (26), it can inferred that in the absence of noise, exact CIE XYZ tristimulus values can be obtained from the **data** recorded by colorimeters and color cameras if there exists a transformation that transforms the sensor response matrix, , into the matrix of CIE XYZ color matching functions, [38]. This is equivalent to the requirement that the HVSS be contained in the sensor visual space defined as the column space of [26]. For devices using three channels, this reduces to the requirement that be a nonsingular linear transformation of . This fact has been known for some time and is referred to as the Luther-Ives condition [197], [198]. Recent reiterations of this result can be found in [199] and [200]. A device that satisfies (generalizations of) the Luther-Ives condition will be said to be colorimetric."
249538382,1/22,7.0,0.045,"-We propose a strategy for **data** generation that simulates normal behavior and fraud jointly through user interaction within a real ERP system and is capable of modeling frauds and normal behavior in the P2P and O2C business processes. -We conduct multiple simulation runs and construct ready to use datasets with detailed fraud annotations that allow for direct application and comparison of ERP fraud detection approaches. -Finally, we provide both raw **data** and ready to use datasets to the general public to allow for open comparability of ERP fraud detection systems. 3 The remaining paper is structured as follows: Section 2 outlines the requirements for **data** generation, introduces our **data** generator, showcases the modelled business scenario and chosen fraud cases, and details the **data** generation process. Section 3 presents an analysis on the collected data, while Section 4 aggregates parts of the **data** into ready to use datasets for direct use in fraud detection applications. Section 5 concludes the paper. Empirical realism: We generate our **data** directly within a real ERP system modeling a production company in a realistic profit maximization setting."
134689280,6/20,1.0,0.3,"Until now we have been using the term archaeological traces to characterise archaeological evidence, whereas it was proposed that at the human scale information on built environments should distinguish discrete occupiable spaces. Lucas (2015) cautions against the dominant view of archaeological evidence as fragments. However, it is fair to say that there is an important discrepancy in terms of completeness between traces of a built environment and spaces of a built environment. We know that due to site formation processes, there is no perfect preservation of past situations. Yet, social interpretations in archaeology are usually concerned with understanding situations that occurred in the past. By stating 'finding remnants of an assemblage is not the same as finding an assemblage itself', Lucas (2015: 321) urges us to reflect on what survives: archaeological evidence seen as relics. In the context of going from traces to spaces, metaphorically a past lost to a past found, the resolve lies in redressing fragments as surviving traces of entities from a past situation. 4 Following the 3 It may be worth mentioning here that with new recording technologies, especially high-resolution 3D photogrammetry and laser scanning or LiDAR, a cleanly presented 2D archaeological map as end product could systematically refer back to the much fuller source of information of the original digital records. Kyriakidis E (2016, personal communication) argued the advantages of a similar workflow for digitally producing the 2D map of ancient Eleusis from 3D information. If we can ensure **data** lineages through stable links and unique identifiers, this may prove a significant advantage in the future. Providing a **data** lineage still does not exonerate us from a responsibility to produce our mapped interpretations with the most complete and usable information in flexible and readable formats. 4 It should be acknowledged that this is not an argument against the truism that interpretations of the past are a product of the present. However, it is asserted here that a different kind of knowledge is produced from a strict adherence to Lucas' (2015) alternative of seeing material evidence as relics (evidence of why things survive), which suggests a focus on the formation, meaning, and relevance of archaeological traces as entities in and of themselves."
246165803,26/45,2.0,0.578,"For a low-complexity MLA, the **data** may be sufficient to obtain an acceptable prediction. However, for any DeepLearning solution, the **data** are frankly insufficient to take advantage of this type of algorithm. In addition, the number of anomalies is very limited due to the lack of a classification of anomalies and healthy streets' **data** and the volume of **data** that are necessary to define clear differences between each of them from the spectral footprints."
41857677,14/41,1.0,0.341,Software Defined Networking (SDN) enables the remote management of **data** plane to be done by third-party software. The flexibility offered by SDN can be more extended by implementing Network Functions Virtualization. Where Network Service Providers can easily virtualize most of the network features using cloud-based API. More services like NaaS and IaaS can be also provided using SDN application.
5803875,33/49,1.0,0.673,"Figure 3 :
3Example showing direction of BGP announcement and direction of observed detourFigure 3illustrates detours. AS0 announces prefix a.b.c.0/24 to AS1, AS2 and AS3. AS1 geolocates to JP whereas AS3, AS2 and AS0 are in the US. In this case, **data** traversing from AS3 to AS0 will contain a detour from AS2 (Detour Origin) to AS1 (Detour Destination). We do not include sub-paths in our analysis; other portions of the path that may experience a detour. For example, in path AS1{US}-AS2{IN}-AS3{CN}-AS4{IN}-AS5{US}, we only count the detour US-IN-US. We do not count the detour IN-CN-IN."
249538382,10/22,2.0,0.455,"After the preliminary selection of three fraud cases from Baader et al. [4], we select nine additional fraud scenarios to match our identified requirements. Here we select appropriate fraud scenarios from the ACFE's report to the nations [1] in cooperation with business auditing experts. Since, in contrast to Baader et al. [4], our **data** generation approach is also capable of modeling the entire O2C business process, we additionally take care to include fraud scenarios that are conducted within the O2C process."
234551871,7/11,1.0,0.636,"Today's **data** need more security is very important to all the areas in the world. For example, bank analysed data, social media analysed data, personal storage data, credit and debit card analysed data, and machine learning algorithm prediction data. To overcome these problem to apply the ChaCha method. This method done only encryption speed with tiny bit **data** security. So we proposed novel algorithm is RBJ25, it has three part proposed algorithm each layer carrying out some operations in the encryption and decryption part to increase the resistance of the algorithm in such a way that the protection of the **data** is increased along with effective authentication. Finally the proposed algorithm is implemented using Python and analysed through comparison with traditional AES algorithm and chacha20 security algorithm. In the future, to add the prime factors operations of the **data** security in the RB26 method for upcoming journals. 
"
3640435,8/47,1.0,0.17,"While R could technically be analytically approximated using deep expert knowledge, doing so could reduce its portability -let alone performance portability -across alternative and future microarchitectures. In this paper, we propose to learn R automatically from a large amount of benchmarking **data** obtained via the following statistical process."
238719786,3/14,1.0,0.214,"Power representation Polynomial representation Power representation Polynomial representation
0 0 β 7 β 3 + β+1 β 0 1 β 8 β 2 +1 β 1 β β 9 β 3 + β β 2 β 2 β 10 β 2 + β+1 β 3 β 3 β 11 β 3 + β 2 + β β 4 β+1 β 12 β 3 + β 2 + β+1 β 5 β 2 + β β 13 β 3 + β 2 +1 β 6 β 3 + β 2 β 14 β 3 + 1
The USB interface is also known as **data** interface, which enables communication between computers and peripherals. It can also provide power supply for some peripherals like flash memory sticks, disk drives and so on. It is easy to use, low cost and available in different sizes and provides a powerful connection system. USB standard has several versions and in each version **data** transfer speed varies. The speeds can vary from Megabits per second (Mbps) to Gigabits per second (Gbps).  Fig. 3, the block diagram of SIE block is presented. The SIE block handles all the receiving and sending of **data** in the form of transactions. It typically detects all the incoming packets, sends data, handshake and token packets, detects and generates reset, start-of-packet, end-of packet, resume signaling information, decodes and encodes the **data** on the bus in the required form, generates as the packet identifiers (PIDs), converts serial **data** of USB to parallel **data** on registers or memory and vice versa. UTMI block takes care about low level USB signaling and protocol. The main aim of UTMI block is to make the **data** compactible with the USB protocol and also to shift clock domain of the input or **data** signal from USB rate so that it is compatible with central processing unit (CPU)  "
22512771,19/24,2.0,0.792,"For this work, target position **data** were simulated in Dy-naTrack. However, the tracking delivery software supports various motion acquisition methods, like implanted electromagnetic transponders 33 and ultrasound transducers. 34 Dyna-Track effectively compensates for the additional latency by prediction. 35 The tumor trajectories in this study were generated based on 4DCT **data** by fitting an ellipse. The root mean square error of the fit error was 0.13-0.51 mm, which is deemed acceptable as it is substantially smaller than the voxel size utilized for dose reconstruction."
565361,18/29,1.0,0.621,"Due to the large differences in dynamic range of different color devices and due to the normalizing adaptation in the eye, little success can be achieved by gamut mapping schemes that attempt to match tristimulus values. Use of uniform color spaces that incorporate some white point scaling in the specification of colors mitigates the problem of normalization to a limited extent. However, naive schemes that map outof-gamut colors to the nearest color in a uniform color space or scale the entire image colors to lie within the gamut are also unsatisfactory in most cases. A robust and universal gamut mapping strategy remains an elusive goal. However, several researchers have reported encouraging results from experiments with different gamut mapping strategies. The more successful approaches tend to use uniform color spaces or color appearance models and manipulate color **data** using perceptual attributes of lightness, hue, and chroma in an attempt to preserve the more important attributes."
254853881,15/50,1.0,0.3,"Comparison with Sample-wise AT. Previous works (Hendrycks et al. 2021;Yi et al. 2021) try to exploit samplewise AT as a **data** augmentation strategy to obtain higher OOD performance. However, the performance only improves when the distribution shift is dominated by diversity shift, e.g., noise, and blurring. Otherwise, performance might be degraded, as shown in Table 1. One possible explanation is that sample-wise AT fails to capture the domain-level variations as DAT. As a result, it may add perturbations to the invariant features and hurt performance, especially under correlation shift."
27068907,12/25,1.0,0.48,"The SD card is mainly used for **data** reading and writing. The operation is generally realized through the SPI mode, which is relatively easy to achieve. The reading and writing process of the SD card is explained as follows. After power on, initialize the SD card, adjust the signal transmission frequency to a higher level, and send a certain number of clock signals, and write the command at the same time. In this way, the SD card is put into the SPI mode."
8604607,1/30,1.0,0.033,"The AHP is equipped to address a wide range of decisions that involve both quantitative **data** and additional, less-tangible input from stakeholders [5][6][7][8] . This is highly relevant to comparative effectiveness research as the comparison of alternative drugs or interventions is paramount. These complex situations may include tradeoffs between imperfect options, a mix of objective **data** and subjective options, and uncertain future outcomes 9 ."
236196766,5/47,5.0,0.106,"Each of the items in enriched indexes stores **data** about a single commit, issue report, code review, message, etc. For example, for a commit, 54 different fields are stored (see Fig. 9 for a more complete description of some of them 2 ), including, among others: author_uuid (unique author identified, provided by SortingHat), author_date (author date in the commit record), files (number of files touched by this commit), lines_added (number of lines added), lines_removed (number of lines removed), message (commit message), project (project to which the repository is assigned), branches (list of branches in which the commit appears). Enriched items are not normalized due to limitations of Elasticsearch, which does not support table (index) join. This has some impact on the size of the indexes (some fields are repeated once and again, when they could be in a separate table, with cross-references). However, the impact is not large, since those fields tend to be relatively small compared with the whole size of the item. The main impact of this lack of normalization is observed when one of those fields changes, and all items with the old value have to be modified. For example, if the name of an author was wrong, and is fixed, all the items authored for that person need to be fixed. For each of the **data** sources supported, one or more enriched indexes are produced, aimed to have useful **data** to produce the metrics that are finally visualized, or used to produce reports. Therefore, aggregated metrics are not a part of the indexes stored in Elasticsearch: they are computed either by the visualizations, or by the tools producing the reports, by aggregating and filtering **data** present as fields in each of the items. A list of all the fields of all the indexes is also available 3 ."
232380196,11/28,1.0,0.393,"A backbone network, e.g., ResNet [10], is shared between these two learning branches to learn the image representation r 2 R DE for each image x. A projection head f e (·) maps the image representation r into a vector representation z 2 R DS which is more suitable for contrastive loss. We implement this projection head f e (·) as a nonlinear multiple-layer perceptron (MLP) with one hidden layer. Such projection module is proven important in improving the representation quality of the layer before it [5].`2 normalization is applied to z in order that inner product can be used as distance measurements. To avoid abuse of notations, unless otherwise stated we use z as the normalized representation of x for contrastive loss computation. A supervised contrastive loss L SCL is applied on top of the normalized representations for feature learning. The classifier learning branch is simpler which applies a single linear layer f c (·) to the image representation r to predict the class-wise log-its s 2 R DC , which are used to compute the cross-entropy loss L CE . Due to different natures of the two loss functions, the feature learning and classifier learning branches have different **data** sampling strategies. The feature learning branch takes as input anchor point x i together with positive samples {x + i } = {x j |y i = y j , i 6 = j} from the same class and negative samples {x i } = {x j |y j 6 = y i } from other classes. The input batch of the feature learning branch is denoted as
B SC = {x i , {x + i }, {x i }}.
The classifier learning branch directly takes image and label pairs as input B CE = {{x i , y i }}. The final loss function for the hybrid network is:
L hybrid = ↵ · L SCL (B SC ) + (1 ↵) · L CE (B CE ), (1)
where ↵ is a weighting coefficient inversely proportional to the epoch number, as shown in Fig. 2. "
84844201,6/9,1.0,0.667,"A natural question is whether the growth mode we revealed can be implemented, beyond the scale of a few 10 µm set by the size of the graphene flakes, at a macroscopic length scale. In other words, one might wonder whether confined step-flow growth can be achieved underneath a full graphene layer. Obviously, this question deserves more work, but a prerequisite is that intercalation channels exist for Cu. We note that, unlike the case of Co intercalation between graphene and Ir(111), which comes with a variety of intercalation channels (edges [40,14], bent graphene regions [38], point defects [30]), here we did not observe other intercalation channels than edges (at 580 and 700 K). Besides, preliminary attempts to intercalate a thin Cu film (6 eq. ML) deposited at room temperature on top of polycrystalline graphene/Ru(0001) (prepared by catalytic decomposition of ethylene at 870 K; **data** not shown) and subsequently annealed up to 700 K, were unsuccessful. This is also in contrast with the Co intercalation between polycrystalline graphene and Ir(111) [30] or Pt(111) [26]. Point defects in polycrystalline graphene on Ru(0001) do not seem to favor intercalation. Even though we cannot exclude that point defects or other kinds of intercalation channels become active at temperatures beyond the range we explored (580, 700 K), a confined step-flow growth might be induced by generating defects, artificially. These artificial defects could be obtained for example after graphene islands have coalesced, but before a 100% coverage is achieved, or could be created a posteriori by an etching process. After intercalation, a full protection of the surface could be achieved by a second chemical vapor deposition of graphene onto the bare Cu regions (those covering the initially bare Ru(0001) regions, at the location of the graphene defects)."
236196766,13/47,1.0,0.277,"Relationship between how bug reports are closed and developer retention. Research objective: To explore how the timing, or other features, related to how bug reports are closed, could influence core developer retention in a FOSS (free, open source software) project. Example of RQ: Does a longer time-to-close for bug reports cause developers to stop earlier contributing to the source code of a project? Method: Retrieve **data** about the issues (including bug reports) for a large and diverse set of FOSS projects, if possible with different issue tracking systems, so that specific features of it don't affect the results. Retrieve **data** from the source code management system of the same projects. Once all the **data** retrieved is stored in a database, use it to explore different proxies for time-to-close bug reports and for estimating periods of continuous contribution. For estimating time-to-close, explore different strategies for telling bug reports apart from other issues (machine learning on title and description, tags, etc). For estimating periods of contribution explore different approaches (maximum period without contributions, number of contributions over a certain period, etc.) to tell apart frequent (likely core) contributors from casual contributors. Then, explore how to estimate the period until stopping contributions (considering extending temporary periods, such as vacation). Once the most reliable method is exactly defined, conduct the study in as many repositories as possible. Personal trajectories in software development. Research objective: Explore ways to track trajectories of developers, by analyzing their footprints in different kinds of software development repositories. Example of RQ: Do core contributors usually follow a path from messages in communication channels to issue submitters, to code review submitters? Method: Retrieve **data** from mailing lists, GitHub issues and pull requests, and GitHub Git repositories, for a large collection of projects. Merge identities using email addresses for linking identities in email messages to identities in Git commits, and the GitHub commit API to link email addresses to GitHub user IDs. If possible, improve identities **data** by manually merging and de-merging identities using other **data** sources (for example, public Internet profiles). Once the identities **data** is curated, use it to identify contributions by persons in all **data** sources, and explore the different tracks followed."
249258070,44/119,1.0,0.37,"Finally, Ashby (2020) examined **data** from January 1, 2016 to May 10, 2020 for ten of the largest U.S. cities to determine if there were changes in service calls after the start of the pandemic. ARIMA models were used to forecast weekly total call count frequencies as well as weekly call counts broken down across 18 different call types. The frequency of total CFS was estimated to be significantly below what was forecasted for the model for multiple consecutive weeks after pandemic lockdowns occurred in six of ten cities. Three of the remaining four cities also saw non-significant decreases in total call counts. New Orleans saw an initial decrease, followed by a two-week spike in calls, then another decrease. In terms of specific call types, crime-related CFS did not deviate from expected frequencies. Domestic violence calls increased in three cities, decreased in one city, and were in the expected ranges in three cities. Disturbance calls increased in four cities but remained the same in six cities. Drug-related calls were lower than expected in two cities. Finally, traffic-related calls saw an initial decrease, but then slowly increased in later weeks of the study period (Ashby, 2020)."
218971725,7/10,3.0,0.7,"Results were presented in Table 2. Single wave balanced stratified sampling design was not close to optimal. Twowave sampling with balanced stratified sampling at wave 1 performed slightly better but still was not close to optimal for all the choices of wave-1 sample sizes. Our proposed designs were still very close to optimal design for all the four priors. As the NWTS **data** have rich phase-1 information, efficiency gains of our proposed design were also from using the rich phase-1 **data** at the design stage."
134689280,15/20,3.0,0.75,"Data that is not there cannot be analysed. The synchronicity assumed in analysing spatial datasets has the side-effect that the coincidence of all **data** entries makes implicit that the analysis will also assume that this coincidence is all that exists. A record of fragments thus is complete as a record in itself. Inhabitants of a past situation would not have encountered a fragmented world, and therefore I have introduced the preparatory step of conjecture. Conjecturing ensures the spatial information best approximates the social empirical reality of a past situation. The known unknown of any spatially determinant characteristics for which we do not have archaeological traces remains unresolved (the absence of evidence is not evidence of absence). Conjecture merely helps to avoid an analysis of fragments instead of past situations, even if our rendering of that situation is incomplete. Although Lucas (2015) stresses that the evidentiary fragment lacks a temporal dimension, when putting together (incl. conjecture) a time-slice of spatial data, we may pick any moment in the material presence of archaeological evidence that survives from a past situation. The incompleteness of evidence for a past situation does not rob the fragment of its duration. Complementing fragments with synchronic conjectures simply implies an analysis and interpretation focused on what archaeological evidence is evidence of."
238719786,1/14,3.0,0.071,"Multiple FPGAs are been widely used in the areas like multi-processor system on chips (MPSoC), hardware emulation, hardware acceleration and so on. In all the above mentioned applications, to get the desired functionality of the systems, multiple FPGAs must communicate with high speed, with low power, without any errors during the **data** transmission. Error less communication play a crucial role in determining the performance and correctness of the system. So, this paper presents a fault tolerant communication system between the FPGAs. The proposed system uses Bose, Ray-Chaudhuri, Hocquenghem (BCH) codes, Universal Serial Bus (USB) transceiver with serial interface engine (SIE) and an asynchronous FIFO. BCH codes are the class of cyclic codes that are powerful and have the capability of multiple error detection and correction. The main aim of the study is to guarantee errorless and fault tolerant communication between multiple FPGA development boards."
245105154,3/25,1.0,0.12,"ADR is an algorithm employed in the LoRaWAN network to optimize the transmission parameters for stationery LoRa end devices [4]. The LoRaWAN provides the transmission parameters spreading factor (SF), bandwidth (BW), transmission power (TP), and coding rate (CR), that the ADR can manipulate to optimize the end devices' **data** rates, energy consumptions, airtimes and the capacity of the network [4]. The specifications of the ADR are provided in detail in [10]. Semtec provides the simplified descriptions and implementation recommendations of the ADR in [5,11] respectively. The process by which the ADR optimizes transmission parameters for end devices is as follows: initially, the end devices choose transmission parameters randomly, usually the highest TP and lowest SF possible. When the device wants to enable the ADR, it alerts the network server by setting the ADR bit on one of its transmissions to the network server. Once the network server receives the alert, it starts collecting up to 20 uplink messages. From the 20 uplinks, the Frame counter values, and the Signal-to-Noise ratios (SNRs) are collected to be used in the ADR process. From the SNRs collected, the network server determines the maximum SNR (SNR max ) and uses it to calculate the margin using Equation (1) [4]: margin = SNR max − SNR limit − margin default (1) where the SNR limit is the minimum SNR required to demodulate a signal and the margin default is the installation margin specific to the device being used and in most cases is 10 dB. The calculated margin is then used to calculate the number of times (i.e, the N step ) the algorithm is executed using Equation (2):
N step = int(margin/3)(2)
where int is the integer value and based on the computed Nstep value, one of the following actions can be executed:"
252484412,2/5,4.0,0.4,"I have pointed out earlier that a capability can be considered ""transformed by AI"" when AI changes the conditions of its possession and realization. While AI might not have completely transformed this capability yet, I think that we have enough evidence suggesting that it might do so in the not-so-distant future. In particular, AI is starting to show a lot of potential in areas like wildlife conservation and the preservation of biodiversity [41]. For example, databases of drone and satellite images can help track and categorize endangered animal species down to the individual animal, helping re-population efforts and the fight against poaching. In addition, machine learning algorithms can offer insights and solutions into the trends of certain animal populations, their movements, habits, and preferences, as well as mapping food availability and predict migration routes. AI-equipped technologies are also employed in the fight against climate change [31] and in the development of alternatives to fossil fuels [21]. These examples of AI applications suggest that having the capability to ""live with concern for and in relation to nature"" one day might entail the ability to make decisions based on **data** collected through these AI-powered methods, thus changing the standards for a fulfilling relationship with nature and the expectations about what we can and ought to do to make it even more fulfilling."
236196766,4/47,4.0,0.085,"Full-size  DOI: 10.7717/peerj-cs.601/ fig-2 in the case of Git). Arthur's concern is to organize the work of Perceval and Graal when retrieving large quantities of data, by providing a system supporting the scheduling of parallel asynchronous jobs, in several nodes, and making all the details transparent to the next component in the pipeline (usually, GrimoireELK, see below). A common Perceval job consists of fetching a collection of homogeneous items from a given **data** source: tickets extracted from Bugzilla or GitHub issue trackers, commits from a Git repository, or code reviews from a Gerrit instance. Each item is extended with related information (e.g., comments and authors of a GitHub issue) obtained from the **data** source, and metadata useful for debugging and tracing (e.g., backend version and timestamp of the execution). When a **data** source provides several types of items, Perceval usually labels the resulting items in a way that can be identified by other components processing them later. For example, the GitHub Issues API provides both issues and pull requests for a repository: Perceval uses the field pull_request to let other components know if the item is an issue or a pull request."
18625586,14/35,1.0,0.4,The depth of each edge is computed in constant time with a lowest common ancestor query performed with the **data** structure in [27]. The SPQR-tree Decomposition step can be performed in linear time [23].
245105154,7/25,1.0,0.28,Reduction in network throughput when the ADR is employed [9] A contention-aware ADR with restricted usage of **data** rates.
201251303,1/10,1.0,0.1,"Spatial dependence is the measure of the degree to which one object correlated to other nearby objects. It plays an essential role in a wide range of empirical economic studies (Yu, 2017), such as regional and urban economics, environmental and public health (Jerret et al., 2010), social networks (Wong et al., 2006) and agricultural (Holloway et al., 2002). Ignoring the spatial dependence in the **data** may lead to inefficient, and or biased and inconsistent estimation (Anselin and Florax, 2013). Spatial regression is the formation of a regression model using location data. In spatial regression, observations at a site depend on observations located in other adjacent locations, so that there are spatial autocorrelation and spatial heterogeneity. In the presence of spatial autocorrelation in a model, a least square method cannot be employed to estimate the model parameters due to biased and inconsistent estimators. In many applications, we have to model dependent variables that reflect binary outcomes generated by spatially dependent processes. Spatial dependence in binary outcomes result in a situation were observed at one location are similar to others at nearby locations. Holloway, Shankara, and Rahman (2002) show that binary outcomes regarding the adoption of an agricultural program by Bangladeshi rice producers exhibited spatial dependence. One of probit variant models which focused on spatial autoregressive is Spatial Autoregressive (SAR) probit model. As well as spatial autocorrelation and if **data** varies spatially, it is reasonable to think that variances may vary also. Models typically imply heteroscedasticity and autocorrelation, but some specifications include autocorrelation without heteroscedasticity. Heteroscedasticity can be a potential problem in a spatial model with discrete dependent variables and makes the standard probit estimator inconsistent."
27068907,4/25,1.0,0.16,"Communication module: The type of this module has a significant influence on the stability and reliability of the wireless network. This paper chooses to use the JTT-4432 wireless transceiver module, which is very small and easily embedded in the integrated circuit board. The module uses a standard 1.27DIP interface, which operates at the voltage of 1.8V-and consumes low power. There are many operating modes that can be selected as needed. In the standby mode, the operating current is 15mA, while in the transmission mode, the operating current is 30mA. With a sensitivity of -118dBm, it supports one-to-many communication, and realizes the programming function of all registers with ""burst"" **data** transmission. The communication module satisfies the working requirements of the temperature sensor as it employs high precision peripheral components, can work in a very complex environment, and features low power consumption."
249258070,91/119,1.0,0.765,"This study relies on CFS **data** provided by the Houston Police Department (HPD) based on records from their Computer Aided Dispatch (CAD) system. While CFS **data** may not capture all activity an officer engages in, these **data** are one of the best resources available to understand both conventional police activities and officer proactivity (Lum, Koper, et al., 2020;Wu & Lum, 2017;Zhang and Zhao, 2021)."
2423505,1/23,1.0,0.043,"The shortage of labeled **data** is a fundamental problem in applied machine learning. While huge amounts of unlabeled **data** is constantly being generated and made available in many domains, the cost of acquiring **data** labels remains high. Even, worse, sometimes the situation makes it highly impractical or even impossible to acquire labelled **data** (e.g. when the underlying distribution is constantly changing)."
134689280,5/20,2.0,0.25,"This realisation must not be seen as an excuse not to produce the best possible metadata and **data** (re)presentation. Nor will this realisation change the fact that each specific archaeological project may allow for more information being recorded or the same information being recorded in a more useful way. Most significantly, if the archaeological survey map is the end product of a project, it would be fair to expect that it is being prepared in a best possible way to enable flexible future potential use. With the wealth of mapping conventions and symbologies available, especially in this digital age, we have far from exhausted the possibilities to improve on how physical information is conveyed on our maps. 3"
246165803,27/45,1.0,0.6,"This system proved to detect anomalies and create geospatial **data** visualization to represent the condition of the streets on two tested avenues. While the proposed research hypothesis proved true, this project has vast areas of opportunity, potential improvements, and further research to scale a system to a whole-city level. One of the new aspects of this project is the cloud solution. The design and implementation of cloud services to host the website are needed for the visualization tools and the creation and maintenance of a database, relational or not, as well as the complementary systems necessary for the operation of the proposed **data** recovery and analysis platform."
229722484,9/39,3.0,0.231,"In our experiments, we have used α = 1 that is the **data** were sent by using a single iteration. In fact, the interface throughput was very stable since we have performed our experiments in the best case scenario where the WiFi was delivered via a dedicated access point that was in Line of Sight with the sender. There was no interference caused by other surrounding WiFi. The 4G main antenna was in Line of Sight 500 m away from the cell phone. We also noticed that the throughput was greatly improved by dividing each part of **data** d k,I i (to be sent by the interface T i at iteration k) into smaller chunks {p 1 , . . . , p n }. We added to each p i the header needed to rebuild the message at the recipient side. The size of the part p i was chosen as large as possible to increase the throughout, but also small enough to avoid fragmentation by the underlying layers."
245105154,5/25,1.0,0.2,"If the N step < 0, the algorithm increases the TP to its highest possible value. Nothing is done to the SF at this stage since LoRa end devices already have automatic **data** rate decay."
236196766,25/47,1.0,0.532,"In this paper we have presented GrimoireLab, an extensible and modular open source toolset which offers (i) automatic and incremental **data** gathering from a large set of tools used in software development, (ii) storage and enrichment of the retrieved data, (iii) identities management, and (iv) **data** visualization and reporting to allow inspecting specific aspects of software development. GrimoireLab relies on different components that can be used together or standalone. It also may help researchers to enhance reproducibility of their studies, and traceability of their data. GrimoireLab reimplements and extends previous approaches to create a mature platform, currently used in commercial and academic settings."
549001,4/36,1.0,0.111,"Despite the fact that MPC model is rather new, computing matching is an important problem in this model, as the above mentioned two papers demonstrate. This is further witnessed by the fact that the distributed and parallel complexity of maximal matching has been studied for many years already. The best deterministic PRAM maximal matching algorithm, due to Israeli and Shiloach [27], runs in O log 3 n rounds. Israeli and Itai [26] gave a randomized algorithm for this problem that runs in O(log n) rounds. Their algorithm works as well in CONGEST, a distributed message-passing model with a processor assigned to each vertex and a limit on the amount of information sent along each edge per round. A more recent paper by Lotker, Patt-Shamir, and Pettie [32] gives a (1+ϵ)-approximation to maximum matching in O(log n) rounds also in the CONGEST model, for any constant ϵ > 0. On the deterministic front, in the LOCAL model, which is a relaxation of CONGEST that allows for an arbitrary amount of **data** sent along each edge, a line of research initiated by Hańćkowiak, Karoński, and Panconesi [22,23] led to an O log 3 n -round algorithm by Fischer and Ghaffari [20]."
249258070,103/119,2.0,0.866,"Additionally, Maskály et al. (2021) collected survey **data** from police executives in 27 countries around the world to assess the effects of COVID-19 on police organizations and activities. Their findings indicated that, by summer 2020, responding organizations experienced at least some changes to problem-solving or community policing activities (83%), patrol strategies (78.3%), traffic stops (68.2%), officer-initiated activities (60.9%), special operations teams' activities (54.1%), handling CFS (43.4%), and use of tactical teams (34.8%). Collectively, these results demonstrate that routine police activities have been impacted by the COVID-19 pandemic. Such changes have also led to empirical investigations of how police activities have changed since the start of the pandemic."
25183918,1/7,1.0,0.143,"Subcategorization **data** has been crucial for various NLP tasks. Current method for automatic SCF acquisition usually proceeds in two steps: first, generate all SCF cues from a corpus using a parser, and then filter out spurious SCF cues with statistical tests. Previous studies on SCF acquisition have worked mainly with written texts; spoken corpora have received little attention. Transcripts of spoken language pose two challenges absent in written texts: uncertainty about utterance segmentation and disfluency. Roland & Jurafsky (1998) suggest that there are substantial subcategorization differences between spoken and written corpora. For example, spoken corpora tend to have fewer passive sentences but many more zero-anaphora structures than written corpora. In light of such subcategorization differences, we believe that an SCF set built from spoken language may, if of acceptable quality, be of particular value to NLP tasks involving syntactic analysis of spoken language."
236196766,17/47,8.0,0.362,"-New **data** sources. Supporting a new **data** source with GrimoireLab amounts to building some modules which integrate with the rest of the system. The process starts by building a new Perceval client, which will implement a Python generator that will retrieve **data** from the intended source, and produce dictionaries with a common structure. This client usually will automatically plug into the Perceval backend, producing JSON documents that will be stored in Elasticsearch by Arthur and GrimoireELK. Then, enrichment code has to be inserted in GrimoireELK so that enriched indexes can be produced, usually by selecting which fields from raw items should be copied, or transformed, into fields in the enriched index. If identities are to be managed, the appropriate calls to SortingHat will be included in this code too. Finally, new visualizations have to be produced in Kibiter to show the **data** in these new enriched indexes."
129549588,1/17,1.0,0.059,"Rainfall is the main source of water supply, and the time and space distribution characteristics of it is one of the main reasons that composed of the temporal and spatial distribution characteristics [1]. The actual situation shows that in the same climate zone, the same river basin, rainfall is obviously variable in different time and space [2], especially in the mountain plateau, rainfall is significantly different in the factors as longitude and latitude, water system (reservoir, rivers, lakes), the run of the mountains, slope aspect and altitude change, it is the space variability of rainfall. The rainfall spatial distribution of some basin exists the obvious differences, especially in the dry regions [3]. The preliminary analysis of space variance is to understand the change rule of the natural factors in the changeable environment, so that it is good to the related research. The analysis research of the space variation law of rainfall is based on the actual observation rainfall **data** in a period, and to analyze the space mutation characteristics of the characteristic parameters, its own parameters and the relationship of all the parameters in the space. The rainfall distribution and the distribution of the vegetation have a lot of correlation, it is usually like that the area of higher plant coverage will have a corresponding rainfall, and the area with more rainfall, plant growth power and coverage rate in the ground is higher than that the less rainfall region [4]. In the mountains district, human activities attach more influence to the ground runoff, soil and water loss and landslide. Therefore, only if the spatial distribution law of rainfall fully understood in this area, that can be reasonable allocation and use of water, and give full play to the ecological and economic benefits of water resources, and do service for the human production and life."
249258070,37/119,2.0,0.311,"Second, a significant increase was observed for violent crime calls. This finding was counter to some of the initial studies using CFS **data** to examine trends in aggravated assaults (Ashby, 2020; Mohler et al., Table 3 Interrupted time series analysis using ARIMA models. 17.53*** 2020) after the initial onset of COVID-19. This discrepancy could be due to measurement differences as our measure also included shootings in addition to different types of assaults. However, these initial studies only examined trends until April or mid-May of 2020 and were perhaps unable to account for longer term effects of the pandemic. For example, recent research found an increase in gun violence from the beginning of the pandemic through March 2021 across several U.S. states, including Texas generally and the Houston region specifically, when compared to the same time-period the year prior. The increases in gun violence were attributed to both prolonged psychological distress and increased gun sales resulting from the pandemic (Ssentongo et al., 2021). The current results also suggest that COVID-19 was associated with increased demands for police responses to violence, even after the initial wave of the virus. Third, the findings indicated that officers were engaged in more frequent self-initiated patrol activities compared to the pre-pandemic data. This increase remained after the death of George Floyd (when compared to pre-pandemic data), but at a lower rate. These observed changes to proactive patrol could also be attributed to changes in the routine activities of citizens. Again, the **data** showed that three of the reactive call types significantly decreased post-pandemic and another three reactive call types experienced no changes in frequency. As Ashby (2020) noted, a reduction in reactive CFS could create additional time for officers to focus on other tasks, such as proactivity. The current results may also lend further support to the findings from Lum, Koper, et al. (2020) demonstrating how proactivity is often manifested as generalized patrol even after the pandemic, as well as Maskály et al. (2021) results showing increases in directed or extra patrols since COVID-19. While there was initial concern that the pandemic may have necessitated a move to precautionary policing, a recent survey revealed that citizens are not supportive of reducing preventative patrol even during the pandemic . In this regard, decreases in reactive demands for police services coupled with citizen expectations of police services during the pandemic could account for this increase."
38256305,4/49,1.0,0.082,Satellite Remote Sensing (RS) **data** and Geographical Information System (GIS) software have a huge potential and wide application in assessing and categorizing natural hazards [37][38][39][40]. GIS integrated remote sensing **data** and geospatial analysis can be used to infer factors related to the occurrence of major earthquake shocks and/or earthquake-induced secondary effects. The secondary 
12790199,6/21,1.0,0.286,"There are two ways to satisfy ""Group the green block and the red apple"": either the robot can lift the red apple and place it near the green block, or it can lift the green block and place it near the red apple. The planning system selects between these alternatives based on prior **data** about objects with the given attributes (green, red, block, and apple). The plan tree is constructed using the choice with the highest predicted success likelihood. The planning system's search will produce a series of action processes, which are interaction processes that issue motor commands and monitor their progress."
246863515,1/44,1.0,0.023,"However, learning long-term treatment effects is very challenging in practice, since long-term outcomes are often observed only after a long delay. This is especially a problem for randomized experiments, because experiments usually have relatively short durations due to cost considerations. For example, industry online controlled experiments (i.e., A/B testing) usually last for only a few weeks, so practitioners commonly recognize the inference of long-term effects as a top challenge [Gupta et al., 2019]. In contrast, observational **data** are often easier and cheaper to acquire, so they are more likely to include long-term outcome observations. Nevertheless, observational **data** are very susceptible to unmeasured confounding, which can lead to severely biased treatment effect estimates. Therefore, long-term causal inference is very challenging with only a single type of data, either due to missing long-term outcome (in experimental data) or unmeasured confounding (in observational data)."
207778550,3/48,1.0,0.062,"When the degree of correlation exceeds a critical value, depending on the data, it may cause the well-known effect that the resulting mean lies outside the **data** interval and its uncertainty decreases, see for example [4]. In the field of nuclear **data** this phenomenon is also known as Peelle's Pertinent Puzzle (PPP) [5]. This effect is mainly related to an incorrectly constructed covariance matrix from measurement observables, which may suggest that the used statistical model is not adequate to describe the **data** [6][7][8][9]. As a practical matter, in nuclear **data** evaluation physically unreasonable evaluated results may be generated by the least-squares method in certain extreme cases (strong correlations and discrepant input data) if no compensation for PPP is applied."
226239351,31/37,2.0,0.838,"Window evaluation may give **data** also for technology evaluation. Assume that an MT technology has been used for building an MT system for the language pair a-b and the question is raised how good a quality that technology would provide for another language pair c-d. Polished rough translations show the final quality for the pair a-b for a given text type. If a and b are structurally more distant from each other than c and d, window evaluation tells indirectly how good a quality is achievable for the pair c-d for a similar text type. If, on the other hand, c and d are more distant from each other than a and b, window evaluation remains silent."
202915961,1/6,2.0,0.167,"Mapping is a visual way to reflect the patterns of spatial and structural distribution of vegetation. The complexity of mapping of vegetation cover is due to its heterogeneity and complex structure, seasonal dynamics, variability under the influence of natural and anthropogenic factors. Thus, the most important problem of mapping the vegetation cover is operative to obtain reliable information about its spatial characteristics and condition. The use of remote sensing **data** is one way to quickly obtain **data** for mapping plants. Currently this method is actively used and developed."
55648852,20/40,3.0,0.5,"Once the Cube database is organized in the new format, we plotted all shots registered at one station during one day using Matlab tools. This way of representation allows us view the movement of the vessel and to estimate the acoustic wave (1.5 km/s) registered on the stations near the coast. Indeed, controlling the arrival time of the acoustic wave is a simple and very effective procedure to check that the GPS **data** times are correct, and that there is synchrony between the GPS **data** time of the air-guns and the stations."
17671315,25/32,1.0,0.781,"Figure 3 :
3Targets and collected **data** before pre-processing
"
150005643,7/12,1.0,0.583,"Factor 2: General versus Word-Specific Knowledge General Word Knowledge General spelling knowledge progresses from smaller to larger units: phonemegrapheme (1 or 2 letter) connections, phonological and orthographic onsetrime correspondences within syllables, and morphological analyses of root words and affixes (Davis & Drouin, 2010). The comparative frequency of legal letter groups (orthotactics) (Conrad, Harris, & Williams, 2013)  sensitivity to orthotactic patterns and the relative statistical frequency of cooccurring grapheme patterns (Treiman & Kessler, 2013). As an illustration of this general sensitivity, **data** from an analysis of superior, average, and poor spellers (Silliman, Bahr, & Berninger, 2013) revealed that a poor speller in grade 1 spelled the compound careless as ckault, which shows the child is struggling with two critical aspects involving the grain-size of the compound. First, the child appears to parse the compound inappropriately, representing it as a single syllable. Second, it is orthographically plausible to represent the k sound with ck; however, in American English, ck can only occur after a short vowel; hence, this child's misspelling represents an implicit awareness of permissible orthotactic sequences, but not their constraints on word position. Statistical learning manifests early in learning French as well. In French, like English, consonants cannot double in word-initial position. Research showed that children recalled items without doublets better than they recalled those with doublets (Pacton et al., 2014)."
235829209,1/47,1.0,0.021,"Consider a different scenario: an unknown nonlinear dynamical system is encapsulated into a blackbox and only an ensemble of trajectories (input and output data) are available. Comparing actual trajectories to interpolated trajectories is one way to gauge chaos. A typical method to interpolate from known trajectories is to build a surrogate model with machine learning techniques. A surrogate model needs to be established first, then predictions can be made by evaluating trajectories with given initial conditions. This procedure is known as ""supervised learning"" [2]. To validate the model, the **data** is often randomly split into two clusters: a large training set and a small testing set. A model is then constructed from the training set. The performance of the model, i.e., the prediction accuracy, is measured by comparing the testing **data** against its prediction. The performance of the model depends on the type and complexity of the model, the volume of training data, the algorithm used for training, etc."
9847410,3/4,1.0,0.75,"Raja Parasuraman's pioneering work led to the emergence of Neuroergonomics as a new scientific field. Neuroergonomics is defined as the study of the human brain in relation to performance at work and everyday settings (Parasuraman, 2003;Parasuraman and Rizzo, 2008). Since the advent of Neuroergonomics, significant progress has been made with respect to methodology and tools for the investigation of the brain and behavior at work. This is especially the case for neuroscientific methods where the availability of ambulatory hardware, wearable sensors, and advanced **data** analyses allow for imaging of brain dynamics in humans in applied environments."
117171389,10/36,1.0,0.278,"Spectrum congestion in millimeter-wave bands are not yet severe; however, frequency bands are allocated to various radio services. In addition to remote sensing and radio astronomy, high-speed wireless **data** transmission technologies using 90 GHz bands have been actively developed for connecting high-speed trains and remote access units (RAUs). This implies that radio interference at 90 GHz would be an issue in the near future. In the linear cell radar system, comprehensive RAU control would be useful to suppress interference between the RAUs. The beam direction of each RAU could be controlled by a central control unit to avoid such interference. All the RAUs could be connected to the central control unit through optical fiber links. However, strong interference would occur, by strong radio-wave reflection from a smooth surface on an aircraft. Figure 13 shows an interference model in a liner cell radar system to calculate the ratio of a desired signal from an FOD and an undesired signal from another RAU located at the opposite side of the runway. The beam cross-section was assumed to be Gaussian with a 1-degree FWHM (full width half maximum). The radar cross-section of the FOD was assumed to be −20 dBsm. Figure 14 shows the ratio between the desired and undesired signals (D/U ratio). The possibility of interference would be roughly estimated by this calculated D/U ratio. If the beam angle difference was smaller than 1 degree, the D/U ratio would be smaller than 0 dB. Thus, the angle difference between the RAUs should be larger than 1 degree to suppress the interference described in Figure 13."
134689280,11/20,1.0,0.55,"It is important to recognise that material evidence is still a category of empirical information and therefore adheres to an empirical tradition of knowledge production (cf. supporting Smith's (2015) 'better arguments'). The usual mode of conduct that sees archaeology interpret data, even if we can identify various archaeological **data** as unwittingly interpretive data, 6 has relied heavily on correlating analogous information. Citing ethnographic, (ethno)historical, and experimental sources of information (used as analogous verification for interpretations), Nicholas and Markey (2015) develop an argument for the use of 'traditional' or 'indigenous' knowledge in archaeology. Questions can certainly be asked about to what extent treating evidence empirically is the only valid structure of reasoning. A critical realist would not deny indigenous knowledge causal power. In explanation (why something happened or occurred in that way), indigenous knowledge will play an equally valid role alongside history, personal agencies and memories, sociocultural systems and categories, and human-environmental relationships, both internal and external to the situation or phenomenon being studied. What such knowledges demand is a structural linkage of that understanding to archaeological evidence. In this chapter, archaeological evidence has become material evidence, and all we know about this evidence is that it refers to a presence to human beings situated in the past. Therefore, the empirical information we are restricted to is material presence (see Vis, under review, 2016)."
252484412,2/5,3.0,0.4,"Finally, machine learning algorithms that process **data** collected through dating apps and social media are now able to provide individuals with suggestions of events, activities, and even specific partners tailored to their sexual preferences and identities."
565361,4/29,1.0,0.138,"The historical milestones in the search for uniform brightness and lightness scales are described in Wyszecki and Stiles [12, pp. 493-499]. Typical experiments determine these scales either by a process of repeated bisection of the scale extremes or by moving up in increments of a JND. A cube-root power law relation between brightness and luminance provides a satisfactory fit for most experimental **data** and, therefore, has the most widespread acceptance at present [12, p. 494]."
236963055,1/15,1.0,0.067,"The improvement of information technology infrastructure, and the improvement of the ability to analyze environmental **data** lead an organization or a business to achieve a competitive advantage (Grover & Kohli, 2013). Although the dimensions of digital transformation are numerous, those components that have impact on businesses and different industries, and have been considered by researchers and managers of organizations, are recognized as industry 4.0, presented in 2011 (Hofmann & Rüsch, 2017). Ronaghi and Forouharfar (2020) believe ""The concept of 'Industry 4.0' is directly related to the installation of smart equipment and instruments for optimal controlling of resources, as well as increasing efficiency besides improving flexibility"" (Ronaghi & Forouharfar, 2020, p.2). The presence of time stamps in the blockchain structure prevents any distortion and falsification of information without the knowledge of stakeholders. Therefore, this collective responsibility increases the security and reliability of **data** (Raval, 2016). Using distributed, open-source, peer-to-peer systems, blockchain has the potential to create cleaner economic processes and harmony and balance between the economy, society and the environment . On the other hand, due to the distribution of information in the blockchain network, the method of interaction between users, energy consumption and waste of resources are among the challenges of using this technology . Given the features and challenges, this technology can affect sustainable development (Schulz et al., 2020)."
236522469,5/33,3.0,0.152,"Therefore, tests were performed by reducing or increasing thresholds that are functions that limit the results of the CNN output. Values equal to 1 suggest maximum identification in the model outputs, which can lead to the identification of species that are not recognized in the field, and values of 0 suggest no identification of any species, so manual adjustment of the Threshold is essential for fine-tuning the model output; this will help prevent outputs from presenting results that will be considered false-positive. After initial training, we observed that modifying the threshold resulted in non-recognition of some species or false recognition. This led to a training model with variation in the number of species and thresholds. All results were compared with field **data** to obtain a model that best reflected real conditions of the studied area. Herein, thresholds modify the output according to input limits. The network receives inputs, then applies a linear combination, and, if that combination is greater or less than the specified limit value, it will produce an output of 1 or 0, respectively. Therefore, results with low probabilities would be rejected. Equation 1 represents the threshold function, where Sigma (∑) is the sum of input (x) and weight (w) pairs.
output = 0 se ∑ i w i x i < Threshold 1 se ∑ i w i x i ≥ Threshold(1)
"
226239351,31/37,1.0,0.838,"The figures in Table 5 are not informative for the casual reader. For a system engineer they provide relatively straight-forward **data** on progress. When quality distances are measured regularly, using similar, general text type, the numerical generic distances should demonstrate a decreasing tendency. Since structural distances are further divided into subclasses at Kielikone (see Figure 3), the numbers tell how mature the different transfer parts are and where attention should be focused."
88514824,2/12,1.0,0.167,"Thus, we develop a Bayesian scaling estimation method with non-decimated wavelet transform (NDWT) motivated by real-life signals that are known to possess a certain theoretical degree of self-similarity. Bayesian approaches have been previously employed in this context. The Hurst exponent for Gaussian **data** was estimated with a Bayesian model in [11,2,4]. Holan et al. [7] developed a hierarchical Bayesian model to estimate the parameter of stationary long-memory processes. A Baysian model for the parameter estimation of auto-regressive fractionally integrated moving average (ARFIMA) processes [9] are discussed in [6,19,16]. These models are based on time domain data. However, the de-correlation property of wavelet transforms facilitates a simplified model construction, and multiple wavelet-based Bayesian techniques has been developed. Based on a Bayesian approach, Vannucci and Corradi [23] estimated parameters for long memory process with a recursive algorithm and Markov chain Monte Carlo (MCMC) sampling. A Baysian wavelet model for ARFIMA processes is illustrated in [10]."
565361,17/29,1.0,0.586,"With the advent of HDTV, the problem of negative lobe truncation in the camera sensitivities is to be entirely eliminated by implementing matrix transformations of recorded color tristimuli. The gamma-correction mentioned in Section III-A1 has still been retained due to its perceptual benefits. Instead of YIQ, an opponent color space encoding for gammacorrected RGB **data** has been standardized as the YCrCb space [51]. This space has also been used frequently in recent work on image compression."
244631546,5/16,1.0,0.312,"It can be seen from the above, the seq2seq model converts the input sequence into a fixed-length semantic vector C, and then decodes the semantic vector C to generate a sequence Y [11]. But the length of the semantic vector C is fixed, so **data** loss will occur when the sequence is generated. This article adds an attention mechanism to the seq2seq model. In the encoding stage, the input sequence can not only be transformed into a fixed-length semantic vector C, the input sequence X i will correspond to a different semantic vector C i . In this way, the **data** loss will be reduced when generating the sequence [10] (Figure 4). The abstract generated in this way is more similar to the abstract generated after manual re-understanding, which is more in line with the author's original intention and high intelligibility [12]. At the same time, it conforms to the characteristics of English long reading."
235829209,25/47,3.0,0.532,"Surrogate models have been widely used in studying nonlinear dynamical systems [3,4,5,6,7,8], including charged particle motion in modern accelerators [9,10,11,12,13,14,15]. These models are obtained by training on either simulated **data** or experimental data, which have a high computational demand or require complicated experimental processing. If models can predict the dynamical system properties accurately with reduced resource requirements, they can be used for more efficient applications, such as optimization problems. Improving the prediction accuracy is the highest priority in these applications. In contrast to these existing approaches, the main advantage of using data-driven chaos indicators is that the requirement on the absolute accuracy of surrogate models is less demanding, and therefore can be structured with less complexity and data."
249258070,41/119,1.0,0.345,"The current inquiry adds to the body of knowledge in this area by exploring potential changes to both reactive and proactive officer activities brought on by the pandemic using CFS **data** from Houston, Texas collected from January 1, 2018 through December 31, 2020. This study is informed by routine activity theory and perspectives on proactive policing. Trends are examined for seven different call types: violent crime, property offenses, disorder incidents, suspicious incidents, traffic-related activities, service-related activities, and non-crime events. In doing so, observed trends can be compared to the other large jurisdictions to further our understanding of how the pandemic has impacted demands for police services (e.g., Ashby, 2020). We also examine trends in officer proactivity through officer-initiated activities identified in the CFS **data** performed by three units: patrol, specialized crime investigation units, and the department's specialized response unit. This provides a unique look into how COVID-19 may have influenced officer-initiated activities."
22512771,12/24,1.0,0.5,"Static ITV+5/midV: Actual target position **data** are ignored for both delivery and dose accumulation. For ITV+5, the dose is calculated based on the dose-influence **data** for the reference phase only. For midV, the dose is calculated for the midV phase, respectively. The accumulated dose represents the planned dose distribution for PTV ITV+5 /PTV midV ."
38256305,20/49,2.0,0.408,"In the near future more Sentinel radar images will be available from ESA with different acquisition times and illumination geometries. These should be continuously evaluated and integrated into the existing database, adding to the refining of the tectonic pattern of this area. Satellite imagery can serve as a georeferenced base for mapping linear features related to subsurface structures, thus contributing to the structural inventory. GIS-integrated evaluations of different satellite **data** have contributed to the detection of subsurface structures in the Koyna area. It has also delineated areas prone to potential damage."
245864793,17/42,1.0,0.405,"The control architecture of the CardioVR-ReTone was developed to allow the deployment of several exoskeleton control modes: assistive, partially assistive, and resistive. An industrial open controller manufactured by Siemens, CPU 1515SP PC2, was considered the main control unit. The PLC had a CANOpen communication module, used to connect with every actuator EPOS4 controller and several IOs modules used to connect the signals from the exoskeleton joysticks and mechanical safety limit switches mounted on the exoskeleton's structure. The mechanical safety limit switches were used to activate the safe torque off functionality of the actuators in cases of malfunction, considering the positioning process. The open controller operating system hosted the VR engine and Simulink. Simulink ran the kinematic algorithms and sent the positioning, speed, and torque **data** to every joint actuator controller. Feedback was received from every actuator controller and sent back to the Simulink Kinematics algorithm. Surface EMGs placed on human arms sent information about muscle activity using Bluetooth to the open controller, which fed the **data** to Simulink for processing and torque adjustment. The architecture of the CardioVR-ReTone operating platform was based on a distributed control approach; the ROS (Robot Operating System) platform is currently considered the first option for implementing control-related functions."
244314113,7/8,1.0,0.875,"Anak Rasa bangga dan cinta akan bangsa dan negara dalam diri seseorang perlu ditanamkan sejak usia dini. Tujuannya agar sejak kecil, anak-anak mengenal negara dan bangsanya sendiri dan memiliki semangat untuk menjaganya. Dengan sikap dan tingkah laku yang bermanfaat bagi kepentingan masyarakat dan menghindari penyimpangan-penyimpangan sosial yang **data** merusak nilai-nilai kebudayaan."
249258070,101/119,1.0,0.849,"The current inquiry adds to the body of knowledge in this area by exploring potential changes to both reactive and proactive officer activities brought on by the pandemic using CFS **data** from Houston, Texas collected from January 1, 2018 through December 31, 2020. This study is informed by routine activity theory and perspectives on proactive policing. Trends are examined for seven different call types: violent crime, property offenses, disorder incidents, suspicious incidents, traffic-related activities, service-related activities, and non-crime events. In doing so, observed trends can be compared to the other large jurisdictions to further our understanding of how the pandemic has impacted demands for police services (e.g., Ashby, 2020). We also examine trends in officer proactivity through officer-initiated activities identified in the CFS **data** performed by three units: patrol, specialized crime investigation units, and the department's specialized response unit. This provides a unique look into how COVID-19 may have influenced officer-initiated activities."
244631546,11/16,1.0,0.688,"In this paper, we applied the technology of abstractive text summarization technology to the automatic generation of the topic belonging to the English reading comprehension. To achieve the goal, the seq2seq model and the attention mechanism are united to make the summary generated by the automatic system be more fit for the summary generated by human beings. Besides, we reduced the **data** loss rate in the process of the summary generation. As illustrated above, a large number of reading questions are needed by both official language examination board and private education organization. We put the related automatic technology into application that could largely relieve the pressure on question generating task. Also, our work could provide a great deal of CET exercises for students. Our future work is more about the other types of CET reading comprehension, such as the careful reading, whose question generating type is different from long reading question generation. We are going to try to use deep learning to generate the careful reading question generation.
"
233705419,8/53,1.0,0.151,"The EDI hive IoT framework is a cloud system based on the latest microservices architecture, which allows for a flexible orchestration of resources. This means that many user groups with large amounts of **data** can access the platform for different applications without performance restrictions. For **data** safety purposes, the platform can be operated as a private cloud on-or off-premises [9]. In addition to general use, role/rights, measurement **data** from management functions (e.g., aggregated measurement data), etc., the EDI hive offers other generic applications that can be used to optimize and control processes ( Figure 3). In particular, the ""EDI hive Cause-and-Effect Chain Editor"" can be employed to formalize existing expert knowledge and use it for the calibration of AI-based models [10]. With the EDI hive standard names application, the system and system parameter names in the EDI hive can be semantically networked with regard to different languages. Furthermore, specific and frequently abbreviated control and measurement system channel names can be translated into different languages. In contrast, relevant status **data** can be calculated or predicted from simple measurable parameters using valid simulation models or based on expert knowledge. The acquisition of such parameters can be referred to as a soft sensor supporting the AI algorithms, which can then be trained with a larger and technically more meaningful database and be calibrated for prediction [6,7]."
249258070,97/119,2.0,0.815,"Second, a significant increase was observed for violent crime calls. This finding was counter to some of the initial studies using CFS **data** to examine trends in aggravated assaults (Ashby, 2020; Mohler et al., Table 3 Interrupted time series analysis using ARIMA models. 17.53*** 2020) after the initial onset of COVID-19. This discrepancy could be due to measurement differences as our measure also included shootings in addition to different types of assaults. However, these initial studies only examined trends until April or mid-May of 2020 and were perhaps unable to account for longer term effects of the pandemic. For example, recent research found an increase in gun violence from the beginning of the pandemic through March 2021 across several U.S. states, including Texas generally and the Houston region specifically, when compared to the same time-period the year prior. The increases in gun violence were attributed to both prolonged psychological distress and increased gun sales resulting from the pandemic (Ssentongo et al., 2021). The current results also suggest that COVID-19 was associated with increased demands for police responses to violence, even after the initial wave of the virus. Third, the findings indicated that officers were engaged in more frequent self-initiated patrol activities compared to the pre-pandemic data. This increase remained after the death of George Floyd (when compared to pre-pandemic data), but at a lower rate. These observed changes to proactive patrol could also be attributed to changes in the routine activities of citizens. Again, the **data** showed that three of the reactive call types significantly decreased post-pandemic and another three reactive call types experienced no changes in frequency. As Ashby (2020) noted, a reduction in reactive CFS could create additional time for officers to focus on other tasks, such as proactivity. The current results may also lend further support to the findings from Lum, Koper, et al. (2020) demonstrating how proactivity is often manifested as generalized patrol even after the pandemic, as well as Maskály et al. (2021) results showing increases in directed or extra patrols since COVID-19. While there was initial concern that the pandemic may have necessitated a move to precautionary policing, a recent survey revealed that citizens are not supportive of reducing preventative patrol even during the pandemic . In this regard, decreases in reactive demands for police services coupled with citizen expectations of police services during the pandemic could account for this increase."
249258070,77/119,2.0,0.647,"Second, a significant increase was observed for violent crime calls. This finding was counter to some of the initial studies using CFS **data** to examine trends in aggravated assaults (Ashby, 2020; Mohler et al., Table 3 Interrupted time series analysis using ARIMA models. 17.53*** 2020) after the initial onset of COVID-19. This discrepancy could be due to measurement differences as our measure also included shootings in addition to different types of assaults. However, these initial studies only examined trends until April or mid-May of 2020 and were perhaps unable to account for longer term effects of the pandemic. For example, recent research found an increase in gun violence from the beginning of the pandemic through March 2021 across several U.S. states, including Texas generally and the Houston region specifically, when compared to the same time-period the year prior. The increases in gun violence were attributed to both prolonged psychological distress and increased gun sales resulting from the pandemic (Ssentongo et al., 2021). The current results also suggest that COVID-19 was associated with increased demands for police responses to violence, even after the initial wave of the virus. Third, the findings indicated that officers were engaged in more frequent self-initiated patrol activities compared to the pre-pandemic data. This increase remained after the death of George Floyd (when compared to pre-pandemic data), but at a lower rate. These observed changes to proactive patrol could also be attributed to changes in the routine activities of citizens. Again, the **data** showed that three of the reactive call types significantly decreased post-pandemic and another three reactive call types experienced no changes in frequency. As Ashby (2020) noted, a reduction in reactive CFS could create additional time for officers to focus on other tasks, such as proactivity. The current results may also lend further support to the findings from Lum, Koper, et al. (2020) demonstrating how proactivity is often manifested as generalized patrol even after the pandemic, as well as Maskály et al. (2021) results showing increases in directed or extra patrols since COVID-19. While there was initial concern that the pandemic may have necessitated a move to precautionary policing, a recent survey revealed that citizens are not supportive of reducing preventative patrol even during the pandemic . In this regard, decreases in reactive demands for police services coupled with citizen expectations of police services during the pandemic could account for this increase."
22512771,1/24,1.0,0.042,"To assess the impact of MLC tracking on target coverage and organ-at-risk (OAR) dose, the expected deviation between the planned and delivered dose must be quantified. Several methods have been proposed to compute the delivered dose based on offline dose reconstruction. [15][16][17][18] Recently, we have presented an online dose reconstruction solution for assessment of prostate SBRT, 19 which calculates and accumulates dose in real-time based on dose-influence data, while accounting for the machine/target motion interplay. Dose-influence **data** describe the influence of the fluence distribution on the patient dose. To make this approach applicable to dose calculation, the fluence distribution is subdivided into small rectangular segments, called bixels. Online dose reconstruction provides real-time quality assurance during treatment and provides the means to directly validate the performance of MLC tracking. Moreover, it is a prerequisite for replanning scenarios in which the treatment plan is changed on the fly during delivery. For example, drift motion might result in a gradually changing trade-off between target coverage and OAR dose which can be compensated for during delivery by replanning between beams."
249258070,63/119,2.0,0.529,"Additionally, Maskály et al. (2021) collected survey **data** from police executives in 27 countries around the world to assess the effects of COVID-19 on police organizations and activities. Their findings indicated that, by summer 2020, responding organizations experienced at least some changes to problem-solving or community policing activities (83%), patrol strategies (78.3%), traffic stops (68.2%), officer-initiated activities (60.9%), special operations teams' activities (54.1%), handling CFS (43.4%), and use of tactical teams (34.8%). Collectively, these results demonstrate that routine police activities have been impacted by the COVID-19 pandemic. Such changes have also led to empirical investigations of how police activities have changed since the start of the pandemic."
55648852,20/40,2.0,0.5,"We analyzed separately both earthquake and shots data. For the shot database we started with the Cube stations. These stations save the **data** in binary daily files that should be then converted to an appropriate format. The GFZ Potsdam institute provides useful algorithms to convert Cube format to MiniSeed format. During the recorded period, many of the 80 stations deployed lost the GPS signal sometimes, leading to more than one daily file. We found out that the registered **data** had some gaps, meaning that for certain periods of time the station did not register. The most probable cause of this is the loss of GPS signal. Fortunately, MiniSeed files are written with an absolute scale of time, thus, allowing us to identified and exclude these gaps. Another step we performed was to convert MiniSeed into SAC in order to choose the more suitable type file to work with. On the other hand SAC files have the time information not in absolute values but in a single time vector from 1 to the end of samples. Therefore, gaps could not be well identified using this type of files. For this reason we decided to work directly with the MiniSeed data. To reduce computation time we transformed the **data** into .mat format taking only the pieces of signal we needed. Indeed, we cut the signal 30 s before that **data** and 60 s after each shot. When we find a gap in the registration, the shots occurred in that period were not taken into account for that station."
58008953,26/26,1.0,1.0,"Table 1
1Run sheet generated by the software and the fed response **data** (E.A.-IU/ml) after experimentation of the runs.Std. 
Run 
Factor 1 
A:CS "
170072629,20/21,1.0,0.952,Source : Processed primary **data** (2016) 
246863515,1/44,6.0,0.023,"These literature consider using the causal effect of an intervention on a surrogate outcome (e.g., patients' short-term health) as a proxy for its treatment effect on the outcome of primary interest (e.g., long-term health). To this end, many criteria have been proposed to ensure the validity of the surrogate outcome. Examples include the statistical surrogate criterion [Prentice, 1989], principal surrogate criterion [Frangakis and Rubin, 2002], consistent surrogate criterion [Chen et al., 2007], among many others. However, these criteria can easily run into logic paradox [Chen et al., 2007] or rely on unidentifiable quantities, showing the challenge of causal inference when the primary outcome is completely missing. When multiple surrogates are available, , Price et al. [2018] consider transforming these surrogates to optimally approximate the primary outcome. Their approaches can avoid the surrogate paradox discussed in Chen et al. [2007]. Nevertheless, learning surrogate transformations requires experimental **data** with long-term outcome observations in the first place, which can be very demanding in practice."
254617983,6/13,1.0,0.462,"The EncephalApp ® cell phone application has been verified as a reliable method of measuring cognitive speed and flexibility in various populations [37]. The app demonstrates acceptable test/retest reliability (95% CI: 0.65-0.92, p < 0.001)) with resistance to improvements due to instrument bias (i.e., learning how to take the test). Instructions for use are first read aloud to participants, then they are guided through five full practice rounds to ensure they understand the purpose and functions of the test. Once they have been oriented to the test, they then complete five full rounds of the test with the Stroop-off, followed by five more with the Stroop effect activated. Scores are recorded on the cell phone with a time stamp which can be associated with EEG **data** for analysis."
236208828,7/27,1.0,0.259,"Covariates included in all models were proportion of county population aged ≥65 years, 4 state-level COVID-19 testing rate obtained from the COVID-19 Tracking Project database, 5 2018 Hierarchical Condition Category (HCC) risk score acquired from the Centers for Medicare and Medicaid Services (CMS) database as a proxy for countylevel medical comorbidity, and environmental factors. State-level COVID-19 testing rate is calculated as all tests completed (whether symptomatic and asymptomatic, voluntary or contact tracing) divided by the state-level population. The HCC risk score, based on medical risk profiles and demographics of county Medicare beneficiaries, was developed by CMS to risk-adjust Medicare spending for beneficiary health status. 19 20 While the score was designed to reflect healthcare access and hospital admissions in a geographical area, it does compare favourably with other comorbidity indices in prediction of outcomes, 19 and aggregate county-level scores are publicly available. 20 As such, we are using the HCC risk score as a proxy for county-level comorbidities. For environmental factors, we included average daily temperature (degrees Fahrenheit), 21 average daily precipitation 21 and average particulate matter of diameter ≥2.5 μm (PM 2.5 ). 22 All **data** sources used in this analysis are publicly available and are listed in online supplemental table S1."
253536255,8/31,1.0,0.258,"The numerical **data** were presented as mean ± standard deviation (SD) and analyzed using SPSS v19.0 statistical software (SPSS Inc., Chicago, IL, USA). The significance of the differences in each group was evaluated with a two-tailed Student's t-test and p-values of <0.05 were considered to be significant."
215725489,12/13,2.0,0.923,"However, grouping the **data** by dietary guilds shows significant clusters within the guild morphology data. Though the clusters still overlap there is a pattern within the **data** particularly between Guild 1 (diet consisting of largely Lepidoptera), Guild 3.1, (generalist and Diptera diet), Guild 3.3 (generalist with Coleoptera) and Guild 4.2, (largely Diptera with notable Trichoptera presence), where species following these diets generally produce similar size and shape of guano. When looking at grouping by the size of the bat, there is a similar pattern to that shown in dietary guild, with the largest separation between the smallest (S1) species and the largest (S4) species. Considering that the size and diet of a bat is intrinsically linked with one another [34] it would be hard to pull apart their separate influences on the guano morphology data. A species within the smallest group of bats is more likely to have a very different diet than a species in the largest group of bats, for example, P. pipistrellus and R. hipposideros are both in S1 and G3.1 and are quite different to E. serotinus and R. ferrumequinum who are both in S4 and G2, therefore it is unknown the true cause of the divergence."
157096864,75/80,1.0,0.938,"Figure 3
3in the Army of Novorossiya NOTE: List based on research conducted by Roger McDermott of the Jamestown Foundation and Michael Kofman (coauthor of the report) of the CNA Corporation in addition to known **data** about the various separatist groups that participated in the conflict. Great Host of Don Cossacks, Independent LPR forces, and Prizrak ""Ghost"" Brigade are not part of the same group; they are different groups fighting for the same cause."
92835393,2/15,2.0,0.133,"All **data** were statistically analyzed with the help of MSTAT (Gomez and Gomez, 1984). Analysis of variance (ANOVA) was measured and significant differences between means were calculated by Ducan's multiple range test (DMRT)."
249258070,52/119,2.0,0.437,"Lastly, interrupted time series analysis was employed to examine COVID-19's impact on police reactive and proactive activities. In time series data, observations have a natural temporal ordering. Observations close in time may have stronger correlations than observations further apart. Because of this non-independence or autocorrelation, t-tests may not be able to detect the intervention effect adequately. Interrupted time series analysis using ARIMA modeling, which not only features a quasiexperimental design, but also takes into consideration of the autoregressive moving-average process of the data, would produce statistically more rigorous findings. Based on the results of the augmented Dickey-Fuller tests, as well as examinations of both an auto-correlation function (ACF) and partial auto-correlation function (PACF), ARIMA models for different types of policing activities were identified and analyzed. A binary variable (before-after-March 12, 2020) was set up to examine the interrupted effects of the COVID-19. In the case of examining the patrol and DRT self-initiated activities, to control for the step change between the emergence of COVID-19 and the death of George Floyd, the indicator of the George Floyd incident was also included in the models. Fig. 1 presents the time sequence trend graphs for each reactivity and proactivity measure. With respect to reactivity, violent crime calls appeared to increase slightly after COVID-19. For calls for property crime, there appeared to be a reduction coinciding with COVID-19, but then a return to pre-COVID levels. Disorder calls varied greatly pre-COVID, with observable increases and decreases, but appeared to increase after COVID-19. Suspicious incident CFS exhibited a decreased trend that continued after COVID-19, but with periodic fluctuations. Traffic-related CFS notably declined after COVID-19. The visual examination of the plotted time series **data** for serviced-related activity calls suggested a decrease with the emergence of COVID-19. For non-crime events, there appeared to be a decreased trend before and after COVID-19."
219918661,2/6,1.0,0.333,"The research method uses a qualitative approach with primary **data** types. Primary **data** types were obtained through Focus Group Discussion (FGD) and in-depth interviews. FGDs were carried out twice each time followed by 15 young coffee farmers in NagoriSaitButtuSaribu and NagoriPamatangSidamanikPamatangSidamanikSubdistrict, Simalungun District, bringing the total number of young farmers who participated in the FGD to 30 people. The FGD was carried out deliberately namely Arabica coffee farmers with the age limit of young coffee farmers according to the local view (emic), ie aged 20 to 40 years. Research subjects in-depth interview were young coffee farmers who were involved in coffee businesses that were deliberately selected by the snowball technique. In-depth interviews with research subjects were conducted semi-structured using interview guidelines. As a qualitative study, the **data** analyzed are in the form of words rather than a series of numbers."
196643668,7/34,1.0,0.206,"SNP calling is a statistical likelihood procedure (Nielsen et al., 2011) for each nucleotide position in the genome. As a result, the number of false positives will scale with the overall genome size. Moreover, chemically mutagenized lines have a low true positive rate (1/125,000 to 1/500,000 bp) resulting in a relatively higher proportion of false positives. This is in stark contrast to the use of SNP calling for distinguishing natural populations, in which multiple orders of magnitude more true positives are present. We initially attempted to score each SNP as a molecular marker in our sequencing **data** and found that many adjacent neighboring SNPs were not linked in the three fully sequenced individuals that shared the ""10"" pedigree. This violates the predicted inheritance of these chromosomes and DNA segments (data not shown). We hypothesized that a high ratio of false positives in the SNP calling procedure was interfering with mapping and cosegregation. To detect positions in the genome that were false positive SNP calls, we identified genomic positions that were scored as variant in more than one independently mutagenized line. We compared SNP calls from the line 10 derivatives (10-2, 10-3, and 10-d), the aphenotypic EMS-treated line 12 (12-2) and the previously published dhr2-1 mutant (Krothapalli et al, 2013). SNPs shared between independent lineages are highly unlikely to be due to independently mutagenized chromosomes. Far more likely, any SNP variation shared between the 10, 12, and dhr2-1 pedigrees would be caused by systematic bias in the generation and analysis of sequencing data. These shared SNPs should detect 1.) errors in the reference sequence, 2.) differences between the mutagenized material and the originally sequenced line, and 3.) positions in the genome that frequently return a likely SNP call due to structure or paralogy. Furthermore, only those SNPs present in the 10 lines and not in 12-2 or dhr2-1 can be causative for the extreme dwarf locus segregating in that lineage. Figure  Only a minority of differences was found when comparing the three lineages of line 10, which indicates the majority of these shared SNPs are not the result of base calling errors in the reference sequence. Table 3 provides the filtered common SNP variations for individual samples considering either genome-wide SNP **data** or only SNPs in coding sequences."
57759233,24/28,1.0,0.857,"Figure 3 :
3Pre-and posttest neurophysiologic measures. (a) Nonlesioned hemisphere amplitude with single-pulse TMS testing. (b) Lesioned hemisphere amplitude with single-pulse TMS testing. (c) Nonlesioned hemisphere CSP duration. (d) Lesioned hemisphere CSP duration. Nonlesioned **data** is denoted by a closed circle, and lesioned **data** is denoted by an open circle. Note: **data** points are labeled with a superscript participant identifier consistent with Table 1 (participant IDs 1-8). The y-axis representing change differs between the measures. CSP: cortical silent period; ms: milliseconds; SP: single-pulse; TMS: transcranial magnetic stimulation. Amplitudes are measured in μV (microvolts).
"
233438695,2/62,2.0,0.032,"Data collection for the 'neighbouring' pillar required referring directly to the neighbourhood inhabitants for which we conducted a household survey across the case study neighbourhoods. A questionnaire was designed in which each indicator was developed into a set of questions in order to gain an in-depth knowledge regarding different aspects of each indicator. After piloting the questionnaire and finalising it, a household survey was conducted in case study neighbourhoods. Distribution took place based on a spatially stratified non-representative systematic random sampling using drop and collect method as it results in a higher response rate [107,108]. A second collection round was arranged in case respondents could not complete the questionnaire in the first collection round. In total 1304 questionnaires were distributed, 488 returned. This provided us with sufficient critical mass for undertaking relevant statistical analyses for our purpose [109]. We used SPSS software for **data** processing, and ran descriptive analysis, correlation analysis, and crosstabular analysis, to study the value and status of each indicator and the relationship between them. Results were scored between 0 and 200 so that each indicator received a score between 0 (lowest) and 200 (highest) showing the value of the indicators."
155578419,10/10,5.0,1.0,"The first improvements which we have planned are particularly due to the limited **data** basis for the estimation of probabilities of death and migration and expected number of births in each municipality. Even if we had the **data** for say 5 years, the variance on an average over the years would be very large for small municipalities. W e are now thinking of combining the municipalities into groups in order to obtain a larger **data** basis per region. We have not yet decided how we shall form these groups of municipalities, but a study concerning the dependency of migra tions on variables both of a demographic and of a non-demographic nature has been started."
53743789,27/44,1.0,0.614,"Statistical analyses were performed with the R software, version 3.2.3 and Systat, version 13. The binomial response variable 'survival' (i.e., probability or proportion of survival) was analyzed with Cox's proportional hazard [54] test ('coxph' function) from the 'survival' package in R. We used **data** for animals that were dead at day 3, 4, and 5 and censored the **data** for individual insects that were alive on day 5. We used the function survfit to model expected survival for all groups, with 95% confidence intervals. These models were used for graphical representation of survival within each treatment group."
217125084,36/57,1.0,0.632,"To explore the reason of these duplication events, we searched for the genomic regions containing the MAPKK genes which are possible synteny. Most duplicate gene pairs occurred in syntenic genomic regions, suggesting that these multiple gene copies were caused by whole genome or segmental duplications ( Fig. 4; Additional files 11 and 12). Particularly, the duplication events of group A MKK1, MKK2 and MKK6 took place in the common ancestor of core eudicots corresponding with the γ WGD ( Fig. 4; [40]). The two duplications of group A MKKs in Brassicaceae were involved in the α/β WGDs within the Brassicaceae lineage (Additional file 11; [40]). With the studies on the WGD events for many species were previously carried out, we collected these **data** and their paleopolyploidy histories (Fig. 3). We then assessed the duplication events to the influence of the size in group A MAPKKs. The comparison implied that the WGDs might be conducive to the expansion of the orthology groups from some species. In order to further confirm the roles of genome duplication to the gene family expansion, we carried out the co-relationship analysis between rounds of genome duplication about MAPKK genes. The correlation coefficient was calculated as 0.549 (P < 0.01) for the group A MAPKKs. The results suggested that the WGD significantly contributed to the gene expansion for group A MKKs."
184487142,12/47,2.0,0.255,"Semi-supervised learning Carmon et al. [5] recently showed that using unlabelled **data** can improve the adversarial robustness as well. They employ a simple, yet effective, semi-supervised learning technique called self-training to improve the robustness of CIFAR-10 classifiers. We employ this idea in our framework and we train our CIFAR-10 smoothed classifiers via self-training using the unlabelled dataset used in Carmon et al. [5]. Details can be found in Appendix E.2."
119479526,24/29,1.0,0.828,"Figure 11 :
11The model prediction, uncertainty intervals, true model and synthetic **data** points are plotted versus x for (a) kombine and (b) MultiNest, respectively.
"
221635250,11/22,1.0,0.5,"Raw mobility spectra for positively charged THABr clusters taken with the Perez-LT-3 o DMA, with the blower running at the lowest (3200 rpm, gray) and the highest (9000 rpm, black) settings tested. The aerosol flow was between 1.3 and 1.5 L/min. Fig. 4 shows raw mobility spectra for positively charged THABr clusters at the lowest and the highest settings of the blower used, showing a drastic increase in resolution as the flow rate goes up. The bipolar source used produces dominantly singly charged ions (Fernandez de la Mora & Barrios, 2017), so the ordering of the peaks in the spectrum reveals directly their composition: monomer (bare cation), dimer, trimer, etc, from left to right. The upper spectrum taken at 3200 rpm resolves up to 18 clusters. The lower spectrum taken at 9000 rpm goes only up to the octamer. Note that the noise level is about 0.1 fA, as expected for this electrometer. As a result of the rather low signal, the zero drift of the electrometer is not negligible. It was corrected by assuming a linear variation of the baseline with the voltage, such that the horizontal regions between isolated peaks would be indeed flat. As an example, in the **data** shown at 9000 rpm (lower continuous black line) the last datum that reads approximately 0 fA when corrected would have read 0.4 fA, and the flat theoretically horizontal regions between peaks 1-6, if not corrected, would have had an unphysical finite upward slope. Uncorrected **data** are shown also for reference as the dotted line falling slightly above the corrected continuous line for 9000 rpm. Spectra were taken at the pump settings and flow rates indicated in Table 3. The peaks for the various clusters in these spectra taken at several pump speeds were fitted to Gaussian curves to obtain the resolving powers shown in Fig. 5. The figure includes the continuous gray line C V 1/2 scaling with peak voltage as theoretically expected from diffusive broadening (Rosell et al., 1996). The coefficient C (1.55 V − 1/2 ) used is not obtained by any rigorous theoretical analysis, but empirically as a low-voltage fit (gray line in Fig. 5) to the upper envelope of the data:"
218971725,1/10,4.0,0.1,"In this work, we exploit an optimal multi-wave sampling approach for design-based estimators. In survey literature, the well-known Neyman allocation (Neyman, 1934) is the optimal sampling strategy; it minimises the variance of population total for the variable of interest. The regression parameter can be written as the total of its influence functions (Breslow et al., 2009a), so Neyman allocation can then be adopted for minimising the variance of regression parameter. The influence functions also depend on phase-2 **data** so that a multi-wave sampling can be useful."
40828380,6/13,1.0,0.462,"Our interest in the first example is to study the effect which the parameter p has on various performance measures. The **data** for this example is as follows: K 15, L-5, the service rates for servers 1 and 2 are geometrically decreasing with (a) 3 (1) 2 (2) 2, It can be verified that A-4."
207778550,30/48,1.0,0.625,"An example of this effect is seen in the measurements of 10 B(n,α) 7 Li performed on two separate occasions at the same laboratory using the same multi-grid fission chamber, by Zhang et al. in 2002 [109] and by Zhang et al. in 2011 [110]. For the earlier measurements, it was not known that particle leaking had occurred. Thus, the measured cross sections were significantly lower than other measurements, as is seen in Fig. 11. Initially these **data** could have been considered to have had an USU component. For the later measurements it was understood that particle leaking can occur in such experiments, and a more complete kinematic analysis was carried out to remove its effect. Those **data** agree with recent measurements, such as those of Giorginis and Khryachkov [108] who understood the particle leaking problem, as is shown in Fig. 11."
232380196,25/28,1.0,0.893,"In this section, we conduct some ablation studies to characterize our hybrid networks. Concretely, we study whether the proposed PSC loss is less sensitive to **data** sampling, the advantage of using PSC loss in feature learning comparing to cross-entropy loss, and the advantage of our curriculum based joint training comparing to the two-stage learning strategy. Table 3. Evaluation of the sensitivity of PSC loss to **data** sampling. Hybrid-PSC with random PSC and Hybrid-PSC with CB-PSC denote in the PSC based hybrid network, we use random **data** sampling and class-balanced **data** sampling for the feature learning branch respectively. Classification accuracy (%) on long-tailed CIFAR-100 is reported.  Table 4. Evaluation of the advantage of supervised contrastive losses over cross-entropy loss for feature learning in long-tailed classification. CE-CE denotes both feature learning and classifier learning adopt cross-entropy loss, i.e., our supervised contrastive loss is replaced by cross-entropy loss. Classification accuracy (%) on long-tailed CIFAR-100 is reported. contribute to the insensitivity of the PSC loss on **data** sampling. Firstly, in PSC loss, the image features and prototypes are both 2 -normalized, which breaks the strong correlations between class frequency and feature norms. Secondly, assuming the affinity score between a sample and its prototype is s yi i = z i · p yi /τ . For a sample x i with label y i ∈ {1, 2, . . . , C}, the gradient of the PSC loss L P SC (z i ) w.r.t s yi i is constant, and the gradient w.r.t the affinity to a prototype from a negative class c ∈ {1, 2, . . . , C}\y i , is exp(s c i )/ y∈{1,2,··· ,C},y =yi exp(s y i ). The denominator excludes the dominating term of s yi i and thus results in a prominent gradient. The constant gradient for positive class and prominent gradients for negative classes can help to alleviate the overfitting in over-sampling and enhance the inter-class separability of the features."
249258070,31/119,2.0,0.261,"Collectively, there were ten categories of police reactive and proactive activities coded from the data, and these categories make up the dependent variables for the current study. Police reactivity to CFS were coded into seven different categories using an approach consistent with previous research utilizing CFS **data** (see Wu & Lum, 2017). Violent crimes included CFS involving reported shootings, robbery, and several types of assaults. Property offenses was a category comprised of burglary, theft, and forgery type offenses. Disorder incidents consisted of an array of disturbances, including general, family, and noise CFS. Suspicious incidents included calls where an alarm was sounded (e.g., vehicle alarm set off) and reports involving a suspicious person or vehicle. The trafficrelated activities category comprised CFS for traffic accidents, driving while intoxicated (DWI), and other traffic-related issues (i.e., road rage). Service-related activities included calls to assist first-responders, including other officers, fire fighters, or emergency medical services. Lastly, the non-crime events category consisted primarily of assisting specialized units with transporting individuals and responding to silent 911 calls."
38256305,2/49,1.0,0.041,"Pore pressure diffusion is considered to play a key role in controlling the occurrence of earthquakes associated with Koyna and Warna reservoir [8][9][10][11][12][13][14][15][16][17][18][19]. Hence, the prevalent fault structure and tectonic setting in the region that influence seismicity need further investigation. The detailed inventory preparation of the near-surface fault and fracture pattern is likely to help detect relatively high permeable areas that allow intrusion and infiltration of surface water. Towards this end, satellite **data** were harnessed to detect near-surface fault and fracture zones and to understand the structural pattern via visual lineament analysis. The Sentinel satellite radar images available since 2015 from ESA are assumed to delineate sub-surface structures whose subtle morphological details are enhanced, which were earlier lacking in detail, due to radar backscatter of the surface. Landsat 8 **data** available since 2013 are also seen to show improvement when compared to previous Landsat missions because of enhanced radiometric and thermal resolutions. One of the goals of the present paper was to investigate whether additional structural/tectonic information can be gleaned from these newly-available satellite data."
17671315,18/32,2.0,0.562,"Since the differentiation of noisy **data** is an unstable procedure andf (t − λ) is the kernel of the integral equation (56), we calculate the derivativef (t) in a special way. For each point t k := z k , k = 1, ..., M z − 1 we approximate the derivativef (t k ) aŝ
f (t k ) ≈f (t k+1 ) −f (t k−1 ) 2h z .(59)
Next, we extend this approximation as the discrete even function for t k = −z k , k = 1, ..., M − 1. Even though (59) seems to be a non-regularizing procedure, it works quite well for our goal, since in the discrete integration in (56) the right hand side of (59) is actually multiplied by h z /2."
53478339,1/24,3.0,0.042,"We present a multi-proxy skeletal δ 18 O, Sr/Ca, and spectral luminescence record of seasonal to interannual variability in riverine influence obtained from nearshore GBR coral microatolls. Annual mean SST and mean summer and winter values were calculated from a mid-Holocene (4665 cal. yr BP) record spanning 31 years, and a modern record spanning 17 years. The combined **data** provide high-resolution information on past climate variability within the north-eastern Australian region and suggest that an altered mid-Holocene hydrological cycle influenced coastal oceanographic conditions of the GBR."
16212589,3/6,7.0,0.5,"Although our measurements for these Na § channels extend the measurable range and show a higher limiting slope, they do not contradict previous estimates. As indicated above, our **data** also show a slope of six charges in the range of 0.1 to 0.001, where most previous estimates of limiting slope were derived. For skeletal muscle Na + channels, however, this range is not sufficiently negative to reach the true limit."
1520137,20/35,1.0,0.571,"We study how visual perception of a target bar can be biased by contextual bars in the image, and how a Bayesian model of object inference can account for the data. Human observers are more likely to perceive a target bar when the contextual contrast, i.e., the luminance difference between the contextual bars and background, is weaker rather than stronger. Relative to the situation without the context, they are biased to perceive the target in a context of weak contrast when the target can perceptually group well with the context, as if the context fills in the target. Meanwhile, they are biased not to perceive the target in a context of strong contrast, as if the context suppresses the perception, regardless of whether it could perceptually group well with the would-be target. The Bayesian model illustrates that the context influences the perception by biasing (1) observers' prior belief that a target should be present and (2) observers' internal model of the likely input contrasts from a target bar. Our **data** suggest that brain areas beyond the primary visual cortex along the visual pathway are responsible for inferring object causes for input images."
29602952,8/19,2.0,0.421,"To make posterior inference about (p, π, θ), we use a grid method in three dimensions in a manner similar to the one discussed earlier for (p, π). With 100 intervals in each variable, we have to evaluate the joint posterior density at 106 values of (p, π, θ), not too time-consuming though. It is unnecessarily complex to run a Gibbs sampler here. Because each of p, π and θ lives in (0, 1), the grid procedure is still attractive. Note that for the ignorable selection model, a posteriori p and θ are jointly independent of π. In fact, Thus, we use a grid to draw (p, π), and we draw π independently. In either case, we have used 10, 000 iterations, perhaps too many! In Table 2 we have compared the ignorable and the nonignorable selection models for Crow's **data** when inference is made for p, π and θ. The correlation is almost zero under both the ignorable and the nonignorable selection models, but the difference between these models for inference about p and π is enormous with much larger estimates from the ignorable selection model. Under the nonignorable selection model, the posterior mean, posterior standard deviation and 95% credible interval for p are .257, .033, (.190, .320). This small correlation seems to have some effect: the posterior mean, posterior standard deviations, the 95% credible interval without the familial correlation are .271, .035 and (.206, .340)."
15294885,21/25,1.0,0.84,"variable [ 13 ,
13Definition 3.1] and by a relation between M(f ) andM (f ) shown in [17, Eq. (5)]. By using the phase φ(f ) ofM (f ), we can rewrite the complementary PSD asM (f ) = |M(f )|e jφ(f ) = k(f ) M(f )M(−f )e jφ(f ) , where 0 ≤ φ(f ) ≤ 2π. In the next lemma, the properties of the impropriety frequency and the phase functions are provided. Lemma 2: The impropriety frequency function k(f ) and the phase function φ(f ) satisfy 0 ≤ k(f ) ≤ 1, k(−f ) = k(f ), and φ(−f ) = φ(f ), ∀f. (17) Proof: Sincem[−k] =m[k] by definition, we haveM (−f ) =M (f ), which implies φ(−f ) = φ(f ). This also leads to k(−f ) = k(f ) by (16). By using the property |M(f )| 2 ≤ M(f )M(−f ) shown in [17, Eq. (5)], we have 0 ≤ k(f ) ≤ 1. ✷ For example, an uncorrelated real-valued PAM **data** sequence results in k(f ) = 1, ∀f , whereas any proper-complex **data** sequence results in k(f ) = 0, ∀f . By using the impropriety frequency function, we can rewrite the MSE (15) in the form of a function ofs(f ) as a function of s(f )."
207778550,10/48,4.0,0.208,"USU are experimental uncertainty sources whose estimated magnitudes must be determined based on the experience of experimenters and evaluators. It should be noted that Report JCGM 100:2008 [79] clearly indicates that what it considers to be USU are completely indeterminable (unknowable). As mentioned earlier, nuclear **data** evaluators, motivated by practical necessities, must proceed, albeit cautiously, beyond this STOP sign! This observation is fully consistent with the discussion in Sect. II that points out differences in how uncertainties are approached in traditional metrology and in nuclear **data** evaluation work."
6519114,1/6,2.0,0.167,"Our initial analytical focus was on the differences in ecosystem carbon budgets when comparing symmetric versus asymmetric climate change. For this, we used four different scenarios 20 : ambient scenario corresponding to the historical recorded temperature **data** during the period of 1961-1990 (T amb ), symmetric warming (T sym ), double asymmetric warming (T asy2 ) and triple asymmetric warming (T asy3 ). The three scenarios for temperature increases were based on a combination of recorded recent temperature increases (SI: Figure S2) and the predicted future magnitude of temperature increases simulated by a regional climate model (RegCM3) under the A2 IPCC CO 2 emission scenarios (SRES A2) 40 (SI: Figure S3). In the second step, the interactive effects of changes in temperature, precipitation, and atmospheric CO 2 concentrations were investigated. The precipitation treatment had two levels: an ambient level corresponding to the historical mean precipitation amounts recorded during the period of 1961-1990 (P amb ), and precipitation change based on the 2071-2100 predictions from the RegCM3 (P cha ) 40 . The model MT-CLIM (Version 4.3) was used to compute meteorological variables not included in the standard weather station records and required by the Biome-BGC model 41 . The CO 2 treatment also had two levels: an ambient level corresponding to the historical concentrations recorded during the period of 1961-1990 (C amb ) based on the Mauna Loa measurements (http://co2now.org/), and a scenario taking into account the gradual predicted increase in atmospheric CO 2 concentrations from 626 ppm v in 2071 to 836 ppm v in 2100 (C inc ) as predicted by the SRES A2 emission scenario **data** 42 ."
56162659,1/10,2.0,0.1,"Taken together, these studies indicate that impairments in nonverbal fluency can emerge both pre-and post-surgery. Since no study reported **data** collected pre-and post-surgery and at follow-up in the same patient sample, it is unclear whether an impaired ability in generating novel responses, can be subjected to an effect of reorganization/adaptation. As fluency refers to the ability to use one or more strategies to achieve the maximum number of new responses and avoiding repetitions [4], it is reasonable to assume that the use of strategies in design fluency tasks can be characterized by flexibility. In a recent meta-analysis [7] the need of more studies with longer post-op cognitive follow-up testing to better understand the conclusive effects of glioma surgery on cognition has been highlighted."
53743789,15/44,1.0,0.341,"Our **data** suggests that the expressed Cry toxins did not solely induce starvation (as cause of death) in the presence of antibiotics, i.e., presumed absence of microbiota, as hypothesized by Mason et al. [21]. For O. nubilalis, already on day 4, survival was reduced to less than 50% on both Bt maize varieties and for S. littoralis on the Spanish Bt maize to around 60%. In the study by Mason et al. [21], however, starvation did not affect survival rates before day 6. However, in our experiments, continuous presence of antibiotics or only a pretreatment with antibiotics until the onset of the bioassays did make some although small differences. This was possibly because even when stopping the administration of antibiotics at the beginning of the bioassay, a carry-over effect may last for the tested five-day period, meaning that the reestablishment of an effective gut microbiota probably takes longer than the testing period. Antibiotics alone did not affect larval survival on non-Bt control maize varieties, which is in agreement with all other studies listed in Table 1."
249303694,22/29,1.0,0.759,"Author
Contributions: Conceptualization, N.M.M., S.M. and M.M.; methodology, N.M.M. and S.M.; formal analysis, N.M.M. and S.M; investigation, N.M.M.; **data** curation, N.M.M.; writing-original draft preparation, N.M.M.; writing-review and editing, N.M.M., S.M. and M.M.; and supervision, S.M. and M.M. All authors have read and agreed to the published version of the manuscript. Funding: This research received no external funding. Data Availability Statement: Data available upon request from the first author.
"
15434390,26/32,1.0,0.812,"Altogether, our findings reveal a role for NOV in the modulation of CFA-induced pain by exerting antiinflammatory and anti-allodynic effects. Our study provides for the first time evidence that, besides their recently demonstrated roles in the pathogenesis of neuropathic pain, MMP-2/-9 could be involved in chronic inflammatory pain as well. We hypothesize that, during chronic inflammation, NOV downregulation in DRG and spinal cord contributes to MMP-2/-9 induction thereby participating in the maintenance of pain intensity. Because NOV appears as a novel mediator in the functional interplay between cytokine and MMPs in pain processes, it may alone or in concert with other drugs represent a new interesting analgesic. Knowing that recent evidence renders MMP-2/-9 useful targets for neuropathic pain relief [56], the investigation of NOV involvement in neuropathic pain would be worthwhile research, and preliminary **data** from our laboratory in this matter appear promising. Nevertheless further comprehensive research is needed to investigate the precise mechanisms involved in such function in order to improve therapeutic solutions."
6375277,6/16,1.0,0.375,"Certain limitations in both the available expression **data** as well as NCA itself could be addressed to make this approach more powerful. Gene expression analyses obtained from whole blood leukocyte samples provide an integrated signal from different leukocyte populations which are difficult to deconvolute, and so using a single cell population would be advantageous, such as could be obtained using cell sorting or other methods. Additionally, the number of transcription factors which can be used in NCA is approximately the number of expression profiles in the **data** set, and so a greater number of expression profilesobtained at best shortly after the endotoxin administrationwould also have been useful. Finally, NCA's scaling property, which makes it difficult to predict the direction of transcription factor activity, as well as NCA's current inability to incorporate time course information from the **data** set are important limitations to the method. Some approaches that may overcome these challenges include recent studies in"
238581401,20/34,1.0,0.588,"Interestingly, the potential of MTs as detoxifying proteins has been known for decades and this function has also been linked to possible resistance to some chemotherapeutics [31][32][33]. The detoxifying ability of MTs has been reported even for some nonmetal-based drugs. Chemotherapeutics that are sensed and bound by MTs are neutralized before reaching their intended target(s) and thereby become clinically ineffective. Thus, MT expression represents potential predictive biomarkers of resistance to specific treatments [34,35]. In light of these facts and our **data** presented here, CBD usage might be a relevant factor to be kept in mind for cancer patients not only undergoing the trials with DSF-repurposing therapy but also treated with some standard-of-care chemotherapy drugs."
252622102,18/27,2.0,0.667,"Family Study population are known to be relatively consistent over time (Chodur et al., 2016;Fretts et al., 2018;Kauffman et al., 2019;Kumar et al., 2016), so this may be a reasonable assumption. Additionally, the single follow-up assessment prevents us from estimating time of depression onset and time-varying confounding. Fourth, loss-to-follow-up was greater among male participants. Compared to females, males tend to have poorer diet quality and health behaviors and are less likely to report depression symptoms (Brave Heart et al., 2016;Noble et al., 2015). In our study, on average, those who were lost to follow up had fewer depressive symptoms at baseline and a slightly higher AHEI score than those with complete **data** (Appendix Table A1). Although this could have induced a positive, non-significant association between diet quality and reporting depressive symptoms, our sensitivity analysis using imputed outcomes did not offer evidence of this. Fifth, we were unable to exclude participants with possible postpartum depression because we did not have pregnancy information at follow up."
230635187,4/15,1.0,0.267,"FIGURE 1
1Study Cohort and CONSORT Diagram (A) Study cohort: Scatterplot showing the distribution of left ventricular ejection fraction (LVEF) against anthracycline cumulative dose, with control patients in blue (n ¼ 121), case patients in red (n ¼ 238), and the rest in gray (n ¼ 357). (B) Consolidated Standards of Reporting Trials (CONSORT) diagram: selection of case and control patients for exome sequencing in the discovery cohort. *Participants with complete **data** and good-quality DNA. PCS2 ¼ Preventing Cardiac Sequelae in Pediatric Cancer Survivors. /l of dimethyl sulfoxide (DMSO) or inhibitors of the protein products. One mmol/l DOX was associated with cell death and was not used (data not shown"
2903113,5/11,1.0,0.455,"HEYL Localization Is Altered in Cancer Tissue-We have previously shown that in prostate cancer biopsies HEY1 expression is predominantly cytoplasmic rather than nuclear, and we hypothesized that this cellular localization provides a growth advantage in cancer cells, circumventing the repressive effects of nuclear HEY1 (25,26). To understand better the mechanism(s) of repression of AR by HEY proteins, we examined the subcellular distribution of HEYL protein by confocal microscopy with a monoclonal antibody. In normal and benign transformed prostate epithelial lines, RWPE-1 and BPH-1, respectively, endogenous HEYL was entirely nuclear (Fig. 7A). In our inducible LNCaP:HEYL cell line treated with doxycycline, the exogenously expressed HEYL was also nuclear, demonstrating that the transfected HEYL behaves similarly to endogenous protein, and furthermore, we observed a co-localization of HEYL and AR in the nucleus of these cells in the presence of androgen (Fig. 7A, bottom panel). In addition, we verified the specificity of the HEYL antibody by immunofluorescence and Western blotting of LNCaP:HEYL cells treated with or without doxycycline (Fig. 7A). To examine expression patterns of endogenous HEYL in human prostate tissue, we used prostate needle biopsies from patients with prostate cancer and stained them for HEYL. As shown in Fig. 7B, endogenous HEYL was expressed in the epithelial cell compartment of the prostate and showed nuclear localization in benign cells (Fig. 7B, left panels) with little expression detected in the cytoplasm. However, in all stages of cancer examined, HEYL nuclear intensity decreased, in most cases correlating with increasing cytoplasmic expression (Fig. 7, B and C). The expression score for each patient is plotted in Fig. 7C. This shows that nuclear expression decreased in all stages of the disease studied but remained high in adjacent benign tissue. Furthermore, expression of HEYL in the cytoplasm remained low in adjacent tissue but at the same level or higher in prostate cancer. Collectively, these **data** suggest that HEYL is excluded from the nuclei of cancer cells but not benign cells, indicating that nuclear exclusion of HEYL occurs in the early stages of prostate cancer formation or progression."
37841149,3/15,1.0,0.2,"To resolve these two possibilities, we examined the virulence of ROP54HA II and ⌬rop54 II parasites in IFN-␥ receptor-deficient (IFN-␥R Ϫ/Ϫ ) mice. We predicted that the  virulence of ⌬rop54 II parasites would mimic that of the parental line if virulence were dependent on an IFN-␥-mediated immune response (but would still be dramatically lower if merely due to a reduction in growth in vivo). To test this, we i.p. injected 5,000 ROP54HA II or ⌬rop54 II parasites separately in IFN-␥R Ϫ/Ϫ mice and observed their morbidity. The IFN-␥R Ϫ/Ϫ mice demonstrated identical morbidity kinetics when infected with either ROP54HA II or ⌬rop54 II parasites (Fig. 6B). These **data** demonstrated that IFN-␥ signaling is necessary for the difference in virulence of ROP54HA II and ⌬rop54 II parasites and suggest that ROP54 enables parasites to evade an IFN-␥mediated immune response (14)."
53380409,4/119,1.0,0.034,"The **data** sample was collected by the ATLAS detector during the pp collision running of the LHC at ffiffi ffi s p ¼ 13 TeV in 2015 and 2016. Events were selected for the different channels with various triggers, as described in their respective papers [9-18]. Channels featuring charged or neutral leptons were selected with single or multiple electron and muon triggers with various p T thresholds and isolation requirements or with missing transverse momentum triggers with varying thresholds. A high-p T jet trigger was used in the fully hadronic channels. After requiring that the **data** were collected during stable beam conditions and with a functional detector, the integrated luminosity amounts to 36.1 fb −1 ."
15394341,9/18,1.0,0.5,"Figure S2 :
S2Twenty-second catalog earthquake waveforms, ordered by event time in 1 week of continuous **data** from CCOB.EHN (bandpass, 4 to 10 Hz). (A) FAST detected 21 (blue) out of 24 catalog events within the region of interest in Figure 2. (B) False negatives: FAST did not detect 3 (black) out of 24 catalog events in this data. Autocorrelation detected all 24 catalog events.
"
253240026,19/31,1.0,0.613,"After 10 days of Ti treatment, 950 and 1277 were detected as up and downregulated genes, respectively, in the root. We also determine that 57 and 79 genes were up and downregulated, respectively, in shoots. Venn analysis helped us to determine sets of genes that are common or uniquely upregulated and downregulated at 10 days across the two tested tissues. In the case of upregulated genes, only six genes are shared, whereas 944 and 51 are specific for root and shoot, respectively ( Figure 4A). In the case of downregulated genes, 20 genes were shared, whereas 1257 and 59, were specific for root and shoot, respectively (Supplementary Figure S4, Supplementary Tables S3-S6). These **data** suggest that Ti treatment causes changes in the transcript level of a large number of genes in the roots, while it causes changes in transcript level in only a few genes in the shoot, and that the responses to Ti seem to be mainly organ specific."
233438695,35/62,1.0,0.565,"Author
Contributions: Conceptualization, M.R.S.; R.K.; methodology, M.R.S.; R.K.; software, M.R.S.; validation, M.R.S.; R.K.; formal analysis, M.R.S.; investigation, M.R.S.; resources, M.R.S.; **data** curation, M.R.S.; writing-original draft preparation, M.R.S.; writing-review and editing, R.K.; visualization, M.R.S.; All authors have read and agreed to the published version of the manuscript.
"
