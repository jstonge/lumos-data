text	corpusid	sentiment
Pathway analysis of differential gene and protein expression suggests that some CDK12 functions are conserved across cell types . In addition to cell type - specific regulation described above , we identified common ALE events that were regulated by CDK12 in multiple cell lines . From our experiments with SK - BR-3 , MDA - MB-231 and 184 - hTERT cells , and from the available datasets from HCT-116 cells ( 27 ) , we found that depletion of CDK12 promotes distal ALE splicing of the DNAJB6 ( DnaJ homolog subfamily B member 6 , MRJ ) gene transcript ( in SK - BR-3 , MDA - MB-231 and 184 - hTERT , avg = 0.24 ) . In an analysis of TCGA RNA - seq data for tumors containing CDK12 mutations or bi - allelic CDK12 deletions ( n = 18 comparisons ; mutation / deletion : control ) , we found the DNAJB6 distal ALE event in 78 % of comparisons on average , as compared to 46 % of control ( n = 54 comparisons ; control : control ) comparisons ( Fisher 's exact test P = 0.03 ) . Unlike the long genes that were regulated in a cell type - specific manner , DNAJB6 encodes two small protein isoforms ( 36 and 27 kDa ) from transcripts containing 10 and 8 exons , respectively ( Figure 8A ) . The short isoform of the DNAJB6 protein ( DNAJB6 - S ) is a cytosolic HSP40 family chaperone with implicated roles in Huntington 's disease ( 72,73 ) . By contrast , ALE splicing introduces a nuclear localization signal into the long isoform of DNAJB6 ( DNAJB6 - L ) and therefore it operates primarily in the nucleus . Increased nuclear localization of DNAJB6 - L has been reported to mitigate tumorigenicity and metastasis of breast and esophageal cancer cells ( 74,75 ) . We found that treatment of SK - BR-3 cells with CDK12 siRNA-1 increased expression of DNAJB6 - L with a concomitant decrease of DNAJB6 - S expression ( Figure 8B and C ) . This suggests that the high native CDK12 levels in SK - BR-3 cells can reduce the expression of DNAJB6 - L , consistent with overexpression of CDK12 functioning to promote tumorigenesis . We tested this hypothesis functionally in MDA - MB-231 cells , where DNAJB6 - L had been previously shown to decrease cell migration potential ( 74 ) . We first confirmed that treatment of MDA - MB-231 cells with CDK12 siRNA-1 increased gene and protein expression of DNAJB6 - L ( Figure   8B - D ) . To examine the cellular phenotype associated with CDK12 expression we used a scratch wound assay and live cell imaging of MDA - MB-231 cells as a functional test for cell migration ( Figure 9 ) . In separate assays we also coated the scratch wound with collagen - I to examine the ability of cells to invade into an extracellular matrix . Depletion of CDK12 by siRNA ( Figure 9A ) decreased the ability of MDA - MB-231 cells to migrate and invade into a matrix ( Figure 9B and C , ' Dep ' ) . In this experiment , cells were pre - treated with Mitomycin C to inhibit cell proliferation to ensure that the changes in migration and invasion rates were not due to impaired cell growth caused by the siRNA treatment ( Supplementary Figure S10A ) . The same result was also observed using a different CDK12 siRNA construct ( CDK12 siRNA-3 ) , suggesting that these observa-   tions were not due to off - target effects ( Supplementary Figure S10B ) . Transfection of CDK12 siRNA - treated MDA - MB-231 cells with a CDK12 cDNA to re - introduce CDK12 ( Figure 9A ) recovered the migratory and invasive properties ( Figure 9B and C , ' Res ' ) . Unlike SK - BR-3 cells , MDA - MB-231 cells do not over - express CDK12 . Therefore , we also tested the effect of CDK12 over - expression on cell migration and invasion . Compared to a vector control , MDA - MB-231 cells transfected with a CDK12 cDNA decreased DNAJB6 - L expression and were able to migrate and invade at a faster rate ( Figure 9A - C , ' OE ' ) . These experiments show that the ability of MDA - MB-231 cells to invade is correlated with CDK12 expression and inversely correlated with the expression level of DNAJB6 - L ( Figure 9D ) . Therefore , our results suggest that CDK12 can increase the invasiveness of a breast cancer cell line , likely through ALE splicing of the DNAJB6 gene .	25069869	maybe
"representing types other than the first two . We compiled a list of 80 stable quasicrystals and 78 approximants from the Crystallography of Quasicrystals handbook [ 31 ] ( see Table S1 , Supporting Information and Supplementary Data ( supporting file 2 ) for digital data ) . In addition , the compositions of 10 000 ordinary crystals were randomly extracted from the Materials Project database , which recorded a total of 126 335 crystals . [ 32 ] We also used 90 crystals from our laboratory data on failed quasicrystal syntheses . These instances form the class "" others "" . The detailed data preparation procedure is given in the Experimental Section ."	233913481	maybe
c. Intermolecular DEER analysis of free hnRNP A1 DEER with singly spin - labelled proteins was applied to characterize protein - protein interactions . Contributions to the DEER signal that enable this analysis are schematically displayed in Figure S6 . The DEER primary data for hnRNP A1 singly spin - labelled at sites 231 , 271 , and 316 are shown in Figure S6 , analogous to the data in main text Figure 1H. The samples in this series were at 50 Î¼M protein concentration , labelling efficiency as determined by spin counting is annotated ( no spin dilution ) . Deuterated glycerol 50 % ( v : v ) was used as cryoprotectant in this series . A distance analysis was performed in the same way as for the distance restraints ( homogenous background correction followed by single - Gaussian fit ) and is shown as well . This analysis implicitly assumes that all of the short - range interactions that are not removed by the background fit arise from dimerized protein and that the monomers and dimers are otherwise homogenously distributed in the sample ( background dimensionality of the DEER fit is three ) . The distance distributions are very broad and very similar for all three sites , which demonstrates that the proteins are not interacting in a well - defined manner , but rather form a disordered complex or a condensed phase . Note that distance data derived in this way can only serve as a guideline to monitor proteinprotein interactions . They are probably a poor approximation of the actual distance distributions , given that a fraction of hnRNP A1 is likely in the LD state , where local spin label concentration is expected to be very high .	250953295	no
Through a multiple linear regression model , we correlated the share of users who abandoned PT during 2020 , with income equality variables , PT service characteristics , quality of service aspects and pandemic severity data . Empirical findings revealed that the presence of income inequalities resulted in lower abandonment rate , which could mirror the behaviour of captive users . Simultaneously , regarding PT trip characteristics , results imply that PT vehicle transfers and waiting time are the two most critical trip segments as per user opinion , for continuing or not using PT modes . Additionally , results confirm our initial hypotheses that : ( a ) in cities with higher pandemic impact ( as per number of deaths ) users were deterred to use PT and ( b ) improved disinfection in vehicles could contribute to sustaining ridership . Based on the empirical findings of the regression model analysis , specific policy implications can be derived . The methodology of this paper aims at identifying the key factors that influenced travel behaviour , in terms of abandonment of PT , during the COVID-19 era . These factors may highlight suitable measures , which can be followed by PT and governmental agencies , towards maintaining PT ridership during pandemic and post - pandemic circumstances . At first , the proper and frequent disinfection of vehicles could enhance the perception of safety to PT users and convince them to select PT . Likewise , changes in the PT network , towards the direction of providing more direct trips , can contribute to limited interaction between passengers and thus minimize the possibility of infection . In the same sense , PT operators should ensure that waiting facilities ( bus stops , metro platforms , etc . ) adhere to the health and safety protocols ( clean surfaces , proper ventilation , etc . ) , in order to build confidence among users that PT is not a hotbed of COVID-19 contraction . Furthermore , in regions with higher income inequalities , operators should expect a comparatively lower decrease in PT ridership and thus , the application of PT preferential treatment measures ( dedicated bus lanes , traffic signal priority , etc . ) ( Pulichino & Coughlin , 2005 ) would increase commercial PT speeds and ultimately improve PT service frequencies so as to address crowding events .	255826268	no
Based on existing literature , expert opinion , and other secondary sources ( Ioannidis et al . , 2020 ) , the prominent factors responsible for the spread of COVID-19 are considered for constructing Bayesian network ( Roy and Ghosh , 2020;Tantrakarnapa et al . , 2020 ) . These factors are listed in Table 1 . The dataset for the United States of America corresponding to these crucial parameters is retrieved from various authorized sources for the purpose of illustration and analysis using COVID-19 Bayesian model . The major sources of the data are Centres for Disease Control and Prevention ( CDC , 2020 ) , Calgary ( 2020 ) , Health System Tracker ( 2020 ) , National Weather Service ( NWS , 2020 ) , Statista ( 2020aStatista ( , 2020b , Statistics times ( 2020 ) , UNODC ( 2016 ) , World Tourism Organization ( UNWTO ) ( 2019 ) , and World population review ( 2020 ) . Specific data collected from each source are also listed during the course of discussion . The collected data accounts for the COVID cases from the beginning of the pandemic till 20 October 2020 , and it is used for developing the probability tables corresponding to each parameter in the COVID model following the top to down approach .	232144614	maybe
"Siamese nets are typically trained on a collection of similar ( positive ) and dissimilar ( negative ) pairs of data points . When labeled data are available , such pairs can be chosen based on label information ( i.e. , pairs of points with the same label are considered positive , while pairs of points with different labels are considered negative ) . Here we focus on datasets that are unlabeled . In this case we can learn the affinities directly from Euclidean proximity or from graph distance , e.g. , by "" labeling "" points x i , x j positive if x i â x j is small and negative otherwise . In our experiments , we construct positive pairs from the nearest neighbors of each point . Negative pairs are constructed from points with larger distances . This Siamese network , therefore , is trained to learn an adaptive nearest neighbor metric ."	3278749	no
"In the remainder of this section we investigate the extent to which different F - theory GUTs generate distinguishable experimental signatures . To this end , in subsection 4.1 we first list candidate signatures of interest which have strong dependence on the parameters of F - theory GUTs . Using these signatures , we compute the corresponding value of âS 2 between a fixed "" LHC point "" and various F - theory GUTs . In particular , we show that this type of analysis is capable of determining both N 5 and Î , and moreover , can distinguish between scenarios with small and large PQ deformation . Restricting to the case of single messenger F - theory GUTs and a particular value of Î , we next compute the value of âS 2 between models with different values of â P Q . We find that at 5 fb â1 of simulated data , â P Q can be determined up to an uncertainty of â¼ Â±80 GeV , while at 50 fb â1 , this improves to an uncertainty of â¼ Â±10 GeV. In particular , this shows that the LHC is indeed sensitive , albeit indirectly , to string scale physics ! Finally , although outside the main focus of this paper , in Appendix E we consider the sensitivity of the endpoint of the ditau invariant mass distribution as a function of â P Q ."	18658021	no
"Example See table 3 . Explanation We recommend that reviewers assess the risk of bias in the included studies using a standard approach with defined criteria ( see item 12 ) . They should report the results of any such assessments . 89 Reporting only summary data ( such as "" two of eight trials adequately concealed allocation "" ) is inadequate because it fails to inform readers which studies had the particular methodological shortcoming . A more informative approach is to explicitly report the methodological features evaluated for each study . The Cochrane Collaboration 's new tool for assessing the risk of bias also requests that authors substantiate these assessments with any relevant text from the original studies . 11 It is often easiest to provide these data in a tabular format , as in the example . However , a narrative summary describing the tabular data can also be helpful for readers . Item 20 : Results of individual studies For all outcomes considered ( benefits and harms ) , present , for each study , simple summary data for each intervention group and effect estimates and confidence intervals , ideally with a forest plot ."	32270800	no
For GBM we used the 8 - channel ctime data to carry out this test on GRB 210812A. We considered all the detectors where the second pulse was visible in any channel ( n1 , n6 through nb , energy channels 1 through 6 , and b0 and b1 , energy channels 0 and 1 ) , and data from ACS and BAT ( 25 - 350 keV ) . We find that the ratio of the pulses in all the channels and all three instruments is consistent with the mean value within 1.6 standard deviations ( see Figure 5 ) . We thus conclude that GRB 210812A passes the count ratio test for lensing .	238634528	no
Any methods , additional references , Nature Research reporting summaries , source data , extended data , supplementary information , acknowledgements , peer review information ; details of author contributions and competing interests ; and statements of data and code availability are available at https://doi.org/10.1038/ s41591 - 022 - 01688 - 4 .	246942644	yes
Data were analyzed by normality tests ( Shapiro - Wilk and Kolmogorov - Smirnov ): a normal distribution was confirmed . Thus , in comparison of the irradiation conditions and CFU counts , data were analyzed with a parametric test ( Dunnett 's or Tukey test ) by SPSS v15.0 ( IBM , Armonk , NY , USA ) , with significance accepted at p < 0.05 .	17038325	no
Supplementary Figure S1 . TALENs induce higher somatic indel rates than ZFNs in zebrafish embryos . ( a ) Data points represent somatic indel rates for each of the 84 ZFN and 34 TALEN pairs tested . Black bars indicate median somatic indel rate for each type of nuclease . Indel rates were significantly higher for TALENs compared to ZFNs ( p=5.1x10 -12 using Wilcoxon rank sum test ) . Black data points represent ZFNs and TALENs for which germline mutants were generated . Panel ( b ) shows data for nucleases that induced somatic indels at rates up to 1 % .    Figure S2 . The distribution of somatic indel size is similar for nucleases with different somatic indel rates . Somatic indels that were induced by ZFNs ( a ) and TALENs ( b ) have similar size distributions regardless of the indel rate . Median indel size and number of sequence reads are as follows .	16342575	no
We begin by illustrating that the spatial variations of the line - center Q / I and U / I signals of the Ly - Î± line are very sensitive to the geometric complexity of the corrugated surface that delineates the TR . Secondly , we demonstrate that the significant CLV of the Q / I line - center signal of the Ly - Î± line calculated in Carlsson et al 's ( 2016 ) 3D radiation MHD model of the solar atmosphere can be reduced by increasing the magnetic field strength and/or the geometrical complexity of the model 's TR . We then show how this can be exploited to constrain , from the CLASP line - center data , the magnetic strength and geometric complexity of the solar TR by applying the statistical inference method discussed inÅ tÄpÃ¡n et al . ( 2018 ) . To this end , we confront the statistical properties of the CLASP line - center data with those of the polarization signals calculated in a grid of 3D model atmospheres characterized by different degrees of geometrical complexity and magnetization .	119083583	no
In an indoor environment the risk to a susceptible individual of acquiring a new TB infection in the presence of an infectious source is proportional to the fraction of contaminated exhaled air and the duration of the exposure ( Riley et al . , 1978 ) . A systematic approach to identifying transmission sites must be based on both these factors . By equipping our study participants with unobtrusive personal CO 2 /GIS monitoring devices we were able to integrate data regarding both the level of risk at different sites visited and the length of time an individual remained exposed to that risk . Applying a Getis - Ord - GI * cluster analysis ( Getis and Ord , 1992 ) primarily located the community school as a potential TB hot spot .	14416738	no
Between 27 November 2009 and 12 March 2012 , 208 women were randomly assigned to sacrospinous hysteropexy ( n=103 ) or to vaginal hysterectomy ( n=105 ) . The figure shows the flow of women through the study . Baseline characteristics were similar between the groups ( table 1 ) and pelvic measurements and characteristics did not differ at baseline ( table 2 ) . Table 3 presents the results on the primary outcome and the additional definitions of surgical failure . Sacrospinous hysteropexy was non - inferior to vaginal hysterectomy for anatomical recurrence of the apical compartment with bothersome bulge symptoms or repeat surgery for recurrent apical prolapse : sacrospinous hysteropexy 0 % ( n=0 ) versus vaginal hysterectomy 4.0 % ( n=4 ) , difference â3.9 % ( 95 % confidence interval â8.6 % to 0.7 % ) for the intention to treat - last observation carried forward approach . Non - inferiority of sacrospinous hysteropexy was also shown in the intention to treat analysis with conservative imputation and the per protocol analysis . The original primary outcome variable of overall anatomical failure occurred in 50 % of the women after sacrospinous hysteropexy compared with 44 % after vaginal hysterectomy ( 95 % confidence interval for difference â7.4 % to 20.1 % ) . No notable differences were found for anatomical recurrences in the different compartments , except for the posterior vaginal wall : sacrospinous hysteropexy 4 % versus vaginal hysterectomy 14 % ( 95 % confidence interval for difference â18.2 % to â1.8 % ) . Table 4 shows the intraoperative and postoperative details of the women , including the secondary outcomes of complication rate and length of hospital stay . Five serious adverse events were reported during hospital stay : two after vaginal hysterectomy and three after sacrospinous hysteropexy . One woman developed paralytic ileus after vaginal hysterectomy . She had also experienced this problem after orthopaedic surgery . She aspirated gastric contents eight days after surgery , developed aspiration pneumonia , and died because of multi - organ failure . The other serious adverse events were atrial fibrillation , which required cardioversion ( vaginal hysterectomy ) ; stroke two days after surgery , but with full recovery and no loss of function ( sacrospinous hysteropexy ) ; postoperative pneumonia ( sacrospinous hysteropexy ) ; and anaphylactic reaction to prophylactic antibiotics before the surgical procedure ( sacrospinous hysteropexy ) ; in this last woman the surgical procedure was postponed for several months , without any problems . None of the serious adverse events were judged to be related to the type of surgery . Tables 5 and 6 provide details on the other secondary outcomes . Functional outcome and quality of life did not differ significantly between the groups ( table 5 ) . Postoperative recovery was similar after both interventions , with comparable recovery index-10 scores at 1 , 2 , 4 , and 6 weeks after surgery ( table 6 ) . Among the patients who completed the pelvic organ prolapse / urinary incontinence sexual questionnaire before and after surgery , there was significant improvement in scores in both surgical groups ( P<0.002 each ) but no significant difference in total scores between both interventions ( table 6 ) . Flow of women through study . * intention to treat : two patients allocated to vaginal hysterectomy ( vH ) received sacrospinous hysteropexy ( sH ) and were analysed in the vH group . Data at six and 12 month follow up were missing in one patient after sH and six patients after vH ; one patient after vH had recurrent apical prolapse but pelvic organ prolapse quantification ( POP - Q ) score was missing , this patient was included in the intention to treat - last observation carried forward analysis . â Missed data imputed as failure . â¡Per protocol analysis : two patients did not receive intended treatment . excluded per protocol analysis : lost for follow - up at 12 months ( n=8 ) , missing or incomplete POP - Q score ( n=5 ) , and major protocol deviations ( n=9 ) ; two patients met two criteria to be excluded from per protocol analysis Pain scores on the visual analogue scale did not differ notably between both interventions , except for day 14 in favour of hysterectomy . In eight out of nine women who experienced buttock pain , a typically reported problem after sacrospinous hysteropexy , the pain resolved ( visual analogue scale score < 2 ) spontaneously within the first six weeks . One woman underwent suture cutting and vaginal hysterectomy after four months because of persistent pain localised at the place of the sacrospinous hysteropexy sutures . After this procedure she was free of symptoms .	6322667	no
This study makes use of data from AEGIS , a multiwavelength sky survey conducted with the Chandra , GALEX , Hubble , Keck , CFHT , MMT , Subaru , Palomar , Spitzer , VLA , and other telescopes and supported in part by the NSF , NASA , and the STFC .	235606438	maybe
"Community acceptance - The community acceptance measure consisted of six items assessing the way participants perceived general manifestations of acceptance from others in the community . The measure included items such as "" since the war , people in this community have been good to you "" and ' since the war , you feel you have been welcomed back into the community where you live . "" As opposed to the daily discrimination scale discussed below , these items were not phrased to specifically refer to the experience of being a child soldier . Items were scored on a Likert scale with response options of "" not true "" to "" sometimes true "" or "" very true . "" This measure was administered at both waves of data collection and exhibited strong internal reliability ( Cronbach 's Î± = .90 at T1 and Cronbach 's Î± = .89 at T2 ) . For each child , we computed a subscale score for community acceptance at T1 and T2 . We also computed a "" change in community acceptance "" by subtracting the T1 score from the score at T2 . An increase in the community acceptance score between baseline and follow - up would thus indicate a positive change in community acceptance . Because change in community acceptance differed for those starting at higher or lower levels at baseline , all analyses were adjusted for T1 community acceptance . Baseline scores and scores for change in community acceptance were treated as continuous measures in analyses ."	9872390	no
ERRBS is a slightly modified version of RRBS 36,37 . Libraries were prepared by MspI restriction enzyme digestion of high molecular weight genomic DNA , followed by end repair , size selection , bisulfite conversion and library amplification as previously described 38,39 . Libraries were sequenced on a HiSeq 2000 Illumina machine using 75 bp single - end reads . Data alignment was performed to human genome hg19 as previously described ( see data analysis description ) 38,39 . Average reads per sample were 138,596,488 with a mean alignment rate of unique reads of 63.7 % , covering on average 4,399,235 CpGs per sample at a minimum threshold coverage of 10X. Average coverage depth per CpG was 72.3 and average bisulfite conversion was 99.86 % determined as previously described 38,39 . See Supplementary Table 3 for detailed sequencing statistics . A subset of patient samples were processed using SeqCap Epi 4 M CpGiant Enrichment kit ( NimbleGen - Roche ) and SureSelect XT Human Methyl - Seq ( Agilent Technologies ) per manufacturer 's recommendations . These were sequenced using a paired - end 100bp approach on a HiSeq 2000 ( Illumina , Inc. ) .	13938356	no
where x is the GW and AGN data . We consider the AGN association ( i.e. Î» > 0 , because at least a fraction of the BBH come from AGNs ) to be confident if K > 100 . The number of follow - up observations needed to reach this requirement as a function of the true value of Î» given in input is shown in Fig .   3 for different sky maps . It is clear that for poorly localized events like GW190521 , tens of GW follow up campaigns are Figure 3 . Number of GW events to be followed - up to obtain a confident association ( i.e. for a Bayes factor K = 100 ) between AGN flares and BBH events , as a function of the true input value of Î» in the simulations . Each curve corresponds to a different fixed GW sky map , with a range of localization volumes ( from â¼ 10 â4 to 10 Gpc 3 at 99 % CI ) . This figure applies to the ideal case in which the AGN flares associated to the GW events are all detectable ( we assume a magnitude limit g < 20.5 ) . The orange line shows a comparison with the result from Bartos et al . ( 2017a ) ( B17 ) , who do not consider follow - up observations of AGN flares , but instead compare the GW localizations with AGN positions . The other differences with B17 are that their N corresponds to the number of events needed to reach 3Ï using a pâvalue statistical method , and that they consider a slightly lower AGN number density . required in order to make a confident association , even in the most optimistic case where Î» tr = 1 and we can detect all AGNs where the BBH merger could happen . Only a few to tens of events are needed to make a confident association for better - localized events such as GW170814 or GW190814 down to Î» tr = 0.1 . This is an obvious consequence of the fact that the number of background contaminants scales with the comoving volume , and that the localization volume of these events is orders of magnitude lower than the one of GW190521 . We compare our results with the predictions by B17 who uses only GW localizations ( i.e. without follow - up observations ) to probe the origin of BBH mergers and to potentially associate them with AGNs . Fig . 3 shows that we find a similar scaling relation of the number of events required to reach K = 100 as a function of Î» as theirs , although slightly less steep than N(K = 100 ) â Î» â2 . The main differences with the B17 predictions , other than follow - up observations , are that their N corresponds to the number of events needed to reach 3Ï using a pâvalue statistical method ( so that here the scaling of the number of events needed could be different as we are not directly considering the width of a distribution ) , and that they consider a fixed ( in redshift ) and lower AGN number density .	232417150	no
The RMSE values presented in Table 4 indicate the acceptable prediction accuracy of the alternative models for intentions to visit during the COVID-19 pandemic , with the training data 's mean RMSE value equalling 0.2806 and the testing data 's mean RMSE value equalling 0.2904 . The RMSE values presented in Table 5 likewise reveal the acceptable prediction accuracy of the alternative models for intentions to travel after the COVID-19 pandemic , with the training data 's mean RMSE value equalling 0.3859 and the testing data 's mean RMSE value equalling 0.4084 .	245008959	no
The EtOAc solution is cooled to 0 Â° C and while stirring , the HCl solution in EtOH is added dropwise to precipitate a white solid . The precipitate is then filtered , washed with EtOAc ( 3x 15 mL ) , and dried under pressure to give imidazole-1 - sulfonyl azide hydrochloride as white solid ( 5 g , 76 % ) . The NMR spectroscopic data were in agreement with those described in the literature . [ 3 ] Caution ! Imidazole-1 - sulfonyl azide and its salts ( including chloride salt ) are known to be energetic materials that are sensitive to chock and friction . Care should be taken while handling this material	51985550	no
To appraise the accuracy of the extracted defect parameters , we calculated the uncertainty associated with the application of Equations ( 2)-(4 ) to the measured PICTS data ( Table S5 , Supporting Information ) . We found that the uncertainty in the extracted defect energies is on average equal to 25 meV across all sample types and smaller than 60 meV in all cases ( Table S5 , Supporting Information ) . Moreover , the uncertainty associated with the extraction of the capture cross - sections and volumetric concentrations is on average within a factor of 2 - 4 and generally smaller than one order of magnitude - i.e. , a comparatively narrow range considering the â10 orders of magnitude over which these parameters may vary .	235539488	no
The uninformative equilibrium denotes the case where all workers collude by always reports the same answer to all tasks . For traditional peer prediction mechanisms , under this equilibrium , all the workers still can get high payments because these mechanisms determines the payment by comparing the reports of two workers . However , the data requester only can get uninformative labels , and thus this equilibrium is undesired .	44155127	no
ARIMA differs from other longitudinal analysis techniques in the social sciences such as latent growth modelling ( LGM ) and multi - level modelling ( MLM ) in a number of ways . First , it focuses on a singleunit dependent variable over time . It is suitable in situations where there is suitable aggregate data for a phenomenon , but where individual data may be sparse or incomplete ( as is the case in this study ) . Second , while LGM and MLM tend to be applied on data sets with only a few time periods , ARIMA is most suitable for time series with more than 50 time points ( Yanovitzky and VanLear , 2007 ) . Third , neither LGM or MLM adequately reflect the time series character of a data set and do not capture trends that are caused by the internal dynamics of the variable under study ( Hollanders and Vliegenthart , 2008 ) . This limitation is typically addressed via research designs with a small number of distinct time data points ( often two , three or four ) or with panel data sets ( Shin , 2017 ) . Notwithstanding , a key problem in such designs is that variables are expected to vary at random , so the common practice of selecting data every three or four time units ( Wilson et al . , 2006 ) , can easily result in the incorrect identification of a trend ( Kelly and McGrath , 1988 ) . ARIMA is designed to account for the complex internal dynamics of time series variables through the different mechanisms it employs , as explained above .	235255900	no
Initially , the ability of cells to survive and proliferate from a single cell - an important characteristic of self - renewing cells - was evaluated by a colony - formation assay . All three clones ( ASTcl3 , ASTcl6 , and ASTcl7 ) acquired the ability to form colonies , as evidenced after 5 days of plating ( Figure 2B ) . ASTcl7 formed more colonies compared with ASTcl3 and ASTcl6 ( Figure 2C ) . Notably , primary astrocytes were also analyzed , and proved unable to form colonies ( data not shown ) .	248275166	no
In this experiment , we verify that the results in synthetic datasets can translate into data with higher dimensions . While visualizing the learned energy function is not feasible in high - dimensional space , we can verify whether the learned energy function learns relative densities by inspecting the ranking of samples according to their assigned energies . We train on 28 Ã 28 images of a single handwritten ( a ) Standard GAN ( b ) Energy GAN without regularization ( EGAN - Const ) Figure 2 : Learned energies and samples from baseline models whose discriminator can not retain density information at the optimal . In the sample plots , blue dots indicate generated samples , and red dots indicate real ones .	13619197	no
( iv ) The goodness of fit is always satisfactory ( Ï 2 /d.o.f . < 3 ) at weak and intermediate couplings ( u â [ 0.8873 , 1.8811 ] ) . In a limited number of cases at stronger couplings the value tends to rise considerably , but this apparently does not depend systematically on the number of fitted points and choice of fitting Ansatz . In any case , given the small number of fitted data points , Ï 2 /d.o.f . is a goodness - of - fit criterion of relatively limited value . Instead , the total Ï 2 /d.o.f . varies between 1 and 2 , indicating satisfactory overall quality of the fits .	15208349	no
With rare events , organizations may not have relevant prior experiences to draw inferences and aid decision - making . The Covid-19 pandemic represents such a rare event . Responding to rare events requires organizations to mobilize and adjust existing resources quickly as well as develop new capabilities ( Henningsson et al . , 2021 ) . Further , rare events ( such as the Covid-19 pandemic ) are usually characterized by less available data ( Oehmen et al . , 2020 ) . For example , in the case of the Covid-19 pandemic , retailers may not have accurate epidemiological data on transmission and may have to use other heuristics , such as consumer mobility patterns , to optimize retail decisions . During the early days of the COVID-19 pandemic , due to potential and actual social distancing policies , including mandated lockdowns or potential lockdowns , consumer trends were disrupted , which also affected retail activities globally ( OECD , 2020 ) . As the epidemic growth showed geographic variation , some states , e.g. , New York ( NY ) , observed early surges in hospitalizations and early long - term state - wide lockdowns . Meanwhile , other states , e.g. , Nebraska ( NE ) and Texas ( TX ) , observed increased cases and deaths sometime later than NY . These geographic variations in cases and deaths also produced varying demands on certain items , such as hand sanitizer and masks , as well as varying mobility patterns , including retail activity patterns .	255441206	no
Since some CEOs were born prior to the period covered by the FEMA dataset , their exposure to natural disasters in their formative years ( 5 - 15 years ) may be missing in our dataset . To construct a more comprehensive countylevel natural disaster database that covered the period of all CEOs ' formative years , we searched additional data sources , which included the United States Census Bureau ,	255566528	no
where was a small value ( 10 â12 ) close to zero and Î± took on a transform - specific value summarized in Table 1 . The transform - specific maximum value was computed as T ( 10 ) . Once the Gaussian samples were generated for each transformation function , the samples were inverse - transformed via the corresponding T â1 into the simulated neural responses . The code used to generate simulated data can be found at https://github.com/sinzlab/bashiri-et-al-2021 .  	237495187	yes
We use IRIS 1400Ã slit - jaw images ( SJI ) of an ondisk plage region ( NOAA AR 11809 ) centered at [ x , y ] = [ 383,124 ] , with a Field - Of - View of 119 Ã120 . The observations were taken on 04 - Aug-2013 10:38 - 11:41 UTC . IRIS was in sit - and - stare mode ( IRIS obs - id 4043007648 ) taking only the 1400Ã SJI passband images with cadence of 5.6 s and exposure time of 4 s. We use level-2 IRIS data that was corrected for flat - field , dark current , geometry and co - alignment ( De Pontieu et al . 2014b ) .	119242247	no
These data have important implications for patient care . Special regulatory designations allow drugs to be approved at earlier stages based on less rigorous clinical testing ; for example , one review showed drugs with orphan designations or granted accelerated approval are also more likely than drugs without these designa- tions to be tested in single arm studies without placebo or active comparators . 4 While many physicians and patients trust that FDA approved products are effective and safe for use , products approved on the basis of more limited data are at greater risk for later changes to their effectiveness or safety profiles . 31 Ponatinib ( Iclusig , Ariad Pharmaceuticals , Cambridge , MA)-designated for priority review and orphan status , and granted accelerated approval - was approved for refractory chronic myeloid leukemia in 2012 and its approval was suspended a year later as emerging data showed it to be less safe than it originally appeared . The suspension was lifted a few months later , with a stronger warning label and limitations to prescribing . 32 Given the increased likelihood of post - approval changes in the prescribing information for these therapeutics , regulators may want to ensure that the provisional nature of these drugs is well communicated to patients and physicians . Currently , only drugs approved through accelerated approval have this information integrated into their official labels . In addition , the FDA may want to consider new guidance on advertising practices to ensure that all advertisements prominently feature the limited nature of the data supporting agents approved through these pathways .	5001680	no
"Desire to return to normalcy ( Î± = .93 , 1.1 % missing data ) was measured with seven items ( e.g. , "" Even though we may lose some people in the process , it 's time for people in Brazil to return to business as usual "" ) ."	256194844	no
Data sharing : No additional data are available .	67859663	yes
As arule , when apples , pears , orother fruit ripen , the associated appearance of the appetizing colors of the ripe fruit is av isual indicator of their degree of ripeness . [ 81 ] At the same time , t he Chl originally present in the unripe green fruits is broken down , presumably to produce phyllobilins . C hl breakdown in the peel of Golden Delicious apples ( Malus domestica)a nd of Williams pears ( Pyrus communis)w as shown to yield the nonfluorescent type - I phyllobilins epi-9 and epi-11,also named Md - NCCs and Pc - NCCs . [ 59 ] Thesame ( epi - type , that is , RCCR-2 derived ) NCCs were also found in senescent leaves of the corresponding apple and pear trees , thereby indicating acommon pathway in the leaves and fruit of these fruit trees . [ 59 ] Several NCCs , including Ej - NCC-2 ( epi-29,T able 1 ) , were identified ( on the basis of mass - spectrometric and UV - spectroscopic data ) in quince ( Cydonia oblonga , M iller ) [ 82 ] and in loquat fruit ( Eriobotrya japonica ) . [ 83 ] Likewise , t he NCCs Bo - NCC-1 ( 3)a nd Bo - NCC-2   Figure 19 for the structures of type - II phyllobilins derived from pFCC ) . Figure 21 . Ripening fruit ( left ) and degreening florets of broccoli ( right ) undergo Chl breakdown and accumulate colorlessp hyllobilins . [ 59,61 ] Angewandte Chemie Reviews ( 17 ) , as well as Bo - DNCC-3 ( 30 ) , were characterized in degreening broccoli florets ( Brassica oleracea , v ar . Ital . ) . These three NCCs are known representatives of the normal stereochemical series of type - I and type - II phyllobilins . [ 61 ] Five NCCs were described earlier in senescent spinach leaves ( Spinacia oleracea ) , the so - called So - NCCs ( epi-1 , epi-5 , epi-11 , epi-12 , epi-13 ) , which belong to the epi series of NCCs . [ 50,64 ] As expected , in ripe(ning ) fruit and ( degreening ) vegetables , Chl breakdown follows the common PaO / phyllobilin pathway and furnishes colorless type - I and type - II phyllobilins , inaspecies - dependent way . Clearly , these plantderived components of our food are acommon source of Chl catabolites , w hich , hence , a re part of our daily nutrition . [ 6a ]	16512518	no
The Gibbs sampler to sample from this distribution is given in Algorithm 2 . Note that in Line 8 we employ rejection sampling in which sufficient statistics are sampled until the values drawn are valid for the given data model , e.g. , s must be positive for the binomial distribution . The RS - CLT algorithm to compute parameters of the random sum CLT is shown in Algorithm 3 .	52177722	no
Every two years , participants are mailed a questionnaire assessing risk factors and the interval occurrence of disease . Records of diagnoses of pulmonary embolism have been collected prospectively on each biennial questionnaire since study inception . Data describing time sitting were collected in 1988 and 1990 , and data describing physical activity have been collected since 1980 . We therefore began prospective follow - up in 1990 among women who responded to both the 1988 and 1990 questionnaires ( n=99 290 ) . Outcome ascertainment occurred from 1990 to 2008 .	37410	no
When we compared the non - normalized data to the data normalized to PMMoV , a difference was noticed , especially in the facilities that serve a larger population . On the other hand , while comparing data normalized to the PMMoV and data normalized to the flow , the results were very consistent .	251161435	no
Quantitative impacts of AM in human genetics have been investigated by focusing on the deviation from the Hardy - Weinberg equilibrium ( HWE ) in trait - associated variants . However , this approach requires large sample sizes , especially when the effect sizes of the associated variants are small . Furthermore , ancestral endogamy ( mating within the limits of a specific social group ) could confound these relationships [ 10][11][12 ] . An alternative approach is to study genetic similarities between partners . This approach revealed the existence of AM in Europeans on anthropometric traits ( height and body mass index ( BMI ) ) , and social and behavioural phenotypes ( educational attainment and alcohol consumption ) [ 13][14][15][16][17 ] . Although partner genotype - phenotype data have been analysed in these studies , it has been relatively challenging to achieve biobank - scale sample sizes in populations of diverse ancestries .	252466144	no
As of the time of this writing , wastewater surveillance for SARS - CoV-2 has primarily been reported in high - income settings that are well - served by modern wastewater infrastructure ( Naughton et al . , 2021 ) . But wastewater surveillance has a long history of use in lower - income settings as well , most visibly in the context of polio eradication efforts where environmental surveillance has been widely deployed and in long - term surveillance for S. typhi and paratyphi ( Pogka et al . , 2017;Sikorski and Levine , 2020 ) . Such systems , where extant , can be used in response to the ongoing COVID-19 pandemic as exemplified in Pakistan ( Sharif et al . , 2021 ) . Wastewater surveillance systems for COVID-19 have been developed in at least 55 countries with demonstrated success across a range of climatic , economic , development , and logistical contexts ( Tlhagale et al . , 2022 ) . While wastewater surveillance is not without limitations , it is increasingly clear that it can provide useful data concerning the epidemiology of an infectious disease , such as COVID-19 , especially diseases that are characterized by asymptomatic infections or are inefficiently monitored through clinical surveillance ( Safford et al . , 2022;Hrudey and Conant , 2021 ) . The wealth of experience gained during the COVID-19 pandemic can be leveraged to develop robust wastewater surveillance systems to monitor a wide - range of emerging and re - emerging pathogens , especially in settings where clinical surveillance is insufficient to capture spatial and temporal infection dynamics and inform public health response .	248267379	no
One model of the three - dimensional fold of the fibril consisting of five b - sheets per monomer has been proposed [ 13b ] based on ss - NMR and cryo - electron microscopic data . However , long - range restraints at the molecular level in support of this model are still missing . Recently , we have reported pulsed EPR distance measurements to determine the intra - molecular distance between the extremal b - strands in aS fibrils . [ 15 ] A pair - labeling strategy was introduced to infer the orientation of the standard methanethiosulfonate ( MTSL ) label with respect to the plane of the b - strand , as the detected spin - bearing nitroxide of MTSL is located about 0.5 nm from the Ca of the amino acid the spin label is attached to . The resulting distance of ( 4.5 AE 0.5 ) nm between the extremal strands was consistent with the size of the subfilament measured in AFM and cryo - electron microscopic studies . [ 12 , 13b ] Nevertheless the dipolar oscillations observed in the pulsed EPR data , used to extract distances , were very weak and experiments at two different EPR frequencies were required to exclude artifacts . Similar observations were reported in other recent pulsed EPR distance measurements on amyloid fibrils of human islet polypeptide and tau protein . [ 16a , b ] The challenge of these experiments is caused by the required labeling procedure combined with the structural instability of these proteins with respect to point mutations . [ 17 ] To date , despite the wealth of NMR and other spectroscopic data , no EPR distance measurements on aS fibrils have been reported by other groups . In the present study we illustrate how an optimized sample preparation has provided large signals in EPR distance measurements for several selected mutation sites . The result permitted to exploit a labeling strategy to measure distances between largely conserved b - strand regions and to obtain vectorial information on the spatial arrangements of the labels within the strands . The distances and two - dimensional coordinates reported here provide new long - range restraints for the structure of aS fibrils .	11327244	no
Challenges exist in the material selection to maintain the conformal contact with the skin . For example , dead cell efflux through the skin may interfere with the measurement data . Another challenge that limits the adoption of electronic tattoos is that long time - wear over the skin may cause ' irritant ' dermatitis . One potential direction in the development of electronic tattoos is the use of surgical - grade stainless steel and its alloys that can provide high hypoallergenic features .	48355667	no
"As regards the total gravitino relic abundance â¦ e G h 2 , we apply the 3 Ï range derived from WMAP 5 year data [ 66 ] 0.091 < â¦ e G h 2 < 0.128 , ( 3.1 ) which in the figures below will be marked as green bands and labeled "" â¦ e G h 2 "" . As previously in [ 16 ] , we also include the bound on the possible distortion in the nearly perfect black - body shape of the CMB spectrum [ 67 ] by the injection of energetic photons into the plasma . However we note that this constraint ( delineated with magenta line with a label "" CMB "" over it ) seems generally less important than that due to the BBN [ 68,69 ] ."	18667052	no
One important concern regarding the use of -LDP algorithms ( e.g. , in Section 2.1 ) to collect counter data pertains to privacy leakage that may occur if we collect user 's data repeatedly ( say , daily ) and user 's private value x i does not change or changes little . Depending on the value of , after a number of rounds , data collector will have enough noisy reads to estimate x i with high accuracy .	3277268	no
Recent literature has questioned the promises of algorithms ' objectivity ( BiliÄ 2016;Porter 1996;Thelwall 2018 ) . For example , O'Neil ( 2016 ) has suggested , drawing from her own experience as a mathematician in finance , that an algorithm used for HR processes , such as employee recruitment , evaluation , or performance appraisals , are still impaired by racial and gender biases . For machine - learning algorithms , these biases can also stem from the data with which the algorithm was trained . An algorithm trained on historic employment data , for example , would integrate that most managers are male , thereby assuming that women are less interested in management positions . Consequently , this recruitment algorithm would not show an employment advertisement for a management position via social media to women . The advertisement would , in fact , be invisible to women ; thus , women would have no opportunity to apply . In this case , a recruitment algorithm might be actively reifying the original gender bias , based on the data with which it was trained ( Devlin 2017;O'Neil 2016 ) . Similarly , Buolamwini and Gebru ( 2018 ) showed in a recent study that facial recognition algorithms still exhibit significant racial bias , as these algorithms are less able to detect the gender of African - American women than of Caucasian women . Accordingly , Noble ( 2018 ) found that internet search algorithms privilege whiteness and discriminate against African - Americans , particularly against African - American women . The key issue here is that developers of machine - learning algorithms use data to train their algorithms . As these data might be biased according to an external reference point , the training has the great capacity to be faulty ( Barocas and Selbst 2016;Martin 2018 ) .	189902940	no
In this study , a number of different sequences were chosen to understand the effects of structure on hybridization reaction rates and to compare kinetics of these sequences in solution and on surfaces . Model sequences were chosen based on a series of stable single - stranded structures that form GNRA tetraloops where N can be A , G , C or T and R must be a purine ( 10)(11)(12)(13 ) . The hairpins that can form from the tetraloops are unique in that they do not consist of a series of repeating bases ( 14 ) or large multi - base loop regions ( 15 ) . The stability of the four - base loop arises from a number of factors including base stacking between the third and fourth A , hydrogen bonding between an amino proton on the G and an oxygen from the phosphate between the second and third A , and base pairing between the G and the third A in the loop ( 10 ) . In addition to the model tetraloop sequences , a series of random sequences , denoted as random coils , were used for comparison . These sequences have no known stable structure and have similar melting temperatures and identical lengths . To study the possible surface effects on the hybridization rates , kinetic data were obtained both in solution and when one strand was covalently bound to a silica microsphere .	13920464	no
In addition , we have annotated two major assembly updates for rat ( Rnor 6.0 ) and zebrafish ( GRCz10 ) . Both gene sets include manual annotation from the HAVANA project . We have also recently updated our lincRNA annotation methods to using candidate transcript models built from RNA - seq data . These are tested for protein coding potential by searching for Pfam domains and alignments to the UniProt database . Models that show no protein coding potential are labelled as lincRNA . We have applied this method to generate lincRNAs for rat and sheep and aim to extend the method to other species over the coming year . We have also produced preliminary transcript models for Crab - eating macaque ( Macaca fascicularis ) and sperm whale ( Physeter macrocephalus ) by aligning experimental data and homologous proteins ; these are available on our Pre ! website .	5570268	no
Olivetti et al . [ 57 ] synthesized the available data on consumption rates relative to available reserves for nickel ( Ni ) , manganese ( Mn ) , cobalt ( Co ) , lithium , ( Li ) , and natural graphite . They found that the ratio of known reserves to primary mine production ( also known as the static depletion index ) has increased for Co , Li , and natural graphite , suggesting that continued demand has resulted in additional exploration and extraction . Mn and Ni did not show an upward or downward trend , indicating that the ratio of production to known reserves has remained relatively constant . This highlights the challenge of attempting to place a single number on finite resource depletion as part of an LCA ; society 's understanding of available resources is not static . Increased demand drives advancements in exploration and recovery technologies . Material recovery potential through   recycling adds another layer of complexity . As Olivetti et al . [ 57 ] rightly point out , there is a time lag between when batteries are manufactured and when they reach the end of their life , so regardless of what can be recovered , recycling is unlikely to address any near - term ( 10 - 20 year ) material supply constraints . If battery technologies do not evolve away from reliance on these critical materials in coming decades , recycling can be an important long - term strategy . Pyrometallurgical recycling facilities will recover Ni , Co , Mn , and Copper ( Cu ) , [ 58 ] while hydrometallurgical recycling facilities will recover all of the aforementioned metals , as well as Li and aluminum ( Al ) . Direct recycling will recover an even larger range of materials , many of which can be reused without further processing . Given this context , it is worth revisiting the assertion by Peters et al . [ 11 ] that abiotic depletion ( an impact category representing depletion of non - renewable resources , such as minerals and fossil fuels ) is the most important impact of batteries on a normalized basis , exceeding the importance of GWP . Many of the nuances in critical material use and supply outlooks are lost in typical LCA practices and reducing these impacts to a single score is more likely to create confusion than generate useful insights , particularly when fossil fuel and critical material depletion are combined in a single score . This is particularly true for materials like Co and Li , for which demand is growing rapidly . In fact , a greater cause for concern is the geographic diversification , or lack thereof , in reserves and supply for some of these materials .	237792009	no
We begin by discussing what we refer to as the ' informed ' ( or ' critical ' ) view in contrast to Anderson 's popular view ( Sect . 2 ) and explain what we mean by big data and machine learning methods ( Sect . 3 ) . We then elaborate on two paradigmatic uses of big data and machine learning methods in science : skin cancer detection and protein folding ( Sect . 4 ) . On this basis , we develop a taxonomy of expert knowledge that can be applied to big data and machine learning - driven research ( Sect . 5 ) . Finally , we argue that this taxonomy provides a fresh perspective on several debates surrounding the role of big data and machine learning in science : whether they concern inductive methods , the removal of the need for theory , or the constitution of a new scientific paradigm ( Sect . 6 ) .	256060110	no
Data on GDP and total energy consumption were taken from the China Statistical Yearbook and the China Energy Statistical Yearbook respectively . CO 2 emissions data were calculated using Eq . ( 1 ) . Fig . 1 describes relative changes in emissions , energy consumption , and GDP in China during the period 1990 - 2012 . As shown in Fig . 1 , the Chinese economy has undergone spectacular economic development , with an annual growth rate of 16.31 % over the past twentytwo years . China 's GDP increased from 1866.7 to 51,894.2 billion Yuan between 1990 and 2012 . Although China has made remarkable developmental progress , it has not yet completed the historical task of industrialization and its development is unbalanced . Thus , China still faces an arduous task in developing its economy , eliminating poverty , and improving the livelihoods of its population . Economic growth can improve living standards , but it can also lead to increases in energy consumption and CO 2 emissions . While the economy prospered , it is worth bearing in mind that China 's total energy consumption jumped from 1311.76 million t in 1990 to 3617.32 million t in 2012 ( Fig . 1 ) . According to our calculations , CO 2 emissions increased from 1.89 billion t in 1990 to 8.02 billion t in 2012 ( Fig . 1 ) . The upper fitting curve in Fig . 2 shows the correlated relationship between economic growth ( the independent variable ) and energy consumption ( the dependent variable ) during the period 1990 - 2012 . The lower curve displays the correlated relationship between economic growth ( the independent variable ) and CO 2 emissions ( the dependent variable ) during the same period . As shown in Fig . 2 , the three variables are strongly correlated ( displaying high R 2 values . ) Fig . 3 displays a scatter plot and distribution overlay of economic growth levels , energy consumption levels , and CO 2 emissions data in the form of a box chart , with the bottom and top of the box representing the 25th and 75th percentiles . Form Fig . 3 , we find CO 2 emissions to be highly concentrated at 5.26 billion t , and mainly dispersed from 3.33 to 6.68 billion t. Energy consumption is mainly distributed between 1300 and 2500 million t , and is concentrated at 1700 million t ( Fig . 3 ) . GDP is distributed from 8440.5 to 26,581.7 billion Yuan , with the most concentrated GDP at 12,033.3 billion Yuan .	45215519	yes
We engage in a historical comparative analysis of business leaders ' recollections and memories in the form of oral histories to analyze their ethics behind their foundations ' activity in different countries . Oral history refers to the collection , transcription , and recording of memories and voices directly from participants of past events ( in video or tape interviews ) and their preservation and interpretation as historical sources ( Ritchie , 2010 ) . It is acknowledged as a preferred longitudinal research methodology in emerging economies because alternative data sources , such as wellorganized national and corporate archives , are often absent or inaccessible ( Austin et al . , 2017;Jones & Comunale , 2019 ) .	237212641	no
We further tested MixMir on a published set of adrenal cortex Dicer - KO experiments , performed by Krill et al . ( 25 ) . The authors found that while mouse embryos with Dicer - KO adrenal cortex cells developed normally up to E14.5 , at E18.5 they experienced total adrenal cortex failure . In all they found 16 miRNAs that were downregulated in the adrenal cortex of both E15.5 and E16.5 mice , including miR-34c , miR-21 , miR-10a and let-7d , which play a role in tumorigenesis among other functions ( 25 ) . They also presented lists of miRNAs specifically downregulated at each stage . We analyzed the mRNA microarray expression data ( see Methods ) from both E15.5 and E16.5 embryos using the linear model , miReduce , Sylamer , cWords and MixMir . When compared to the miRNAs that are downregulated at both E15.5 and E16.5 , we found that most methods were able to find either an exact or offset seed match to let-7d either as the first or second motif returned , with the exception of the linear model , which performed worse . Overall , MixMir ranked true miRNA seeds higher than the other methods in both E15.5 and E16.5 datasets ( Table 5 ) . Most notably , MixMir found both miR-34b and miR-34c in the top ranked motifs at E15.5 , which no other method was able to do . We also performed a separate analysis of motif ranks and miRNA matches for E15.5 and E16.5 separately , as some miRNAs were found to be significantly downregulated at one stage and not at another -- namely , there were more such miRNAs at E16.5 , as expected . We found sim - ilar results in this analysis , in particular that MixMir consistently found biologically significant miRNAs , with performance comparable to miReduce for both time points . cWords and the linear model were comparable for E16.5 only ( Supplementary Table S8 ) .	7202546	no
In fact , our data suggest that emotion representations have a prolonged developmental trajectory . Because most studies on the development of emotion perception , emotion experience , and emotion understanding are constrained to childhood , little is known about emotion conceptualization in adolescence . These results reveal that there are continued changes in emotion conceptualization throughout late adolescence and into early adulthood , a finding that prompts new questions about the role of emotion concept development in the social and affective changes that occur during adolescence . 11 Additionally , our methods ensured all participants recognized emotion terms used in our tasks . This is an important methodological advance beyond prior studies , which mostly assumed that child participants understood the terms used in tasks without systematically testing their comprehension . We believed that participants ' responses on these tasks are only interpretable if we had evidence that they had a working understanding of each term , a decision that potentially augments the validity of these results . However , this methodological choice implies that merely having separate definitions for emotion words is not enough to produce a fully multidimensional emotion representation : The sophistication of emotion concepts continues to deepen even after people have learned to associate different emotion definitions with different emotion words .	3680363	no
"The results of both of these experiments only hold if the GRMHD models used as synthetic data provide a good description of M87 . As multiple observation epochs become available , it will be possible to explicitly measure the statistics of the stochastic fluctuations , empirically addressing this assumption . It will also enable direct ensemble - to - ensemble comparison like that described in Kim et al . ( 2016 ) . A promising , alternative approach would be to perform a principal component analysis ( PCA ) decomposition of the snapshots within each model Figure 11 . Visibility amplitude and closure phase residuals for an SSM fit to the April 5 , high - band data for a "" good "" snapshot image frame from a MAD simulation with a * ï =ï 0 , iï =ï 167 Â° , and R high ï =ï 160 . The reduced - Ï 2 values for the fits are 5.9 ( THEMIS ) and 7.3 ( GENA ) . All residuals are normalized by their corresponding estimated observational errors . Figure 12 . Three sample SSM fits to April 6 high - band data . All are from models with THEMIS - AIS p AIS ï >ï 0.1 . In panels ( a ) and ( b ) , the prominent photon ring places a strong constraint on Î¸ g . In panel ( c ) , the extended disk emission results in a smaller Î¸ g estimate . ( Medeiros et al . 2018 ) , and fit images generated by varying the weights of the PCA components to the data to mimic the set of possible realizations of the turbulence ."	145969867	no
"where k c is the cut - off frequency of wide - field imaging , and k ex is the spatial frequency of the excitation pattern . With Eq . ( 1 ) , at least in principle , SR - SIM could achieve perfect imaging without sidelobe ( blue lines in Fig . 1a ) . Inspired by the above , we developed a high - fidelity SIM reconstruction algorithm by engineering the equivalent PSF of SR - SIM into an ideal form , called "" HiFi - SIM "" . The flowchart of HiFi - SIM is shown in Fig . S1 , which contains three main steps . In preprocessing , the raw data was deconvoluted 26 using a theoretical OTF . In reconstruction parameter estimation , an improved normalized crosscorrelation method was used to estimate the pattern wave vectors . In short , a notch filter was applied to the normalized cross - correlation calculation 8,23 , which can effectively suppress contributions from low - frequency signal and local periodic structures to the cross - correlation map , such that the peaks corresponding to the wave vectors protruded enough to be automatically determined from most of raw data , including low SNR data , TIRF - SIM data , and even data with obvious periodic structures ( Fig .   S2 ) . Thus , a pre - set mask or hand - correction was not required as before . Once the reconstruction parameters were correctly determined , the 0 - and Â±1 - order spectrum components were separated , shifted , and combined to yield a directly combined spectrumS directlyÃcombined Ã°kÃ ( Eq . ( 9 ) in Supplementary Note 1 ) , using a method similar to fairSIM . After that , HiFi - SIM performs a two - step spectrum optimization onS directlyÃcombined Ã°kÃ."	232486236	no
Moovit data are available at the city level . Moovit covers 87 major cities worldwide , spanning across four ( 4 ) continents ; North America ( New York , Miami , San Francisco , Washington , etc . ) ; South America ( Brasilia , Buenos Aires , Santiago , Bogota , etc . ) ; Europe ( London , Paris , Berlin , Rome , etc . ) and Asia ( Singapore , Bangkok , Jakarta , Kuala Lumpur , etc . ) . For the present study , we utilized five ( 5 ) PT service attribute variables ( Variables 7 - 16 in Table 1 ) , that pertain to the years 2019 ( pre - pandemic ) and 2020 ( pandemic ) . These five ( 5 ) variables are regularly estimated by Moovit and they are closely related to PT quality of service :	255826268	no
For this report , we determined the maps of genome - wide RNAP location in time - course experiments after salt shock and compared these data to global gene expression . Our study not only confirmed a massive dissociation of RNAP from the genomic DNA at the early phase of the osmotic stress response , but also identified a hyperdensity of 70 promoter - like sites at the intergenic regions of salt shock response genes , contributing to RNAP redistribution and transcription of salt - responsive genes during osmotic stress response .	73465551	no
In view of device failure , it is important to consider why the like - species of oxygen vacancies and interstitials can cluster together as observed . We propose a schematic picture to enable a better qualitative understanding of the microphysics underlying the observed oxygen migration into rings , and the subsequent formation of clusters of oxygen vacancies and interstitials and the associated band diagram ( Figure 4 ) . Initially , incipient oxygen defects are uniformly spread throughout the as - grown TaOx film ( Figure 4a ) , which then laterally migrate due to thermallydriven forces upon formation of the conducting channel ( Figure 4b ) , as discussed above . Local changes in the electrical potential due to the clustering of negative interstitials and positive vacancies can cause significant bending of the tantalum oxide conduction and valence bands that can partially neutralize the charge on each species , [ 38 ] as indirectly evidenced by significant band - shifts in Figure 2c . This bandbending can decrease repulsions among likecharged species and also enable them to agglomerate , as the cohesion energy for oxygen vacancies can be quite low , and is likely to stabilize the ring [ 7,34,39,40 ] ( Figure 4c ) . We also calculated an approximate potential profile across the ring ( Figure S16 ) that look qualitatively similar to the one proposed in this cartoon . Subsequent lateral forces followed by clustering of vacancies and interstitials follows the initial bending of bands , as shown in Figures 4b-4c . Due to continued supply of energy through cycling and the large surface - area - to - volume ratio of the rings , they break apart to form clusters of oxygen interstitials and vacancies ( Figure 4d ) , associated with the fading of the ring observed in Figure 2b . Additionally , we observe that most of the bright regions in Figures 1b-1c are in proximity or contact with a dark region , and vice versa ( pointed out in Figure S3 ) . This suggests that there are significant vacancy - vacancy and interstitial - interstitial attractive forces or there are significant vacancy - interstitial barriers . The attractive forces likely originate from the strong clustering , as mentioned above . The barrier could originate from the oppositely charged defects in the bright and dark regions behaving as dopants , creating an electric field at the interface of these regions to prevent complete neutralization of the charged defects , much like oppositely charged dopants in a p - n junction . Direct observation of clustering of like - species is an important observation that shines light on a prominent failure mechanism of such devices . We specifically point to the fact that many real world devices are smaller than the ring features observed here and are operated at much lower power levels . Similar experiments utilizing low - power operations on identical devices have yielded strikingly different results , with the device endurance being much higher ( > 10 8 ) and no rings were observed . [ 17 ] As our measurements show , in - operando x - ray absorption spectromicroscopy is a powerful tool for studying chemical and electronic structure in oxide materials , including device evolution and failure with electrical     cycling and inhomogeneous localized phenomena . With in - operando , high - voltage electrical cycling of tantalum oxide devices , we observed the development of submicrometer features with a ring of oxygen interstitials and an inner core of oxygen vacancies , which could be reproduced using thermally - driven lateral forces . A key observation here is that a significant amount of displaced oxygen moved radially outward from the conduction channel and was stored as interstitials , with a unique spectral signature , in the tantalum oxide film rather than in to the adjacent tantalum metal electrode . [ 41,42 ] These results provide experimental data that help in understanding previous models regarding oxygen ion migration , [ 3,[5][6][7][8]17,26,32 ] metastable cohesion of oxygen defects , [ 7,34,40 ] role and sign of thermophoresis , [ 12][13][14]43 ] the composition and structure of conduction channels that tend towards failure , [ 5,6,8,31 ] and the localization of resistance switching . [ 14,37,43 ] Most importantly , we directly observed a failure mechanism caused by clustering of like - species of oxygen .	6318390	no
1.5 1.5 Figure 5 : Hyper - parameter search for the pruning algorithm according to Han et al . ( 2015b ) . Each point of the grid represents a weight decay coefficient -quality factor pair . The number and the color indicate the performance in terms of accuracy ( left ) or connectivity ( right ) . The red rectangle indicates the data points that were used in Fig . 3A.	2835189	no
In this study , we evaluated human TRIB2 - interacting proteins and investigated if the Trbl - mediated degradation of String is likely to be functionally conserved in vertebrate TRIB2 pseudokinase , which have been linked to a variety of cancer - associated signaling pathways [ 34 ] . Here , we show that mammalian CDC25B and CDC25C are novel interacting partners of TRIB2 . Consistently , the overexpression of TRIB2 promotes polyubiquitination and proteasome - dependent degradation of CDC25C. Our data suggests TRIB2 - mediated degradation of CDC25C takes place in the nucleus . In accordance with a potential functional role of TRIB2 in cell cycle regulation , we also find that TRIB2 protein expression is tightly regulated during the cell cycle .	15558823	no
The involved scales are v L = 0.025 eV and v R = 2 v 2 u / âm 2 A â 1.2 Â· 10 15 GeV. As a consequence of non - zero Î· , the zeroth - order values U e3 = 0 and Î¸ 12 = Î¸ 23 = Ï/4 are modified to |U e3 | â B Ç« Î·/ â 2 , tan 2 Î¸ 23 â 1 â 2 Î· and tan 2Î¸ 12 â 4 â 2 B Ç« / Î· , where for simplicity also Î· is assumed to be real . The value sin 2 Î¸ 12 = 1 3 is achieved for B Ç« = Î·/2 . The ratio of the neutrino mass squared differences âm 2 â /âm 2 A is approximately 3 4 Î· ( 4 Ç«+Î· ) . A choice of parameters which leads to neutrino properties that agree with the data , and which we will use in what follows , is B = 1.1 , Î· = 0.1194 and Ç« = 0.0542 . The low energy phase Ï is the Dirac - type CP violation phase which can influence neutrino oscillations .	6032126	no
a 0.5 M HCl is a moderately corrosive first step and therefore it is not possible to differentiate the release of divalent ions from loosely sorbed / exchangeable phase or as a result of dissolution of amorphous or soluble phases . Furthermore , the first step was originally used for analysis of Fe from within a different sediment environment . The implications regarding these points are included in the results / discussion section as the authors consider the results provide valuable supporting data .	49294667	no
In response to COVID-19 , a new method is required to investigate the equality of access to food stores . However , studies analyzing the fairness of access to food stores in terms of consumer demand are rare , and little research attention has been given to access to food stores in Taipei City . In this study , the Gini coefficient was used prospectively to quantify the equality of access to food stores at the city and village levels in Taipei . The experience of older adult citizens was also considered , and the Gini coefficients of older ( over 65 years ) and non - older subpopulations were investigated . This approach allowed us to obtain accurate data on Taipei as an aging society and to examine whether specific groups face worse fairness than others do .	256000608	no
Given the unexpected , initial increase in resistance , we conclude that the transport properties as a function of annealing are , in the n - type regime , more strongly governed by the diminishing carrier concentration than by the carrier mobility , which generally increases upon structural ordering . The latter process , in combination with multi - band effects , explains the transition to the p - type regime characterized by higher carrier concentrations and lower resistivity . For Pb 2 Sb 2 Te 5 , the influence of two bands with different carrier types even leaves a fingerprint in the Seebeck coefficient changing its sign as a function of the measurement temperature . For PbSb 2 Te 4 , on the other hand , the changing relevance of conduction - band and valence - band tails over the course of annealing can best be tracked in tunneling measurements of the DOS . Altogether , the experiments imply that the Fermi level must shift downward with respect to the band extrema upon structural ordering . The differences between PbSb 2 Te 4 and Pb 2 Sb 2 Te 5 in the Seebeck data suggest that the two processes involvedreduction of band tails and Fermi - energy shift - concur in different ways in the two materials , with Pb 2 Sb 2 Te 5 starting already with a comparatively low Fermi energy but yet noticeable band tails .	243862877	no
The TA - states can be represented by their cluster - size distribution that form the basis of kinetic theory of nucleation , and the shortening of the ACT time upon a stimulus pulse may be described by their evolution . On the microscopic scale , the TA - states may be described by their degree of medium - range order in the disordered - network structure that fl uctuates locally and temporally upon excitations . Numerical computations [ 14][15][16 ] based on the kinetic theory of nucleation have shown that , in response to a temperature change , the cluster population of the melt - quenched amorphous phase n am evolves gradually to the steady - state distribution n ss at an elevated temperature in a fi nite amount of time . [ 17 ] This time dependence is a consequence of the thermally - activated process during the growth of Phase - change ( PC ) materials have broad applications in rewritable DVD disks , [ 1 ] non - volatile electronic memories , [ 2 ] reconfi gurable electronics , [ 3 ] and more recently , in the area of neuromorphic computing [ 4][5][6][7 ] by virtue of their accumulative nature of the amorphous - to - crystalline phase transition ( ACT ) in PC materials , which allows biological - like read / write operations . PC memory ( PCM ) devices utilize both fast phase transitions between the amorphous ( a- ) and crystalline ( c- ) states of PC materials , and accompanying large electrical - resistance contrast , offering feasible intriguing applications in fast / nonvolatile / nanoscale built - in information storage , particularly for their ability to scale down to nanometer length scales . [ 8][9][10][11][12][13 ] However , the overall operation speeds of PCM devices , along with their corresponding power consumption , are intrinsically limited , in particular , owing to the ACT being much slower than the amorphization process . Moreover , much still remains to be done due to the contradictory nature of increasing the ACT speed while at the same time extending the amorphousstate data - retention properties of PC materials .	15289695	no
"Gaussian linear dynamical systems ( LDS ) provide very efficient learning and inference algorithms , but they can typically only be applied when the observations are themselves linear with Gaussian noise . While it is possible to apply a Gaussian LDS to count vectors ( Belanger and Kakade , 2015 ) , the resulting model is misspecified in the sense that , as a continuous density , the model assigns zero probability to training and test data . However , Belanger and Kakade ( 2015 ) show that this model can still be used for several machine learning tasks with compelling performance , and that the efficient algorithms afforded by the misspecified Gaussian assumptions confer a significant computational advantage . Indeed , the authors have observed that such a Gaussian model is "" worth exploring , since multinomial models with softmax link functions prevent closed - form M step updates and require expensive "" computations ( Belanger and Kakade , 2014 ) ; this paper aims to help bridge precisely this gap and enable efficient Gaussian LDS computational methods to be applied while maintaining multinomial emissions and an asymptotically unbiased representation of the posteiror . While there are other approximation schemes that effectively extend some of the benefits of LDSs to nonlinear , non - Gaussian settings , such as the extended Kalman filter ( EKF ) and unscented Kalman filter ( UKF ) ( Wan and Van Der Merwe , 2000;Thrun et al . , 2005 ) , these methods do not allow for asymptotically unbiased Bayesian inference and can have complex behavior . Alternatively , particle MCMC ( pMCMC ) ( Andrieu et al . , 2010 ) with ancestor resampling ( Lindsten et al . , 2012 ) is a very powerful algorithm that provides unbiased Bayesian inference for very general state space models , but it does not enjoy the efficient block updates or conjugacy of LDSs or HMMs ."	17551686	no
Finally , LabVIEW was used from National Instruments to collect the data and a mechanical loading reactor to apply strain to the samples following a sinusoidal signal at different frequencies and fixed strain .	237270389	no
We thank an anonymous referee for providing crucial comments and suggestions that greatly improved the manuscript . We thank Luis Aguilar for fruitful discussions and advice . VRP acknowledges support from a CONACYT / UNAM scholarship . CRZ , VRP , MT and JH acknowledge support from UNAM - DGAPA - PAPIIT grants IN108117 , IN104316 and IA103017 , Mexico . ARL acknowledges support from program FONDECYT 1170476 , Chile and a PREI - DGAPA - UNAM academic exchange scholarship . This work has made use of data from the European Space Agency ( ESA ) mission Gaia ( https://www . cosmos.esa.int/gaia ) , processed by the Gaia Data Processing and Analysis Consortium ( DPAC , https://www . cosmos.esa.int/web/gaia/dpac/consortium ) . Funding for the DPAC is provided by the institutions participating in the Gaia Multilateral Agreement .	119332076	yes
where z is represented as a vector of z ij 's for all i = j. It is possible to calculate the marginal probability of each edge p(z ij = 1 | x , q ) for all i , j in O(n 3 ) time using the inside - outside algorithm ( Baker , 1979 ) on the data structures of Eisner ( 1996 ) .	6961760	no
To evaluate the real chronic effects of China 's long - term air pollution control plan , it is necessary to exclude COVID-19 effects in 2020 . One possible solution is to predict the air pollutant concentration in each city in 2020 according to annual data in the past several years as a normal condition and then compare the difference between the data and real annual data in 2020 . Considering the advantages of grey prediction theory in small sample prediction ( Wu et al . , 2013a(Wu et al . , , 2013b , it has been used to predict air quality indicators with limited original data and few samples ( Zhou et al . , 2020b;Wu et al . , 2018;Chen and Pai , 2015 ) . In this paper , the GM(1,1 ) model can be described as follows :	237424987	no
"After performing the Gaussian fits on short baselines , we derived amplitude and phase self - calibration solutions and applied them to all baselines . For the amplitude self - calibration , we used a total flux density of 1 Jy , which is comparable to the average of historical values at 1.3 cm ( e.g. , Bower et al . 2015b ) . This choice of normalization does not affect our remaining analysis , which only relies on the fractional visibility amplitudes relative to the total flux density . In addition , we averaged the data across all IFs , to maximize our sensitivity . Figure 2 shows the resulting visibility measurements , including upper limits on baselines to Spektr - R ( computed by PIMA ) and highlighting the amplitudes for our most sensitive ground baselines . These baselines are expected to have signals that are dominated by refractive noise ; they have / up to 8.4 after the final incoherent averaging in time , indicating a reliable detection of image substructure . For each figure , we show the expected envelope of the ensembleaverage image and the predicted "" renormalized refractive noise""Ër ef ( u ) = ÎË(u ) 2 1/2 , whereËis the complex visibility function of the source after centering the image and normalizing the total flux density ( for details , see Appendix A of J18 ) ."	244103062	no
We depicted schematically in Fig . 1 that several corrections are needed to proceed from the direct measurement to the derived one . For the Higgs measurement we exemplified two of them , electron calibration ( Sect . 5 ) and the background beneath the enhancement at 125 GeV ( Sect . 6.2 ) , motivating that a physics model 14 is not needed for either correction . In contrast to Morrison 's assertion , virtually every single correction to determine the number of events in the enhancement at 125 GeV can be derived from data alone , using templates obtained directly from material data . 15 Thus , the mass measurement of the enhancement can not depend logically and causally on simulation , as already suggested by Massimi and Bhimji ( 2015)(p . 81 ) . While physicists strive to reach independence of physics models , they compromise in actual practice to use models in the simulation because of their convenience for inter - and extrapolations , and thus their adaptability to special conditions ( cp . Sect . 5 ) .	244199112	no
On the basis of highly accurate laboratory rest frequencies , and the first data release ( DR1 ) from a largescale , high sensitivity spectral line survey , GBT Observations of TMC-1 : Hunting for Aromatic Molecules ( GOTHAM ) , predominately in the K ( 18 - 27 GHz ) and K a bands ( 26 - 40 GHz ) , a number of the authors here recently reported the astronomical detection of 1 - cyano - CPD using spectral stacking and matched filtering techniques ( McCarthy et al . 2020b ) . From these observations , which represent â¼30 % of the project goal , an upper limit for 2 - cyano - CPD relative to 1 - cyano - CPD was estimated to be roughly 1/3 . Because the abundance ratio in the laboratory ranges from 1/2 to 1/4 ( Sakaizumi et al . 1987;McCarthy et al . 2020a ) , it was unclear if 1 - cyano - CPD is formed selectively in TMC-1 or if the apparent absence of 2 - cyano - CPD is simply a question of sensitivity , given its somewhat lower stability and consequently lower abundance . With the second data release ( DR2 ) and additional laboratory measurements , this ambiguity has now been resolved , and in doing so a common formation for this isomeric pair is implicated .	231979207	no
To further investigate why these methods fail , we performed a sequence of experiments with the two nested ' C 's data , while changing the distance between the two clusters . The results are shown in Figure 6 . We can see that all three methods fail to cluster the points correctly once the clusters can not be separated using non - overlapping convex shapes .	3278749	no
We used an IQ - demodulator with a 50 MHz bandwidth ( Model AD8333 , Analog Devices ) for fast , memory - efficient optoacoustic signal detection in the FD . The IQ demodulator enables homodyne detection of baseband signals that consist of an in - phase component I t Ã° Ã Â¼ A cos Ï t Ã° Ã Â½ and a quadrature component Q t Ã° Ã Â¼ A sin Ï t Ã° Ã Â½ . Signals with amplitude A and phase Ï were extracted from acquired I and Q data using the following equations :	56894658	no
More recently , contradictory data have been reported . Lemon et al . [ 52 ] investigated cancer development and longevity of cancer - prone Trp53 + /â mice exposed to a single 10 - mGy CT scan or gamma irradiation . CT - scanned mice lived longer than the control mice , and CT caused a significant increase in the latency of sarcoma and carcinoma . In another experiment from the same group , 4 Gy was administered first to the same mice and weekly CT scans were repeated 10 times [ 53 ] . The overall lifespan was about 8 % longer in mice exposed to multiple CT scans after 4 - Gy irradiation than the control mice receiving 4 Gy alone . Increased latency periods for lymphoma and sarcoma progression contributed to the overall lifespan increase . Thus , conflicting data exist regarding the oncogenicity of CT radiation exposure . However , it should be noted that the former study suggesting the bionegative effect used only 20 mice per group , whereas the latter two studies employed about 100 or 200 mice per group . than the control mice receiving 4 Gy alone . Increased latency periods for lymphoma and sarcoma progression contributed to the overall lifespan increase . Thus , conflicting data exist regarding the oncogenicity of CT radiation exposure . However , it should be noted that the former study suggesting the bionegative effect used only 20 mice per group , whereas the latter two studies employed about 100 or 200 mice per group .	51969583	no
We have established that , although MnAlGe is not a van der Waals compound , due to the large separation between the magnetic square net layers of Mn atoms , the AHE is dominated by the 2D electronic features in the band structure . There are three important points we would like to emphasize . First , the electronic states near the Fermi energy were dominated by Mn - d orbitals , while the s and p orbitals of the nonmagnetic Al - Ge subunit only contributed far from the Fermi energy . The fat bands observed in Figure S2 , Supporting Information , clearly show the relative contribution of the orbitals in the band structure . Hence , the transport properties of MnAlGe were entirely determined by the Mn - square net layers . Second , the unique 2D distribution of the Berry curvature in MnAlGe that arose from the band anti - crossing of the nodal line perfectly matched the 2D FS obtained from the band constituting the nodal line . Therefore , the AHE observed in this compound originated from the 2D feature of the bands that contained nodal lines . Moreover , the scaling of Ï yx A versus xx Ï 2 indicates www.advmat.de www.advancedsciencenews.com the intrinsic contribution to AHE . It should be noted that the relation of Ï yx A versus xx Ï 2 is not strictly linear in the temperature dependent AHE data . Therefore , a temperature range 2 - 100 K has been used for linear fitting to obtain the intercept â560 S cm -1 as the intrinsic contribution ( see discussion in Supporting Information for the departure from linearity , Figure S17 , Supporting Information ) . Based on the ARPES study , the nodal - line anticrossings was situated just below the Fermi energy that enhanced the AHC . This can be understood from Figure 2f , which shows that shifting the nodal line from above to below the E F moves AHC from the base of a peak in the Ï xy A versus E data to almost the peak . This explains the observation of a large AHC in experiments compared to the value predicted by DFT , when the Fermi energy is placed below the nodal line . Finally , the part of the FS that contributed the majority of the charge carriers for conduction exhibited dispersion in all three dimensions . Thus , the electrical resistivity and the ordinary Hall effect will demonstrate a small anisotropy , which is consistent with experimental observations . Next , we discuss how MnAlGe compares with other well - known 2D , FM , anomalous Hall systems . Quasi-2D kagome lattice compounds Co 3 Sn 2 S 2 and Fe 3 Sn 2 have recently been established as topological Weyl and massive Dirac semimetals . Interestingly , the separation between the Mn layers in MnAlGe ( 5.93 Ã ) was larger than the separation between the two Co - kagome layers in Co 3 Sn 2 S 2 ( 4.39 Ã ) and comparable to that of the Fe - kagome layers in Fe 3 Sn 2 ( 6.60 Ã ) . Notably , while the FS in Fe 3 Sn 2 is open and quasi-2D , the FSs in Co 3 Sn 2 S 2 are 3D. The value of the AHC in MnAlGe was higher than in Fe 3 Sn 2 ( 170 S cm â1 ) and comparable to that of Co 3 Sn 2 S 2 ( 505 - 1130 S cm â1 ) . In a true , van der Waals , topological nodalline , compound Fe 3 GeTe 2 , the separation between the two magnetic layers was significantly larger ( 8.16 Ã ) , while in Fe 1/4 TaS 2 , which forms by the Fe intercalation of the van der Waals gap of TaS 2 , the separation between the Fe layers ( 6.07 Ã ) was approximately equal to MnAlGe . Importantly , the AHC and FM transition temperature of MnAlGe were among the highest reported , as shown in Table S2 , Supporting Information .	232302278	no
of racial discrimination might affect children 's socioemotional development not only through an increase in harsh parenting practices , as hypothesised here , but also through a decrease in supportive parenting . Although we were not able to assess this mechanism with the data we analysed , other studies show that psychological distress is associated with less nurturing and supportive parenting ( McLoyd , 1990 ) . Parental support is important not only as a predictor of the healthy development of children ( Pettit et al . , 1997 ) , but as a moderator in the association between experienced racial discrimination and detrimental outcomes among children ( Simons et al . , 2002 ) . Future studies that are able examine the multiple pathways , and their particular details that link vicarious racial discrimination to children 's health and development , will improve our understanding of the intergenerational transmission of ethnic inequalities in health . We did not find any associations between living in a neighbourhood where racist incidents are common , and children 's socioemotional development . We had proposed in the introduction that living in a racist neighbourhood would have a detrimental effect on maternal mental health by producing a state of heightened vigilance from the constant fear of either them , or their children , experiencing racial discrimination . It is possible that hypervigilance may also be elicited via other exposures to racial discrimination ( including personal , and those of family members ) , and not only through living in a neighbourhood where racist events are common . This is a plausible explanation given the documented association between fear of racism and poor health outcomes ( B ecares et al . , 2009 ) , and that ethnic minority mothers report they vicariously experience racism by witnessing discrimination against their children ( Sanders - Phillips et al . , 2009 ) .	31367378	no
In this paper , we address the aforementioned gaps in the literature using longitudinal data on children from Ethiopia , India , Peru , and Vietnam . In particular , we investigate a wide range of child , household , and community - level predictors of growth recovery and faltering at different periods from conception through early adolescence . A methodological innovation of our study is that we employ different estimators , including panel data estimators that deal with bias arising from fixed unobservables and a new measure of accelerated growth that addresses limitations of existing measures . We also examine whether the incidence , timing , and persistence of growth recovery , as measured by recovery from stunting , through middle childhood are significantly associated with cognitive achievement in this period and whether these associations persist through early adolescence .	1298933	no
We next aligned the sequence of HCoV - NL63 with the complete genomes of other coronaviruses . The percentage nucleotide identity was determined for each gene and is listed in Table 2 . All genes except the M gene shared the highest identity with HCoV-229E. To confirm that HCoV - NL63 is a new member of the group 1 coronaviruses , we conducted phylogenetic analysis using the nucleotide sequence of the 1a , 1b , S , M and N genes ( Fig . 4b ) . For each gene analyzed , HCoV - NL63 clustered with the group 1 coronaviruses . The 1a , 1b and S genes of HCoV - NL63 are most closely related to those of HCoV-229E. However , further inspection revealed a subcluster of HCoV - NL63 , HCoV-229E and PEDV . Phylogenetic analysis could not be performed for the ORF3 and E genes because the regions were too variable or too small for analysis , respectively . Bootscan analysis by the Simplot software version 2.5 ( ref . 28 ) found no signs of recombination ( data not shown ) .	24428187	no
We made the assumption that the odds ratios from case - control studies approximate the hazard ratios from cohort studies . To obtain pooled relative risk estimates we weighted the log of the odds ratios or hazard ratios by the inverse of their variance . We ran random effects models , which include assumptions on potential variability across studies . We used the DerSimonian and Laird Q test for heterogeneity . Since this test statistic has low power with studies of small sample size and excessive power if there are many studies ( especially if they are large ) , we also calculated the I 2 statistic for each analysis . 8 This statistic describes the percentage of total variation across studies that is due to heterogeneity rather than chance ( 25 % low heterogeneity , 50 % medium , 75 % high ) . We used Galbraith plots 9 to visually examine the impact of individual studies on the overall homogeneity test statistic , and we used meta - regression to evaluate the amount of heterogeneity of study type , sex , and migraine aura status on some of the cardiovascular events . We evaluated potential publication bias by visually examining for possible skewness in funnel plots 10 and statistically with the methods described by Begg and Mazumdar 10 and Egger . 11 Egger 's method uses a weighted regression approach to investigate the association between outcome effects ( log odds ratio or log hazard ratio ) and its standard error in each study . Analyses were carried out with Stata 8.2 . Figure 1 summarises the selection of studies . Of 5746 potentially eligible articles identified through the electronic search , 5714 were excluded after an evaluation of the title and abstract . A further seven were excluded : two used the same cohorts as other studies but had shorter follow - up , 12 13 one did not present confidence intervals for the relative risks , 14 one was cross sectional and did not present overall estimates for the follow - up data , 15 one was cross sectional and the temporal association between migraine and cardiovascular events was not clear , 16 one used only descriptive statistics , 17 and one was a case - control study from a database that also contained a cohort analysis . 18 Overall , 25 studies were suitable for inclusion in the analysis ( table 1 ) .	15984735	no
Browsing of DMRs located on first - Alus showed that transcription - factor binding sites are also present upstream of the differentially methylated Alu ( example Figure 5E , bottom track ) . To investigate whether these sites would eventually become accessible under conditions of low DNA methylation at the first - Alu , we examined JunB ChIP - seq data in either resting or activated T - cells ( 49 ) at the interval between the first - and the second - Alu ( schematic Figure   5F ) . Heatmaps showed that in activated T - cells , JunB binding eventually invaded the Alu1 - Alu2 interval at a small number of promoters carrying weak MeDIP signal at the first - Alu ( Figure 5 G , framed region ) . We did however not detect any signal beyond the second Alu element . We next used the same dataset to examine the distribution of NF - B at promoter - proximal Alu elements upon T - cell activation . Unlike JunB , NF - B was reported to use Alu elements as binding platforms ( 51 ) . Yet , we observed only minor accumulation of this transcription factor on first - and second - Alus ( Supplementary Figure S5D ) . In addition , this accumulation did not seem to correlate with promoter activity , as increased NF - B density on Alu elements was observed at the bottom of the heatmap , matching promoters with low H3K4me3 signal ( Supplementary Figure S5D , green arrow ) . This further suggests that Alu elements neighboring promoters do not systematically function as enhancer elements .	248695401	no
A quantitative and qualitative content analysis methodology was employed as ' a research technique for making replicable and valid inferences from data to their context ' ( Krippendorff , 2018 : 403 ) and to make inferences about media representation ( Deacon , 2021 ) . A coding schedule was based on the previous work of , to allow for some comparison of media coverage between broadsheet mainstream newspapers and the Daily Sun tabloid 's online stories . One thousand fifty stories were found between March 2020 and August 2021 and these were coded manually . This timeframe was selected as it starts with the outbreak of the pandemic in South Africa and the first lockdown in March 2020 and concludes as the ' third wave ' of the pandemic wound down in the third quarter of 2021 . Although the sample excludes the ' fourth wave ' which resulted from the highly infectious ' Omicron ' variant detected towards the end of 2021 , this sample spans three ' waves ' of the pandemic in South Africa as well as various stages of lockdown declared in response to it . The quantitative content analysis was complemented by a qualitative content analysis and close reading of a smaller sample of 130 stories across this timeframe , selected via purposive sampling .	256025385	no
To summarize , although different findings would suggest that climate change and environmental pollutions might provoke detrimental effects on mental health , reliable data are a few . However , with no doubt , this is an intriguing and emerging field requiring to be deepened in the future by controlled studies in larger and heterogeneous populations that might better reflect the clinical reality .	231689955	no
Funding : The National Bowel Cancer Audit is commissioned by the Healthcare Quality Improvement Partnership ( HQIP ) as part of the National Clinical Audit and Patient Outcomes Programme , and funded by NHS England and the Welsh Government ( www.hqip . org.uk/national-programmes ) . Neither HQIP nor the funders had any involvement in the study design ; in the collection , analysis , and interpretation of data ; in the writing of the report ; or in the decision to submit the article for publication . The researchers had full independence from the Healthcare Quality Improvement Partnership .	13755243	no
In the integration ( distillation ) step , we are interested in combining all past skills ( Ï 0 , . . . , Ï i ) with the newly acquired skill Ï i+1 . Traditional approaches have used policy regression where data is generated by collecting trajectories of the expert policy on a task . Training the student on these trajectories does not always result in robust behaviour . This poor behaviour is caused by the student experiencing a different distribution of trajectories than the expert during evaluation . To compensate for this distribution difference , portions of the trajectories should be generated by the student . This allows the expert to suggest behaviour that will pull the state distribution of the student closer to the expert 's . This is a common problem in learning a model to reproduce a given distribution of trajectories ( Ross et al . , 2010;Bengio et al . , 2015;Martinez et al . , 2017;Lamb et al . , 2016 ) . We use a method similar to the DAGGER algorithm ( Ross et al . , 2010 ) which is useful for distilling policies ( Parisotto et al . , 2015 ) . See Appendix : 8.2.1 for more details . As our RL algorithm is an actor - critic method , we also perform regression on the critic by fitting both in the same step .	3619097	no
For our Google Trends prediction models , we will apply SFPS - BVE to the entire dataset , consisting of 84 days , without setting aside any days for testing . We do this since we are predominantly interested in analyzing the impact of local and nationwide COVID-19 data on the three Google Trends variables rather than quantifying the predictive capacity of such variables . When analyzing Google Mobility data , however , we set aside the last seven days of our study period ( May 23rd -May 29th ) to also comment on the predictive capacity of our obtained models . We elect to use a test set for this analysis since these variables are the primary focus of this study , and we wish to assess the predictive and extrapolatory capacity of the obtained models .	255441206	no
We checked that the effect of finite mass corrections to the angular distribution , the use of m h instead of the quark mass m in the threshold factor , as well as the scaling violations in the fragmentation function due to the reduced ( i.e. s â sz ) CM hadronic energy , have a negligible impact on our results . The effect of the ISR correction is displayed in Fig . 3 , where BELLE data for D * + â D 0 Ï + are displayed before and after the ISR correction has been applied , both in x and moment space . The ALEPH data are also shown in moment space . We see that the corrected spectrum for BELLE is harder and lower in normalization than the uncorrected one . This is to be expected , since ISR lowers the available hadronic energy , thus softening the spectrum and increasing the cross section at the same time . We can also see that the effect for BELLE is not large , but nonetheless not negligible . It is instead much less prominent , up to the point of being negligible , for the ALEPH data taken on the Z 0 peak , as expected .	18414302	no
First , the prevalence of individuals at high risk for having a CMD in KB is higher than rates found in other population - based studies in India , even when our data are disaggregated by age and gender to allow for more precise comparisons to the populations sampled in those studies ( Table 5 ) . By contrast , the only other population - based study that is similar to KB , with regard to the prevalence of individuals at high risk for having a CMD , is also from a slum in Mumbai ( Jain & Aras , 2007 ) . While these findings suggest that slums , and particularly non - notified slums , may suffer from a higher burden of CMDs than non - slum communities do , future population - based studies that compare a variety of non - slum and slum populations ( including both non - notified and notified settlements ) in the same urban location , as well as adjacent rural locations , would be required to more definitively understand disease burden in different environments .	37115168	no
Evidence from observational studies suggests that changing the built environment has the potential to influence cycling behaviour , 64 but few data from controlled intervention studies are currently available to confirm this . Our review shows that it is unclear whether increases in cycling could be achieved at lower cost by addressing attitudes and perceptions about cycling .	5476641	no
To define the manipulation of proximity ( high vs. low ) , we conducted a pretest and an additional pilot test . Fifty Italian consumers ( Mage 26 ; 53 % female ) were included in the pretest . We recruited these participants via the ProlificAcademic ( ProA ) online crowdsourcing platform given that its participants produce higher - quality data compared to other platforms ( Peer et al . , 2017 ) . We asked participants to indicate the maximum distance between the drop - off bin and the home that they were realistically willing to travel to dispose of exhausted batteries in specific bins . The smallest distance ( 50 m ) and the largest distance ( 5 km ) indicated by respondents were chosen for the manipulation of low and high proximity in the experiment , respectively .	253429969	no
We then evaluated whether combined inhibition of vessel co - option and angiogenesis is more effective at limiting tumor growth when compared to angiogenesis inhibition alone . Mice with established control - or ARPC3 - knockdown tumors were treated with the VEGF - A inhibitory antibody B20 - 4.1.128 combined with capecitabine ( Fig . 6f - h ) . In control tumors , which have a predominantly replacement HGP ( Fig . 6f ) , no significant inhibition of tumor burden was observed in response to treatment when compared to vehicle control ( Fig .   6 g ) . However , in ARPC3 knockdown tumors , which have a predominantly desmoplastic HGP ( Fig . 6f ) , tumor burden was significantly suppressed by treatment ( Fig . 6 g ) . In addition , although treatment with B20 - 4.1.1 led to a reduced tumor vessel density in both control - and ARPC3 knockdown - tumors , this effect was more pronounced when vessel cooption was suppressed by knockdown of ARPC3 ( Fig . 6h , Supplementary Fig . 14 ) . The administration of capecitabine alone did not significantly suppress tumor burden or tumor vessel density in either control - or ARPC3 - knockdown tumors ( Supplementary Fig . 15 ) . These data suggest that simultaneous inhibition of angiogenesis and vessel co - option may be a more effective strategy for the treatment of advanced liver metastases than current strategies which target angiogenesis alone .	3437207	no
We have demonstrated an all - optical , fast , and non - invasive method to resolve , with unprecedented resolution , the crystalline integrity of atomically thin WS 2 crystals via experimentally probing and theoretically interpreting their nonlinear optical properties . In particular , we showed that PSHG raster - scanning imaging microscopy enables highresolution pixel - by - pixel ( pixel size of 120 Ã 120 nm 2 ) mapping of the armchair crystal axis orientation , which can be used to provide firstorder information on crystallographic imperfections stemming from inhomogeneities in the distribution of armchair orientations . Moreover , the measured pixel - by - pixel PSHG data were fit to a new theoretical model based on the nonlinear optical response of such crystals , which was utilized as a second - order filter that effectively enhances the optical contrast and provides quantification of the crystal quality in terms of the standard deviation of the calculated armchair orientational distributions . Consequently , we demonstrate an ultrahigh - resolution nonlinear optical method that can be used to identify small variations in the crystal armchair direction . This information with such a high resolution is unattainable by conventional SHG imaging as well as by Raman and photoluminescence mapping .	52134764	no
Since the seminal works of Kolmogorov ( 1941 ) and Kraichnan ( 1965 ) , it is well known that the turbulence in magnetized media should not necessarily be isotropic . In addition , after the past 50 years of investigations , ample evidence exists for various types of anisotropy of solar wind turbulence ; for a review , see Oughton et al . ( 2015 ) . For example , the radial evolution of solar wind intermittency using magnetic field and velocity as measured by Helios in the inner heliosphere for the parallel and transverse components relative to the local magnetic field has been investigated by Bruno et al . ( 2003 ) , suggesting parallel and perpendicular cascades ( Oughton & Matthaeus 2005 ) . The probability density functions of the magnetic field increments beyond the ecliptic plane using Ulysses data have also been obtained by Perri & Balogh ( 2010 ) . Moreover , it has become evident that to resolve anisotropy in turbulent solar wind flows , the orientation of a scale - dependent local background magnetic field is rather important ( e.g. , Kiyani et al . 2013;Oughton et al . 2015;Gerick et al . 2017 ) .	126036325	maybe
We acquired systematically time - resolved STM data of the switching events as af unction of the temperature , tunnelling bias and tunnelling current . We find that the range of tunnelling conditions employed here does not influence the switching events , s ow ec an use STM to follow the natural thermally activated rotation of the guest molecules within the nanopore ( Supporting Information Figure S10 ) . However , the possibility of tip - induced activated rotation under different tunnelling conditions exists . N oc orrelation of the rotations and positions of the neighbouring caged guests was noticed , we therefore considered them as independent rotors . W e recorded the frequencyo fr otation events by % 1208 8 as afunction of temperature ( see plot in Figure 5Aand Methods in Supporting Information ) . With an Arrhenius equation fitting , the barrier is determined to be 0.95 eV AE 0.07 eV with acorresponding pre - exponential factor of % 2.3 10 14AE1 s Ã1 .	237617152	no
Unfortunately , velocity - space cascades have traditionally been difficult to diagnose , both in satellite data and in numerical simulations . Although several 3D simulations of kinetic / gyrokinetic turbulence exist ( e.g. , Howes et al . 2008Howes et al . , 2011Servidio et al . 2015;Told et al . 2015;Wan et al . 2016;Groselj et al . 2017;Franci et al . 2018;Arzamasskiy et al . 2018 ) , thus far the velocity - space cascade produced by nonlinear phase mixing has been directly diagnosed only in 2D simulations of gyrokinetic electrostatic turbulence ( Tatsuno et al . 2009(Tatsuno et al . , 2012 , with little other indirect evidence ( BaÃ±Ã³n Navarro et al . 2011;Cerri et al . 2014 ) .	51838881	no
Code for Africa is a civic organisation which has since 2015 been at the forefront of various data - driven practices and projects within and outside news organisations . It has branches and partnerships with 15 civic organisations ( as of May 2018 ) that include Cameroon , Ethiopia , Ghana , Kenya , Morocco , Nigeria , Sierra Leone , South Africa , Tanzania and Uganda . Its operations involve working with newsrooms to train data journalists or aggregation of data in digital platforms for investigative journalism and fact - checking purposes . A successful example is a joint partnership with Kenya 's Star newspaper to create a doctors ' database and a public platform - dubbed Dodgy Doctors - to weed out quacks in the medical profession ( see : https://health.the-star.co.ke/ ) .	158951976	no
Based on the originally communicated locations of the GW signal and the GRB detection , high - energy neutrino candidates were initially searched for in the ANTARES online data stream , relying on a fast algorithm which selects only up - going neutrino track candidates ( AdriÃ¡n - MartÃ­nez et al . 2016b ) . No up - going muon neutrino candidate events were found in a Â±500 s time window centered on the GW event time -for an expected number of atmospheric background events of â¼ 10 â2 during the coincident time window . An extended online search during Â±1 h also resulted in no up - going neutrino coincidences .	217180814	no
Data were subsequently organized into tables to ease comparisons , and the importance of some concepts representing the key elements of the analysis were highlighted . The data was interpreted by seeking out how the curriculum design and delivery of the Elevator pitch and Business Plan development changed through the adoption of distance learning . An online survey was developed and filled in by the students enrolled in the third edition of the CLab@Salento , in the aim to grasp their reactions and insights about the effectiveness of the new distance learning mode as well as the main problems and challenges encountered .	231690009	no
The characterization data for 1 and 2 are consistent with their formulations . [ 17 ] The vivid orange color of 2 ( both in the solid - state and in solution ) is noteworthy for a 6d 0 5f 0 metal complex . The electronic absorption spectra of 2 exhibits a broad , intense electronic absorption band from the UV to visible wavelength range , and a strong absorption between 450 and 550 nm . Since 1 is pale yellow and the 6d 0 5f 0 electronic configuration of Th IV precludes metal - localized ff , d - f , and d - d transitions , and on the basis of definitive prior work , [ 12c ] we conclude this transition is due to a spin - allowed but orbital - forbidden p ? ( N)!p * ( N = C ) and ligand - to - metal charge transfer ( LMCT ) .	7988916	no
All of our discussion throughout the paper will be completely model - independent and can be applied to any BSM scenario , including supersymmetry , extra dimensions , little Higgs theory etc . In Section 5 , however , we shall use a specific example in order to illustrate each of our three proposed methods . Instead of considering a decay chain of some BSM model , we chose to select an example which is already present in the Tevatron data , and will soon be tested at the LHC as well : the dilepton event samples from top quark pair production and from W -pair production . Those two dilepton samples satisfy all of our assumptions , and would be a perfect testing ground for any new ideas about mass measurements in missing energy events from new physics . In Section 5 we will show that using any one of our three M T 2 -based mass measurement methods , one can in principle determine the mass of each of the three particles : top quark , W -boson , and neutrino , independently and in a completely modelindependent fashion . Section 6 contains a summary and a discussion of our main results . In Appendix A we collect all relevant formulas for the endpoint functions M ( n , p , c ) T 2,max ( M c , p T ) .	9472861	no
Fluorescence corresponding to the Alpha variant could be detected , as this variant also harbors S : Î69/70 . However , the fluorescence plateau values detected were considerably lower compared to those of Omicron . In addition , since Alpha has been completely displaced by Delta , the presence of the former variant in the monitored wastewater is unexpected . It should be also highlighted that the data obtained from the National Genomic Surveillance Network regarding the SARS - CoV-2 variants that circulated during each period were critical for the interpretation of the RT - PCR findings . This is based on the fact that the developed assay aims at a specific viral genomic target . In our case , up to 16 December 2021 , the vast majority of the genomic sequences that were characterized from Thessaloniki belonged to the Delta variant ( 92.8 % , i.e. , 1059 out of 1141 clinical samples that underwent typing ) ( National Public Health Organization - Greece ( EODY ) , 2021c ) and this assisted in drawing safe conclusions about the performance of our wastewater monitoring methodology .	249960144	no
We introduce the SAGUARO GW optical counterpart search strategy , where we tile the highest probability regions of the localization with the Steward Observatory Mt. Lemmon 1.5 m telescope and its 5 deg 2 imager . With this facility we obtain observations covering 60 or 120 deg 2 down to â¼ 21.3 mag within Î´t 30 min of receiving the GW alert if it is observable . We also present the SAGUARO software suite that we utilize to trigger the observations , process the data , and display the candidates for vetting . The robustness of this system allows us to start tiling the localization within minutes of receiving the GW alert and produce lists of candidates within hours .	189927965	no
The spring constant of the PEG micropillars was determined using an AFM cantilever as a reference . First , the cantilevers spring constant was determined using the integrated tool of a JPK BioAFM ( atomic force microscope , JPK Instruments AG ) . To calibrate the micropillars , the AFM cantilever was vertically fi xed in a custom - made micromanipulator such that its tip was situated approximately 1 Î¼ m below the top of the PEG pillar . Both the cantilever and pillar were made to bend by moving highlighting the differences observed in Figure 2 ( a ) . The comparison in Figure 2 ( b ) illustrates that for forces smaller than 7 nN only a few more maximum force counts are observed on the Î± v Î² 3 -integrin antagonist than on the Î± 5 Î² 1 -integrin antagonist . In contrast , at forces above 7 nN the number of maximum force counts on the Î± 5 Î² 1 -integrin antagonist is up to four times greater than on the Î± v Î² 3 -integrin antagonist . In general , the data shows a trend towards higher maximum force counts at higher force levels for cells on the Î± 5 Î² 1 -integrin specifi c antagonist , suggesting that these cells must exert a greater pulling force on the pillars when adhering to them .	2772643	no
To increase the external validity of our findings we used a populist sampling frame to identify both the recipes and the ready meals . However , the nutritional content of recipes varied substantially between individual recipe books ( data available from the author ) , suggesting that a different selection process may have led to different findings . Selecting books that were bestsellers in the run - up to Christmas may have influenced the selection of recipes , and the transient nature of bestseller charts may challenge the representativeness of the sample . The size of the sample prevented subgroup analyses comparing individual chefs or supermarkets .	5347191	yes
Figure 3d - f shows the correlation plot for the long dimer 2 along with the vibronic intensity ratio and FWHM as af unction of E 0 - 0 .W ed iscern the J - type coupling of the monomer units from the H - type coupling of the dimer by the redistribution of the oscillator strength to the vibronic transition for the most red - shifted emission : s tarting from the lowest E 0 - 0 and moving higher , the intensity of the vibronic sideband first decreases and then increases again , corresponding to as uppression of H - type coupling followed by ad ecrease in J - type coupling . T he same behavior is seen more clearly in the correlation plot of the peak FWHM in panel ( f ) . While the H - type coupling is only weakly visible for the long dimer , i ts hould become more pronounced for the short dimer as stated above . Q ualitatively , s ingle - molecule spectra of the short dimer 3 in panels Figure 3g - i also follow this trend , although the J - type character is less pronounced . TheH - type coupling is clearly visible as adistinctive increase of I 0 - 1 /I 0 - 0 at decreasing E 0 - 0 values . Asimilar correlation is also seen in the Huang - Rhys factors of the spectra , as discussed in Figure S16 . This representation of large sets of data offers an intuitive visualization of the non - trivial interplay between J - and H - type coupling in multichromophoric aggregates . I np articular , t he transition from J - to H - type behavior , indicated by the dashed blue lines , c onveys the impression that aq uantitative analysis of dipole - coupling strengths could be possible . W en ote that the overall PL intensity does not decrease significantly in H - type aggregates . Ther adiative rate decreases in such aggregates , b ut the PL quantum yield remains almost the same due to an egligible overall non - radiative rate in these molecules . [ 12 ] Ac omplete analysis of these characteristics would require careful considerations of the microscopic molecular dynamics involved , since the backbone can be quite flexible and the strongest Htype couplings may occur only within as mall region of the overall segment . [ 17 ] Then oise in the scatter plots of the peak width and the I 0 - 1 /I 0 - 0 ratio in Figure 3s hould also be noted . Thed ata for 2 Figure 3 . PL spectra of 2875 , 2743 , and 1857 single molecules of 1 , 2 and 3,s orted by the 0 - 0 peak - transition energy E 0 - 0 and normalized to I 0 - 0 .I n1,t he vibronic - intensity ratio I 0 - 1 /I 0 - 0 and spectral FWHM decreases with decreasing E 0 - 0 , ase xpected for J - aggregation . In 2 and 3,s pectral signatures of J - aggregation within the chromophores are identified in analogy to 1.Above acertain red - shift , t he spectral shape changes and H - aggregation dominates : t he spectra broadena nd the oscillator strengthshifts to the 0 - 1 transition . This threshold is indicated in blue . The vibronic - intensity ratio increases on either side of the set threshold . Green lines indicate averages over 50 points . and 3 show as omewhat larger scatter with the transition energy than for 1.The reason for this difference is simple : the additional degree of freedom - interchromophoric spacing , which determines the strength of H - type coupling in 2 and 3does not necessarily correlate fully with the effective chromophore length , that is , w ith the degree of J - type coupling . Very small variations in the interchromophoric spacing , as predicted by molecular - dynamics simulations , [ 17 ] have adrastic impact on the spectral width and vibronic coupling without necessarily affecting the transition energy , which is dominated by the degree of J - type coupling . These fluctuations show up as noise in the 2D plots , s ince , e ven in the regime where the spectra are dominated by J - coupling , H - type interactions can still occur , giving rise to spectral broadening and asuppression of I 0 - 0 .F inally , w es tress that this analysis approach is universal and can be applied to arange of different molecules .	203983353	no
The need for compact , high - performance imaging spectrometers that span an application space from satellite imagery to food safety has never been higher . In this data - driven world , consumers want to know more about the chemicals in their food or how to precisely match the paint color on their living room wall . Companies need fast , reliable methods of product inspection with high spatial and spectral resolution , necessitating imaging spectrometer instrumentation . A pushbroom imaging spectrometer images a slit onto a 2D detector array , where the length ( longest dimension ) of the slit sets the full field of view ( FOV ) of the spectrometer and lies along one of the dimensions of the detector array , while the spectral dispersion created by the grating spreads along the orthogonal dimension , along which the width ( smallest dimension ) of the slit is imaged . An increase in system requirements for spectral range and resolution , compactness , and FOV of spectrometers has motivated the emergence of technologies and applications in hyperspectral imaging .	35066680	no
After the above process , the first unknown freeform surface Î© is generated , and the initial plane can be replaced . All the unknown freeform surfaces can be generated successively using this process , and the preliminary surface construction stage is completed . But the actual image points of the feature rays may be far from the ideal image points . Therefore , the iteration process is used to regenerate the freeform surfaces and reduce the deviations 27 . We take the system obtained after completing the preliminary construction process as the new initial system . When regenerating each surface in each iteration step , the coordinates of the points where the rays intersect with the initial surface are preserved as the coordinates of new feature data points , as shown in Figure 3c . The target points for the rays during iterations are generally their corresponding ideal image points . To accelerate the iteration process , an alternative negative feedback mode can be used . Here , the target point T i for each ray is determined on the basis of its ideal target point T i , ideal ( also the ideal image point ) as well as its actual image point T i * before the current surface is regenerated :	52133102	no
Funding : The Costa Rica HPV Vaccine Trial is a longstanding collaboration between investigators in Costa Rica and the US National Cancer Institute ( NCI ) . The trial is sponsored and funded by the NCI ( contract N01 - CP-11005 ) , with funding support from the National Institutes of Health Office of Research on Women 's Health . GlaxoSmithKline ( GSK ) Biologicals provided vaccine and support for aspects of the trial associated with regulatory submission needs of the company under a clinical trials agreement ( FDA BB - IND 7920 ) during the four year , randomized blinded phase of our study . This manuscript was not prepared in collaboration with GSK Biologicals investigators , and GSK Biologicals had no role in the study design and the collection , analysis , and interpretation of data from CVT in this paper , or in the writing of the article . GSK Biologicals took no part in the decision to submit an article for publication . The analysis reported here was supported by the intramural research programs of the NCI and the National Institute of Environmental Health Sciences , both parts of the National Institutes of Health .	23126892	no
We compute bootstrap CIs by resampling transitions within the time series . Bootstraps that accommodate the dependence relationships that may be present in time series is an open - ended topic 72 , because generally there is no resampling scheme that logically guarantees resampled data to be equiprobable under the true generating process , in contrast to the bootstrap argument for independent samples . Nonetheless , in our case , the likelihood calculation sums over observations and expectations of change from one timestep to the next , and it is these transitions that are assumed to be independent across time periods and approximately independent between types . Unaccounted dependence between observations enters by either failures of the Markovian assumption in the true generating process , or by effects of competition between types induced by finite population size . We resample in a way that approximates independence and roughly preserves population size so that resampled transitions have similar frequencies to the originals .	232380291	no
The Agricultural , Forestry and Fishing sector ( A ) , has been the least affected economic compartment with a GDP variation accounting for 0.13 % ( â584 million euro ) of the total change . According to data provide by OECD ( 2020a ) , the COVI-19 related spike in the consumption of vegetable and citrus fruits has contributed to boost a significant increase in the demand of agricultural products , with Spain experiencing the major sectoral gains ( +587 million euro ) . In line with the analysis provided by Eurostat for the food - related retail sector , the demand of agricultural products increased during the two first months of the pandemic and stabilized in the following period ( Eurostat retail trade database ) . The non - closure of supermarkets and essential shops , together with the panic buying behaviours has contributed to sustain the demand of the agricultural compartment ( Jaspal et al . , 2020 ) . Consequently , minor variations have taken place for the related carbon dioxide emissions change , that reduced by 338 thousand tons ( â0.17 % of the total change ) .	231677611	yes
The model considers a weighted network G = ( V , E t , W t ) with stable agents V , time - varying links E t , and link weights W t . We define the agents V and assigned them to specific CBGs based on the population size of each CBG documented in the ACS demographic data . Then using the dwelling locations of the devices provided in the Veraset data , we considered two devices to be in contact if they presented in the same POI at the same time . Here , the dwelling locations of the devices are defined according to the time the devices spent in a location . We use 5 mins as the threshold amount of time to filter out the locations where the devices might be waiting for traffic lights . The length of the overlap of their time spent in the POI is denoted as the duration of their contact . As such , we create an empirical weighted contact network among the devices in the Veraset data . In addition , we estimated the home CBGs of the devices . The links between any pair of CBGs can be extracted . Based on the proportion between the population size of empirical data and the synthetic population , we have a scalar to quantify the difference between the number of devices and synthetic agents . The scalar is then applied to determine the number of links that should be synthesized for each pair of CBGs . The weights of these links follow the distribution of the weights in the empirical contact network . Next , we assign the links to the synthetic agents in these two CBGs , where the degree distribution for the agents is consistent with the degree distribution of the devices in the same CBGs in the empirical data . We generate and assign links by repeating the above steps for all pairs of CBGs . This approach allows for creating synthetic contact networks based on actual mobility data and to maintain key structural and attribute information of the agents and the networks .	233025194	no
For the comparison of performance between LINDEN , iLoci and Plink we utilize the tool GAMETES ( 28 ) to generate simulated GWAS data and implant epistatic loci . We further post process the GAMETES output to simulate linkage disequilibrium and locus density . We describe this procedure in detail later in this section .	7189674	no
Assuming limitations of the deposited data , this work was undertaken to gain a comprehensive view about the influence of cold and heat treatment ( as well as cold and heat recovery ) on the cauliflower mitochondrial proteome in relation to leaf transpiration and respiration rate , stomatal conductance , rate of leaf photosynthesis , photorespiration as well as chlorophyll content and fluorescence . The current study extends our previous complexomic and functional data [ 41 ] .	4634905	no
Knowledge of the underlying parameters of the spreading model is crucial for understanding the global properties of the dynamics and for development of effective control strategies for an optimal dissemination or mitigation of diffusion [ 1,2 ] . However , in many realistic settings effective transmission probabilities are not known a priori and need to be recovered from a limited number of realizations of the process . Examples of such situations include spreading of a disease [ 3 ] , propagation of information and opinions in a social network [ 4 ] , correlated infrastructure failures [ 5 ] , or activation cascades in biological and neural networks [ 6 ] : precise model and parameters , as well as propagation paths are often unknown , and one is left at most with several observed diffusion traces . It can be argued that for many interesting systems , even the functional form of the dynamic model is uncertain . Nevertheless , the reconstruction problem still makes sense in this case : the common approach is to assume some simple and reasonable form of the dynamics , and recover the parameters of the model which explain the data in the most accurate and minimalistic way ; this is crucial for understanding the basic mechanisms of the spreading process , as well as for making further predictions without overfitting . For example , if only a small number of samples is available , a few - parameter model should be used .	9246232	no
An essential part of the sensor system that requires further elaboration for technically viable point - of - care operation is the pump source . Our current demonstration relies on a bulky benchtop - type Nd : YLF laser , emitting pulses with an energy of 500 nJ at a rather low repetition rate of 20 Hz . The pulse length amounts to 20 ns , leading to a low duty cycle of 4 Ã 10 â7 and an accordingly low average output power , which requires a long integration interval of 2 s for the read - out camera . In a point - of - care system , this bulky solid - state laser may be replaced by a compact high - power laser diode , emitting at 520 nm with a CW output power of , e.g. 900 mW 36,37 . Under pulsed operation , these diodes could provide pump - pulse energies typically ranging from 120 to 130 nJ , which is still above the lasing threshold from 30 to 40 nJ of the current devices . Moreover , the repetition rates can be greatly increased to , e.g. to 1 kHz , such that the system could be operated at~10 times higher optical powers and hence greatly improved signal - to - noise power ratios ( SNRs ) . Note that a repetition rate of 1 kHz is still low enough to allow for relaxation of excited triplet - state dye molecules with typical lifetimes on the order of tens of microseconds 38 between subsequent pulses . It should also be noted that the design of the laser cavity and the pumping scheme could be further optimized , thereby offering even higher output powers and lower thresholds , which might eventually be compatible with pump - power levels offered by light - emitting diodes ( LEDs ) . On the receiver side , signal read - out and data analysis may rely on compact highly sensitive cameras for visible wavelengths and on compact powerful processors , both of which are readily available on the market .	232365767	no
Based on the detailed sampling of the VHE and Xray light curves reported here , coupled with the measurement of an unexpected low - energy spectral cutoff in the VHE low state , it is clear that the existing models will require significant revision . Analysis of the pulsar timing evolution over periastron will provide important additional input , including more accurate measurements of the system geometry . It will also allow for more sensitive searches for GeV emission in the Fermi -LAT data , with the dominant magnetospheric emission from the pulsar removed by a temporally - gated analysis .	119493684	no
The uptake by HeLa cells of fluorescein - labelled pDNA complexed with LPEI or HIS revealed that the cell fluorescence associated with p3NF - luc-3NF and pCMVluc were quite comparable after 5 h incubation whatever the polymer used ( Figure 1 insert ) . Compared to pCMVluc , the remarkable effect on the luciferase gene observed in Figure 1 with p3NF - luc-3NF may be likely due to a larger number of pDNA copies imported into the nucleus .   This could imply that the weakness of the TATA - like promoter in p3NF - luc-3NF was counterbalanced by the higher number of pDNA copies in the nucleus . The cell fluorescence associated with pTAL - luc was a third ( with LPEI ) to a fifth ( with HIS ) less than that with p3NF - luc-3NF , suggesting that pTAL - luc polyplexes were slightly less taken up by the cells . Nevertheless , this uptake difference can not explain the 1300 - fold higher luciferase activity observed with p3NF - luc-3NF compared to pTALluc ( Figure 1 ) . This could be consecutive to an enhancement of the 3NF - plasmids penetration in the nucleus . Similar results were obtained with C2C12 cells except that the cell - associated fluorescence was 2 - to 3 - fold higher than with HeLa cells ( data not shown ) .	5632772	no
This research explored the dark side of social media use among Gen Z during the first pandemic lockdown in the UK and adds to empirical evidence of the devastating effect of the COVID-19 pandemic on young people 's mental health . Using the S - O - R framework , this study reveals the detrimental effect of COVID-19 information overload on social media that resulted in Gen Z social media users ' psychological ill - beingsocial media fatigue and fear of COVID-19 . Both social media fatigue and fear of COVID-19 motivated Gen Z to disengage from social media and translated perceived information overload into social media users ' discontinuance intention . However , as social media is considered the main means by which members of Gen Z maintained contact with each other during the lockdown , FoMO was seen to buffer the impact of social media fatigue and fear of COVID-19 on Gen Z 's social media discontinuance intention . Our research provides unique and original evidence demonstrating the psychological mechanism associated with Gen Z 's social media use during the outbreak of the COVID-19 pandemic in the UK and advances understanding of the ' side effects ' of COVID-19 from social and psychological perspectives . We also highlight a series of practical implications for social media users , social media platform providers , and health officials , institutions , and organizations to consider in using social media in a more effective and sustainable manner during a global pandemic and in the post - pandemic time . The present study has several limitations , such as utilizing cross - sectional data and focusing on one age group and one country during the initial pandemic phase . However , in light of the continuing pandemic , such limitations also have important implications for avenues of future work .	233547464	no
In Hartford et al . ( 2018 ) the authors provide an impressive generalization of the case of node - value data to several node sets , V 1 , V 2 , . . . , V m of sizes n 1 , n 2 , . . . , n m . Their goal is to learn interactions across sets . That is , an input data point is a tensor A â R n1Ãn2ÃÂ·Â·Â·Ãnm that assigns a value to each element in the cartesian product V 1 Ã V 2 Ã Â· Â· Â· Ã V m . Renumbering the nodes in each node set using permutation matrices P 1 , . . . , P m ( resp . ) results in a new tensor we denote by P 1 : m A.	56895597	no
2D SANS pattern of F27 sample show intensity peaks around Q y â Â±0.02 Ã â1 even at low field of 0.004 T ( Figure 3a ) . Increasing the magnitude of the applied magnetic field changes the 2D SANS pattern of F27 IONPs from curved and diffuse horizontal stripes at low fields into sharp straight stripes at high fields ( Figure 3a - f ) . Importantly , the field - induced patterns revert back to their original state by removing the magnetic field . The radially averaged data shown in Figure 2 indicates the presence of chains , thus 2D anisotropic SANS data is divided into sectors parallel to the applied field H to reveal the structural details of these chains .	233985173	no
The new KamLAND data [ 1 ] confirm the expected deficit of Î½ e due to oscillations with parameters in the LMA region . More importantly , the new data show the expected distortion of the energy spectrum . In their new paper [ 1 ] , the KamLAND collaboration report a goodness - of - fit test for a scaled no - oscillation energy spectrum with the normalization fitted to the data . They find a goodness - of - fit of only 0.1 % . We confirm that the hypothesis of an undistorted scaled spectrum can fit the data with less than 0.2 % probability .	2973769	no
Currently , the sentiment analysis of Tweets related to COVID-19 has mainly focused on identifying specific emotions ( e.g. , angry , fear , anxiety , etc . ) and top topics . However , not much study has dedicated to investigating the correlations between Tweet sentiment , public health policies and the on - going progress of COVID-19 . Moreover , machine learning methods are not widely used for sentiment analysis in these studies . Our study combined the benefits of Twitter data and machine learning methods - being real - time and of large scale , and thus more accurate , and carried out a correlation study that gave researchers quantified insights into the specific factors that triggered Tweet sentiment changes . Furthermore , most of the existing studies focus on providing an overview of public sentiment change across the globe or concentrate on country - level investigation . Our study seeks to provide a city - level analysis that could be more helpful for local governments to implement policy interventions that take the context of each city into consideration .	236251116	no
We begin by curating a list of sources which have RV measurements available , looking in particular for sources which have had no previous planet detections . Although numerous surveys have been published over the years , we limit ourselves to just the largest surveys in order to provide a degree of catalog homogeneity . Specifically , we seek one large survey in each celestial hemisphere to provide the necessary data . To this end , we identify the Lick - Carnegie Exoplanet Survey ( LCES ) using the HIRES instrument on Keck - I , and the High Accuracy Radial Velocity Planet Searcher ( HARPS ) mounted on the 3.6 m ESO telescope at La Silla as most suitable .	231719821	no
The speckle pattern from the subset window can be tracked with high accuracy by using the proposed INCC procedure . In contrast to a 1D line profile provided by the LTP and the NOM , SAM provides a 2D map of the slope in a single scan by dividing each speckle image into multiple subset windows and performing the pixel - wise analysis perpendicular to the scanning direction . Moreover , unlike the LTP and the NOM , SAM is able through the proposed data analysis procedure ( Mode 2 ) to test strongly curved mirrors by measuring the first derivative of the slope .	237601079	no
Medium from neuronal cultures was harvested and stored at -80 Â° C . Cell lysates were collected for cellular protein normalization and analysis of p - tau levels by western blot analysis . Human and mouse AÎ² peptides were measured with MSD Human V - PLEX AÎ² Peptide Panel 1 ( 6E10 ) Kit ( K15200E , Meso Scale Discovery ) and Thermo Fisher Mouse AÎ² Peptide ELISA Kits ( KMB3481 and KMB3441 , Thermo Fisher Scientific ) according to the product manuals . For human AÎ² measurement , the plates were read with a Sector Imager 2400 , and the data were acquired and analyzed with Discovery Workbench software . For mouse AÎ² measurement , the plates were read with a FlexStation - III , and the data were analyzed with Prism-6 software . For experiments with secretase inhibitors , neuronal cultures were treated with a Î³ - secretase inhibitor ( compound E , Copd - E , at a final concentration of 200 nM ) , a Î² - secretase inhibitor ( OM99 - 2 , final concentration of 750 nM ) , or dimethyl sulfoxide ( vehicle ) as described 10 . All inhibitors were from EMD Millipore .	4709641	no
This perturbative data can be connected to non - perturbative data with the help of the perturbative - non - perturbative relation ( 2.9 ) . The difference from the SUSY double - well example , with broken SUSY , discussed in section 2.1 is that in the SUSY Sine - Gordon system , with unbroken SUSY , there are two saddles contributing to the non - perturbative ground - state energy : a real bion and a complex bion [ 18,19 ] . The real bion reduces the ground state energy , while the complex bion increases it by exactly same amount , resulting in a cancellation :	67834284	no
To identify modulators of endothelial tube and lumen formation using the new optimized assay , we performed a high - content screening of a compound library containing 150 FDA - approved cardiovascular drugs in a 96 - well plate format at a final concentration of 5 ÂµM in duplicate . Sunitinib was used as a positive control . Using the image analysis approach , we quantified two morphological parameters : total tube length and lumen area . Treated wells were normalized to negative control ( vehicle , DMSO ) wells . Compounds that changed the total tube length or lumen area by > 4 Ã SD from the mean of the DMSOtreated control wells were considered enhancer hits ( Figure 2a ) . Of the 150 compounds , we found that several L - type calcium channel blockers with different chemical structures could enhance the formation of lumen compared to controls ( Figure 2b ) . Lacidipine was selected for further validation and mechanistic studies . Dose - dependent effects of Lacidipine on the lumen area confirmed the screen results and demonstrated that the half - maximal effective concentration ( EC 50 ) of Lacidipine is ( 250 nmol / l ) in this assay ( Figure 2c ) . Our data shows that L - type calcium blockers enhance the endothelial lumen formation in our assay .	248442083	no
The simplest interpretation for the resonance at 27.5 cm Ã1 in an S = 1 system would be axial ZFS with D = 27.5 cm Ã1 and vanishing E. However , simulations with these parameters did not reproduce the field dependence of the FD - FT THz - EPR spectra ( Supporting Information , Figure S5 ) . The alternative scenario , where D is negative and the rhombicity in the ZFS lifts the degeneracy of the m s = AE 1 levels is well in accordance with the experimental data . This assumption predicts two EPR transitions at j D j+j E j and 2 j E j . The observed transition at 27.5 cm Ã1 then corresponds to 2 j E j % 27.5 cm Ã1 . This yields j E j % 13.5 cm Ã1 and ( due to j E j j D j /3 ) creates a constraint on D < Ã41 cm Ã1 . The second EPR transition is then expected at j D j+j E j , which would be above 54 cm Ã1 and therefore outside the spectral window of the data in Figure 9 .	236928203	no
Generative Adversarial Network ( GAN ) ( Goodfellow et al . , 2014 ) has been a new promising approach to unsupervised learning of complex high dimensional data in the last two years , with successful applications on image data ( Isola et al . , 2016;Shrivastava et al . , 2016 ) , and high potential for predictive representation learning ( Mathieu et al . , 2015 ) as well as reinforcement learning ( Finn et al . , 2016;Henderson et al . , 2017 ) . In a nutshell , GANs learn from unlabeled data by engaging the generative model ( G ) in an adversarial game with a discriminator ( D ) . D learns to tell apart fake data generated by G from real data , while G learns to fool D , having access to D 's input gradient .	13669032	no
COVID-19 is a notifiable disease in Ireland under Infectious Diseases Regulations ( Regulations is the Infectious Diseases ( Amendment ) Regulations 2020 ( S.I. No . 53 of 2020 ) . Notifications are registered on the Computerised Infectious Disease Reporting System ( CIDR ) . Data on confirmed COVID-19 cases notified to the HSE Health Protection Surveillance Centre were obtained from covid-19.geohive.ie . The time series of COVID-19 case counts and SARS - CoV-2 wastewater viral concentrations and daily loadings were smoothed using generalised additive models ( GAMs ) ( Wood , 2011 ) . These smoothed time series were then log10 transformed , and a series of first order differences were calculated for each of them ( i.e. time series of changes from one time point to the next ) . Finally , the time series of first order differences of COVID-19 cases was related to those for viral concentration and load using Spearman rank correlations ( Ï ) . This analysis was conducted using R version 4.0.3 and GAMs were fit using the mgcv package ( R Core Team , 2020;Wood , 2011 ) . Additionally , a grid search was employed to consider a range of lead and lag times between SARS - CoV-2 wastewater and case - based data ranging from â6 to 6 weeks ( LaValle et al . , 2004 ) . For statistical analyses , wastewater samples with levels of SARS - CoV-2 N1 below the detection limit of the assay were given the concentration of 1.25 gc / reaction , one quarter of the quantification limit of this assay .	248814946	no
"Let us briefly recall what local data of gerbes , isomorphisms and 2 - isomorphisms are , for the details we refer the reader to [ 18 ] . For a given gerbe G over M , one can choose a sufficiently "" good "" open cover O of M that permits to extract a cocycle c â A 2 ( O ) , D 2 c = 0 , in a certain way . Suppose that two gerbes G 1 and G 2 are given , and O 1 and O 2 are open covers that permit to extract cocycles c 1 and c 2 . Suppose further that A : G 1 â G 2 is an isomorphism . Then one can choose a common refinement O of O 1 and O 2 that permits to extract a cochain b â A 1 ( O ) such that c 2 = c 1 + D 1 b. The cochains for isomorphisms add under the composition of these isomorphisms . Finally , if a 2isomorphism Ï : A 1 â A 2 is given and b 1 and b 2 are cochains for A 1 and A 2 , respectively , for a suitable open cover O , one can always extract a cochain a â A 0 ( O ) such that b 2 = b 1 + D 0 a. The cochains for 2 - isomorphisms add under both the horizontal and the vertical composition of 2 - isomorphisms . Conversely , one can reconstruct gerbes , isomorphisms and 2 - isomorphisms from given local data , and the two procedures are inverse to each other in an appropriate sense . In particular , they establish a bijection between H 2 ( M , D(2 ) ) and the set of isomorphism classes of gerbes over M ."	115171819	no
Finally , we need to know for whom commitment contracts are most likely to be acceptable , efficacious , effective , and cost effective . In other words , what characteristics of people make them particularly likely to take up a contract and use it to achieve behaviour change , and how might consumer detailing be used to augment contracts ' effectiveness and cost effectiveness ? We might expect that people most willing to accept commitment contracts are those who recognise their difficulties with resisting temptations and who are motivated to change this . People for whom commitment contracts have the greatest incremental efficacy may be those with particularly high levels of impulsivity . 2 However , getting such people to accept the contracts may be a particular challenge . If we can identify people in whom commitment contracts are more effective , programmes could be targeted at these groups . Such data might also suggest ways to broaden the acceptability and efficacy of commitment contracts , perhaps through interventions that help people link present behaviours to future consequences . 11	5328532	no
Analysts were asked to run linear regression on AFB and a transformed AFS variable . Since age at first sexual intercourse tends to have a markedly non - normal distribution ( see Fig S1 ) , we asked the analyst for a within - sex inverse rank normal transformation before running statistical models . Analysts were asked to include birth year of the respondent ( represented by birth year -1900/10 ) , its square and cubic to control for non - linear birth cohort effects . For those with family - based data , we suggested controlling for non - independence of family members or only include one family member in the analyses . We furthermore asked studies with family data to run a pooled GWAS on both sexes . Combined analyses that included both men and women also needed to include interactions of birth year and its polynomials with sex . In general , we asked to include top principal components to control for population stratification and cohort specific covariates if appropriate . Some cohorts only used birth year and not its polynomials because of multi - collinearity issues / convergence of the GWA analysis . Omission of these nonlinear birth year effects is unlikely to lead to biased inferences , since genotypes are not usually considered to be truly associated with birth year . However , inferences might be less accurate ( i.e. , have larger standard errors ) , since omission of nonlinear birth year effects can lead to larger residual variation .	235710711	no
Other genes identified by the network analysis have been previously linked to OA , but have not been studied for their potential as biomarkers / therapeutic targets . For example , Apolipoprotein D ( APOD ) was found to be downregulated in every zone of the OA cartilage . It was also 1 of the 207 mRNAs identified as significantly dysregulated from the meta - analysis and was the top - ranked gene of the MI network . Research has previously implicated APOD as being an important gene in OA pathogenesis . For example , APOD is strongly upregulated by retinoic acid [ 27 ] , which is in turn regulated by ALDH1A2 - an OA risk locus [ 28 ] . In vitro studies have shown APOD to be upregulated upon SOX9 overexpression , a master transcription factor essential for cartilage ECM formation [ 29 ] . Furthermore , a recent study into the identification of knee OA genes shared by both cartilage and synovial tissue proposed that APOD may manage OA through chondrogenesis in articular cartilage and immune regulation in the synovium [ 30 ] . The high ranking of APOD in the MI network makes it an interesting candidate for future studies into OA . In particular , research should investigate its potential as a biomarker / drug target . Fibrillin-1 ( FBN1 ) was another gene that was discovered from analysis of the MI network whose encoded protein was also found to be upregulated in the middle and deep zones of OA cartilage according to the MS data . This is particularly interesting as FBN1 is the causative gene of the inherited connective tissue disorder Marfan syndrome [ 31 ] . Moreover , it was 1 of 300 proteins identified via lectin - affinity chromatography in a previous study investigating the proteome of human OA synovial fluid [ 32 ] . The fact that this gene encodes microfibrils that play a structural role in all connective tissues , and mutations in which are known to cause a disease of the musculoskeletal system , warrants further investigation of its role in OA .	248256122	no
demonstrated enhanced signal and optical gain compared to a communication link directly using a blue LED 20 . However , in their work , low absorption was observed in the UV wavelength region , which restricted the application of their material to a UV - based communication link . We envisage that the achieved data rates can be further improved by using a more complex modulation scheme ( e.g. , orthogonal frequency - division multiplexing ) , preequalisation , bit loading and power allocation . Moreover , with the improvement in the modulation bandwidth of the solar - blind UVC LED and realisation of the UVC LD , a higher modulation bandwidth of up to hundreds of megahertz can be expected in the near future .    b Bit - error rate ( BER ) of data transmission at different data rates without a CsPbBr 3 perovskite NC layer and a 500 - nm long - pass filter . For comparison , an optical density ( OD ) filter was added to ensure that the optical power illuminating the APD is the same as that in the case of CsPbBr 3 perovskite NCs and is below the saturation limit of the APD . The insets show the corresponding eye diagrams . c BER of data transmission at different data rates with the colour - converting CsPbBr 3 perovskite NC layer and UV light filtered by a 500 - nm long - pass filter . The insets show the corresponding eye diagrams modulation bandwidth of the CsPbBr 3 perovskite NC layer is lower than that in the prior work by Dursun et al . 2 , the PLQY in the present work is significantly higher by approximately 30 % when the NCs are drop - cast in the form of a thin film , and thus , a higher photon conversion efficiency is exhibited that can improve photodetection . Moreover , the lower modulation bandwidth in the present work compared to prior work could be attributed to the competing band states and dynamics of recombination mechanisms in the CsPbBr 3 perovskite NCs 45,46 . However , thorough investigations are still required to understand the mechanisms so that one can potentially manipulate the recombination dynamics favourable for the design of perovskite - based optoelectronic devices in the future . Compared to other prior works , our study highlighted the superior performance of the CsPbBr 3 perovskite NC layer with a high - PLQY and a fast - PL decay time for a novel receiver design and potential monolithic integration with a Si - based receiver in a UVbased communication link .	204738084	no
Further information on experimental design is available in the Nature Research ' Life Sciences Reporting Summary ' linked to this article .   Compartment - specific eQTLs show greater cell - type specificity and distal regulatory element enrichment . a , Diagram describing the integration of kidney eQTLs , GWAS , singlecell expression and regulatory region . b , Heatmap of cell - type - specific expression of identified CKD target genes . The blue / yellow color corresponds to the level of expression ( z - score ) . Endo , endothelial ; Podo , podocyte ; PT , proximal tubule ; LOH , loop of Henle ; DCT , distal convoluted tubule ; CD - PC , collecting duct principal cell ; CD - IC , collecting duct intercalated cell ; Fibro , fibroblast ; Macro , macrophage ; Neutro , neutrophil ; NK , natural killer cell . c , Density plots of best eVariants in tubule ( top ) and glomerulus ( bottom ) and the relationship to transcription start site ( TSS ) . d , Distance of top eVariants from TSS ( -log 10 ) by groups . e , Odds ratios of the top eVariants on kidney promoter by groups . The groups were compared to randomly selected variants matched by MAF and distance to TSS ( n = 5,000 randomly selected times ) . Center lines show the medians ; box limits indicate the 25 th and 75 th percentiles ; whiskers extend to the 5 th and 95 th percentiles , outliers are represented by dots ( d , e ) . f , Odds ratios ( y - axis ) of eGenes from each group enriched by kidney - specific cell type expression . P was calculated by two - sided Fisher 's exact test . RTEC : PT , LOH and     Colocalization of CKD GWAS leading SNPs with kidney compartment eQTLs . a , GWAS variant and eQTL variant are not the same one , but in the same LD ( r 2 > 0.8 ) ; b , The regulatory direction of risk allele of each SNP on its target gene . â , higher gene expression with risk allele ; â , lower gene expression with risk allele ; N / A , this gene or SNP was excluded by data pre - processing .	52901748	no
To further narrow the rRNA region and the number of proteins implicated in SrmB binding , the purified SrmB - TAP complex was mildly digested with RNase A. This treatment should remove all rRNA regions that are not protected by SrmB , and all proteins that bind to these regions but do not interact directly with SrmB. The digested product was then re - purified on the calmodulin column ( SrmB retains the CBP after TAP purification ) , and analyzed for its RNA and protein content . Whatever the RNase A concentration in the range 0.05 - 0.5 mg / ml , the $ 0.5 - kb RNA fragment was converted into a $ 0.2 - kb fragment ( Figure 2A ) . After purification by urea - PAGE , this fragment was probed on a northern blot with oligonucleotide probes complementary to different regions of domain I ( Figure 2D ) . An in vitro transcript encompassing domain I was run in parallel as a control . Whereas the $ 0.2 - kb species hybridized with probes b ( 192 - 214 nt ) , c ( 240 - 259 nt ) and d ( 312 - 331 nt ) , no signal was detected with probes a ( 128 - 147 nt ) and e ( 409 - 428 nt ) ( Figure 2B ) . Thus , the $ 0.2 - kb product corresponds to the central region of domain I. Using oligonucleotide c for primer extension , its 5 0 extremity was mapped to nucleotide 198 ( data not shown ) . Therefore , the fragment spans nt 198 to $ 400 of 23S rRNA . To further confirm this localization with a different technique , the $ 0.2 - kb product was labeled at its 5 0 -end and partially digested with RNase T1 , as above . The profile of the digest unambiguously matched the succession of Gs in the central region of domain I. This is illustrated on Figure 2C , where a part of the gel is aligned with the 23S sequence from G263 to G291 . The protein composition of the partially digested SrmB complex showed that , compared with the undigested control , the number and amount of minor proteins were greatly reduced , resulting in a complex containing essentially SrmB , L4 and L24 ( compare lanes ' Ã'and ' + ' on Figure 2E ) . In particular , band 2 was no longer detected . Mass spectrometry confirmed the identity of the r - proteins . Of note , the binding sites for L4 and L24 both lie within the 0.2 - kb RNA fragment [ ( 16 ) ; Figure 2D ] , and they are in close proximity in the 3D - structure of the ribosome ( Figure 2F ) .	13084021	no
With a proper definition of energy in hand , in the third section we consider a large class of time symmetric initial data generalizing the form of solutions considered by [ 9 ] . The fourth section describes some particular negative energy solutions , and the fifth section discusses the time evolution of this data . We point out that while bubbles such as ours and those of [ 9 ] may become large , as long as the standard boundary conditions are preserved they never reach infinity . We conclude with a discussion of some open problems for the gravitational theory and with regards to the AdS - CFT conjecture .	18058298	no
Our conclusion is that the higher energy setup has a much greater ultimate sensitivity to Î¸ ( 4fam ) 13 than the ISS - inspired 20 GeV one . On the other hand , both setups are not able to improve the present bounds on Î¸ 14 when marginalizing over Î¸ 24 , Î¸ 34 ( see , however , Sec . 4.3 ) . The silver channel can significantly improve the Î¸ ( 4fam ) 13 -sensitivity when only one baseline is considered at the 50 GeV setup . However , it has a negligible impact when the combination of the golden channel data at the two baselines is considered .	15254909	no
A formal perturbation equation describing the genotypephenotype relationship was proposed ( 48 ) to compute the fitness effect , or Evolutionary Action ( EA ) , of mutations . This equation is a product between the size of a mutation and the functional sensitivity at the position being mutated . EA quantified the likely functional impact of individual mutations on par or better than other methods in blind and objective assessments ( 49 ) , and also helped in the interpretation of exome data ( 50 ) , ignoring any interaction effects . Newer methods have begun to integrate EA over entire populations of mutations in cohorts of patients ( 51 - 54 ) , Cohort Integral ( CI ) ( 55 ) . These attempts sum the separate effects of individual mutational steps to identify genes for specific traits or diseases . None , however , capture interaction epistasis effects , which we now try to do with application to the low mutational frequency of cancer driver genes .	248099763	no
In this study , we have applied our planetary accretion shock model ( Aoyama et al . 2018 ) to the two accreting proto - gas giants - PDS 70 b and c , for which HÎ± emission fluxes and profiles were very recently observed ( Wagner et al . 2018;Haffert et al . 2019 ) . We have demonstrated that the new observational data , namely , spectral profiles , combined with HÎ± luminosity , help us to narrow down the possible ranges of preshock velocity and number density . As a result , better constraints on mass accretion rate and protoplanet mass gives rise to deeper insight into late - stage accretion onto gas giants .	209921697	no
During this step , to further confirm dependability of the coding process , we also conducted a coding reliability check ( Boyatzis , 1998;Miles et al . , 2020 ) . After data from all firms were coded , we selected a sample of 178 representative codes and terms ( ~ 17 % of the total number of coded passages and terms ) for the reliability check . One researcher who had collected data , but not conducted the coding was provided with a list of agreed - upon operational definitions , the list of codes , coding rules , and the coded passages . The researcher reviewed each of the coded passages and the team discussed each coded passage or term that lacked intercoder agreement ( 17 of 178 passages and terms ) . After discussion primarily surrounding study and supply chain context , and coding adjustment of the passages or terms in question , the team reached an agreement on 100 % of the coded passages and terms ( Braun & Clarke , 2006;Windscheid et al . , 2018 ) .	236943539	no
stations , ( v ) workplaces , and ( vi ) residential places . These data have been constructed by comparing visits and lengths of stays at certain places relative to a baseline ( Google Mobility , 2021 ) . The retail & recreation cate - gory provides data on mobility trends for places such as restaurants , cafes , and shopping centers . Grocery & pharmacy category provides data on mobility trends for sites considered to be essential trips , including grocery markets , drug stores , and pharmacies . Similar subcategories of related locations are grouped within parks , transit stations , workplaces , and residential places ( Google Mobility , 2021 ) . The use of such types of consumer mobility data is also in vogue in the extant literature ( e.g. , Persson et al . , 2021 ) .	255441206	no
In this study , we will concentrate on mobile app entry , which connects the pre - launch and launch stages of the MAP ( Olaleye , Ukpabi , Karjaluoto , & Rizomyliotis , 2019;Talwar et al . , 2021 ) , reflecting the transformation from conventional SMEs to sustainable SMEs . Mobile apps are described as end - user software applications developed for a mobile operating system that expands the handset 's functionality by allowing users to perform specific activities , such as searching for information and social interaction . Tectonic trends in digitalization through mobile applications and consumer interaction via diverse social media networks have created convincing channels for SMEs to deliver an efficient business model due to improved and simpler user / customer data collection and enhanced productivity in customer support , virtual collaboration , and electronic payment .	237669349	no
According to the procedure , the first step is to collect extensive literature from the online library of the Delft University of Technology . The bibliometric data were collected on September 15 , 2019 , from the Web of Science Core Collection , excluding books ( BKCIeS and BKCI - SSH ) and conference proceedings ( CPCIeS and CPCI - SSH ) . The publications in local journals and unpublished academic documents are excluded due to language barriers , unavailable permission , etc . The timespan is set from 1970 to 2019 . The searching topics were as follows :	224918115	maybe
We did not find any obvious relationship between our measured coronal loop magnetic field strengths and the magnitude of the photospheric magnetic flux of the active regions in this survey . We performed some preliminary checks , however , to investigate whether we could uncover any obvious correlations with other properties of the loops . Excluding the loop segment where the measured field strength was too high for the weak field approximation to be valid , we found a strong correlation ( r=0.66 ) with the measured temperature , such that higher magnetic field strengths lead to higher loop     were made around the loop , although our sample does cover quite a wide range of loop properties from cooler , denser cases to hotter , more tenuous ones . We also found that a relationship can be established with the loop pressure that extends to the loop segment with the highest field strength ( shown in Figure 4 ) . This segment also has the highest density and lowest temperature , which act to offset each other and allow the loop to follow the same trend as the others and the correlation between the parameters is also strong ( r=0.68 ) . Our initial survey has been limited by the need to select a sample from data taken early in the mission when calibration degradation was minimal . Ongoing progress in improving the EIS calibration will allow a wider study to take advantage of more extensive data ( including flare data ) in the future . This should help to clarify these relationships further . Landi et al . ( 2020 ) estimate the uncertainty in their measurements to be on the order of 70 % -driven by multiple factors such as the cross - calibration between the short - and longwavelength detectors , the density diagnostic ratio , atomic physics parameters , and also the accuracy of the energy separation between the 4 D 5/2 and 4 D 7/2 levels . This includes an estimate of the contribution from the radiometric calibration and sensitivity degradation over time . As discussed , we chose observations from early in the mission to minimize the impact of the time - dependence of the calibration . Based on the Warren et al . ( 2014 ) model , sensitivity loss is minimal ( < 10 % ) for the datasets we use , so this contribution is reduced from 50 % to 24 % . This propagates through to produce an uncertainty in I M IT /I M 2 of 51 % . We adopt this value in Table 1 . Furthermore , the conversion from I M IT /I M 2 to B is not linear ( see Figure 2 ) . To assess the impact of the uncertainties on this conversion , for each loop , we performed a 10000 run Monte - Carlo simulation where we randomly perturbed the I M IT /I M 2 value within a uniform distribution covering the range defined by the 51 % uncertainty . We then take the standard deviation of the magnetic field strength distribution , with the estimated â¼20 % uncertainty in the 4 D 5/2 and 4 D 7/2 energy separation added in quadrature , as our evaluation of the uncertainty in B. These range from 20 - 36 % and are added in Table 1 .	235489762	no
ICD codes were used to estimate age - cause specific mortality rates by sex , quintile of deprivation and Census year from five broad underlying causes of death : circulatory diseases , respiratory diseases , neoplasms , external causes and other causes . All deaths in our data included an ICD code entry ; however , deaths that were ill defined or did not refer to an identifiable ICD code were classified as ' other ' . Cause of death categories were mutually - exclusive , and harmonisation ensured comparability of causes over time . The ICD codes included in each category are available in appendix 5 . The absolute number of deaths and proportions of deaths in each cause - specific category are given below in Table 2 .	128361072	no
Data were entered into an Excel spreadsheet , and analysed using a combination of Excel and Stata 14 . All cost and income data were inflated using the local inflation rate to reflect prices in October 2015 , and then converted to USD using the average conversion rate in October 2015 , R 13.08 = 1 USD ( XE , n.d . ) . Participants were interviewed in a private space and all data were anonymised prior to analysis . The trial , including the costing study , was approved by the Research Ethics Committees of the University of Witwatersrand ( approval number : R14/49 M111177 ) , the London School of Hygiene and Tropical Medicine ( approval number : 6099 ) , and the Provincial Research Committees of Gauteng , North West and Limpopo .	52186833	no
Emissions and concentrations of CO 2 , CO , CH 4 , and H 2 S in exhaust gases from Welch Ranch vents 7 - 12 were measured twice during the campaign , once on 13 May 2009 and again on 15 May 2009 . Results from Wilcoxon signed - rank tests for paired data indicate that median CO 2 emissions were significantly lower ( p b 0.05 ; 51 % lower , on average ) on the second sampling day relative to the first , but that emissions for CO and H 2 S did not significantly differ ( p > 0.05 ) between days . These findings indicate that temporal variations in concentrations and fluxes can be large , even over small , daily timescales .	25018835	no
Global processing is achieved through iterative message passing in space and time . Spatio - temporal processing is factorized , into a space processing stage and a time processing stage , which are alternated within each iteration . We aim to decouple , conceptually , the data from the computational machine that processes the data . Thus , our nodes are processing units that receive inputs from several sources : local regions in space at the present time , their neighbor spatial nodes as well as their past memory states ( Fig . 1 ) .	197860214	no
"Bullying victimisation was assessed during interviews with mothers when the children were aged 7 and 10 years , and separately in private interviews with the children during home visits when the children were 12 years old . Details of psychometric measurements for the bullying measures reported here have been described previously . 13 14 We explained to the mother or child that : "" someone is being bullied when another child says mean and hurtful things , makes fun , or calls a person mean and hurtful names ; completely ignores or excludes someone from their group of friends or leaves them out of things on purpose ; hits , kicks , or shoves a person , or locks them in a room ; tells lies or spreads rumours about them ; or does other hurtful things like these . We call it bullying when these things happen often and it is difficult for the person being bullied to stop it happening . We do not call it bullying when it is done in a friendly or playful way . "" When bullying was reported , the interviewer asked the mother or child to describe what happened . An independent rater later checked notes taken by the interviewers to verify that the events described related to instances of bullying , operationally defined as evidence of repeated harmful actions between children where a power differential existed between the bully and the victim . This review was done blind to data on self harm . Mothers ' and children 's narratives of bullying experiences were coded as "" never , "" "" yes , but isolated incidents , "" or "" frequently . "" Children were also asked directly if they had been bullied "" a lot . "" Of the cohort children , 16.5 % ( 350/2127 ) were reported by their mothers to have been frequently bullied before age 10 , and 11.2 % ( 237/2124 ) of the children reported themselves to have been bullied a lot before age 12 ."	16517615	no
Astrometric observations with the Gaia spacecraft might ultimately reveal the full three - dimensional geometry of the system . Ranalli et al . ( 2018 ) predicted that the astrometric signal of Ï Men b will be detectable with a signal - to - noise ratio higher than 10 by the end of the mission . Indeed , the fit to the existing Gaia data exhibits an excess scatter of 295 Âµ ( 37Ï ) , perhaps a hint of planet - induced motion . Direct imaging might also be fruitful some day , although Zurlo et al . ( 2018 ) have already ruled out any companions with orbital separation 10 - 20 AU and an infrared contrast exceeding 10 â6 , corresponding roughly to 30 Jupiter masses .	119426461	no
whereas the 5â²-CCA- , 5â²-CCG- , and 5â²-CTT - PAM - flanked protospacer was cleaved with just ~10 % . Taken together , these results clearly demonstrate that RbCas12a requires a PAM defined as 5â²-YYN for cleavage , at least in a pure in vitro system . It should be noted that 5â²-Ð¡Ð¡V and 5â²-Ð¡TW ( where V represents C , A , or G ; and W represents A or T ) were not able to cleave DNA templates with efficiencies of more than 25 % under the conditions of the experiment .   Recently , we demonstrated that the cleavage activity of at least three V - A nucleases ( AsCas12 , LbCas12a , and FnCas12a ) persists after a substantial reduction in the crRNA scaffold length , up to its complete removal , at high concentrations of crRNA . Furthermore , we showed that the trans - addition of a 20 - base scaffold RNA rescued the cleavage activity of these enzymes . Thus , we proposed the concept of split crRNA , which , in a complex with V - A nucleases , was comparable to cleavage activity observed with full - sized crRNA [ 17 ] . Here , we expand our observations and investigate the ability of RbCas12 to be programed with split crRNAs . As shown in Figure 6A , in reactions containing both full - sized and split crRNAs , the target DNA was cleaved by~90 % under the conditions of the experiment . We previously showed that increasing the spacer - only crRNA concentration could increase the cleavage efficacy of AsCas12a [ 17 ] . The data presented in Figure 6B demonstrate that increasing the concentration of spacer RNA from 0.5 to 5 ÂµM causes dose - dependent DNA substrate cleavage by RbCas12a . It is possible to cleave the DNA template reasonably efficiently ( ~50 % after a 20 - min incubation ) at a protein : RNA ratio of more than 1:500 . Efficient cleavage of cognate targets was also observed when split crRNAs with unrelated spacer sequences were tested ( Figure S2 ) .	251705929	no
Through these three translational mechanisms , participants described how they made soft data meaningful , and thus endowed them with function in relation to quality and safety , either diagnostically ( Aggregation and Triangulation ) or illustratively and persuasively ( Instrumentalization ) . The three approaches to generating soft intelligence were not mutually exclusive , and two or more were often present in participants ' accounts , with overlap evident between our categories of Aggregation and Triangulation . However , there were also important distinctions between the two : whereas Aggregation implied that soft data could become useful independently , through the accumulation of multiple soft data , Triangulation saw generating soft intelligence only as a complement to or means of validating data derived from conventional sources .	13927359	no
While many existing methods combine retrieval and editing [ 13,30,18,24 ] , these approaches rely on a fixed hand - crafted or generic retrieval mechanism . One drawback to this approach is that designing a task - specific retriever is time - consuming , and a generic retriever may not perform well on tasks where x is structured or complex [ 40 ] . Ideally , the retrieval metric would be learned from the data in a task - dependent way : we wish to consider x and x similar only if their corresponding outputs y and y differ by a small , easy - to - perform edit . However , the straightforward way of training a retriever 32nd Conference on Neural Information Processing Systems ( NeurIPS 2018 ) , MontrÃ©al , Canada .	54446010	no
We developed a standardised three page questionnaire and uploaded it for online response . We recruited respondents through newspaper advertisements , the NepalNews internet site , social networks , and personal contacts . If no response came through internet or email , we used phone interviews to complete questionnaires . Questionnaire data included each doctor 's class number , birthplace , place of high school , and pre - medical training ( paramedical or intermediate science ) ; spouse 's birthplace ; postgraduate work history , current practice location , and postgraduate degrees ; perceived personal factors influencing career practice location ; and contact information for classmates .	27473419	no
-Accession codes , unique identifiers , or web links for publicly available datasets -A list of figures that have associated raw data -A description of any restrictions on data availability	205572824	maybe
The case study of the Ceuvel was based on the analyses of both primary data and secondary data . The primary data included four semistructured interviews that we conducted at the end of 2019 and beginning of 2020 . Two of which were with some of the early initiators of De Ceuvel -both architects -and two were with civil servants directly involved . The secondary data was retrieved from a study in 2017 on Urban Living Labs in which both De Ceuvel and BSH were cases , executed by two fellow researchers ( Steen & van Bueren , 2017a;Steen & van Bueren , 2017b ) , one of whom is co - author of this paper . This data includes e.g. semi - structured in - depth interviews with two other members of the initiating team of De Ceuvel , i.e. the founder of Metabolic -a start - up in clean - tech at the time -and a landscape architect . Furthermore , various documents and analyses by others ( Barba Lata & Duineveld , 2019 ; Donovan , 2017 ) were studied and complemented with observations .	230551072	maybe
This investigation therefore highlights two intrinsic problems confronting behavioural scientists using large - scale social data . First , large numbers of ill - defined variables necessitate researcher flexibility , potentially exacerbating the garden of forking paths problem : for some datasets analysed there were more than a trillion different ways to operationalize a simple regression 19 . Second , high numbers of observations render minutely small associations significant through the default null hypothesis significance testing lens 29 . With these challenges in mind , our approach , grounded in SCA and including comparison specifications , presents a promising solution so that behavioural scientists can build accurate and practically actionable representations of effects found in large - scale datasets . Overall , the findings place into context popular worries about the putative links between technology use and mental health indicators . They underscore the need for open and impartial reporting of small correlations derived from large - scale social data .	58006454	no
The derived parameter ranges , particularly for n and B , are strongly correlated . The critical frequency scales as Î½ c â BT 2 e and sets the spectral peak , while in the one zone model at fixed radius the bolometric luminosity is proportional to the synchrotron emissivity near the peak which scales as j Î½ â¼ nB 2 T 5/2 e . For the model to produce the observed flux , T e > T b â¼ 6 Ã 10 10 K where T b is the observed 230 GHz brightness temperature . We see clear correlations as anticipated from the forms of Î½ c and j Î½ . In particular , the magnetic field strength is anti - correlated with both the particle density and electron temperature . The spectral shape and our assumed parameter bounds ( particularly Î² < 10 3 ) provide some additional information , leading to our inferred parameter ranges . Using simultaneous 233 and 868 GHz data leads to better constrained parameter ranges than the same exercise done in von Fellenberg et al . ( 2018 ) . The basic results are otherwise identical .	197935194	no
The margin of an example is then the scaled distance between 0.5 and its probabilistic prediction . We also consider 2 scenarios . In scenario M1 , we put higher costs on examples with lower margins . From Table 1 , ALC is better than LC in this scenario . BLC performs better than both ALC and LC on data set 2 , and performs the second best among the active learning algorithms on data sets 1 and 3 .	3031257	no
"In Â§ 4 , we consider vectorlike ( "" QCD - like "" ) gauge theories . In Â§ 4.1 , we study in some detail the infrared theory of an SU(3 ) gauge theory with one sextet - representation Dirac fermion , as it has not been previously considered in the literature ( this theory is confining ) . In Â§ 4.2 , we give our results for the conformal window for SU(N ) vectorlike theories with N D f two - index symmetric Dirac fermions . In Â§ 4 . Comparison of our results for the conformal window with those of other analytic approaches are given in Â§ 6 . We begin , in Â§ 6.1 , by giving comparisons of our approach with the truncated Schwinger - Dyson equations and supersymmetry - inspired estimates , see Tables 3 , 4 , 5 , 6 . In Â§ 6.2 , we compare some features of the various approaches . In Â§ 6.3 , we compare with the available lattice data ."	17103287	no
In this work we use data collected by the TA SD array in a 9 - year period from May 2008 to May 2017 with reconstructed energies above 43 EeV , zenith angles less than 55 â¢ , and declinations Î´ > â10 â¢ using the same quality cuts as in Abbasi et al . ( 2014 ) . This dataset comprises 284 events . We neglect the finite angular and energy resolution of TA events , and consider the detector fully efficient , i.e. with a flat response for all showers with energies and zenith angles in the considered range , so that its directional exposure Ï TA equals the geometrical one for Î´ > â10 â¢ , which varies with declination but not with right ascension ( Sommers 2001 ):	119426691	maybe
Fig . S1 The process of creating the browse interface . The first step is to divide the data by batch and cell - type and identify the differentially expressed genes for each condition . The next step is to compute similarity between signatures and store the results in an adjacency matrix . Then , a canvas layout is computed with the Network2Canvas tool . The gene - set libraries are first converted to an adjacency matrix using the Sets2Networks tool , and then the Network2Canvas tool is used to create a canvas from the adjacency matrix . The two types of canvases are finally integrated to form the web - site using JavaScript , PHP and HTML .  	3931753	no
"The Effect Modification models were defined at two points in time , early and later , and were specified by including a multiplicative interaction term between parks from the two successive time periods ( i.e. an interaction between childhood parks and adulthood parks ) ( Fig . 1 ; see Model 4a ) . These models emphasised the temporal sequence of exposure during early or later life as being important for the eventual association with cognitive ageing . As before , we compared the partial Fstatistics of each life course model with the "" saturated "" model . A pvalue of over 0.05 signified that the life course model fitted the data as well as the "" saturated model "" . The life course model with the highest pvalue was deemed the most appropriate as this meant that it not only fit the data as well as the "" saturated model "" , but was more parsimonious . All models were adjusted for sex in a complete - case analysis . A positive regression coefficient represented higher residualised change in cognitive function between the time points ( i.e. relatively better cognitive change ) whereas a negative regression coefficient represented decreasing residualised change in cognitive function between the time points ( i.e. relatively worse cognitive change ) . The multiplicative interaction regression coefficient was interpreted as the coefficient of one park term being conditional on another ."	4135248	no
The outbreak of the COVID-19 epidemic has led to great changes in the world economy and environment . Therefore , it is crucial to assess the variations in shipping activities and pollution emissions caused by the COVID-19 epidemic . This study made an attempt to investigate the effects of COVID-19 pandemic on the merchant ship activity and the resulting atmospheric pollutant emissions in Shanghai port waters . By comparing the AIS data in February 2019 and in February 2020 , it can be found that the count and utilization frequency of merchant ships including cargo ships , container ships and tankers are reduced during the epidemic period . Furthermore , the reduced utilization frequency is found to vary with different ship sizes for each merchant ship type . In addition , it is found that the COVID-19 pandemic resulted in longer ship turnaround time that might be caused by more operation time required for completing the berthing and anchoring activities during the epidemic period .	235369013	no
In this report , we analyzed the RISE of the nuclear RNA - Seq data together with those from cytoplasmic or whole cell RNA to identify the delayed pairing patterns of splice sites in depolarization - regulated splicing . Their splice site - specific accumulation within genes or around exons and their regulation by depolarization/5 - azaC support the pre - mRNA origin of the reads rather than genomic DNA , where in the latter case , random distribution of reads and non - regulation is expected . The analysis has led to the first - time observation of not only delayed 3 splice site usage of the endogenous STREX and other exons we have studied ( Figure 2 ) but also globally delayed , or depolarization - regulated , across intron - or exon - pairing of splice sites in the pituitary cells .	252152818	no
Online data collection was carried out December 10 - 18 , 2020 , through Prolific Academic ( http://prolific.ac ) , one of the most popular and reliable crowdsourcing platforms for behavioral research ( Palan and Schitter , 2018 ) . There were no time limits on task completion , and the average response time was less than 2 min . Participants received 0.63 British pounds , which guarantees an hourly rate in line with the Prolific compensation policy .	236457761	maybe
"As originally demonstrated in [ 5,6 ] , the values of the relevant SM parameters can strongly influence some of the CMSSM predictions , and , in contrast to common practice , should not be simply kept fixed at their central values . We thus introduce a set Ï of so - called "" nuisance parameters "" of the SM parameters which are relevant to our analysis , The set of parameters Î¸ and Ï form an 8 - dimensional set m of our "" basis parameters "" ( 2.1 ) . In terms of the basis parameters we compute a number of collider and cosmological observables , which we call "" derived variables "" and which we collectively denote by the set Î¾ = ( Î¾ 1 , Î¾ 2 , . . . ) . The observables will be used to compare CMSSM predictions with a set of experimental data d , which is available either in the form of positive measurements or as limits , as discussed below . Table 1 : Experimental mean Âµ and standard deviation Ï adopted for the likelihood function for SM ( nuisance ) parameters , assumed to be described by a Gaussian distribution ."	419784	no
It is notable that MiME consistently outperformed GRAM in both Table 3 and Figure 3 in terms of test loss and test PR - AUC . To be fair , GRAM was only using Dx code hierarchy ( thus ungrouped 5814 Dx codes were used ) , and no additional domain knowledge regarding treatment codes . However , the experiment results tell us that even without resorting to external domain knowledge , we can still gain improved predictive performance by carefully studying the EHR data and leveraging its inherent structure .   Next , we conducted a series of experiments to confirm that MiME can indeed capture the relationship between Dx codes and treatment codes , thus producing robust performance in small datasets . Specifically , we created three small datasets D 1 , D 2 , D 3 from the original data such that each dataset consisted of patients with varying degree of Dx - treatment interactions ( i.e. visit complexity ) . We defined visit complexity as below to calculate for a patient the percentage of visits that have at least two diagnosis codes associated with different sets of treatment codes ,  	53037206	no
"Individuals form their risk perceptions using the information set available to them and their individual circumstances , like their age , gender or education . As our analytical framework indicates with equations ( 1 ) and ( 2 ) , these risk perceptions , mediated by other factors such as trust and social norms , drive vaccine behavior . While it is out of the scope of this paper to provide a detailed analysis of the formation of risk perceptions , the data allows to have a preliminary look at the relationship between vaccine acceptance and risk perceptions about COVID-19 infection . The survey we use includes a question on the likelihood that a person of the same age and in the same community as the respondent becomes sick from COVID-19 . We create a dummy variable that indicates whether a respondent stated that this event was "" very "" or "" extremely likely "" . We call this variable the "" perception of high risk of infection "" . Columns 1 and 2 of Table 3 correspond to equation ( 2 ) of our framework and look at the correlations between risk perceptions and information and individual characteristics . Men , people living in rural areas , and younger individuals have all a perception of a lower risk of becoming sick from COVID-19 . People in good health perceive their risk to be low as well . Interestingly , individual beliefs appear to be associated to risk perceptions in an unusual direction : individuals who have higher trust in government health authorities and those who believe that many individuals in their community will accept the vaccine also report higher Standard errors in parentheses clustered at country level . All estimations include country and month fixed effects . Reference category for age is age 81 - 90 and reference category for education is tertiary education . * p < 0.05 * * p < 0.01 * * * p < 0.001 ."	255801813	no
We see in Figure 3 g that the LG peak dominates the emission at low excitation density in the fully treated sample . We note that the results for low excitation density are consistent with our macro - PL measurements performed at similar fluence ( Figure 1b ) . At higher excitation density ( Figure 3h ) , the initial t = 4 ns PL snapshot is also dominated by the LG emission though the relative fraction of the WG peak is higher than in the lower excitation density case . The PL signal of the LG peak plotted over the charge - carrier density for the fully treated sample also shows deviation from a bimolecular dependence ( Figure 3i ) . Since the LG domains grow in size as the light treatment continues toward completion ( cf . Figure 2h ) , we expect less Auger Adv . Mater . 2019 , 31,1902374 ) ( g , h ) . c , f , i ) The initial peak intensity corresponding to WG and LG energies just after pulse excitation ( which were extracted from fits to the spectra with Gaussian functions ) as a function of charge excitation density . Dashed lines in ( c ) denote a second - order recombination rate ; in ( f ) and ( i ) , these bimolecular lines are shifted appropriately as a guide to the eye to the appropriate data set . recombination in the fully treated film as carriers are in fact less concentrated compared to the partially treated sample . Nevertheless , Auger recombination does still reduce the fraction of LG ( compared to WG ) at higher fluence , which is indicative of significant carrier accumulation in the LG - rich surface . Again , we suggest that the slight deviation of the WG from the bimolecular dependence is due to fast energy transfer from the WG to LG regions at high excitation fluence . In addition , we again observe a decrease in the LG peak fraction after the initial pulse as time proceeds in the fully treated film ( Figure 3g , h ) , which is due to enhanced effective charge densities within the LG regions .	201844388	no
Using the CMS labels of the core consensus samples as a ' gold standard ' , we developed a novel classification framework for predicting CMS subtypes using aggregated gene expression data from all cohorts ( Online Methods ) . CMS labeled samples were split into two equal partitions for training and validation , and a Random Forest classifier was generated from 500 balanced bootstraps of the training data . When applied to the validation data , the classifier demonstrated robust performance across gene expression platforms ( Affymetrix , Agilent , and RNA - sequencing ) and sample collections ( FFPE , fresh - frozen ) with a > 90 % balanced accuracy across all subtypes ( Supplementary Table 4 , Supplementary   Fig . 3 ) . This corroborates both the portability of the classifier as well as the evident subtypespecific signals across datasets .	5092451	no
Funding : The Netherlands Cancer Registry is funded by the ministry of Health , Welfare , and Sport of the Netherlands . The funders had no role in the conduct of the study ; collection , management , analysis , or interpretation of the data ; or preparation , review , or approval of the manuscript .	6017377	no
Study design . Qualitative , quantitative , and mixed - methods studies with a longitudinal element were included ( randomized control trial , non - equivalent control group design , and pre - test / post - test only ) . Other . We only included empirical studies published in peerreviewed journals . We focused on peer - reviewed research because there is a sufficient data within the peer - reviewed literature to answer the research questions and peer - review provides assurance of quality and rigor . We searched English language databases only , but did include articles published in other languages . We included studies from 2009 onwards , because such studies tend to use more rigorous methodologies and incorporate findings from previous research .	233290880	no
For each measurement , we can estimate a minimum image size by finding the equivalent Gaussian that achieves the same quotient on the corresponding baselines . This criterion is motivated by the property that long baselines will tend to measure more flux density than extrapolated by the equivalent Gaussian on short baselines , reflecting small - scale power from image substructure . This criterion also makes the simplifying assumption that the source has isotropic size ; this assumption is both supported by our data ( see Section 3.2 ) and is not especially problematic because the ALMA - LMT and SMT - LMT baselines sample similar orientation angles ( see Figure 1 ) .	146068771	no
We then tested the hypothesis that dry season parasitemias were maintained low and subclinical due to decreased parasite replication capacity during this period . We cultured P. falciparum for 36 - 48 h in vitro directly after blood draw from rapid diagnostic test positive ( RDT + ) samples of asymptomatic individuals at three time points of the dry season ( January , March and May ) and from samples of children presenting with their first clinical malaria episode of the ensuing transmission season ( MAL ) . By flow cytometry , we measured the increase in parasitemia and parasite development at 0 , 16 However , the number of hours in culture needed to increase parasitemia was shorter in the dry season samples than in samples from malaria - causing parasites in the transmission season ( Fig . 5a ) . In accordance with an earlier increase in parasitemia in vitro during the dry season , we could frequently identify on Giemsa smears mature schizonts after 16 and 24 h of culture and young ring stages after 30 or 36 h in the dry season samples , whereas mature schizonts of malaria - causing parasite samples were mostly observed after 36 h in culture , and young ring stages were largely found after 48 h in vitro ( Fig . 5b ) . When we calculated the number of hours in culture at which the highest increase of parasitemia could be detected for each sample , we observed that it decreased from the beginning to the end of the dry season - January , 26   in the wet season ( Fig . 5d ) . Finding later developmental parasite stages at earlier times in this short - term in vitro experiment during the dry season could indicate a faster than 48 - h intraerythrocytic replicative cycle , or , alternatively , that dry season parasites circulate longer without adhering to the host vascular endothelium and were more developed than circulating parasites in clinical malaria cases at the time of the blood draw . To test the latter , we used the RNA - seq data described in Fig . 4 to estimate , with a likelihood - based statistical method previously described 28 , the age in hours post - invasion ( hpi ) of circulating parasites from subclinical children at the end of the dry season ( May ) and from clinical cases during the wet season ( MAL ) . We determined that parasites circulating in the dry season had a transcriptional signature of ~17 hpi , 95%CI ( 14.05 , 20.8 ) , whereas parasites circulating in malaria cases during the wet season had a transcription profile similar to parasites with ~7 hpi , 95 % CI ( 6.5 , 7.7 ) ( Fig . 5e ) . Accordingly , imaging the thick blood films made in the field at the time of the blood draw , we confirmed that the more developed trophozoite stages of P. falciparum were present on subclinical samples collected at the end dry season , whereas clinical malaria samples in the transmission season presented much smaller ring stages of P. falciparum ( Fig . 5f , g ) . All together , these data show that , at the end of the dry season , P. falciparum can be found circulating at later stages of the ~48 - h asexual cycle than what is seen during clinical malaria cases in the wet season .	225081365	no
The general workflow of the server is illustrated in Figure 1 . The first step comprises the input of data . There are two different kinds of input data .	1243113	no
1 More precisely , one should write for the evidence p(d|model ) , in order to show explicitly that it is conditional on the assumption that the model is the true theory . From there one can further employ Bayes ' theorem to obtain the posterior probability for the model 's parameters given the observed data , namely p(model|d ) . This is the subject of Bayesian model comparison ( see e.g. [ 21 ] for an illustration ) . Here we do not employ the evidence for this purpose ( see instead [ 10,16 ] for applications to the CMSSM ) , and therefore drop the explicit conditioning on the model under study , although in the following one should always interpret p(d ) â¡ p(d|model ) .	419784	no
The SMT HMW amino - acid sequence identity was calculated by the BLAST program . The data were retrieved from the UniProtKB databases : UniProtKB - A6BM71_CHICK .	255738711	no
The spectroscopic properties were consistent with the data available in the literature . 13	4288419	no
The spread of the coronavirus pandemic offers a unique opportunity to improve our understanding of the role of urban planning strategies in general , and urban diversity in particular , in the resilience of urban communities confronting a pandemic . To this end we designed a comprehensive multi - stage methodology that analyzes the relationship between the level of neighborhood homogeneity with respect to the UO population ( as well as the JR and Arab ) population and the probability of being infected by the coronavirus , using detailed data spanning all neighborhoods in Israel .	245007305	no
At MD Anderson , raw sequencing data were converted to a fastq format and aligned to the human genome ( hg19 , GRCh37 ) using the BWA - MEM algorithm . The aligned BAM files were processed using Picard and GATK with default parameters and then variants were called using MuTect and Pindel against pooled unmatched normal sequences developed in - house . Variants with low - quality sequencing , no obvious protein - coding change or common polymorphisms with a population frequency of 0.14 % in public variant databases were filtered out .	247227467	no
Chorionic placental arteries homogenates from normotensive and preeclamptic donors were used for quantification of sphingolipids by LC - MS / MS . The levels of ceramide ( Cer ) species , sphingosine ( Sph ) , and S1P were analyzed by the Lipidomics Analytical Core at the Medical University of South Carolina , as previously described [ 67 ] . Lipid extraction was performed according to Bligh and Dyer [ 68 ] . For quantitative analysis of sphingolipid , eight - point calibration curves were generated for each target analyte . Synthetic as well as internal standards were spiked into an artificial matrix , and then subjected to an identical extraction procedure as the biological samples . These extracted standards were subsequently analyzed by the LC - MS / MS system operating in positive multiple reaction - monitoring ( MRM ) mode employing a gradient elution . Results were then calculated by plotting the sample area ratios against their corresponding standard . The MS analysis represents the mass level of particular sphingolipid ( in pmols ) per total sample used for lipid extract preparation . For the final data presentation , MS results were normalized to total protein ( mg ) .	211064969	no
[ Figure 2 : Characterization data of the EMI films with 1D fillers ]	231648194	no
Steady - state fluorescence anisotropy binding titrations were performed on a PTI Model QM-4 spectrofluorimeter at 25 C following the intrinsic fluorescence of the single tryptophan residue ( exc 295 nm and em 324 nm ) . To measure the affinity of the protein toward rrm1 , the THAP zinc finger was diluted to 0.5 mM in a volume of 4 ml and the 16 - bp rrm1 DNA duplex ( 100 mM ) was prepared in a buffer consisting of 50 mM Tris , 30 mM NaCl , pH 6.8 . The rrm1 solution was progressively added to the protein sample with protein : DNA ratios ranging from 1:0 to 1:6 . To study the influence of the ionic strength on the non - specific binding , samples with different protein : DNA ratios ranging from 1:0 to 1:6 were initially prepared in 250 mM NaCl ( 100 ml of THAP zinc finger at 3 mM ) and were then exchanged in buffer containing suitable NaCl concentrations ( 30 or 150 mM ) . Fluorescence anisotropy was calculated including a correction factor as previously described ( 27 ) and the data were fitted from a previously described equation ( 28 ) using a non - linear fit with GOSA software ( 22 ) .	12635856	no
Rheological data with strain and angular frequency sweeps for 2 gl -1 NFC and 42 % ( w / w ) protein .     a ) Representative stress - strain curves . b ) YoungÂ´s moduli , e ) yield strength , d ) Ultimate tensile strength , e ) strain - to - failure . f ) work - to - fracture and g ) slope after yield point . All data is presented with standard deviation . Figure S7 . Representative stress - strain curves for HFB - dCBM-48 ( solid blue line ) , dCBM-48 ( dashed blue line ) and unmodified NFC film ( solid black line ) from the cyclic tensile measurements . The results show that deformations after the yield point were not recovered after stress release and therefore the deformations were plastic but as the Young 's modulus did not change , it is indicated that displaced interactions could reform after plastic deformation .	16900350	no
We also assume that the modulation of the brain cortex cells ' redox status sufficiently contributes to 3 - EA protective property . Monoamine oxidase A and B ( Mao - A and Mao - B ) degrade amines and are also a source of mitochondrial ROS [ 27,28 ] . Moreover , Mao - A is expressed at a high level in neurons , whereas Mao - B is expressed in astrocytes [ 29,30 ] . Mao inhibitors prevent dopamine - induced mPTP pore formation and cell death [ 31 ] . Catalase is a key enzyme in brain cells that utilizes ROS during ischemia and reoxygenation [ 32 ] . Its overexpression in brain cells before MCA occlusion has a powerful protective effect , while this approach is not effective in the therapeutic regimen [ 33 ] . In our experiments , the incubation of cerebral cortex cells with 3 - EA lead to the suppression of basal and OGD / Rinduced expression of genes encoding both forms of monoamine oxidase ; the protective effect of 3 - EA is observed both in neurons and astrocytes . As for the gene encoding catalase , its baseline expression increased almost threefold after pretreatment of cells with 3 - EA . The increased level of catalase persisted after OGD / R. Our in vitro results are supported by the data obtained in animal experiments . Daily intravenous administration of 18.0 mg / kg 3 - EA during a week following MCA occlusion ameliorates the severity of the neurological disorder and preserves neurons ' cellular population and brain tissue integrity . In addition , restraining the activity of local oxidative stress and simultaneous prevention of ischemia - induced AC 's drastic depression highlights the importance of the antioxidant property of the novel hydroxypyridine compound .	253174807	no
There is an increasing need to identify novel biomarkers of DM complications particularly in view of potential applications in precision medicine . Available data suggest that circulating both HSP and anti - HSP levels may be exploited as biomarkers of diabetic vascular diseases ( Table 3 ) ; however , studies performed in this area have important limits . They are often conducted on small groups of patients and without adjustment for conventional risk factors and confounders . Sometimes patients with diabetic complications are compared with healthy subjects , not taking into account that DM itself can affect HSP circulating levels . Finally , there are insufficient prospective studies assessing the importance of HSPs / anti - HSPs in predicting outcomes and guiding intervention . Therefore , it would important in the future not only to identify independent associations between HSPs / anti - HSPs and DM complications in large cohorts of well - characterised patients with DM , but also to prospectively validate promising biomarkers for future applications in clinical practise .  	36044298	no
Despite the formation of a structurally appropriate neoartery the TE50 graft dilation and pulsatility data gathered over 8 months indicated a potential mismatch between the mechanical properties of the native artery and the regenerating graft . Dilation is known to reduce blood flow velocity and generate turbulence , which may limit the durability of the TE50 graft and should be prevented in future studies . This dilation of TE50 could be limited either by chemically modifying PGS [ 7b ] to slow graft degradation or by reinforcing the graft through the addition of an outer sheath layer made from materials previously reported to facilitate collagen production . [ 7c ] The mouse AA and neoarteries regenerated from TE50 grafts comprised similar fractions of elastin and SMCs , as well as a typical endothelium layer , but significantly lower amounts of collagen . It is likely that limited generation of collagen in the graft adventitia was the main contributing factor to graft dilation over time , with the loss of mechanical strength due to the rapid degradation of the original graft not compensated for by adequate collagen deposition . The dilation that the TE50 grafts experienced differs from that seen in aortic aneurysm , which is associated with an increase in collagen content as a response to selective elastin degradation . [ 36 ] Here EL generation occurred at an early stage , but limited collagen regeneration compromised the graft and led to early dilation . This indicates that early and balanced production of both organized elastin and collagen is required for the formation of a mechanically viable neoartery . Various groups have reported the generation of appropriate collagen types and amounts within their vascular graft prototypes and similar strategies could be adopted to improve the TE50 graft . [ 7b , c,22,37 ] The de novo production of organized EL in the intima - media has been identified as the missing element in biodegradable vascular graft regeneration . [ 5,7a ] Most elastogenesis is classically restricted to late fetal and early neonatal periods , [ 38 ] with limited elastin synthesis in adulthood that is in response to the loss of elastin due to injury or disease . [ 39 ] In blood vessels , elastin is an extremely durable insoluble protein and mature elastic fibers generally persist for the lifespan . [ 40 ] Adv . Mater . 2022 , 34 , 2205614 Figure 8 . Proposed remodeling of TE50 . After implantation , the non - porous TE50 vascular graft allows migration of arterial smooth muscle cells ( SMCs ) from adjacent tissue to form intima - media with a circumferential aligned and layered structure . TE is gradually released from the graft . Amorphous elastin and elastin fibers are produced and assembled to form elastic lamellae , possibly with the help of M2 macrophages . The internal elastic lamellae are formed at a later stage through the joined effort of SMCs and endothelial cells . The outer surface encounters both phagocytosis activities from M1 macrophages as well as the deposition and remodeling of collagen fibrils by an interplay of arterial SMCs , fibroblasts , pericytes , and M2 macrophages to form adventitia . Upon complete degradation of TE50 , the adventitia meets intima - media to form the neoartery with spatial and microstructural features that resemble the native artery .	252366756	no
To investigate the ICP27 RNA binding specificity , HSV-1 RNA sequences that interact with ICP27 were first identified . A yeast three hybrid analysis identified 31 HSV-1 sense RNAs , mapping to 28 different open reading frames , which interacted specifically with ICP27 in vivo ( 26 ) . ICP27 was also found to specifically associate with seven HSV-1 RNAs in in vivo UV - crosslinking studies . The late RNA for the glycoprotein C ( gC ) gene was one of the RNAs that UV - cross - linked to ICP27 in infected cells ( 3 ) . To further refine the pools of possible RNA binding sequences , a yeast three - hybrid screen was performed with an RNA library generated from nucleotides 95 155 - 98 129 of the KOS HSV-1 genome , which encompasses two late genes , UL43 and UL44 ( gC ) . Sequences corresponding to both the mRNA coding and noncoding strands from UL43 and gC were identified in the yeast three hybrid screen as interacting with ICP27 ( data not shown ) . No obvious consensus sequences were identified in these sequences ; consequently EMSA was used to screen these sequences for those that bound to ICP27 with high affinity . A 294 - nt region of gC , corresponding to nucleotides 96 946 - 97 239 of the coding strand of the KOS HSV-1 gC mRNA , was chosen as an EMSA binding substrate . This region of the gC mRNA was chosen over the other sequences because it was within the coding region of the gC mRNA and was small enough to screen . Nineteen overlapping 30 - mer DNA oligonucleotides corresponding to coding strand of the gC RNA were used in EMSA experiments ( Figure 1C ) . RGG box motifs in other proteins recognize both RNA and DNA quadruplex structures ( 30,31 ) , so gC DNA was used instead of gC RNA for this initial screening to provide a more stable substrate for analysis . The ICP27 N - terminus was incubated with individual radiolabeled gC DNA 30mers at 37 C and resolved by nondenaturing acrylamide gel electrophoresis . Figure 2A shows a gC DNA sequence that the ICP27 N - terminus was able to shift its migration to a more slowly migrating band , gC 11 - 40 , and a second sequence , gC 31 - 60 , whose migration was not affected by addition of protein . Some sequences ' migration were moderately affected ( Figure 2B ; 121 - 150 ) , whereas most gC sequences were shifted well by the ICP27 N - terminus ( Figure 2B ; gC 1 - 30 , 91 - 120 and Figure 2C ; 61 - 90 . ) Of the gC DNA oligonucleotides tested , fourteen were shifted , two were shifted moderately and three showed no discernable shift ( Table 1 ) .	10080465	no
One function of p63 is the regulation of developmental processes . Several mutations in the p63 DNA - binding domain are responsible for a family of human syndromes characterized by a combination of ectrodactyly , ectodermal dysplasia and facial clefting ( 37)(38)(39)58 ) . These observations led us to test the influence of disease - related p63 mutants on transcriptional activation of S100A2 . In reporter assays , we found an even stronger transcriptional activation employing two TAp63 g mutants derived from SHFM patients compared to wild - type p63 ( Figure 5 ) . In contrast , three p63 mutants responsible for the EEC syndrome had essentially lost their activation potential on the S100A2 promoter . A TAp63 g mutant related to the ADULT syndrome yielded some residual S100A2 activation when compared to wild - type TAp63 g ( Figure 5 ) . Interestingly , these observations correlate with severity of the epidermal syndrome phenotype since SHFM patients , in contrast to patients suffering from EEC and ADULT syndromes , are characterized by a lack of epidermal dysplasia ( 62 ) . Therefore , it is tempting to speculate that the ability of p63 to stimulate expression of S100A2 plays a role in developing the phenotype of these patients . Further research is required to establish a stronger link . S100A2 was identified as a potential tumor suppressor by subtractive hybridization between normal and tumorderived mammary epithelial cells in man ( 14 ) . Consistent with these findings S100A2 expression is markedly downregulated in several tumor tissues ( 15)(16)(17)(18 ) . However , it was shown that S100A2 expression is increased in other tumors ( 21)(22)(23)(24)(25)(26 ) . It was discussed that overexpression is an early event in tumorigenesis . Furthermore , a physical interaction between S100A2 and p53 proteins enhances transcriptional activity of p53 which implies antitumorigenic properties of S100A2 ( 27 ) . A possible interaction also between p63 and S100A2 proteins has not yet been investigated . Recently , it was demonstrated that S100A2 expression is able to diminish expression of Cox-2 protein which provides further evidence for a tumor suppressive function of S100A2 ( 28 ) . Interestingly , in line with these observations we showed that expression of S100A2 increases following DNA damage ( Figure 6A and C ) . The enhanced expression of S100A2 correlates with binding of p63 g protein to the S100A2 promoter ( Figure 6D ) . Generally , detection of different p63 isoforms on the mRNA and protein levels is difficult . It is possible to differentiate between TAp63 and ÃNp63 mRNA variants . On the protein level we were able to observe p63 g versus total p63 protein expression . After DNA damage we exclusively find an increase in the TAp63 isoforms on the mRNA level . Combining these observations with the data from the ChIP assays suggests that TAp63 g is induced after DNA damage and subsequent binding to the S100A2 promoter mediates its regulation ( Figure 6D ) . Supportive of this notion is the finding that p53 - negative Hep3B cells also show an increase in transcription of S100A2 together with enhanced expression of the TAp63 isoforms after DNA damage is observed ( Figure 6C ) . In conclusion , it is possible that regulation of S100A2 transcription by TAp63 g is a supporting mechanism to complement and enhance cellular response in preventing tumor transformation ( 34 ) . This is consistent with earlier observations implying that TAp63 g is able to substitute partially p53 function in hepatocellular carcinomas lacking p53 expression by transactivating the maspin tumor suppressor ( 55 ) .	887548	no
Thus , the experimental constraints on x s + are provided essentially by the Î½ andÎ½ dimuon data sets . Following Refs . [ 3,9 ] , we determine the uncertainty range of x s + by the 90 % confidence criteria on the dimuon production data sets . This range is 0.018 < x s + < 0.040 . The two sets of PDFs that represent the best fits corresponding to the lower ( upper ) bound value of x s + will be referred to as CTEQ6.5S1 ( CTEQ6.5S2 ) . The variation of x s + 8 The parton number integral is strongly correlated with the normalization of the Î½ andÎ½ dimuon production data sets compared to the theoretically calculated inclusive charm production cross section . There are various sources of uncertainty on this overall factor : experimental ( global and energydependent ) normalization of the total cross sections ( â¼ 2 â 5 % ) , fragmentation function of charm quark to charmed hadrons , branching ratio of charmed hadron decay to muon ( â¼ 10 % ) , . . . , etc . These are taken into account according to our standard uncertainty analysis . The limits of x s + obtained above correspond to Â±20 % ovreall variation of the normalization factor , as determined by this analysis procedure . As the magnitude of x s + varies , the shape of s + ( x ) also adjusts to best fit the global data . A plot of s + ( x ) for these PDFs will be shown in the next section .	7797305	no
"We found that the reporting is mostly not case - specific , and data ( on economic , environmental and social dimensions ) are aggregated - that is , numbers that are reported , such as GDP growth or land restoration figures , tend to be Table 2 References to a selection of CSR guidelines and standards that Salini Impregilo - WeBuild pledges to comply with UN Business & Human Rights Guiding Principles "" The responsibility to respect human rights requires that business enterprises : ( a ) Avoid causing or contributing to adverse human rights impacts through their own activities , and address such impacts when they occur ; ( b ) Seek to prevent or mitigate adverse human rights impacts that are directly linked to their operations , products or services by their business relationships , even if they have not contributed to those impacts . "" ( UNOHCHR , 2011 , p 14 ) UN Sustainable Development Goals ( https:// sdgs . un . org/ goals ) "" End poverty in all of its form everywhere "" ( # 1 ) "" End hunger , achieve food security and improved nutrition and promote sustainable agriculture "" ( # 2 ) "" Ensure healthy lives and promote well - being for all "" ( # 3 ) "" Ensure availability and sustainable management of water and sanitation for all "" ( # 6 ) "" Ensure access to affordable , reliable , sustainable energy for all "" ( # 7 ) "" Protect labour rights and promote safe and secure working environments "" ( # 8.8 ) "" Protect , restore and promote sustainable use of terrestrial ecosystems , sustainably manage forests , combat desertification , and halt and reverse land degradation and halt biodiversity loss "" ( # 15 ) "" Promote peaceful and inclusive societies [ â¦ ] , provide access to justice for all and build effective , accountable and inclusive institutions at all levels "" ( # 15 ) UNI EN ISO 9001 ( quality management system standards ) "" When planning for the quality management system , the organization shall [ â¦ ] determine the risks and opportunities that need to be addressed to [ â¦ ] prevent , or reduce , undesired effects "" ( ISO 9001:2015(E ) , 6.1.1 , p. 4 ) UNI EN ISO 14001 ( environmental management system standards )"	244888151	no
It is worth noting that the presence of the SARS - CoV-2 has also been demonstrated in the urine of SARS - CoV-2 infected patients ( Holshue et al . , 2020;Wang et al . , 2020b;Wang et al . , 2020c ) . The virus was more stable in urine than in the stool . The infectious virus was detectable for up to 3 days in the urine of two adult COVID-19 patients and after 4 days in the urine of one child . In turn , the SARS - CoV-1 retained infectivity in a urine sample for 5 ( 21 - 25 Â° C ) ( Duan et al . , 2003 ) to 17 days ( 20 Â° C ) ( Wang et al . , 2005 ) . None of these studies reported a period of complete virus inactivation . More and more authors show the presence of SARS - CoV-2 in urine , but the incidence of this phenomenon is low , and its significance from a clinical point of view is probably low ( Peng et al . , 2020;Liu et al . , 2020aLiu et al . , , 2020bYoon et al . , 2020 ) . The presence of the virus in the urine is not necessarily an indicator of infectious particles in this material . The infectivity of the viral particles can be assessed using in vitro tests on cell culture ( Sun et al . , 2020;Zhang et al . , 2020d;Wang et al . , 2020c;Xiao et al . , 2020b ) . Sun et al . ( 2020 ) showed that the urine sample was for the first time positive for SARS - CoV-2 RNA on day 12 postinfection ( p.i . ) and had periodically showed positive results in RT - PCR test until 42 days . They observed cytopathic effect in Vero E6 cells for the 12 p.i . specimen after three days ( Sun et al . , 2020 ) . Table 4 presents data on SARS - CoV-1 and SARS - CoV-2 in urine and stool . The knowledge of the stability of SARS - CoV viruses in human excretions is of great importance as it allows to predict their role as a source of virus particles .	231690061	maybe
In this study , we find that prostate cancer patients with menin overexpression show poor overall survival . Although menin has been extensively characterized as a tumor suppressor in multiple endocrine neoplasia type 1 17 , our data , and previous literature on estrogen receptor , strongly argues that menin can facilitate oncogenic gene activation through hormone receptor signaling in a contextual manner .	12739981	no
We can then study the minimax risk of sampling , M I ( F G , , n ) : = inf X sup P âF G R I ( P , X ) . A few remarks about M I ( F , , n ): First , we implicitly assumed ( P , P X(X1 : n , Z)|X1 : n ) is well - defined , which is not obvious unless P X(X1 : n , Z ) â F G . We discuss this assumption further below . Second , since the risk R I ( P , X ) depends on the unknown true distribution P , we can not calculate it in practice . Third , for the same reason ( because R P ( P , X ) depends directly on P rather than particular data X 1 : n ) , it detect lack - of - diversity issues such as mode collapse . As we discuss in the Appendix , these latter two points are distinctions from the recent work of [ 7 ] on generalization in GANs .	43929785	no
We are broadly in agreement with these arguments . However , expanding the ways that we think about trust should not preclude in - depth analysis of particular facets . We would not wish to suggest that all the complexity and nuance of patients - herbalist interactions can be reduced to a series of signal - based transactions . However , it is clear from our data that herbalists and patients are engaging signalling practices and that ST gives us some theoretical purchase in understanding these .	454642	no
Optical Coatings filter ( pass band 4.76 Âµm to 5.60 Âµm ) . Spectra were recorded on a Bruker Vertex 80 spectrometer equipped with a mercury cadmium telluride ( MCT ) detector . Data were collected at 4 cm â1 resolution . Typically , 80 time points were recorded for each experiment . The SP-02 cell was fitted with a glassy carbon working electrode ( diameter 3 mm ) , a platinum counter electrode and a silver wire pseudo - reference electrode . These were attached to a Princeton Applied Research VersaSTAT 3 potentiostat . Data collection was controlled by the Bruker Opus package , interfaced to the potentiostat using a custom Opus3D script and TTL connection . IR data was processed and analysed using Fit_3D ( Dr Simon J. George , Lawrence Berkeley National Laboratory , USA ) and curve fitting was carried out using SciDAVis .	12136592	no
As detailed in our response to the Editor 's comments , above , we have now re - analyzed our data using two alternative approaches to addressing missing data , per Reviewer 1 's recommendations . First , we re - ran pre - registered analyses on primary and secondary outcomes ( 3 - month depressive symptoms [ primary ] ; post - intervention and 3 - month hopelessness [ secondary ] ; post - intervention and 3month perceived agency [ secondary ] ; 3 - month generalized anxiety symptoms [ secondary ] ; 3 - month trauma symptoms [ secondary ] ) using two alternative missing data approaches recommended by Reviewer 1 . Specifically , we conducted :	242291039	no
A decline in diagnostic testing for SARS - CoV-2 is expected to delay the tracking of COVID-19 variants of concern and interest in the United States . We hypothesize that wastewater surveillance programs provide an effective alternative for detecting emerging variants and assessing COVID-19 incidence , particularly when clinical surveillance is limited . Here , we analyzed SARS - CoV-2 RNA in wastewater from eight locations across Southern Nevada between March 2020 and April 2021 . Trends in SARS - CoV-2 RNA concentrations ( ranging from 4.3 log 10 gc / L to 8.7 log 10 gc / L ) matched trends in confirmed COVID-19 incidence , but wastewater surveillance also highlighted several limitations with the clinical data . Amplicon - based whole genome sequencing ( WGS ) of 86 wastewater samples identified the B.1.1.7 ( Alpha ) and B.1.429 ( Epsilon ) lineages in December 2020 , but clinical sequencing failed to identify the variants until January 2021 , thereby demonstrating that ' pooled ' wastewater samples can sometimes expedite variant detection . Also , by calibrating fecal shedding ( 11.4 log 10 gc / infection ) and wastewater surveillance data to reported seroprevalence , we estimate that~38 % of individuals in Southern Nevada had been infected by SARS - CoV-2 as of April 2021 , which is significantly higher than the 10 % of individuals confirmed through clinical testing . Sewershed - Keywords : SARS - CoV-2 COVID-19 Virus Wastewater Mutation Variant	248325387	no
The structure of this paper is as follows . In the next section we outline the sectors , input data , model and scenarios used for our modelling application . The results are then presented , discussed and conclusions drawn in the subsequent sections .	11081915	no
We can apply the same distributed algorithms also for DP variational inference JÃ¤lkÃ¶ et al . ( 2016 ) ; Park et al . ( 2016 ) . These methods rely on possibly clipped gradients or expected sufficient statistics calculated from the data . Typically , each training iteration would use only a mini - batch instead of the full data .	621737	no
SI Figure 16 . Simulation of two site chemical exchange at 400 MHz for a system with 1 ppm ( 400 Hz ) separation . Both symmetric ( 1:1 ) and 8:2 population were computed using the DNMR subprogram in Topspin 3.5 . In addition , calculated coalescence points ( 1:1 ) exchange at different field strengths with a 1 ppm separation of exchanging species are :   Figure 18 . Representative imino proton exchange and base opening calculation graphs . A ) A representative graph of the imino proton T1 inversion recovery data ( graph is of the UB sequence G4 imino proton recovery with 6.5 mM NH3 at 3 Â° C ) . X axis is recovery time in seconds ; Y axis is peak intensity ( arbitrary units ) . B ) A representative graph of Ïex vs. 1 / catalyst . ( graph is of the UB sequence G4 imino proton ) .	40899594	no
( a ) Mean viability of SBMA flies ( AR52Q ) reared on food containing vehicle ( EtOH ) , DHT , or DHT in addition to the AF2 modulators described by Estebanez - Perpina et al . ( 2007 ) 19 . * P = 0.03376 for 0.5 ÂµM Meclofenamic acid , * * * P = 0.000228 for 5 ÂµM Meclofenamic acid , * * * * P â¤ 0.0001 for 50 nM and 5 ÂµM Tolfenamic acid , * * P = 0.006852 for 0.5 ÂµM Tolfenamic acid , * * * P = 0.000314 for 50 nM Flufenamic acid , * * * * P â¤ 0.0001 for 5 ÂµM Flufenamic acid , * * * * P â¤ 0.0001 for 0.5 ÂµM Triac . ( b ) Mean viability of SBMA flies reared on food containing vehicle , DHT , or DHT in addition to the AF2 modulators described by Lack et al . ( 2011 ) 21 . * P = 0.030346 for 1 ÂµM ZINC03445992 , * P = 0.020803 for 0.1 ÂµM ZINC02058890 , * * P = 0.008581 for 1 ÂµM ZINC00012342 . ( c ) Mean viability of transgenic flies expressing AR52Q ( ELAV > UAS - AR52Q ) reared on food containing vehicle or DHT and transgenic flies expressing AR52Q - K720A or AR66Q - E897 K reared on food containing DHT . * * P = 0.001136 for AR52Q - K720A. ( d ) Mean viability of SBMA flies ( ELAV > UAS - AR52Q ) reared on food containing MEPB in the absence of DHT . * P = 0.023999 for 50 ÂµM MEPB . ( e ) Mean viability of SBMA flies ( ELAV > UAS - AR52Q ) reared on food containing DHT and bicalutamide . * * * P = 0.00081 for 0.05 ÂµM Bicalutamide , * * * * P â¤ 0.0001 for 0.5 ÂµM and 5 ÂµM Bicalutamide . ( f ) Mean viability of SBMA flies ( ELAV > UAS - AR52Q ) reared on food containing DHT and ibuprofen . All data were evaluated by Chi - square analysis ; n = 50 adult flies / treatment group for all experiments . Comparisons of data shown in a , b , c , and e were made between the actual population frequencies of each treatment group and the predicted population frequency determined by the sum of all treatment groups of AR52Q flies . In d , the predicted population frequency of each treatment group was determined by the ethanol + DMSO group . In f , the predicted population frequency of each treatment group was determined by the DHT + 1 ÂµM ibuprofen group . All graphs represent mean Â± s.e.m .   ( a ) Schematic depicting the cDNA construct used to generate transgenic SBMA mice . ( b ) Fluorescence in situ hybridization of an AR121Q - specific probe ( red ) and a general marker of chromosome 17 ( green ) in chromosome spreads isolated from lungs of AR121Q mice . Representative image from two indenpendent experiments . Scale bar , 10 Î¼m . ( c ) Western blot analysis of spinal cord and muscle expression of transgenic human AR in AR121Q mice and a previously published SBMA mouse model ( AR97Q ) . ( d ) Quantification of the levels of transgenic human AR compared with that of endogenous mouse AR in AR121Q and AR97Q mice . n = 3 mice per group , * P = 0.00396968 for mono and * P = 0.00703522 for total by unpaired multiple t - test , two - tailed . ( e - g ) Representative brain ( e ) , testis ( f ) and liver ( g ) sections from 7 - week - old NTG and AR121Q mice from one independent experiment . Sections were stained with H&E for assessment of morphology , in addition to AR ( N20 ) and ubiquitin antibodies . Scale bars represent 100 Î¼m . ( h ) PolyQ and ubiquitin costaining in skeletal muscle of NTG and AR121Q mice . Representative images are shown from one independent experiment . ( i ) Quantification of fibers with centralized nuclei in lower and upper hindlimb muscles . n = 2 , 2 , 3 , and 3 mice for NTG , vehicle , 50 mg / kg , and 100 mg / kg MEPB treated AR121Q groups . Graphs represent mean Â± s.e.m . ( j ) Representative images of testis from NTG , AR121Q and AR121Q treated with 100 mg / kg MEPB mice from one independent experiment . Scale bars represent 500 Î¼m . All graphs represent mean Â± s.e.m .   	4710370	no
Compared with increasing coverage , partner notification identifies more chlamydia positive individuals for each unit of resource invested in a screening programme . There is considerable scope to improve partner notification outcomes . Furthermore , reallocation of resources to ensure provision and monitoring of effective partner notification is likely to result in substantial cost savings in comparison with increasing screening coverage only . It is not clear from the available data how much additional benefit should be expected from a given level of investment in partner notification . The wide range of reported partner notification and the diverse methods of organisation make it difficult to generalise , and urgent evaluation is needed to establish the most cost effective approach to partner notification . Equitable access to screening for men and women should continue to be promoted . However , the additional resources required to increase male screening coverage to reach equity with females would be more effectively employed in the short term in achieving high partner notification efficacy among those who test positive . Partner notification therefore mitigates the impact of sex inequity in screening coverage since the high proportion of partners infected offsets the lower number of men screened Performance indicators must reflect quality and value for money of service provision , not just quantity of services provided . The spreadsheet tool we have developed will enable local services to evaluate their own programmes and allow rapid updates based on national reports . This tool could also be adapted for use in other countries . We provide strong evidence for the cost effectiveness of partner notification in identifying infected cases compared with screening alone . The number of infected individuals ( women and men ) identified through a screening programme is arguably a more appropriate metric for assessing the success of screening than primary coverage by sex .	34225662	no
RNA isolation form MG63 cells in the control and experimental groups . Control cells were cultured under normal condition . Experimental cells were pretreated with { BIW8 } for 24 h. According to the manufacturer 's instructions , the total RNA of MG63 cells was extracted by using TRIzol ( Invitrogen , USA ) . RNA concentration and quality were determined with a NanoDrop Spectrophotometer . Microarray data were converted into recognizable format and annotated with software Genome Studio . The probes detected with p - value lower than 0.01 in at least one sample were accepted as significant and used for further analysis . The raw data were normalized using the quantile algorithm from the package limma of R. 1.13.1 Identification of differentially expressed genes ( DEGs ) . |Fold change| > 1.5 and adj . P < 0.05 were set as the cut - offs to screen out differentially expressed genes ( DEGs ) . 1.13.2 Heatmaps and volcano plots analysis . Clustered heatmaps and volcano plots of the control and experimental groups were generated using the package ggplot2 of R. 1.13.3 Enrichment analysis of DEGs . Functional enrichment analysis of DEGs was performed by DAVID ( The Database for Annotation , Visualization and Integrated Discovery ) to identify GO categories in by their biological processes ( BP ) , molecular functions ( MF ) , or cellular components ( CC ) . The DAVID database was also used to perform pathway enrichment analysis with reference from KEGG ( Kyoto Encyclopedia of Genes and Genomes ) pathways . False discovery rate ( FDR ) < 0.05 was used as the cut - off .	236472278	no
We know from interview - based research that people are reluctant to mention that they have used the internet when they consult their doctor , due to previous negative experiences ( Bowes et al . 2012 , Stevenson et al . 2007 . We examined patients ' accounts of internet use and compared this with interactional data from the associated consultation .	231818279	no
In the following , we describe the development and validation of our approach step by step . Since we did not want to impose assumptions about what elements of movement of the body were more important , we simply collected movement data from the whole body and later used the data to find what was best suited for characterizing the disease , thereby avoiding observer bias . We used a wearable sensor ' suit ' ( a set of wristwatch - sized ( 4.7 Ã 3.0 Ã 1.3 cm ) sensors attached with Velcro to the body or clothing of the individuals ) that allowed us to capture the motion trajectory of all limbs and the body - from foot to hip , from hand to shoulder and from hip to head at a temporal resolution of 60 Hz . In the first step , we compared the joint kinematics of ADLs between healthy controls and patients with DMD and already found significant distinguishing elements : the distribution of joint angles across almost all body joints showed differences between DMD and controls ( Fig . 1b and Extended Data Fig . 1 ) . These quantitative differences are consistent with the qualitative descriptions of DMD in several ways . First , by inspecting the histograms of skeletal joint movement throughout ADLs ( Fig . 1b and Extended Data Fig . 1 for all major joints ) we saw reflection of hyperlordosis in the DMD posture : the right shifted distribution of the angles subtended by the hip joint with respect to healthy controls and correspondingly a stronger flexion ( left shift of the distribution ) of the knee joint . Similarly , the overall stiffer posture in DMD upper - body poses is reflected by the more contracted distribution of the DMD elbow joint angles compared to healthy controls . Second , the characteristic DMD Trendelenburg sign ( waddling gait ) is reflected in the joint angular velocity correlation matrix of ADLs ( Fig . 1c ) where across the lower extremities we saw less anticorrelation between joints moving in the sagittal plane ( knee and hip flexion ) and more correlation in the coronal plane ( sideways abduction of the hips ) that reflect waddling .	256032596	no
Recovering positive examples for data that mixes disjoint sparsity with popularity - based positive structure For our final synthetic experiment , we construct a scenario that combines aspects of our two previous experiments . In this experiment , we consider three disjoint groups . For each disjoint group we use a categorical distribution with nonuniform event probabilities for sampling items within baskets , which induces a positive correlation structure within each group . Therefore , the oracle will expect to see a high negative correlation for disjoint pairs , compared to all other non - disjoint pairs within a particular disjoint group . For items with a high co - occurrence probability , we expect the symmetric DPP to recover a near zero negative correlation , and the nonsymmetric DPP to recover a positive correlation . Furthermore , we expect both the nonsymmetric and symmetric models to recover higher marginal probabilities , or K ii values , for more popular items . The determinantal volumes for positive pairs containing popular items will thus tend to be larger than the volumes of negative pairs . Therefore , for baskets containing popular items , we expect that both the nonsymmetric   for high - sparsity data . 14 disjoint groups are used for data generation . and symmetric models will be able to easily discriminate between positive and negative baskets . When constructing positive baskets , popular items are sampled with high probability , proportional to their popularity . We therefore expect that both models will be able to recover some signal about the correlation structure of the data within each disjoint group , resulting in a predictive AUC higher than 0.5 , since the popularity - based positive correlation structure within each group allows the model to recover some structure about correlations among item pairs within each group . However , we expect that the nonsymmetric model will provide better predictive performance than the symmetric model , since its properties enable recovery of disjoint structure ( as discussed previously ) . We see the expected results in Figure 3 , which are further confirmed by the predictive AUC results : 0.7 for the symmetric model , and 0.75 for the nonsymmetric model .	170078866	no
Deep neural nets ( DNN ) have led to a revolution in the areas of machine learning , audio analysis , and computer vision . Many state - of - the - art results have been achieved using these architectures . In this work we study the properties of these architectures with random weights . We prove that DNN preserve the distances in the data along their layers and that this property allows stably recovering the original data from the features calculated by the network . Our results provide insights into the outstanding empirically observed performance of DNN and the size of the training data .	15654042	no
In this study , we explore the application of our laser - guided cell micropatterning ( LGCM ) system 15 in combination with surface patterning methods 16 to investigate stem cell differentiation at the single - cell level in a cardiomyocyte microculturing environment . In previous studies , we determined the effect of cell - cell contact on MSC cardiogenic differentiation by creating a microenvironment with only one MSC and one cardiomyocyte using the LGCM system . 17 In the study reported here , we first constructed a cardiomyocyte culture model with the controlled alignment of cardiomyocyte constructs , and then utilized LGCM to trap and deposit individual MSCs into the constructed model . Next , we evaluated cell differentiation at the single - cell level through single - cell RT - qPCR and patch - clamp assays . Consequently , we report ( i ) the construction of a laser - patterned , biochip - based , stem cell - cardiomyocyte coculture model with controlled cell alignment ; and ( ii ) single - cell - level data on stem cell cardiogenic differentiation under an in vivo - like cardiomyocyte alignment conditions .	16715613	no
MAPbI 3 thin - films are ferroelectric semiconductors . Any attempts to describe the experimental data with purely ferroelastic material properties , ionic charging , or ion migration assuming zero polarization ( non - ferroelectricity ) , to date , remain incomplete .	73467849	no
For comparison also several other ( known ) K - P alloys were calculated : K3P , K4P3 , KP , K2P3 , and K3P11 . These structures were taken from the Materials Project data base [ 10 ] and subsequently re - optimized using the same methodology as for the intercalation compounds .	3977554	maybe
"Data set . In this experiment , we investigate the impact of label noise on CE and L 5,1 . The CIFAR-100 data set contains 60,000 RGB images , with 50,000 samples for training - validation and 10,000 for testing . There are 20 "" coarse "" classes , each consisting of 5 "" fine "" labels . For example , the coarse class "" people "" is made up of the five fine labels "" baby "" , "" boy "" , "" girl "" , "" man "" and "" woman "" . In this set of experiments , the images are centered and normalized channel - wise before they are fed to the network . We use the standard data augmentation technique with random horizontal flips and random crops of size 32 Ã 32 on the images padded with 4 pixels on each side ."	3384895	no
Our most recent work has focused on the determination of preferred nucleic acid and/or protein substrates of RapA. Excess RapA was previously shown to produce complex effects on in vitro transcription , which included inhibitory effects at ' early ' timepoints and a significant increase in the number of completed transcriptional rounds in prolonged in vitro transcription reactions , which was attributed to RapAs remodeling of DNA - RNA polymerase - RNA ternary complexes ( 23 ) . In this study - given that the interaction of RapA with the polymerase is well established - using primarily purified native RapA ( 21 ) at a ' physiological ' ( 1:1 ) molar ratio with the polymerase , we have conducted experiments in order to clarify the general mechanistic aspects of this remodeling . Our work presents multiple , independent lines of evidence indicating that RNA is a key substrate of RapA. Our biochemical data , supported by a homology model of the RapA NTPase domain - DNA complex , suggest that this RNA - remodeling activity of RapA may be in addition to its DNA - binding activity . Our results are consistent with a model in which RapA promotes RNA release from DNA - RNA polymerase - RNA ternary complexes . Taken together , our data indicate a novel RNA remodeling activity for RapA , a representative of the SWI / SNF protein superfamily . This finding could potentially deepen our understanding of the functions of all SWI / SNF proteins , and may point to yetunidentified activities of eukaryotic SWI / SNF proteins .	11842980	no
Our optical force simulation data ( Figure 3 ) based on the GLMT displays the axial and radial force distributions along the axial and radial directions with beam waists of 2 and 4 Î¼m . When the beam waist is smaller than 2 Î¼m ( not shown in the figure ) , the axial force changes along the axial direction from negative to positive at all longitudinal sections ( planes parallel to the beam axis ) , which forms the laser tweezers mode . 22 Working in this mode , the laser beam traps the cells around its focal point rather than guiding the cells to move along the beam axis . Because rapid relative motion between the trapped particle and the laser beam is always actively created in the laser patterning procedure , a large radial trapping range is required to provide sufficient trapping force even when the trapped particle is away from the optimal trapping region during laser beam navigation . Our laser cell micropatterning experiment , in which a cell in cell suspension was trapped and guided by the focused laser beam in the cell deposition chamber , was consistent with the simulated results . The experiment showed that the limited trapping range in the laser tweezers mode did not allow the trapped cell to follow the rapid 3D movement of the laser beam during high - speed patterning navigation in a large volume of cell culture medium with strong convectional flow . When the beam waist was as large as 4 Î¼m , the axial optical force remains positive along the axial direction in all longitudinal sections ( Figure 3c ) , forming the pure - guidance mode . In this particular mode , the radial force was too small ( Figure 3d ) to confine the cell within the beam axis during the patterning navigation process .	16715613	no
if |scope(child 1 ) âª scope(child 2 ) | â¥ nV ars then createM ixture(root , child 1 , child 2 ) else createM ultivariateGaussian(root , child 1 , child 2 ) end if end if for each child of root do oSLRAU ( child , data ) end for else if isSum(root ) then for each child of root do subset â { x â data | likelihood(child , x ) â¥ likelihood(child , x ) âchild of root } oSLRAU ( child , subset ) w root , child â n child +1 nroot+#children end for else if isLeaf ( root ) then update mean Âµ ( root ) based on Eq . 3 update covariance matrix Î£ ( root ) based on Eq . 4 end if Figure 3 shows the data points along the first two dimensions and the Gaussian components learned . We can see that the algorithm generates new components to model the correlation between x 1 and x 2 as it processes more data .	18362887	no
parameterized by Î 2 . Researchers have found that fusing different kind of n - gram language models together ( Goodman ( 2001 ) , Mikolov et al . ( 2011 ) ) often significantly improves performance . Table 1 shows the perplexity 3 of 4 - gram and NNLMs on a standard split of the Penn Treebank data set ( Marcus et al . ( 1993 ) ) . Interpolation of a NNLM with a 4 - gram LM gives a 16.9 % reduction in perplexity over a single NNLM even though the two LMs have relatively close perplexities . We use the correlation coefficient between the posterior probabilities of the predicted word over the test set from the two models as a simple measure to predict whether the models are diverse . If the posterior probabilities are highly correlated , then the models are less diverse and smaller gains are expected from fusion . The posteriors from the N - gram and NNLM have a correlation coefficient of 0.869 which is significantly lower than the correlation coefficient of 0.988 for a pair of randomly initialized NNLMs . This higher diversity of the NNLM and N - gram LM combination results in significant perplexity improvement upon interpolation .	18275776	maybe
Funding : This study was funded by the Center for Disease Control and Prevention-1R21CE001602 ( principal investigator AYW).The funder played no role in study design , data collection , analysis , interpretation of data , writing of the report , or the decision to submit . The researchers had independence from the funder .	2411937	no
We thank Robert M. Candey ( NASA ) , Joseph B. Gurman ( NASA ) , and Juan Fontenla , for stewarding legacy data and codes through the times and kindly helping us to locate them . We also thank the referee for comments and suggestions that helped us present more clearly the analysis of this unconventional , venerable data set . TdPA acknowledges funding from the European Research Council ( ERC ) under the European Union 's Horizon 2020 research and innovation programme ( grant agreement no . 742265 ) . This material is based upon work supported by the National Center for Atmospheric Research , which is a major facility sponsored by the National Science Foundation under Cooperative Agreement No . 1852977 .	202565565	no
Virtually all natural concepts are vague and various scholars have argued that vagueness plays an important role in grammar . 20 Our claim is that if we integrate singular / plural structures with vagueness , we ca n't really miss where the mass / count distinction comes from and the mass / count contrast gets to be explained in terms of independently needed notions . This will constitute the main argument , I submit , for the present proposal . In what follows , I first present the idea in informal terms , then I spell it out with supervaluations / data semantics .	16023507	no
it follows from the reconstruction formulae written in the form ( 4.45 ) that the reconstructed currents are anti - hermitian j â  Â± = âj Â± , i.e. j Â± â su ( 2 ) . Now with the extra reality conditionÎ¸ 0 â R/2ÏZ = S 1 on the extension of the algebro - geometric data , the reconstruction formula ( 4.24 ) is also easily checked to give an anti - hermitian current so that j Â± â su ( 2 ) . It therefore follows that as a result of imposing the reality conditions , the reconstructed field g in ( 4.27 ) becomes SU(2)-valued , and in particular , the original fields X 1 , . . . , X 4 describing the embedding of the string into the S 3 â R 4 part of the target space are real valued as required .	16763556	no
While we will herein focus on emerging and future material applications of synthetic sequence - defined macromolecules , we briefly highlight contemporary synthetic processes to sequencedefined polymers as they critically influence the building block variety and achievable chain length , which in turn dictate the resulting material properties and thus applications . The synthetic approaches toward sequence - defined macromolecules were recently summarized and can generally be divided into liquid - phase approaches , solid - phase approaches , and fluorous - phase or polymer - tethered methodologies , [ 2 ] with all their individual advantages and disadvantages . Linear synthetic approaches can install one monomer unit per iterative cycle ( Figure 2 ) , be it in a submonomer strategy or by installing the monomer completely , for instance , via single unit monomer insertion ( SUMI ) . By contrast , bidirectional growth ( Figure 2 ) commences from not only one reactive site but two , thus leading to higher degrees of polymerization more rapidly , and symmetric macromolecules . Of course , also multidirectional approaches , leading to star - shaped macromolecules , are possible . The strategy leading to the fast build - up of molecular weight is the so - called iterative exponential growth ( IEG , Figure 2 ) , often termed divergent / convergent approach , which , however , offers the least control over the obtained sequence ( i.e. , only one type of monomer is usually used ) . The latter two approaches are not well - suited for solid - phase or fluorous - phase synthesis and the linear approach offers the highest possible degree of definition . Thus , several prime examples following this linear Emerging applications of a new class of materials , sequence - defined macromolecules , are explored . Such molecularly highly defined macromolecules require stringent synthesis and purification procedures , yet offer unprecedented application possibilities . The first examples of molecular data storage and related technologies are already starting to emerge today . From a more fundamental point of view , such macromolecules offer a unique opportunity to determine quantitative structure - property relationships ( QSPR ) , which critically aids in designing materials with applications ranging from catalysis to artificial enzymes .	58632572	no
The first two are evaluated 55 efolds before the end of inflation and the cosmic string tension comes from the end of inflation when the waterfall field condenses . First , we find that the spectral index is 0.98 which is within â¼ 2Ï range of WMAP3 year data [ 30 ] . The power spectrum is measured to be P R â¼ 10 â9 from which we get that the scale of inflation is of order of the GUT scale	15259259	no
The D - isomer of CFKK - TMR was synthesized inhouse according to standard solid phase peptide synthesis protocols , using D - analogs of the amino acids ( Anaspec , USA ) and Tetramethylrhodamine NHS ester ( Sigma - Aldrich ) . The peptide was conjugated to the nanoneedles according to the same protocol employed for the L - isomer described above . Both L - and D - isomer sensors were interfaced with OE33 and Het-1A cells for 15 minutes according to the interfacing protocol described . The sensors were removed , fixed in 4 % w / v paraformaldehyde in PBS for 15 minutes , and counterstained with DAPI for 5 minutes . The samples were mounted on coverslip with prolong gold ( Life by confocal microscopy . Five separate z - stacks including the nanoneedles and the entirety of the cells were imaged for each sample . The DAPI and TMR channels were acquired sequentially to avoid cross - talk . All stacks were acquired with constant magnification , laser intensities , detector gain and offset on all channels . The data was quantified for all cells in all images from a single Z plane above the needles as described in the confocal microscopy of cells section .	293483	no
Data on admissions were extracted from the hospital records at the end of the trial . The number of admissions identified was cross referenced with the admissions reported by the patients to ensure that we captured events occurring away from the patients ' usual hospital . The cause of the admission ( and thus whether the event counted as a primary outcome ) was assessed independently from the hospital discharge summary by HP and BM with disagreements resolved by discussion ( with WM arbitrating , if necessary ) . Questionnaires were administered by a research nurse at a home visit arranged within two weeks of the calendar year during which the participant was in the trial . Healthcare resource use was collected by questionnaire posted to the participants three , six , and nine months ( one reminder ) and by the research nurse at baseline and the 12 month assessment . Healthcare resource use included consultations with GPs and nurses , respiratory and nursing teams , out of hours services , emergency services , telephone calls to the NHS 24 health information and self care advice service , and courses of oral steroids and antibiotics . The respiratory physiotherapy service in Edinburgh and the nurses in Midlothian maintained detailed timesheets of all patient contacts . All data were entered manually onto the trial database , with 10 % checked for accuracy by an external assessor .	3460301	no
"For graph partitioning , we experimented with a set of classic benchmarks 6 . Since the optimization criteria is modularity , we compared our method only against best known "" modularity optimization "" heuristics : ( a ) FastModularity [ 26 ] , ( b ) Louvain [ 29 ] , ( c ) Spin - glass [ 25 ] and ( d ) Leading eigenvector [ 27 ] . For message passing , we use Î» = .1 , max = median{|Ï(e ) â Ï null ( e)| } eâEâªE null and T max = 10 . Here we do not perform any decimation and directly fix the variables based on their bias Âµ e > 0 â x e = 1 . Table 1 summarizes our results ( see also Figure 1(middle , right ) ) . Here for each method and each data - set , we report the time ( in seconds ) and the Modularity of the communities found by each method . The table include the results of message passing for both full and sparse null models , where we used a constant Î± = 20 to generate our stochastic sparse null model . For message passing , we also included L = |E + E null | and the saving in the cost using augmentation . This column shows the percentage of the number of all the constraints considered by the augmentation . For example , the cost of .14 % for the polblogs data - set shows that augmentation and sparse null model meant using .0014 times fewer clique - factors , compared to the full factor - graph ."	1958495	no
"In this study , we rely on the figurational model developed by Baack ( 2018b ) which shows how data journalists and civic technologists form a community of practice through overlapping skills and complementary ambitions . Both civic technologists and data journalists rely on data and use similar tools and services for their work , and both aspire to empower citizens . This enables them to complement each other : civic technologist can develop tools for journalists or provide technical skills and expertise to them , while investigations by journalists can spark ideas for new civic tech applications . Their practices interlock in the sense that they interdependently respond to each other and expand one another ( cf . Couldry and Hepp 2017 ) . Theoretically , we can therefore describe them as existing along a shared continuum of practices , a shared repertory of "" images , stories , and actions "" ( Mansell 2012 , 33 ) ."	159434250	no
More advanced studies such as high - resolution imaging and changes in protein expression have recently shown that on different topographies or within the same , some bacteria can be impaled or deformed on nanopillars , and some exhibit an enhanced oxidative stress response , resulting in mechanically ruptured and lysed cells or not . [ 44,46 ] This multitude of scenarios suggests that either several mechanisms exist at once for some structures , or one dominates , driven by a particularity of the topography - bacterium pair ( and likely environment ) . Therefore , to elucidate the underlying mechanism , we further probe the surface by SEM imaging ( Figure 5d - f ) and discover the significantly lower number of adhered bacteria to the nanostructures than to the controls , also observing that â50 % of those attached cells are ruptured / lysed ( see the Experimental Section ) . Amongst the bacteria that appear intact on the nanostructures , we note they appear flattened / deformed when resting on nanopillars , yet there are no clear signs of their disintegration ( debris or cytosolic content visible ) . This can be attributed to cellular leakage ( washed away ) , loss of turgor pressure , and/or . The photopic response of the human eye is shown with light blue shaded area . c ) Measured and calculated transmission of C and DS samples as a function of incident angle for incoherent , unpolarized light , for photopic calibrated data . d ) Top : Sequential images of a droplet impacting a surface with an initial diameter D 0 = 2.7 mm , expanding to a maximum diameter D max = 9.45 mm as it spreads on the surface , followed by retraction and take - off . The corresponding plot of drop diameter versus time with the y - axis normalized to D 0 is shown for P100 ( gray ) and P400 ( pink ) at two impacting velocities : 1.0 m s â1 ( dots ) and 2.0 m s â1 ( circles ) . The average contact time < Ï > of the droplet with the surface is indicated to be 13.4 ms and 17.8 ms for P100 and P400 , respectively . e ) Calculated capillary pressure P c plotted for nanocones of pitch 50 , 100 , and 200 nm , as a function of the penetration percentage ( z / h ) , where z is the depth of meniscus penetration and h is the total height . The water hammer pressure generated at impacts of 20 and 110 kph are marked on the graph , with varying values for the water hammer pressure coefficient K WH . The bottom row of schematics serves as a representation of the penetration depth z / h. stretching deformation upon adhesion ( which likely is pre-(full ) rupture provided the number of dead bacteria found by fluorescent imaging which scores viability based on the membrane integrity ) . Analysis of the average cell surface area and its distribution ( Figure 5f ; see the Experimental Section ) reveals an increase , further confirming the bacteria are flattened . Nonetheless , although made of glass , we can not exclude the role of pillar flexibility due to their fine size , evidenced in Figure S23 in the Supporting Information , to contribute to the overall performance via a recently proposed energy storage - release mechanism . [ 48 ] Overall , this demonstration of antibacterial glass indicates that at p â 100 nm , S. aureus is killed with an efficiency matching the best reported structures in silicon , leading to bacteria lysis through stretch - and - rupturing and likely piercing , enhanced by the deflection of nanopillars . Further gains in performance are anticipated by adjusting the AR , however we reserve this investigation for future studies , and instead place emphasis on the potential of RSML as a fabrication tool in controllable nanoscale glass etching to achieve such functionalities .	237494015	no
MF , FB , AS and DF developed the study concept . MF and FB performed the data analysis . MF drafted the manuscript , and FB and DF and AS provided critical revisions . All authors approved the final version of the manuscript for submission .	234345002	no
Consistent with the observation that AXP stimulates the cos - cleavage reaction ( Figure 2B ) , the data presented in Figure 3A demonstrate that both ATP and ADP stimulate DNA packaging when included in step 1 of the reaction , i.e. , during maturation complex assembly . Of note , selective packaging of the matured D L end is observed under these conditions . In contrast , while IHF also stimulates the cos - cleavage reaction ( Figure 2D ) , the host protein alone does not support the transition to packaging ( Figure 3B ) . When AXP and IHF are both included in step 1 , additivity is observed and the host protein stimulates AXP - promoted packaging 2 - 3 - fold ( compare Figure 3A , B ) . Importantly , both must be present during maturation complex assembly ( step 1 ) as addition of IHF or ADP in step 2 has no effect on packaging ( data not shown ) . Similar to the cos - cleavage reaction , AMP - PCP ( 1 mM ) partially stimulates the reaction while AMP has little effect ( Figure 3C ) .	215410041	no
Since civic engagement and exploitation of OSN are vital for SC shaping , particular attention should be paid to addressing privacy and security challenges related to OSN , with the aim of developing safe and ethical SC where people will feel protected , and cultivating smart people who will be actively involved in SC . Smart people KPIs and smart living KPIs , especially those related to education and training , openness and information security , are indicative of the level of privacy and security in a city . The achievement of high values of KPIs , which will lead to the enhancement of cities ' and people 's intelligence , requires : a ) identifying and understanding the factors that affect individuals ' behavior on OSN and SC ( Section 4 ) ; b ) the understanding of differences between privacy and security threats to identify vulnerabilities that facilitate the abuse of private data ; and c ) taking necessary measures ( e.g. , revision of privacy and security legislation , software tools , specialized training and education , etc . ) to prevent and deal with them .	158903122	no
Taking stock : The data reported above is inconsistent with relativist predictions concerning retraction in the target scenarios ( the Yes / No cases ) . What is more , even in cases where a claim is , and was , uncontroversially false ( the No / No cases ) , people do not think that speakers are required to take back their claims when prompted to do so . Assertion is not subject to a retraction norm and the extensive machinery the relativist builds atop the alleged norm is devoid of any empirical foundation . 25	233688409	no
The issue of self medication was addressed by Henquet and colleagues , 6 using data from the German prospective early developmental stages of psychopathology study . 12 13 The authors investigated the association between cannabis use at baseline and subsequent development of psychotic symptoms at four year follow - up and reported that after adjustment for pre - existing psychotic symptoms , cannabis use at baseline still remained significantly associated with psychotic symptoms at follow - up . There was no evidence of an effect of self medication as pre - existing psychotic symptoms did not significantly predict later cannabis use . 6 Ferdinand and co - workers investigated the role of pre - existing self reported psychotic symptoms and showed a bi - directional association between cannabis and psychotic symptoms over a 14 year follow - up study in the general population . 11 They showed that cannabis use predicted later psychotic symptoms in individuals with no evidence of psychotic symptoms before starting to use cannabis and that the reverse was also true , in that psychotic symptoms predicted cannabis use in those who had not used cannabis before the onset of those symptoms . 11 A prospective population based cohort study also found evidence for a self medication effect . 14 Individuals with self reported hallucinations at the age of 14 had a higher risk of using cannabis on a daily basis at the age of 21 . In a sibling pair analysis , however , this study also suggested an independent effect of cannabis use on self reported delusional ideation later in life . 14 Thus , although the cannabis - psychosis link has been investigated in many studies , results on the temporal association between cannabis use and psychotic symptoms remain conflicting . Longitudinal cohort studies with multiple repeated interview based measures of cannabis use and psychotic symptoms are needed to clarify this issue . The EDSP study , 12 13 which completed its recent 10 year follow - up representing the fourth assessment ( assessments at baseline , T1 , T2 , and T3 , see also fig 1 ) , is uniquely suitable for the investigation of the temporal association between cannabis and psychosis .	7009254	no
To compare our findings to observations , we extract the following characteristics from the computed spectra : ( i ) the ratio of the integrated redward over the integrated blueward flux ( L red /L blue ) -which is a measure of the asymmetry of the line shape ; ( ii ) the flux at ' draught ' between the peaks ( F valley ) in comparison to the flux at the maximum point ( F peak ) , which , in practice , quantifies the ' deepness ' of the draught of the double peaked spectra ; and ( iii ) the position of the red emission peak ( v red ) . We show the evolution of these measures in Fig . 3 from t = 40 to 100 Myr ( in intervals of 10 Myr ) with the last data point marked with a square . We compare this to observations of nearby , star - forming galaxies ( the ' Green Peas ' ; data taken from Yang et al . 2016 , also Henry et al . 2015 , and to z â¼ 2 â 3 Lyman - Î± selected galaxies ( Erb et al . 2014 ) . In addition , we also display other simulation results presented in Walch et al . ( 2015 ) , Gatto et al . ( 2017 ) , and Peters et al . ( 2017 ) ( shown as black circles in Fig . 3 ) . These hydrodynamical simulations include supernovae feedback with random SN positions and cover SN rates from 5 to 45 Myr â1 with none including CRs ( but partially include stellar wind and UV feedback ) . We show them only to support the case that the spectral shape we obtain for the ' noCR ' simulation is not an outlier -but in fact typical for hydrodynamical simulations containing thermal feedback . Fig . 3 shows that all the simulations without CRs produce LyÎ± spectra with significant flux at line center ( F valley 0.4F peak ; see also the left panel of Fig . 1 ) . This flux is reduced significantly from t 30 Myr in the CR simulations as the outflow is established . Also the asymmetry of the line is increased leading to L red /L blue â¼ 2 . Both measures are more in line with what is found in observations where mostly F valley /F peak 0.1 and L red /L blue 2.5 ( see also Steidel et al . 2010;Kulas et al . 2012 ) . Determining F valley observationally requires a high spectral resolution since the convolution of the true spectrum with the instrument 's kernel leads to a spreading of the peak flux , and thus , the true value of F valley can be even lower than measured . This effect makes our comparison of F valley /F peak conservative and the true discrepancy between the ' noCR ' simulation and the observations might be even larger .	76652853	yes
In this paper , we report a convolutional neural network - based method , trained through deep learning 41,42 , that can perform phase recovery and holographic image reconstruction using a single hologram intensity . Deep learning is a machine learning technique that uses a multi - layered artificial neural network for data modeling , analysis and decision making and has shown considerable success in areas where large amounts of data are available . Deep learning has recently been applied to solving inverse problems in imaging science such as in super - resolution 43,44 , acceleration of the image acquisition speed of computed tomography ( CT ) 45 , magnetic resonance imaging ( MRI ) 46 , photoacoustic tomography 47 and holography 48,49 .	28072318	no
Calculations : The electronic structure of monolayer VSe2 was calculated within the density functional theory ( DFT ) . The DFT calculations were performed using the VASP package , utilizing the projector augmented phase wave ( PAW ) method , [ 49 ] and the Perdew Burke and Ernzerhof ( PBE ) exchange - correlation functional . [ 50 ] An on - site Coulomb interaction was included within the GGA+U approach using the Dudarev method , [ 51 ] as implemented in VASP . We chose a value â = 3 eV for the V 3d electrons . A separation of 15 Ã between V layers in our supercell was found to be sufficient to represent an isolated monolayer . We   Hz , 50 mV ) shows a differential conductance dip around the Fermi level with a size of ~26 meV , due to a CDW order . Its inset shows a zoom - in of the gap feature .    Figure 2 . Synchrotron - PES data of pristine and ambient - exposed monolayer VSe2 . a , b ) V 2p and Se 3d core - levels of monolayer VSe2 . The V 2p3/2 and 2p1/2 peaks are located at 513.4 eV and 520.9 eV , respectively , thus indicating a spin - orbit splitting of 7.5 eV. The Se 3d5/2 and 3d3/2 peaks are positioned at 53.4 eV and 54.2 eV , respectively . c ) The valence band of the monolayer shows a sharp Fermi edge originating from the V 3dz 2 band . The spectral features between 1 and 5 eV are contributed by the Se 4p derived bands , while the broad bump beyond 6 eV is a substrate peak . d ) Work function of monolayer VSe2 extracted from the secondary electron cutoff , using a photon energy of 60 eV. The upper panel ( red spectra ) shows the effects of air - exposure . In particular , additional peaks , which are located at the higher BE side of the main peaks , are seen to develop at the V 2p and Se 3d core - levels . The sharp Fermi edge of the initial valence band has been reduced substantially , accompanied with a work function decrease of 0.25 eV. Figure 3 . V 3d 1 electronic configuration of 1T - VSe2 , and element - specific XAS and XMCD measurements of monolayer VSe2 . a ) Schematic diagram of the 3d electronic states of 1T - VSe2 in an octahedral crystal - field . The 3d - orbitals of the V 4 + ion are split into two sets of eg and t2 g orbitals , separated by an energy âoct = 10 Dq . b ) TEY detection geometry for the XAS and XMCD data shown in ( c ) . c ) Upper panel shows the XAS spectra of the monolayer measured at 30 K. Spectra highlighted in red and green are , respectively , the XAS obtained with opposite magnetic field ( ~Â±300 Oe ) directions , and their sum gives the total XAS marked in purple . Atomic multiplet structure , identified as a - e , provides direct proof of the d 1 configuration . Lower panel in ( c ) shows the XMCD signal that is within the experimental error , indicating no signs of a ferromagnetic coupling in the monolayer . This result is supported by measurements taken at 16 K and with a 1 T field ( Figure S5 , Supporting Information ) . VSe2 . An overlap between the field - cooling ( FC ) and zero - field - cooling ( ZFC ) curves down to 2 K and in a 7 T field , together with a broad maximum for the measured Ï , a characteristic feature of low - dimensional magnetic systems with a short - range antiferromagnetic ( AF ) interaction , indicates the presence of spin frustration in monolayer VSe2 . Lower panel , a negative Weiss constant obtained from the Curie - Weiss ( CW ) fit to the high - temperature region of 1 / Ï , suggesting an antiferromagnetic ( AF ) origin of the exchange interaction in monolayer VSe2 . d ) A triangular spin - lattice with AF coupling . In this geometry , three neighboring spins can not be mutually antialigned , thus leading to spin fluctuation and suppressed AF correlation .   Figure 5 . ARPES data of monolayer VSe2 . a ) Intensity map as a function of the surface momentum component k// as acquired at 300 K. b ) Zoom - in of ( a ) in the Fermi level BE range . c ) Experimental band dispersion extracted from ( b ) using a second derivative filter . b - f ) Same as ( a - c ) , with data acquired at 11 K. Zero energy represents the Fermi level position . Upon cooling , the V 3d and Se 4p bands are observed to shift towards higher BE . g ) These bands appear as a double - peak structure in the EDCs , which is not resolved at 300 K. The measured intensities of the EDCs have been normalized by the FD function , in order to highlight the effect of temperature on the spectral broadening . A CDW gap opening is evidenced by a leading - edge midpoint shift toward higher BE when cooling down to 11 K from 300 K.	122387435	no
"For all the TCGA NGS datasets , we first have selected the genes appeared in all the datasets and then filtered out the genes whose total read counts across samples are less than 50 , resulting in roughly 14,000 genes in each dataset . We first have divided the lung cancer datasets into training and test sets , and then the differential gene expression analysis has been performed on the training set using DeSeq2 [ Love et al . , 2014 ] , by which 1,000 out of the top 5,000 genes with higher log2 fold change between LUAD and LUSC have been selected for consequent analyses . We first check the subtyping accuracy by directly applying linear SVM to the raw counts in the target domain , which gives an average accuracy of 59.28 % with a sample standard deviation ( STD ) of 5.54 % from ten independent runs . We also transform the count data to standard normal data after removing the sequencing depth effect using DESeq2 [ Love et al . , 2014 ] and then apply regularized logistic regression provided by the LIBLINEAR ( https://www.csie.ntu.edu.tw/~cjlin/liblinear/ ) package [ Fan et al . , 2008 ] . The classification accuracy becomes 74.10 % Â± 4.41 % . Table 1 provides cancer subtyping performance comparison between BMDL , NB - HDP , HDP - NBFA , hGNBP , as well as the baseline hGNBP - NBFA using only the samples form the target domain . In only HDP based methods can not improve the results in the low - related setup , but also the performance will be degraded with more severe "" negative transfer "" adversarial effects when using more source samples . The reason for this is that HDP assumes a latent factor with higher weight in the shared DP will occur more frequently within each sample [ Williamson et al . , 2010 ] . This might be an undesirable assumption , especially when the domains are distantly related . For example , a latent factor might not be present throughout the HNSC samples but dominant within the samples of lung cancer . HDP based methods are not able to discover these latent factors given observed samples due to the limited number of lung cancer samples . In addition to this undesirable assumption , NB - HDP does not account for the sequencing - depth heterogeneity of different samples , which may lead to biased results deteriorating subtyping performance as shown in Table 1 ."	53047134	no
We find no evidence of an effect of the Teenage Pregnancy Strategy on rates of teenage pregnancies or births in England between 1999 and 2016 . Analysis of England - only data showed a clear change in trend during the Strategy period , consistent with previous observations ( Wellings et al . , 2016 ) . However , the similar changes observed in other UK , European and English - speaking countries suggest that England may have seen a similar fall in teenage pregnancy in the absence of the Strategy . This finding of little , if any , impact was consistent across two methods using different datasets , and was robust to sensitivity analyses .	231596085	no
In this work , we develop a new data - driven deep spectral learning ( DSL ) method to enable highly robust and reliable sO 2 estimation , as shown in Fig . 1b . By training a neural network to directly relate the spectral measurements to the corresponding independent sO 2 labels , DSL bypasses the need for a rigid parametric model , similar to existing deep - learning methods for solving optical inverse problems [ 32][33][34][35][36 ] . We show that DSL can be trained to be highly robust to multiple sources of variabilities in the experiments , including different setups , imaging protocols , speeds , and other possible longitudinal variations .	181990850	no
The outbreak of COVID-19 may have influenced the evaluation of air control policies during China 's 13 th FYP . Some previous studies have demonstrated the short - term health implications of improvements in air quality in China using measured PM 2.5 data   and comparing PM 2.5 concentrations between lockdown and non - lockdown cities ( He et al . , 2020 ) , the 2020 situation and 2019 baselines ( Wang et al . , 2020c;Zheng et al . , 2020 ) . Here , we expanded this analysis based on 12 months of air quality data in 325 Chinese cities ( excluding four anomalous cities with large fluctuations after data validation ) and compared the chronic health effects under the COVID-19 situation and normal conditions . The comparison between the annual predicted data and observed data showed no significant difference , though the reduction reached approximately 9.8 % and 13.5 % in comparison with the annual average data in 2019 , respectively .	237424987	no
By using combined purchasing data from LCF / EFS , Nielsen and CGA it is possible to estimate the parameters at subgroup level for the beverage preference vector and the 10 price distributions ( on-/off - trade beer , cider , wine , spirit , RTD ) .	16458570	no
48 of the samples collected from collaborating water company distribution systems and tested using standard methods were also tested using flow cytometry . Total cell count results obtained reflect typical concentrations observed in previous studies on drinking water , in the order of 10 4 to 10 5 per ml of diverse microbial populations ( Hoefel et al . , 2003 ) . Comparison of the portable device peak T intensity and these flow cytometry data , Fig . 5 , reveal a reasonable correlation ( r 2 = 0.56 ) and certainly an improvement in comparison to the regulatory microbial measures . It is interesting to note that the error bars associated with technical repeats of flow cytometry are generally greater than those associated with the new fluorescence device . The improved correlation reflects the benefits of flow cytometry identifying all bacteria in a sample rather than the culturable bacteria only . Hoefel et al . ( 2003 ) demonstrated that HPC counts in a mix of raw and potable waters were generally 2 - 4 log fold less than the numbers of total bacteria reported using the same stains as the BacLight â¢ Kit in this study . With peak T fluorescence capable of picking up an area of identifiable bacterial activity , a correlation would therefore be anticipated .	15392469	no
Our analysis has revealed that blanks is required for the generation of small RNAs at convergently transcribed regions . We analyzed the sequencing data obtained from flies with an extra NLS on otherwise wild - type Blanks and found that 666 loci met the cutoff - criterion of a rescue / mutant ratio â¥5 . Overall , there was a very good agreement between the two datasets . Nonetheless , it appears that increased nuclear retention lowers the siRNA yield from more active regions while it may slightly increase the yield from the regions with lower activity ( Supplementary Figure S6A ) . The regions displayed in Figure 7C - E are examples of rather active loci and the traces reflect the reduced yield seen in the rescue with NLS - blanks . It thus appears that in particular the more abundant dsRNA precursors become trapped in the nucleus . The less abundant ones might benefit from the presumably higher nuclear concentration of NLS - Blanks , which may outweigh the negative effect of a prolonged nuclear retention . Importantly , siRNA generation was entirely dependent on the RNA binding capacity of dsRBD2 . When the corresponding data was analyzed , we found that now only 73 loci met the ratio cutoff - criterion and overall the ratios no longer correlated between a rescue with wild - type blanks protein and the rescue with the blanks variant carrying inactivating point mutations in dsRBD2 ( Supplementary Figure S6B ) .	211044752	no
Data quality . For the users of an atlas it is important to find information on the quality of the data they retrieve . Atlases based on first party material , have protocols for data creation . The GENSAT website provides protocols for the generation of reporter mice and for the applied histological procedures . Similarly , all standard operating procedures are available on the GUDMAP website . The GEISHA website gives the protocols for their high throughput project . For XGEbase the information on how experiments were performed is described in a publication ( 23 ) .	11200612	no
Policy information about availability of data All manuscripts must include a data availability statement . This statement should provide the following information , where applicable :	211265725	no
The ethical implications of this project have been carefully considered . While this research did not present particular ethical implications , best practices have been followed in order to inform the participants and protect the data and integrity of the interviewees . Participation was voluntary and the interviewees were given a plain language document with information about the project . The interviewees were furthermore required to give written informed consent to participate in the study and have been given the possibility to withdraw at any time . Our data have been processed in a manner that ensures appropriate security of personal data , including protection against unauthorised or unlawful processing and against accidental loss , destruction or damage of data , using appropriate technical or organisational measures . To provide maximum confidentiality , we have anonymised the information that all the interviewees provided .	232036490	no
Statistical analyses were performed using IBM SPSS Statistics version 22 ( IBM , Armonk , NY , USA ) . The significant differences in expression levels of SfVg and SfVgR in different developmental stages and tissues were analyzed with a one - way ANOVA analysis followed by Tukey 's test ( Î± = 0.05 ) . The significant differences in interference efficiency and reproductive parameters in the RNAi experiment were assessed by Student 's t - test ( * p < 0.05 , * * p < 0.01 , * * * p < 0.001 ) . All data were shown as means Â± standard errors ( SE ) .  	252836460	no
The drinking water samples largely reflect samples collected from residential sites , though there were two studies that measured Pb in drinking water at schools . Compliance monitoring for the LCR do not require monitoring of schools and daycare facilities unless the school manages their own drinking water system . While the U.S. EPA does not currently require testing at schools and daycare facilities , the agency does provide guidance for reducing Pb in drinking water at these sensitive sites ( U.S. EPA , 2005 and . A recent survey conducted by the U.S. Government Accountability Office ( GAO , 2018 ) found that 59 % of schools did not test , or were unsure if they tested , for Pb in tap drinking water . Of the 41 % of schools that did test for Pb in drinking water , 37 % found elevated levels . School districts varied in the threshold used for determination of elevated Pb . School districts reported using either the 15 ppb standard for compliance monitoring for public water systems , or the 20 ppb action level suggested in the 3Ts for Reducing Lead in Drinking Water in Schools ( U.S. EPA , 2006 ) guidance document for schools and daycares , while others reported using more conservative action levels than 15 ppb . The difference in the LCR and 3Ts standards is reflective of the difference in goals . The LCR standards are intended to identify system - wide problems to inform water treatment protocols , whereas the guidance for schools and daycares are intended to identify issues with specific drinking water outlets ( U.S. EPA , 2006 ) . Identifying the extent of Pb contamination at schools and daycares is essential to understanding the exposure burden for children from their total environment . Currently there is very limited data available for levels of Pb in drinking water at schools and daycares . The availability of multi - media exposure data is even more limited for these sites . In our review , we identified Pb concentration data in soil and drinking water for a limited number of school sites . Our review did not identify data sources for dust Pb loadings at U.S. schools . Considering the substantial amount of time that children spend at these alternative locations , it is imperative that there is a better understanding of potential Pb exposure at these sites to successfully reduce Pb exposure and overall BLLs for this vulnerable population .	201228023	no
"County Health System ( Field Site 1 ) is a large public integrated delivery system on the West Coast , comprising one main hospital , multiple outpatient clinics , a specialty center , and several ancillary services distributed through the region . As the county 's medical safety - net within the area 's stratified ecology of health services , patients , providers , and staff all exhibited a high level of racial , ethnic , and linguistic diversity , with many also reporting histories of immigration . As a public institution , the organization carries a mission of serving all patients without consideration of ability to pay . Despite this stated mission and urban geographic location , the health system rarely acknowledged SGM issues within its public messaging of care for "" all . "" The announcement of the SOGI mandate appeared within the organization 's existing data - centered accountable care initiatives , with the data understood as a new demographic reporting requirement following growing societal awareness of gender and sexuality ."	237292347	no
comparison with other studies By contrast with most previous research , our study included women aged 15 - 49 years , most of whom will have been premenopausal . Thus , the periods of observation for ever users of hormonal contraceptives in this age group had a higher proportion of information relating to current or recent use than those for ever users in a study recruiting older women , because many would have stopped using hormonal contraception many years previously . The Collaborative Group on Epidemiological Studies of Ovarian Cancer 's reanalysis of oral contraception data from 45 studies included women who were generally older than our cohort ( mean age of diagnosis of ovarian cancer was 56 years , with only 18 % of tumours diagnosed in women younger than 45 years ) . 4 The overall relative risk between ever and never users was 0.73 ( 95 % confidence interval 0.70 to 0.76 ) . The Collaborative Group 's analysis found that younger and premenopausal women seemed to have greater percentage reductions in risk of ovarian cancer per five years of oral contraceptive use . 4 However , after accounting for time since last use , no significant heterogeneity by menopausal status or age was seen , demonstrating that how recent a woman last used hormonal contraceptives was more important than the other two factors . Our slightly stronger reduced risk for any ovarian cancer among ever users of any hormonal contraception ( relative risk 0.66 ( 95 % confidence interval 0.58 to 0.76 ) ) was possibly due to 58 % of the total period of observation in ever users arising from current or recent use of combined oral contraceptives . Similar to the Collaborative Group 4 and other more recent investigations , [ 5][6][7][8][9 ] we found that the risk reductions among current users of any hormonal contraception got stronger with longer durations of use and persisted for a number of years after stopping use . The apparent loss of protection 10 years after stopping hormonal contraception could be due to the loss of biological effect ( assuming a causal association exists ) , or reduced statistical power to continue to observe a significant reduction due to the relatively small periods of observation ( 7 % of total person years for ever use ) .	52844692	no
The differences in frequency coverage and timing precision between the GBT and CHIME / Pulsar data sets lead to observable differences in their DM measurements . In particular , while the GBT data yield superior RMS timing residuals in both receiver bands than those obtained with CHIME / Pulsar , the CHIME / Pulsar data nonetheless yield better precision in DM measurements ; the median uncertainty in GBT DMs determined with PulsePortraiture is â¼ 8 Ã 10 â4 pc cm â3 , while the same measure in the CHIME / Pulsar data set is â¼ 2 Ã 10 â4 pc cm â3 . The median DMX measurement uncertainty in the CHIME / Pulsar era has comparable precision to that obtained with GLOW by Donner et al . ( 2020 ) , â¼ 4 Ã 10 â5 pc cm â3 . Further analysis of the DM timeseries for PSR J0740 + 6620 will be the subject of future works .	233004363	no
At age 12 , the children who attended the clinic were more likely to be girls , have a higher birth weight , be from a higher social class , have older and taller mothers , and have mothers with higher levels of education compared with non - attenders . 17 There was a similar pattern of differences between clinic attenders who provided valid measures of physical activity and attenders who did not . The differences between attenders and non - attenders were similar at age 14 . However , the differences between children who did and did not provide valid accelerometer data were markedly reduced at age 14 , with the exception of mother 's level of education .	15672835	no
NGC4993 was also observed during Hubble Space Telescope ( HST ) Cycle 24 ( PropID 14840 , PI : Bellini ) using ACS in F606W. The data were publicly released in April 2017 and were accessed via the Hubble Source Catalog ( HSC ; Whitmore et al . 2016 ) .	55049352	maybe
Clinical study reports ( CSRs ) are large documents , sometimes thousands of pages long , which are generated for regulatory purposes and follow a standard format set out under international guidance . 22 They are routinely created for industry trials , and less well known in the academic community , but contain a wealth of detail on methods and results that is often missing from other sources 23 : one recent study estimates that CSRs contain twice as much information on benefits and harms as academic papers on trials . 24 From 2010 the European Medicines Agency began releasing CSRs on request , after a European ombudsman ruling of maladministration against the agency for withholding such information . 25 Individual patient data ( IPD ) is the raw data collected during a clinical trial , with detailed information on each individual participant . As such it presents important opportunities for research - for example , by allowing third parties to verify trialists ' initial analyses ; permitting meta - analysis of pooled IPD for more accurate point estimates of benefits ; giving greater power for subgroup analyses ; and allowing new hypotheses to be explored in existing data , including on abandoned products and treatments . [ 26][27][28 ] However , it also presents a risk of re - identification of pseudonymised participants . Because of this , IPD is not generally posted in public but shared through various controlled access mechanisms , as with other forms of rich electronic health record data used by epidemiologists .	22525744	no
Having in mind the important role of respiratory viruses in airway epithelial cell damage , we attempted to assess the indirect effect of respiratory viral infection on epithelial regeneration . Incubation of bronchial epithelial cells with supernatants collected over 72 h from either RV1bor PIV3 - infected cells decreased the repair process 24 h post injury . Preincubation of injured and not - injured cells with the LPS inhibitor decreased supernatant - induced repair inhibition . This effect was also seen in cultures stimulated by conditioned media from RV1b in the presence of either TRIF inhibitor or MyD88 inhibitor . These findings may suggest that supernatants activated TLRs by danger - associated molecular patterns ( DAMPs ) and are consistent with data suggesting that respiratory epithelial cells respond to infection and produce endogenous DAMPs , such as for example ATP , HMGB1 , and S100 proteins [ 37,38 ] . DAMPs activate epithelial cell - intrinsic pattern recognition pathways and also recruit and activate cells of the immune system [ 39 ] .	52051096	no
analytical data in agreement with the literature . [ 12 ] (	202718443	no
Our metabolomics study revealed common metabolic signatures affecting all COVID-19 patients and emphasized the major changes to affect the moderate and severe conditions . In particular , our data did not reveal huge alterations in mild patients compared to healthy individuals , suggesting that SARS - CoV-2 infection that induces mild symptoms does not substantially affect the serum metabolome and related metabolic pathways in these patients . Instead , the prevalent differences appear evident in the moderate condition , and are maintained in the severe one . In accordance with the trend of these findings , in a multi - omics study , a high similarity between moderate and severe COVID-19 and a major sharp shift between mild and moderate disease [ 31 ] was identified , which would be responsible for the key differences found in the serum metabolome of our patients ' cohort .	237470810	no
Conventional static force - sensing mechanisms in e - skins mainly consist of resistive and capacitive sensing . Due to its simple mechanism and convenient data collection strategy , resistive pressure sensing has been extensively applied using various recording mechanisms . [ 111 ] Bulky piezoresistive e - skins , like sponge - based sensors , rely primarily on pressure - induced changes in the number of conductive pathways [ 112 ] or in the shape of the sensing material . [ 113 ] Meanwhile , other resistive sensors may analyze the changes in the contact resistance , like the quantum tunneling effect ( Figure 4A ) . [ 114,115 ] This type is much more sensitive and thinner than the bulky option . An e - skin based on bilayer microdome arrays can use microstructures to maximize the changes in surface contact resistance based on the tunneling effect ( Figure 4B ) . [ 115 ] Nevertheless , some drawbacks , like large hysteresis , [ 116 ] large confounding temperature sensitivity , [ 117 ] and varying pressure sensitivity [ 118 ] have limited the performance of resistive sensors . Compared with resistive sensors , capacitive sensors have excellent linearity with lower power consumption . [ 119 ] For piezocapacitive e - skins , capacitance changes are mainly based on the deformation of the dielectric layer . Normal pressure and tangential strain can be measured through a capacitive sensor as the dielectric layer can be deformed under tensile and external pressure ( Figure 4C ) . As demonstrated in Figure 4D , [ 120 ] a capacitive pressure sensing array with cross - arranged electrodes was fabricated using CNTs as the electrode material and PDMS as the dielectric layer .	245168336	no
Participants were requested to wear an actiwatch during the two weeks prior to a qualitative interview and to record their sleep in a structured sleep diary during that same period . An actiwatch is a small , wrist worn , device which measures movement on a minute - by - minute basis . It has been used widely within clinical sleep research as a proxy measure of sleep / wake ( Martin and Hakim , 2011 ) and has been shown to be suitable ( Sadeh , 2011 ) for identifying rhythms . The raw data from the actiwatch can be plotted to create a personalized actogram [ Fig . 1 ] . Each horizontal line in the actogram represents a 24 - h period ( from midnight to midnight ) . Black vertical lines represent movement , with the height of the line indicating intensity of movement . In a ' normal ' , monophasic pattern we would expect movement to be concentrated in the middle of each day with little movement to the far right and far left of each line . In Fig . 1 , which represents the total two - week period from a single participant , what is immediately of interest is ( i ) the constant and continuous movement across the 24h period and ( ii ) a lack of any clear demarcation between day / night movement . The actigraphy data were downloaded prior to the interviews and used during them to encourage participants to reflect on and interpret their personalized graph . The self - completion diaries ( when completed ) were also used during the interviews as prompts to recall and to help participants ' make sense ' of the actigraphy data . The actigraphs and diaries in effect acted as what Latour ( 1987 ) would call ' inscription devices ' ; encouraging a richer understanding of sleep as they provoked participants to reflect subjectively on seemingly objective measures of movement , rest and sleep .	21838	no
An important diagnostic , strongly confirming the low pair dominance independently of the pair equilibrium calculations , is the absence of an annihilation feature in the observed spectrum . Purely thermal plasmas do not show distinct pair annihilation lines even if dominated by pairs ( Zdziarski 1986;Stern et al . 1995 ; . However , the data for this source rule out purely thermal plasmas , see Figure 1 . On the other hand , hybrid plasmas can emit X - ray spectra well reproduced by Comptonization on mostly thermal electrons , but still exhibit relatively narrow annihilation features . The absence of such a feature in the average spectrum therefore implies the pair abundance to be very low .	233204376	no
Conducting the initial review returned 724 articles within the Scopus database . Details of these articles ( including title , abstract , author , journal , year of publication ) were downloaded into an Excel file . This initial number of articles was examined for duplication of entries . There were multiple instances where articles contained references to both sustainability and one or both of the other search references . Once duplicates were removed 567 articles remained to be considered for analysis . All 567 articles were downloaded and reviewed to verify that they actually contained the search terms in the appropriate context . Articles were excluded from the data set for several reasons including not actually relating to sustainability ( e.g. content about sustainable competitive advantage ) or containing a general reference to cognitive / cognition without any depth ( e.g. a mention of cognitive bias ) or where the concept was not a key aspect of the article .	236495231	no
The metagenomes are deposited in European Bioinformatics Institute European Nucleotide Archive under accession no . PRJEB39223 . The non - metagenomic data used for analysis in this study are held by the Department of Twin Research at King 's College London . The data can be released to bona fide researchers using our normal procedures overseen by the Wellcome Trust and its guidelines as part of our core funding . We receive around 100 requests per year for our datasets and have three meetings per month with independent members to assess proposals . The application can be found at https://twinsuk.ac.uk/resources-for-researchers/ access - our - data/. This means that data need to be anonymized and conform to GDPR standards .	231580367	yes
â¢ A high detection significance for a particular chemical species does not indicate that its abundance is constrained accurately . For instance , retrieving on JWST / NIRSpec PRISM observations obtained with the Tiberius pipeline leads to a â¼25Ï detection significance . However , on supplementing these observations with HST / WFC3 G141 and G102 data , the retrieved mixing ratio estimate is 1 dex higher , as the retrieval finds a different spectral baseline .	255522630	no
The interior metric is CAdS in coordinates sec 2 Ï = 1 + r 2 and we have set the AdS scale R to 1 . The induced metrics match on the surface r = r b . This metric is not expected to be a solution to string theory , and initial data corresponding to such a geometry would certainly evolve with time . Nevertheless , any string solution containing a metastable AdS bubble will share certain features of scalar field propagation that we now study .	8847626	no
"Production environments are currently undergoing a transformation induced by the fourth industrial revolution , which adds complexity but also opportunities for sustainable manufacturing . In fact , production systems are transitioning to cyber - physical production systems ( CPPS ) , where the virtual and physical worlds converge ( Monostori , 2014 ) and the value of data is harnessed to achieve desired goals . However , as Tao et al . ( 2018 ) pointed out , the lack of convergence between the virtual and the physical worlds leads "" to low level of efficiency , intelligence , sustainability in product design , manufacturing , and service phases "" . Approaches , technologies and methods are therefore needed to reconcile these two worlds and support relevant strategic goals for the manufacturing industry , sustainability included . For this to happen , "" soft aspects "" at a company or corporate scale come into play when change is introduced in a system , such as competences and capabilities . In the 1990s , management scholars Teece and Pisano ( 2003 ) noted the time dimension of competences and capabilities , as they highlighted the importance of management capability to effectively adapt to changing environments by "" re - configuring internal and external organisational skills and resources "" . These components of responsiveness and adaptation are core parts of the sustainability management field . For example , Dangelico et al . ( 2017 ) built a framework for green product innovation in the manufacturing industry by using sustainabilityoriented dynamic capabilities as theoretical foundations , highlighting the value of a capability - based approach in the pursuit of sustainability - oriented changes ."	229426053	no
Whole - genome sequencing ( WGS ) and a Genomizer analysis ( v 10.1.0 ) were used to conduct a comprehensive and unbiased ranking of other potential genetic risk modifiers , including those associated with a lower risk of Alzheimer 's dementia , helping to exclude other potentially protective genetic factors 10 . For processing the WGS data , the same dragen pipeline described above was used . The data was aligned to the GRCh37 decoy genome ( hs37d5 ) . Variants that were called at a depth of < 10X were filtered out and then were annotated using Ensembl 's Variant Effect Predictor ( VEP ) tool . The version of VEP using was v93 . The filtered and annotated set of variants was then compiled for Genomizer analysis . Further information can be found in the Life Sciences Reporting Summary .	207898971	no
The presented data was collected as part of a larger project , but only the parts of the questionnaire that are of interest for this study 's research questions were included . The relevant questionnaire sections for this article can be found in Supplement D Questionnaire . The questionnaire comprised other sections that focused on consumer behaviour during the lockdown ( e.g. , acceptance of hoarding food and consumer goods , perception of food security ) . The study was approved by the Ethics Commission of the Federal Institute of Technology ( ETH Zurich ) .	234772092	no
From eq . ( 11 ) it is easy to estimate the typical ranges of parameters , for which the model can explain current neutrino data . In case of normal hierarchy , a large atmospheric angle requires Ï ÂµÂµ â âÏ ÂµÏ â Ï Ï Ï . Thus , we find the constraint	10285352	no
The three week wet run ( top ) and flood run ( bottom ) were selected for analysis because the highest average concentration of dissolved Pb was observed for the 3wwet run at the top of the mesocosm ( 21.5 Â± 2.9 mg L â1 ) , ( 10 Â± 2.1 mg L â1 ) and the lowest average concentration was observed for the constant flood run at the bottom ( 10.8 Â± 2 mg L â1 ) , ( 3.8 Â± 0.3 mg L â1 ) ( Tables 2 and 3 ) . Mineral phases and SI 's were calculated from input data ( Table A1 ) and are listed ( Table 4 ) .	49294667	no
To further demonstrate the performance of psRNATarget in analyzing miRNA - mRNA interactions in non - Arabidopsis species , we analyzed another benchmark dataset , referred to as rice miRNA - mRNA interaction data , which was collected from the supplemental data ( the additional file 8) of the paper published by Srivastava et al . ( 8) . The new psRNATarget was able to recall much more validated miRNA - mRNA interactions without significantly increasing the total predictions when searching the same rice miRNAs in the rice miRNA - mRNA interaction data against the same rice transcript library , JGI rice Phytozome 12 genome annotation . Specifically , the recall rate was estimated at 82.7 % by the psRNATarget * The comparison was performed between 65 unique miRNAs / ta - siRNAs in the benchmark dataset ( Supplementary Table S1 ) and the Arabidopsis TAIR10 transcripts . Maximum expectation was set to 5.0 and the maximum number of allowed top targets for each miRNA was set to 200 for both scoring schemas . 2017 release compared with the 62.5 % recall rate by the psRNATarget 2011 release ( Table 2 ) , validating the new psRNATarget 's improved performance in analyzing both Arabidopsis and non - Arabidopsis miRNA - mRNA interactions . Using our Arabidopsis benchmark dataset , prediction performances were also compared between the new psR - NATarget and the standalone pipeline , TargetFinder ( 19 ) . Both applications delivered similar ' recall rate ' and total predictions when we chose to balance the ' recall rate ' and precision through adjusting score cutoff ( Supplementary   Table S3 ) . However , if we chose to maximize ' recall rate ' to cover more validated interactions , the new psRNATarget will recall slightly more validated interactions and report much less total predictions , which in turn indicate much higher precision ( Supplementary Table S3 ) . We further compared performances between new psRNATarget and the TAPIR ( 20 ) using its fast mode since the hybrid mode stringently restricts the size of data that can be analyzed each time due to slow computational speed of the algorithm . We noticed that ' recall rate ' of TAPIR is significantly lower than the other two applications even after we adjusted the cutoff thresholds to maximize the ' recall rate . ' However , TAPIR generated much less predictions than the psRNATarget 2017 release and TargetFinder did , indicating higher prediction precision ( Supplementary Table S3 ) .	52316731	maybe
"To create the raw white light curve , we summed each spectrum over the 181 pixels in the spectral trace . The white light curve has systematic trends that are typical for WFC3 observations ( Zhou et al . 2017 ): the flux increases asymptotically over each orbit ( the "" ramp "" effect ) and there is a visit - long linear trend . The largest ramp occurs in the initial orbit ( orbit zero ) , so we only fit data from orbits one through four in our analysis , following common practice . We fit the light curve with the analytic model of the form F white ( t ) = S white ( t)ÃT white ( t ) , where S white is a systematics model and T white is a transit model . We used the same systematics model as Kreidberg et al . ( 2015 ) . We modelled the transit with the batman package ( Kreidberg 2015 ) . The model parameters are the orbital period p , time of inferior conjunction t 0 , transit depth r p /r s , ratio of semi - major axis to stellar radius a / r s , orbital inclination i , and the quadratic stellar limb darkening parameters u 1 and u 2 ."	119201283	no
"In speech recognition applications it is sometimes necessary to process data continuously as it arrives , so that there will be no latency in response . This makes it necessary that the algorithms used should not have any dependencies that are "" backwards "" in time ."	15370378	no
"MDM2 and MDMX ( also known as MDM4 and HDM4/ HDMX ) downregulate the tumor suppressor p53 . In response to cellular stress , the transcription factor p53 mediates the expression of genes involved in protective processes such as DNA repair , cell cycle arrest , and apoptosis . [ 343,344 ] Binding of MDM2 and MDMX to the N - terminal transactivation domain of p53 blocks this so - called "" guardian of the genome "" , either by mediating its ubiquitylation that finally leads to its degradation by the proteasome [ 345 ] or by acting as a direct antagonist . [ 346 ] An upregulation of MDM2 and MDMX has been detected in many types of cancers , thus resulting in the interaction between these proteins and p53 being prime targets for anticancer strategies . Crystal structures of the complex between MDM2 and the transactivation domain of p53 reveal an a - helical conformation of the p53 interaction domain when bound to MDM2 ( Figure 16 a ) . [ 347 ] P53 hot - spot residues involve Phe19 , Trp23 , and Leu26 . [ 347 ] This structural information together with the crystallographic data of the similarly arranged p53 - MDMX complex [ 348 ] have been used as the starting point for a rational design of the corresponding PPI inhibitors . For some peptidomimetics , helical peptides derived from phage - display selections served as alternative starting points . Examples include the phagedisplay - derived peptides pDi [ 349 ] and PMI [ 350 ] that exhibit dual inhibitory effects for both the p53 - MDM2 and p53 - MDMX complexes . This is considered a desirable feature for efficient anticancer activity . Additionally , mirror - image phage - display ( MIPD ) techniques together with native chemical ligation have provided proteolytically more - resistant d - peptide inhibitors of the p53 - MDM2 interaction . However , these peptides do not feature sufficient cell permeability . [ 351][352][353 ] Finally , although mRNA display has enabled the screening of larger libraries of peptides , [ 354 ] the proteolytic instability and/or poor cellular uptake of these peptides remain major limitations of these approaches ."	17220756	no
showing that in this limit the numerics are under control . For the rescaled equation ( eq.14 ) we can study the lowest mass meson as a function of the quark mass . Figure 3 shows the value of the first meson mass as a function of the quark mass . The important point to note here is that there appears to be a mass gap in the m â 0 limit for l = 0 . The numerics make this calculation difficult , though at m = 10 â10 the value of M 1 is 0.28 . Note that in contrast to the equation of motion with l = 0 , the D7 - brane equation is perfectly well behaved in this limit and has discrete eigenvalues . This will be shown analytically in section 4.2 . The scale is set by the AdS radius R which can be tuned by hand to compare with lattice data .	14226229	no
"RNA concentration , could allow description of "" the real dynamic "" of the virus spreading into the population , allowing for a direct comparison between the three waves . Our data showed that in the Greater Paris area , the first wave showed more highly concentrated samples ( i.e. samples with about 1 million UG / L ) than the 2nd and 3rd waves ( see Fig . 3 ) . Quantitative assessment of SARS - CoV-2 genomes in wastewaters demonstrates the impact of prevention measures such as lockdown or curfew which can Fig . 4 . Relationship between log of the concentration of SARS - CoV-2 genome and the log number of incidence number . Panel A regional scale , in blue average of the 5 WWTP , in red Lowess of the same data . Panel B , in blue SEM WWTP , in red MAV . panel C relationship between SEV and departmental incidence number . Panel D relation between STV and the departmental incidence number panel E , relationship for SEC and Paris incidence panel F , linear regression of all WWTP and the regional average . be once again observed in this project . Some general modeling papers have postulated the decrease of the wave intensity   in accordance with our data ."	245007358	no
To address a potential diagnostic value of miR-574 - 5p , we measured its expression in serum samples from TAA patients and controls ( serum cohort ) . Interestingly , miR-574 - 5p was significantly up - regulated in the serum of patients with TAA compared to the control ( 3 - fold , p < 0.001 ; Figure 2D ) and this up - regulation was higher in patients with a large ( above 49 mm ) aneurysm ( Figure 2E ) . Of note , the cut - off of 49 mm corresponds to the median of the aortic diameter of the TAA group . Circulating levels of miR-574 - 5p are up - regulated in patients suffering TAA independently of the etiology of TAA , compared to the controls ( Figure S3 ) , and miR-574 - 5p levels were not significantly modulated by hyperlipidaemia or the smoking status , either in the control or in the TAA groups ( Figure S4 ) . The ROC ( receiver operating characteristic ) curve analysis revealed an association between miR-574 - 5p and the diagnostic of TAA with an area under the curve of 0.87 ( Figure 2F ) . MiR-574 - 5p discriminated the TAA patients from the controls with a specificity of 85 % and a sensitivity of 78.6 % . These data support a diagnostic potential of miR-574 - 5p for TAA .	199572965	no
To a DCM ( 20 mL ) solution of 4 ( 1.0 g , 0.87 mmol ) was added Me3SiOTf ( 0.35 mL , 1.94 mmol ) at rt and stirred for 2 h. The solvent was evaporated and the crude product was suspended in toluene , filtered , and dried under vacuum to afford 7 ( 1.13 g , 90 % ) . NMR spectroscopic data of this product were identical to that prepared by using 6 and ( Me3S)AuCl ( see above ) .	235074277	no
We determine the ephemeris by measuring the mideclipse time from the CHIMERA g lightcurve . We then use the best model from the Chimera g data and use it fit all ZTF data . In addition , we noticed that there is one non - detection on 2012 - 11 - 1 in Palomar Transient Factory data ( out of 94 observations ) . We add this epoch with half the eclipse duration as uncertainty as a prior ( BJD T DB = 2456232.8854 Â± 0.0018 ) . This results in an ephemeris of : BJD(T DB ) = 2459045.985194(2 ) + 0.431 920 8 ( 14 ) ( 1 )	234763037	no
To a solution of 2,2 - dimethylpropan-1 - amine ( 0.60 mL , 0.44 g , 4.9 mmol ) in dry DMF ( 50 mL ) was added 6methyl-2-(bromomethyl)-pyridine 1 ( 2.00 g , 10.8 mmol ) and K 2 CO 3 ( 1.49 g , 10.8 mmol ) . The solution was stirred at 40 Â° C for 16 h. The organic component was extracted into CH 2 Cl 2 ( 3 Ã 40 mL ) , the extract dried over MgSO 4 , filtered and the solvent was removed under reduced pressure . The product was purified using silica gel chromatography ( Hexane : EtOAc -10:1 ) to yield 1.28 g of L5 as a pale yellow solid ( 88 % ) .    Titration data and speciation curves of L2 and Zn complex 2 . Figure S3 . left : titration of 10 mL of 2 mM L2 and 4 mM HCl with 10 ÂµL aliquots of 0.2 mM NaOH ; right : speciation diagram of 1mM L2 . The theoretical fit and speciation were carried out with Hyperquad and HySS software 3 and gave pK a s of 3.85 and 6.99 . Figure S4 . left : titration of 10 mL of 2 mM Zn complex 2 and 4 mM HCl with 10 ÂµL aliquots of 0.2 mM NaOH ; right : speciation diagram of 1 mM 2 . The theoretical fit and speciation were carried out with Hyperquad and HySS software 3 using formation constants for Zn(OH ) ( 10 -7.84 ) and Zn(OH ) 2 ( 10 -16.86 ) taken from literature . 4 The fit gives pK a s for the Zn complex 2 of 7.84 and 9.02 , and log K d as 4.85 .   Observed rate constants ( k obs ) were obtained by the initial rate method over the first 30 minutes of the reaction . Equation S1 is derived from Scheme S1 , and fitted to the data in Tables S1 to S8 to give the values of k 2 used in Figure S5 .	24006393	no
We next investigated the downstream signaling pathways through which TLR2 induced Raldh2 expression . TLR2 stimulates rapid induction of ERK , which mediates IL-10 production by DCs16,18,23 . Induction of Raldh2 mRNA expression was largely abrogated by inhibitors against ERK ( Fig . 1h ) . Additionally DCs from Erk1 â/â mice had substantially reduced Raldh2 expression upon zymosan stimulation ( data not shown ) . Furthermore , induction of Raldh2 was also inhibited substantially by a syk inhibitor ( data not shown ) . Thus , Raldh2 induction by zymosan is syk - dependent , but largely dectin-1 independent , suggesting that an alternative syk - dependent receptor is likely involved . In summary therefore , zymosan induces Raldh2 expression in DCs via TLR2 - mediated activation of ERK , likely acting in concert with syk - dependent signaling via another receptor .	13330925	no
Finally , t he biomimetic tetranuclear [ MoFe 3 S 4 ] 2 + and [ Fe 4 S 4 ] 2 + and the MoFep rotein of nitrogenase were studied ( Figure 6C ) . All samples contain Fe II , a nd the resonant excitation into the pre - edge yields two distinct features split by~0.9 - 1.3 eV at their maxima due to the additional 5 Dterm discussed above . Once again , inspection of the D RXES and D XES highlights the ability of 1s3p RXES at the pre - edge region to identify the presence of ferrous iron , which is not possible using the Kb XES spectra alone . Future studies including 1s3p RXES full planes collected with higher resolution instruments may allow for amore rigorous quantification of the changes in electronic structure , e nabling better distinction between the different intermediate states . N evertheless , t hese results demonstrate that even in highly covalent systems , meaningful differences in 3d metal valencypersist in the 1s3p RXES data .	231766706	no
The proposed TD method is the first data - specific metric to detect adversarial audio , which focuses on how many adversarial instances are captured ( true positive ) without affecting benign instances ( false positive ) . Therefore , we report the area under curve ( AUC ) score to evaluate the detection efficiency . For the proposed TD method , we compare the temporal dependency based on WER , CER , as well as the longest common prefix ( LCP ) . LCP is a commonly used metric to evaluate the similarity between two strings . Given strings s 1 and s 2 , the corresponding LCP is defined as max s1[:k]=s2[:k ] k , where [: k ] represents the first k portion of a sentence .	52891543	no
Even though the information preference property of VAE might suggest that one should always use the full autoregressive models to achieve a better code length / log - likelihood , especially when slow data generation is not a concern , we argue that this information preference property can be exploited to turn the VAE into a powerful representation learning method that gives us fine - grained control over the kind of information that gets included in the learned representation .	15534684	no
Progress in achieving the millennium development goals has been substantive but uneven , with its equity , effectiveness , and sustainability being often undermined by lack of integration into national health systems . Even where efforts have been made to embed services at the community level , such as in the roll - out of integrated community case management of childhood illness programmes , a lack of full integration and stewardship by national health systems has hindered service use and sustainability . 8 Disease specific approaches often fail to tackle the delivery of services for other diseases or to sustainably strengthen common delivery platforms . 9 Despite both methodological and data limitations in the evidence , 10 there are clear indications that working towards integrated service delivery can improve healthcare use and outcomes . 11 The desire for focus on specific conditions is understandable , but efforts need to be aligned with and steered by national health systems and must be accompanied by deliberate attempts to create synergies with other priorities of the health system .	32617523	no
Each test was repeated at least three times in the present work . The data were presented as the means Â± standard deviations . Statistical analysis was performed using one - way analysis of variance .	252843568	no
are in better agreement with the data . Note that while the Tevatron bounds are somewhat sensitive to the assumption that all the SM fermions are localized close to the Planck brane due to possible variations in the width of the W 2 and Z 2 , this is not true for those from LEP .	623450	no
This research focused on sustainable manufacturing capabilities . The proposed OSR model and associated tool aims to help companies assess their organisational readiness relating to specific capabilities to achieve sustainable manufacturing . The sustainable manufacturing capabilities shared by the case companies as well as the associated themes emerging from the empirical data analysis were already well - addressed in the literature published a decade ago ( e.g. , DeSimone and Popoff , 2000;Liyanage , 2007;Epstein et al . , 2010;Hart and Dowell , 2011 ) . Although the findings of this study did not uncover new capabilities or new themes , they are wellaligned with the literature , thus demonstrating good construct validity of the OSR model .	229426053	no
Moving forward , we believe it 's exciting to extend this principle of learning lossy codes to other forms of data , in particular those that have a temporal aspect like audio and video . Another promising direction is to design representations that contain only information for downstream tasks and utilize those representations to improve semi - supervised learning .	15534684	no
There is limited literature data on   Storage of compost . Oral contamination through contaminated hands is possible for biological and chemical contaminants . This risk is particularly pronounced for children . Studies have shown that a child may ingest as much as 100 mg / day of dust from the soil , and when the child suffers from geophagy -or pica -(pathologic exaggeration of the hand - mouth behaviour ) this may increase up to 5 g [ 82,83 ] . Environmental contamination may result from open air storage of compost or under bad or inadequate protection which exposes it to rain . Pollutants are then washed by rain and carried along by water run - off or spread by percolation into the soil . Wind may also disperse inadequately stored composts . The storage of immature compost also provokes the emanation of a nauseating odor .	11612994	no
To control for potential confounding effects of geography , 16 temporal trends in outcomes , and hospital characteristics , we used a concurrent control group for comparison . This group consisted of all hospital admissions with an intensive care unit stay from hospitals located across the other 11 states in the US Midwest region ( as defined by the US Census Bureau ) , with hospital selection based on a random sampling methodology stratified by hospital bed size and teaching status Unadjusted and adjusted population level data on hospital mortality and average length of stay in Michigan hospitals and comparison hospitals ( 364 hospitals ) . Using this sampling methodology , we initially selected 64 % ( n=631 ) of hospitals in the Midwest region for the comparison group , including all large teaching , large non - teaching , and small teaching hospitals in the region . After exclusions , the final comparison group represented 37 % ( n=364 ) of Midwest hospitals . The sample size calculation was conservatively based on the number of hospitals , rather than hospital admissions , because the analysis accounted for clustering of admissions within hospitals . The sample size calculation assumed a power of 0.80 , a two tailed Î± of 0.05 , detection of a difference in reduction in length of stay between study and comparison group hospitals of 0.1 days ( group standard deviation 0.3 ) , and a fixed study group size of 90 hospitals ( an initial conservative estimate of the number of Michigan hospitals during the study period ) , resulting in a 4:1 ratio of comparison to study group hospitals .	211808	no
Data supporting the findings are found within the manuscript and supplemental tables . Raw data files will be provided by the corresponding author upon request .	73439113	yes
We extended this approach to in vivo imaging by analyzing TSFG signals in 2 dpf zebrafish embryos submitted to artificial hypoxia . Embryos were mounted as described previously except that the observation chamber was sealed ( Fig . 4b ) . The embryo and agarose were deposited in a â 100 ÂµL well at the bottom of the microscope slide , and covered with a coverslip sealed with silicone ( twinsil speed , Picodent , Germany ) while the agarose was still liquid . Within 10 min after mounting , the imaging session started and consisted in recording a time series of 30 images every 5 min during several 2 - 5 hours . After that session , the top cover glass of the chamber was removed to recover normoxia , the dish was filled with embryo medium and placed back under the microscope with the embryo still embedded in agarose . The same region was then imaged . The time between the last hypoxia image and the first one after opening chamber was < 15 min . From the recorded images , we segmented the RBCs and extracted the average oxygenation parameter R = S 401 / S 433 at each time point . Figure 4b shows the time evolution of R in the case of one embryo . The values of R before , during , and after hypoxia for nine embryos is presented in Fig . 4c . We consistently observed a decrease of the R parameter during the hypoxia assay ( typically-40 % after 3 h ) , suggesting that the limited oxygen supply inside the small chamber volume was being consumed by the embryo . After chamber opening , the R parameter returned to its original value , indicating that RBCs recovered their oxygenation state within minutes after hypoxia . This fast recovery is consistent with 58 . Together , these data provide strong evidence for the possibility of label - free functional TSFG microscopy . Importantly , our implementation can probe RBCs in vivo with single - cell resolution and microsecond pixel dwell times .	256269117	no
Although ANN does not depend on the multivariate characteristics of the data , we also examined the data to assess whether they were homoscedastic or heteroscedastic because this allowed us to understand the nature of the data more fully . We employed two approaches for this purpose - first , by using the Glejser test for heteroscedasticity ( Glejser , 1969 ) and , second , by plotting the standardised regression residuals and the dependent variables ( Figs . 2 and 3 ) . Visual inspection confirmed the data to be homoscedastic .	245008959	no
Within the scope of the study , multivariate statistical analysis methods were used in the analysis of the data . SPSS 22 statistical software and Amos 20 software were used in the analysis of the data obtained . Accordingly , Cronbach Aplha and Composite Reliability tests were performed for frequency analysis , scale reliability , AVE values were checked for validity and structural equality modelling ( SEM ) was used to test linear relationships between variables in the model , which includes the main subject of the study , consumers ' attitude towards drone delivery and perceived threat , related primary variables and behavioral intention relationship .	235574170	no
Loneliness refers to a subjectively unpleasant experience that results from a perceived deficiency in one 's social relationships ( Peplau and Perlman , 1982 ) . Concerns about increased loneliness have been expressed and reported in studies utilizing cross - sectional data sets during the COVID-19 pandemic ( Beutel et al . , 2021;Bu et al . , 2020b;Cohn - Schwartz et al . , 2021;Groarke et al . , 2020 ) , and , for example , a longitudinal study on the Dutch general population reported increased prevalence of emotional loneliness after the outbreak of the virus ( van der Velden et al . , 2021 ) . However , some previous longitudinal investigations have reported no significant population - wide changes after the outbreak of the pandemic but have found some evidence of increased loneliness in subgroups such as single individuals living alone , older people , and extroverted youth while social distancing were in effect ( Alt et al . , 2021;Hansen et al . , 2021;Luchetti et al . , 2020;van Tilburg et al . , 2021 ) .	245335854	no
Theresult of this analysis is shown in Figure 2and highlights that the disposition of the phosphorus and magnesium centers within compound 9 is consistent with the coupling pattern observed in the solution - state 31 PNMR spectrum and the multiplicity of signals arising in the 1 Ha nd 13 CNMR data . Thes tructure comprises two ( Dipp BDI ) magnesium units bonded to a [ nBu 2 P 8 ] 2Ã cluster dianion derived from the formal reductive coupling of two neutral P 4 units . A lthough the rationality of this { P 8 } c luster synthesis from the combination of two { P 4 } f ragments appears to be unique , i ts structure may be considered as ah eptaphosphanorbornane fused to an exo - oriented cyclotriphosphane ring and ac onstitutional isomer of the { P 8 } c age within the niobium(V ) species [ Ph 2 CP 8 Nb(OC [ 2 Ad]Mes ) 3 ] , which was derived through treatment of compound 1 with benzophenone . [ 14 ] Thes ingle tris(enolato ) niobium dication and the { Ph 2 C } unit of this previously described species is replaced in the present case by two ( Dipp BDI ) magnesium monocations and two n - butyl substituents . T he magnesium centers contact the Subsequent preliminary investigations indicated that the kinetic control exerted during the syntheses of compounds 8 and 9 is an apparent consequence of the steric demands of both the supporting ( Dipp BDI ) platform and the reactive nbutyl co - ligand . Analysis by 31 PNMR spectroscopy of areaction between [ ( Dipp BDI)MgH ] 2 and half amolar equivalent of P 4 provided am ixture of several phosphorus - containing species . A lthough am inor component comprised broadened resonances at d Ã3.5 and Ã159 ppm reminiscent of those observed for compound 8,the major product of this reaction was characterized by atriplet signal observed at d Ã284.8 ppm ( 1 J P - H = 45 Hz ) . This latter species was identified as the trimeric primary magnesium phosphide , c ompound 10 , through afurther X - ray analysis performed on single crystals produced by fractional crystallization of the reaction mixture ( Figure 3a ) . Analytically pure samples of compound 10 , Figure 2 . ORTEP representation ( 30 % probability ellipsoids ) of compound 9 . [ 17 ] Hydrogen atoms , isopropyl methyl groups and n - butyl groups aside from the P - bonded C59 and C63 atoms were removed for clarity . S elected bond lengths [ ] and angles [ 8 8 ] : P1- P5 2.195 ( 3 ) ( 14 ) , P1 - P5 - P6 92.00 ( 12 ) , P4 - P5 - P6 , 105.80 ( 12 ) , P7 - P6 - P85 9.27 ( 11 ) , P7 - P6 - P5 106.69 ( 12 ) . . ORTEP representations ( 30 % probability ellipsoids ) of a ) compound 10 with hydrogen atoms ( except those attached to P1 , P2 , and P3 ) and isopropyl methyl groups removed for clarity , a nd b ) compound 11 with hydrogen atoms and mesityl methyl groups removed for clarity . [ 17 ] notable as the first primary phosphide of aG roup 2e lement to have been structurally characterized , were found to be unstable once redissolved in [ D 8 ] toluene . M onitoring by 1 H and 31 PNMR spectroscopy at room temperature evidenced the onset of ar edistributive process to as yet unidentified magnesium - containing species and the production of PH 3 , which was observed as abinomial quartet at d Ã245.0 ppm in the 31 PNMR spectrum .	13863997	no
Shape - memory polymers ( SMPs ) represent a very interesting class of stimuli - responsive materials . [ 1 ] The triggered change from a temporary shape to a preprogrammed permanent one ( i.e. , very well suited for the reversible ( switching ) phase ) . [ 25 ] The results of the ITC study are summarized in Table S1 and Figures S3 - S10 in the Supporting Information . Both , zinc(II ) trifluoromethane sulfonate ( Zn(TFMS ) 2 ) and nickel(II ) chloride , featured the desired complexation behavior , i.e. , simultaneous formation of stable terpyridine complexes and labile ones with the histidine ligands . Furthermore , it is important that at the minimum two ligands bind to one metal ion in order to form supramolecular crosslinks . Furthermore , to investigate the procedure of the complex formation when both ligands are present , like it is in the later desired polymers , a 1:1 mixture of both ligands was utilized in the ITC measurement ( ITC titration data in Figures S11 and S12 in the Supporting Information ) . Performing this experiment , it was found that the terpyridine is complexed by half an equivalent of the metal salt in the presence of the histidine . Thus , all the terpyridine ligands are complexed before a complexation of histidine ligands starts and , consequently , no mixed complexes can form , which was additionally confirmed via 1 H NMR measurements ( Figure S13 , Supporting Information ) .	231612311	no
where clearly a drastic decrease of E. coli colonies is observed using the amphiphilic drug release system under visible light irradiation ( Figure 5C ) if compared with the results obtained in dark ( Figure 5D ) . The result demonstrates the hydrophobic cap can efficiently prevent the leaching of the AMP or the influx of the aqueous surrounding media in dark . I.e. , the drug delivery system is comparably stable against drug leakage if stored in dark . XPS data in Figure S3 and Figure S8 also confirm the photocatalytic scission of the hydrophobic chain and the alkyl chain that connects the drug to wall by visible light irradiation . Moreover , if the Au decorated top layer is removed before visible light irradiation ( Figure S9 ) , the drug molecules can not be released .	25983948	no
At r h > 25 au , the coma is too weak to be well measured in the data . It is possible that more volatile species ( N 2 , CH 4 , or CO ) could have dominated sublimation at these times . These latter species , however , have orders of magnitude higher vapor pressure ( and specific sublimation rates ) than CO 2 and N H 3 do at T = 78 K , the Î· = 1 subsolar temperature for r h = 25 au . Any surface abundance in their pure ice forms on the surface of BB must be very low relative to the CO 2 /N H 3 that appear to dominate sublimation at r h â¤ 25 au . Perhaps these more - volatile species were heavily sublimated from BB during its previous perihelion passage to â 18 au , , leaving behind a crust that is . Left : Following Eq . 18 and assuming radiative equilibrium temperatures , we plot the log of AfÏ v th â T vs 1 / T , which should yield a straight line if the coma 's scattering strength is proportional to the sublimation rate of a single species following the Clausius - Clapeyron ( CC ) relation . For either the fast - or slow - rotator bounds on radiative equilibrium ( Î· = 0.75 , 1 ) , the data are well fit by such a form . Right : Relative probability of the enthalpy of sublimation âH in a fit of Eq . 18 to the measured values of AfÏ , marginalizing over the scaling constant . The central red curve gives the nominal case , with Î· = 1 and a dust velocity scaling with the thermal velocity . The left blue curve assumes a fast - rotating limit ( Î· = 0.75 ) and the right dashed curve assumed dust velocities scaling with radiation pressure ( v d â T 4 ) . The enthalpies of sublimation of potential cometary volatiles are marked : the data strongly favor CO2 or N H3 as the driver of BB 's mass loss to date .	237581632	no
In Fig . 8 we show the correlation between C Bs and Br(B â X s Î³ ) normalized to its central SM value . The main message from this plot is that Br(B â X s Î³ ) is changed by at most Â±4 % which is welcomed as the SM agrees well with the data . It will be very difficult to distinguish LHT from the SM in this case . New physics effects in Br(B â X d Î³ ) and A CP ( B â X s , d Î³ ) are small .	18156021	no
Google Trends ( GT ) tool was introduced in 2008 and provides a public view for relative internet search volumes of some queries identified by keywords . The main advantage of Google search is related to nowcasting and forecasting in real time which is a solution of macroeconomic indicators that are released late ( Simionescu and Zimmermann , 2017 ) . The data are based on a representative subsample permanently updated .	237473259	no
â¢ We emphasize , however , that the structure of the mixing matrix V Hd can differ significantly from the known structure of the CKM matrix so that interesting departures from MFV correlations between various processes are possible . Basically all MFV correlations between K , B 0 d and B 0 s meson systems can be modified , while being still consistent with the existing data , even if these modifications amount to at most 30 % in the case of the CP - conserving observables considered here .	18156021	no
By comparison of the 3D structures of Polb and TdT , a TdTspecific loop ( loop1 ; 383 - 400 amino acids ) , located in the palm subdomain ( see Figure 1A ) , was proposed to be important for the specific properties of TdT ( 2 ) . By inspection of the multiple amino acid sequence alignments of Polb , TdT and Polm ( 2,6,8 ) it is apparent that a homologous region to loop1 is present also in Polm ( 367 - 385 amino acids ; see Figure 1A and B ) . Moreover , tridimensional modelling of Polm on the TdT crystal structure , carried out as described in Materials and Methods , predicts a similar spatial location of the region homologous to loop1 , located in the palm subdomain ( data not shown ) .	17553026	no
"Bioinformatics is a powerful tool to find genes associated with a function or involved in a regulatory network ( Figure 1B , left ) . In the case of paradigmatic organisms , such as E. coli , databases contain the up - to - date description of regulatory networks , including the organization of the genes in transcription units , operons , and entire regulons based on experimental data [ 17][18][19][20][21 ] . Additionally , curated databases containing exclusively functional information on TRs [ 22 ] or their putative DNA - binding sites [ 23][24][25 ] are constantly expanded . Hence , finding the annotated genes corresponding to a TR of interest linked to the regulated genes can be a direct task . In other bacteria , gene annotation is often not as complete ; thus , new regulatory networks must be established to find regulons of interest . There is a constant effort to improve regulon prediction with bioinformatics tools [ 26][27][28 ] to address the limits set by the degeneracy and variability of the conserved regulatory motifs in operons around their promoter regions . Thanks to this effort , the accuracy of bioinformatic algorithms that combine transcriptomic and other "" -omics "" data to their pipeline has greatly increased in the last decade [ 29,30 ] ."	246970641	no
5 - Iodo-2Â´-deoxyuridine ( 10.2 g , 28.9 mmol ) was co - evaporated with distilled pyridine ( 3 x 10 mL ) and dissolved in distilled pyridine ( 80 mL ) . To this was added drop - wise a solution of DMTCl ( 9.79 g , 28.9 mmol ) in distilled pyridine ( 50 mL ) over a period of 20 min and the reaction was stirred at rt for 3 h. An additional 0.2 eq DMTCl was added and the reaction stirred for a further 2.5 h. The reaction was quenched by the addition of MeOH ( 80 mL ) and was stirred for 20 min . Characterisation data recorded matches previously reported literature values ( 11 ) .	2777408	no
A dry 50 mL Schlenk flask with magnetic stirring bar was charged with 854 mg ( 3.36 mmol , 1.0 eq ) 4-(benzyloxy)isobenzofuran-1,3 - dione ( 11 )   The spectra are in accordance with previously reported data . [ 8 ] ( S)-9- ( Benzyloxy)-1,2,3,11a- The solvent was removed in vacuum and the resulting solid was dried in oil pump vacuum . [ 8 ] Yield :   The spectra are in accordance with previously reported data . [ 8 ] Benzyl ( S)-9-(benzyloxy)-5,11 - dioxo-2,3,11,11a - tetrahydro-1H - benzo saturated NH 4 Cl solution were added and the mixture was stirred for 5 min . The mixture was diluted with CH 2 Cl 2 ( 50 mL ) and the solid was removed via filtration through a sintered glass frit and was rinsed with CH 2 Cl 2 . The combined organic phases were dried over Na 2 SO 4 , filtrated and the solvent was removed in vacuum . The product was purified via column chromatography ( 60 g silica gel , size : 20 x 3 cm , cyclohexane / CH 2 Cl 2 /acetone = 10:10:1	5458160	no
The study included the understanding of the whole system process flow by means of sites investigation , business process familiarization , data collection and conducting interviews with the staff in the Linens Department . After much sites investigation of the existing process , various problems and inventory shrinkages were identified with recommended possible redesign and RFID - enabled solutions .	154267117	no
The corporation did , in fact , intentionally seek to bankrupt me by forcing me to spend on legal fees . I saw that game really quick and knew I could n't play that game to win . I knew I had to learn to do it myself because I would never have enough money to fight them . I learned quickly and had some wins , but the bottom line is a per - se litigant does not have equal footing in our judicial system to obtain justice . ( Male , Manufacturing , US ) An effective legal strategy is an essential part of a successful whistleblowing campaign . As the above response indicates , it can be difficult where whistleblowing cases are complex ( see also Kenny , 2019 We tested for differences between countries in terms of legal costs reported and did not find significance . We note Fig . 1 Change in income as a result of disclosing , for those providing data . ( Note : 1.0 represents no change , while 0.5 represents a decrease by 50 percent in earnings ) that 48 people described having part of their legal fees waived by lawyers , paid by a union or receiving assistance from a whistleblower support group , but that costs were significant , nonetheless .	245516492	no
The short Pt â¦ Pt distance found in the solid state stimulated us to look for signs of the metalophilic Pt â¦ Pt interaction in solution . Emission and absorption spectroscopy studies were hence undertaken at a concentration of 50 Î¼m in methanol or in aqueous solutions . In methanol , both complexes were highly soluble , and spectroscopically speaking , comparatively highenergy absorption ( 451 nm or lower ) and emission maxima ( 604 for [ 1]OAc and 556 and 591 nm for [ 2]OAc , see Figure 2a ; Table S6 , Supporting Information ) were found , which suggested an absence of metalophilic interaction and hence monomeric species . The distinct absorption of both isomers in MeOH can be attributed to their different HOMO - LUMO gap ( Figure S6a , Supporting Information ) , which critically depends on the proximity between the PtîC bond and the non - bonding electron pair on the NMe bridge . [ 22 ] While in aerated methanol ( 50 Î¼m ) , the luminescence of both complexes was weak , as characterized by low quantum yields ( below 0.0015 , Table S6 , Supporting Information ) ; in degassed methanol , their luminescent quantum yield increased â2 - 4 times ( still remaining lower than 0.005 ) , which demonstrated the triplet nature of the excited states of these monomers , but also suggested that O 2 is not so good at quenching the monomer emission . This observation was confirmed by the singlet oxygen generation quantum yield , which was moderate in aerated methanol solution ( ÏÎ = 0.44 for [ 1]OAc , 0.11 for [ 2]OAc ) . The photodynamic properties of both complexes were hence limited as monomers in methanol . In frozen MeOH / EtOH mixtures ( 77 K , Figure S8b , Supporting Information ) , the phosphorescence quantum yield was further increased by a factor > 20 for [ 1]OAc and > 100 for [ 2]OAc ( see Table S6 , Supporting Information ) , suggesting possible intermolecular ( triplet - triplet annihilation ) or intramolecular ( vibrational ) quenching routes at room temperature . Limited quenching by O 2 was confirmed by luminescent lifetime measurements ( Table S6 and Figure S8 , Supporting Information ): for both isomers , biexponential decay was observed , but considering the very low phosphorescence intensity , we interpret the short component Ï 1 as a consequence of scattered light from the laser pulse ; the longer lifetime Ï 2 , which we interpret as that of the Pt complex , increased by a factor of 2 - 4 upon degassing ( e.g. , from 150 to 602 ns for   for [ 2]OAc , see Table S6 , Supporting Information ) . According to TDDFT calculation on the monomeric cations [ 1 ] + and [ 2 ] + and to data above , the weak emission in methanol can be assigned to triplet ligand - to - ligand charge - transfer ( 3 LLCT ) transitions with a small triplet metal - to - ligand charge - transfer ( 3 MLCT ) character .	236774239	no
The spectral data match literature . 20 1.0 eq . ) in dry DCM ( 10 mL ) at 0 Â° C . After complete addition , the cooling bath was removed and the mixture was allowed to stir at room temperature overnight . The volatiles were removed under reduced pressure , water ( 15 mL ) was added carefully ( cooling ) to the residue followed by NaOH pellets ( 1.97 g , 49.2 mmol , 8.0 eq . ) and the mixture was stirred at room temperature for 6 h , heated to reflux for 30 min and stirred overnight at room temperature . EtOAc ( 40 mL ) was added , the phases were separated and the aqueous layer was extracted with EtOAc ( 2 x 10 mL ) . The combined organic extracts were dried over Na2SO4 and evaporated . The crude was purified by automated flash chromatography ( EA : Hx , 0 Ã  10 % EA ) with 4 - ethyl-1H - pyrrole-2 - carbaldehyde ( S7 ) eluting at 8 % EA ( yellow - brownish oil ( 139 mg , 1.13 mmol , 18 % ) ) and 3 - ethyl-1H - pyrrole-2 - carbaldehyde ( S8 ) eluting at 10 % EA ( faintly yellow oil ( 295 mg , 2.40 mmol , 39 % ) ):	233859029	no
Although WT and Lmo2 â/â ES cells have a similar capacity to produce Flk-1 + cells , our experiments showed that LMO2 exerts its function already at the HB stage by positioning the LMO2 complex to regulatory elements important for the establishment of the haematopoietic program . As the peaks identified by the three - way overlap of the LMO2 , TAL1 and LDB1 ChIPseq data were the sites with the highest number of reads in each of the independent samples , we conclude that these regulatory elements   Table showing the number of genes associated with LMO2 ChIPseq peaks that have increased or decreased expression ( > 4 - fold ) in WT compared to Lmo2 â/â cells . ( D ) Heat map of hierarchically clustered genes that associate with common TAL1 , LMO2 and LDB1 ChIPseq peaks . These genes are either the nearest 5 or 3 gene , or contain the peak within the gene body . Scale bar represents colour index for the log 2 FPKM values . Self - organizing tree analysis identified three clusters , which are numbered 1 to 3 . exhibit the highest affinity for this complex . In the absence of LMO2 , binding of TAL1 only remained at the strongest of these binding sites , albeit at a lower level , whereas the majority of TAL1 binding was found at novel binding sites . It has previously been shown that the interaction of LMO2 with TAL1 directly increases the stability of TAL1 / E2A heterodimer ( 57 ) . Experiments with TAL1 DNA - binding deficient mutants showed that DNA - binding activity of TAL1 was dispensable for specification of haematopoietic development ( 53 ) , only when the interaction of the TAL1 HLH domain with LMO2 was retained ( 57 ) . In addition , in the presence of LMO2 , TAL1 could associate with chromatin in the absence of its DNA binding domain , albeit with a lower affinity ( 58 ) . Our motif analysis of the threeway overlap of LMO2 , TAL1 and LDB1 ChIP indicated a very strong enrichment of GATA binding motifs ( Figure 5 ) . Taken together , this indicates that the interaction through LMO2 plays an important role in directing TAL1 to the correct binding sites , whereas without LMO2 , TAL1 has lower DNA binding activity and specificity . Comparison of our data to previously published LDB-1 ChIPseq data in Flk-1 + cells ( 28 ) and in Lin â bone marrow ( 59 ) showed that the overlap is particularly enriched for those LDB1 peaks that are part of the three - way overlap ( 83 % and 51 % of LMO2 , TAL1 and LDB1 ChIP peaks respectively ) . In addition , our and previous studies identify the same list of target genes ( e.g. Tal1 , Gata2 , Runx1 , Lmo2 , Runx2t2 and Sox7 ) . Intersecting the lists of differentially expressed genes reported by Mylona et al . indicated that the Ldb1 â/â was more similar to the Tal1 â/â , in line with the developmental block occurring earlier than in the Lmo2 â/â . Meta - analysis of the LMO2 complex binding sites identified an overrepresentation of regulatory elements important for haematopoietic development . These included transcription factor genes known to be important at the HB stage ( e.g. Fli1 ( 52,59 ) , Gata2 ( 32 ) , Erg ( 55 ) ) , genes that are important for the HE and endothelial - haematopoietic transition ( e.g. Gfi1 ( 60 ) ) , those with known haematopoietic stem cell function ( e.g. Lyl1 ( 61 ) , Stat3 ( 62 ) ) , and transcription factors with more lineage restricted functions ( e.g. Ebf1 ( 63 ) , Gata1 ( 64 ) , Nfe2 ( 65 ) ) . Our findings indicate that already at the HB stage , LMO2 primes transcription factor genes which will be upregulated at later stages of haematopoiesis and thus regulates all steps of haematopoietic development .	8513595	no
where k refers to each of the 12 USDA soil texture classes ( Ballabio et al . , 2016 ) , USDA k is a texture correction factor taking as values : 0.25 ( sandy soils ) , 0.5 ( sandy clay , sandy clay - loamy , sandy loam and silt ) , 0.75 ( loamy sand , silt - loam , silty clay , silty clay - loam ) and 1 ( clay , clayloam , loam ) . The value of the texture correction factor is based on available SLCH data reported in the literature ( Smit et al . , 1998;Poesen et al . , 2001;Ruysschaert et al . , 2006a ) and at field plot scale in Belgium ( Ruysschaert et al . , 2007c ) . The term ha k refers to the area of arable land in the specific region which has a given USDA k - value ( Ballabio et al . , 2016 ) . In a third step ( Fig . 1 ) , we applied the SLCH rates per country using available data from the literature ( Ruysschaert et al . , 2005(Ruysschaert et al . , , 2006a . Based on these data ( Ruysschaert et al . , 2005(Ruysschaert et al . , , 2006a , SLCH for the sugar beet equals 8.7 t ha â1 per harvest in Belgium , 6 t ha â1 per harvest in Germany , 10 t ha â1 per harvest in Denmark , 10 t ha â1 per harvest in France , 7 t ha â1 per harvest in the Netherlands , 5.6 t ha â1 per harvest in Spain and 4.7 t ha â1 per harvest in United Kingdom . In addition , we analysed data from the grey literature and found that SLCH is ca . 5 t ha â1 per harvest in Greece ( Mikoniati , 2016 ) and 2.3 t ha â1 per harvest in Croatia ( JuriÅ¡iÄ et al . , 2011 ) . There is a tendency for smaller SLCH rates in Mediterranean countries compared to north European countries because of the dry soil conditions at harvest time which largely controls the magnitude of SLCH .	73420972	maybe
We adopt the theory of cultural lag to investigate individual privacy in modern society . When individuals present their opinions , preferences , and thoughts online , their control over this content seems certain at first - that is , the data is co - controlled by an individual both as the data provider as well as the data controller / processor . However , this is not the case for copied , retweeted , shared , or modified versions of the originals , as the original data provider no longer has control over the new data . When the control of the original data provider is uncertain , any guarantee of individual privacy is meaningless , although it is often observed ( Gurevich et al . 2016 ) . At this point , the cultural lag of individual privacy can be observed ; societies and nonmaterial culture are unable to keep pace with the rapid changes in technologies and material culture . Consequently , society must make social adjustments to address this lag .	231744099	no
Various bnAb combinations and bispecific Abs , enabling consecutive targeting of different epitopes , are in clinical development for HIV-1 prevention 16,17 . Predicted potency - breadth curves have suggested that a triple combination consisting of one CD4bs - targeting bnAb , one V2 glycan - targeting bnAb and one V3 glycan - targeting bnAb would have the best neutralization coverage against a panel of clade C viruses 7 . One such combination , VRC07 - 523LS ( CD4bs ) , PGT121 ( V3 glycan ) and PGDM1400 ( V2 glycan ) , has been predicted to have 99 % neutralization breadth ( IC 80 < 10 Î¼g ml -1 ) and a geometric mean IC 80 of 0.09 Î¼g ml -1 against a diverse panel of viruses , compared with 76 % neutralization breadth and a geometric mean IC 80 of 2.64 Î¼g ml -1 for VRC01 alone 17 . ( LS refers to a Fc - modified version to extend half - life . ) This specific triple - bnAb combination is in development for potential efficacy testing and has been safely administered to adults without HIV in a recent phase 1 study 18 . We therefore decided to apply PT 80 to predict PE of 20 or 40 mg kg -1 each of PGT121.414.LS , PGDM1400LS and VRC07 - 523LS delivered together IV . Using available serum concentration data 18,19 , steady - state serum concentrations of each bnAb over 16 weeks were simulated based on popPK modeling ( Methods ) . Because data from the LS forms of PGT121 and PGDM1400 are not yet available , the predictions considered a possible increase of 2.5 - fold in elimination half - life conferred by the LS mutation , with 2.5 - fold being a conservative assumption based on the previously reported fourfold increase 20 . Our results suggest that PT 80 > 200 of a bnAb regimen to a given exposing virus would provide 90 % or higher efficacy to block HIV-1 acquisition with that virus . We applied this threshold ( PT 80 > 200 ) in our definition of neutralization coverage . Neutralization coverage by at least one bnAb in the regimen , averaged over time for a 16 - weekly regimen , and to the 47 viruses ( all subtype C ) acquired by 29 placebo recipients from 703/081 was 71 % ; neutralization coverage averaged over time and to the 70 viruses ( 90 % subtype B ) acquired by 35 placebo recipients from 704/085 was 73 % ( Fig . 6a , b ) . In contrast , neutralization coverage of VRC01 ( at 30 mg kg -1 ) averaged over time and to the 703/081 or 704/085 viruses was 8 % .	251742233	no
Basically , Theorem 5 says that the Gram matrix G â should have high chance of having large smallest eigenvalue if the training data are uniformly distributed . Intuitively , we would expect the smallest eigenvalue to be very small if all x i are similar to each other . Therefore , some notion of diversity of the training inputs is needed . We conjecture that the smallest eigenvalue would still be large if the data are Î´ - separable ( i.e. , x i â x j 2 â¥ Î´ for any pair i , j â [ n ] ) , an assumption adopted by Li and Liang [ 2018 ] , Allen - Zhu et al . [ 2018 ] , Zou et al . [ 2018 ] .	166227799	no
"Other details of this deep learning - based , data - driven design of diffractive layers are presented in the section "" Image datasets and diffractive network training parameters "" . After the training is over , which is a one - time effort , the estimate transformation matrix and the corresponding vectorized form , Aâ² and vec(Aâ² ) = aâ² , are computed using the optimized neuron transmission values in Eq . 2 . After computing aâ² , we also compute the normalization constant , m , which minimizes âa â maâ²â 2 , resulting in :"	237267110	no
The CES - D 8 and 10 item versions were implemented with yes / no response options at follow - up , respectively in ELSA and HAPIEE . For HAPIEE , the CES - D 8 version was simulated by eliminating two items on interpersonal relations that formed the CES - D 10 . The CES - D 8 measured whether 8 symptoms on depressed affect , somatic and retarded activity and positive affect were experienced for ' much of the time during the past week ' ( Radloff , 1977;Steffick , 2000 ) . Affirmative and negative responses to the first 6 and last 2 items , respectively , each counted as 1 ; and were summed to derive a score ranging from 0 to 8 for participants with data on at least 6 of the 8 items , as scoring guidelines require complete data on at least 75 % of the CES - D scale ( Radloff , 1977 ) .	199405167	no
In the case of the signal process , top quarks are produced more abundantly relative to their antiquark partners due to the charge asymmetry of the W boson radiated from the initial - state quark in pp collisions at the LHC . This leads to a higher relative background contamination in the l â final state arising from top antiquark decay compared to the l + final state from top quark decay , as shown in Fig . 7 . As a result , the measurement in the l â final state is more sensitive to the sources that significantly alter the background contributions along with the signal , compared to the ones that impact the signal contribution only . This is reflected in Table 3 where the uncertainties from the signal modeling are lower for the l â case ; whereas other sources , except for the ones listed under flavor - dependent JES , that alter the background contributions along with the signal have a larger impact on the total uncertainty . In the case of the flavor - dependent Table 3 : Summary of the m t uncertainties in GeV for each final - state lepton charge configuration . The statistical uncertainties are obtained by performing the fits again in each case while fixing the nuisance parameters to their estimated values from data . With the exception of the flavor - dependent JES sources , the total systematic uncertainty is obtained from the quadrature sum of the individual systematic sources . The amount of statistical fluctuations in the systematic shifts are quoted within parentheses whenever alternative simulated samples with systematic variations have been used . These are determined from 1000 pseudo - experiments in each case . Entries with < 0.01 denote that the magnitude of the systematic bias is less than 0.01 .	245547826	no
"The "" power - law "" divergences q ( 2nâ1 ) impose further conditions on the asymptotic data , namely the boundary geometry should be such that spinors Ç« ( â 1 2 ) satisfying specific differential equations exist . In d = 2 there is no such divergence . For d = 3 , 4 the only divergent term is q ( 1 ) . This results in the following condition 6"	15634518	no
The above expression is obtained by using , among other things , the remarkable gauge covariant Kaehler identity igr s ( x)D Ac xrD Ac x s â ig rs ( x)D Ac x r D Ac xs = x * A Ï . ( 5.18 ) This calculation shows the topological nature of the theory . All dependence on the metric of Î£ and the background connection A 0 is again buried inside the gauge fermion Î¨ P W . The topological quantum field correlators , therefore , are going to be independent from these data .	14470760	no
The fluorescence lifetime images were recorded using DCS-120 confocal laser scanning FLIM system based on a TCSPC module ( SPC-150 , Becker & Hickl , Berlin , Germany ) . The scanner was attached to an inverted microscope ( ECLIPSE TE2000 - E , Nikon , Japan ) . Single photon excited fluorescence from the sample was collected through a Plan APO 100Ã/NA1.4 oil immersion objective . The signals were detected by Hybrid Photon Detectors HPM-100 - 40 ( Becker & Hickl , Berlin , Germany ) that were connected to a TCSPC module ( Becker & Hickl , Berlin , Germany ) . The excitation source was a picosecond super continuum ( 400 - 650 nm ) laser with an acousto - optic tunable filter ( AOTF ) ( SC400 - 4 , Fianium , UK ) . The AlexaFluor 546 and Alexa Fluor 647 fluorescence were excited by 545 and 640 nm , respectively . In order to avoid significant pile - up error in all our measurements , the peak count rate never exceeded the recommended 10 % of the excitation rate . The fluorescence signals were collected using band - pass filters ET590/50 for AlexaFluor 546 , and ET700/75 for AlexaFluor546 and AlexaFluor647 ( Chroma Technology Corp. , Bellows Falls , USA ) . All images were acquired at 256 Ã 256 pixels . The signal acquisition time was around 60 s. The number of nuclei analyzed for each particular experiment was not less than 10 . The analysis of the FLIM data , including lifetime and FRET efficiency calculation was performed using SPCImage ( Becker & Hickl , Berlin , Germany ) as described in the manufacturer 's protocols 13 .	241112281	no
We hypothesised that differences in frailty , and change in frailty over time , between first generation migrants and non - migrants in Europe would be modified by migrants ' economic origins , host region and , for the first time , country - level migrant integration policies ( the magnitude of any migrant health inequality being reduced by more inclusive migrant health policies ) . We aimed to quantify the extent to which post - migration socio - economic status and , for the first time , citizenship may explain these expected differences in frailty and hypothesised that acquisition of citizenship may attenuate effect modification by host country migrant integration policies . This work builds upon existing cross - sectional studies of European migrant health in SHARE ( Aichberger et al . , 2010;Brothers et al . , 2014;Ladin and Reinhold , 2013;SolÃ© - AurÃ³ and Crimmins , 2008 ) by incorporating further waves of data collection . This increases the number of subjects ' initial interviews available for cross - sectional analyses and permits longitudinal modelling of frailty trajectories ( i.e. frailty over time ) at ages over 50 years . It aims to enrich our understanding of the health issues facing an aging and expanding European migrant population to support policymakers in the strategic planning of health and social care delivery .	51728226	no
The ecosystem flora and fauna will also benefit from this as there will be lesser pollution 699 and toxic contaminants in the environment . the overall impact assessment were cut off at 5 % . Among the resources studied , 723 electricity contributes 75 % on average to each of the impact categories studied ( PLife1 , 724 L1 , I1 ) and disposable ( PLife2 , L2 , I2 ) . Deionised tap water is the second most polluting 725 resource after groundwater . Reusable PPE coveralls have a water consumption 726 potential of 1 % . In the PLife phase , water consumption was identified as the most 727 significant contributing factor for the reusable coverall , yet the software did not consider 728 irrigation groundwater data input . Thus , the software did not account for irrigation 729 groundwater consumption in the other inputs at this stage , which brought the total 730 contribution to 90.89 % . Only the contribution of deionised tap water was depicted in the 731 analysis . The reason for the same might be that the land and groundwater themselves 732 are not polluting sources , but when we manipulate them through anthropogenic uses , 733 then these natural resources get interrupted . Therefore , the natural inventory is maybe     J o u r n a l P r e -p r o o f   J o u r n a l P r e -p r o o f       J o u r n a l P r e -p r o o f	256325640	no
Over recent years , of all of these risk factors , particular focus has been placed on the examination of socioeconomic status and its importance with regard to the impact on incidences of stroke . The majority of the studies examining this factor have tended to use individual - level data from which an inverse correlation is reported between incidences of stroke and socioeconomic status . For example , based upon hospital administration data , with adjustment for risk factors , Hart et al . ( 2000 ) found an inverse association between strokes and categories of deprivation . Additionally , based upon panel data from the US Health and Retirement Study , Avendano and Glymour ( 2008 ) found that both wealth and income were significant contributory factors to incidences of stroke .	41103767	no
To analyse global costs of invasive crustaceans , we used data from the InvaCost database , which primarily presents costs from sources written in English , and sources from 16 additional languages ( Angulo et al . , 2020 . InvaCost captures cost data resulting from both systematic searches of the Web of Science , Google Scholar and Google search engine , and opportunistic contacts with experts and stakeholders . Each recorded cost entry was characterised by various descriptors as described by Diagne et al . ( 2020 ) and in the online database repository ( https://doi.org/10.6084/m9.figshare.12668570 ) . InvaCost is a dynamic database that allows new cost entries to be corrected and added as they develop or are reported over time . The current version of InvaCost includes 13,123 cost entries ( i.e. reported economic costs , or rows of data ) of invasive alien species extracted from published peer - reviewed and grey literature ( InvaCost version 4.0 ; as of June 2021 ) . Although there may be costs that we have not captured ( e.g. , unpublished or outside the search languages ) , InvaCost is the most up - to - date compilation of invasion costs and therefore the best tool available to draw parallels with the current stateof - the - art in cost reporting and associated knowledge gaps . However , the results may change with future research and as monetary cost data become available for different species , countries , sectors , and other factors .	245553758	yes
"Offer an approach to describe and categorize the focal SCM / OM generic skills and analyze how the skills can be adopted and implemented in SCM / OM study programs Leseure ( 2019 ) United Kingdom Defines and compares the two standard options available to instructors teaching planning within an undergraduate OM module : ( a ) the traditional "" technical "" approach or ( b ) the "" conceptual "" or "" conversational "" approach Reflective action research Technical approach helps in staging learning in manageable chunks and conceptual approach offers more opportunities for learning . Students undergoing technical approach rarely end up with an insightful understanding of planning systems and students undergoing conceptual approach can benefit only if they engage and have enough knowledge prerequisites Hoefle et al . ( 2020 ) USA Describes the process followed for transforming a traditional , core OM / SCM course into an experiential , integrated , , and coordinated course Analysis of data related to OM course from 30 schools and a case study Create a reference point for redesigning the course and to be relevant to all business majors , the redesign process incorporated learning goals about integration across operations , the supply chain , and the business characteristics , most of them ( 42 % ) were born between 1965 and 1979 ( i.e. were from the X generation ) , had more than 10 years of teaching experience ( 61.7 % ) , and taught subjects that were fairly well - balanced between qualitative and quantitative approaches ( 48.1 % ) ."	237706348	no
"MSCs were individually encapsulated in Dex - TA microgels using DOCKING and differentiated into the adipogenic and osteogenic lineages , which was visualized using both conventional histological stains and label - free analyses ( Figure 2 m   Error bars indicate Â± standard error , n â¥ 32 . i ) Besides staining nuclei of dead cells , EthD-1 also stained Dex - TA and its intensity linearly ( R 2 = 0.99 ) correlated to the microgel E - modulus . Coefficients of variation ( CV = standard deviation / average ) of various microgel populations including soft , medium , and stiff ones were determined as a relative measure for inter - microgel variation within populations . The error bars indicate Â± standard error , n â¥ 32 , and Â± standard deviation , n â¥ 97 . j - l ) The viable ( closed circles ) and metabolically active ( open circles ) cell fractions of in vitro cultured single - MSC - laden microgels were determined using live / dead ( k ) and MTT staining ( l ) . Datapoints indicate average , n â³ 100 . m ) In soft Dex - TA microgels , adipogenic differentiation after 4 weeks of culture in adipogenic differentiation medium ( DM ) was confirmed using Oil - Red - O ( ORO ) staining and n ) label - free detection of lipids using hyperspectral coherent anti - Stokes Raman scattering ( CARS ; characteristic lipid peak at 2850 cm â1 ) . o ) In stiff Dex - TA microgels , osteogenic differentiation after 4 weeks of culture in osteogenic differentiation medium was confirmed using Alizarin Red ( AR ) staining and p ) label - free detection of calcium phosphates using hyperspectral spontaneous Raman ( characteristic phosphate peak at 960 cm â1 ) . q , r ) Quantification of the per - cell adipogenic ( q ) and osteogenic ( r ) differentiation as a function of microgel stiffness and culture medium . "" GM "" indicates growth medium , lines indicate means , n â¥ 27 ( q ) , n â¥ 55 ( r ) , significance is indicated ( * * * * p < 0.0001 , Kruskal - Wallis analysis of variance ( ANOVA ) , validated with Mann - Whitney individual sample comparison ) . The yellow scale bar indicates 1 cm , the white scale bars indicate 50 Âµm , the black scale bars indicate 10 Âµm , and the red scale bar indicates 1 Âµm . www.advmat.de www.advancedsciencenews.com Figure S16 , Supporting Information ) . Quantification of intracellular lipid and extracellular calcified matrix deposition as proxies for adipogenesis and osteogenesis of MSCs revealed that the stiffness of Dex - TA tethered to cells played an essential role in their lineage commitment . Specifically , single - cellresolution analysis of MSC differentiation revealed that the adipogenic population fraction inversely correlated with microgel stiffness ( Figure 2q ) , while the osteogenic population fraction was characterized by a positive correlation with microgel stiffness ( Figure 2r ) . It is of note , that the single - cell - microgel platform offered unique opportunities toward handling , manipulation , and analysis of cells . For example , single - cellmicrogel analysis revealed the heterogeneity in lineage commitment within a population of differentiating stem cells under controlled chemical and mechanical stimuli . Furthermore , the single - cell microgels were demonstrated to be compatible with label - free analyses , which offered the opportunity of time - lapse monitoring of cell behavior in 3D while minimizing methodology - induced biases by omitting destructive analyses techniques . Regardless , our data indicated that DOCKINGmediated tethering facilitated the transduction of biomechanical cues from non - cell - adhesive biomaterials to MSC , thereby steering cell fate ."	237400940	no
As PSCs have demonstrated a photoconversion energy as high as other commercial solar devices ( CdTe , CIGS , polycrystalline Si ) , one of the key challenges is achieving their long term stable performance when exposed to outdoor conditions . It can be seen from Table 3 and 5 that PSCs are fabricated with a wide variety of materials and design architectures , many of which are intrinsically unstable . It can also be noted that even the similar PSC architectures fabricated at different laboratories resulted in different stability , which is because the durability of these devices largely depends on the purity of starting materials , fabrication methods and conditions , and also the characteristics of the device interfaces . Unlike silicon and thin film solar cells where decades of research has brought them to deliver a stable performance over 20 years with negligible intrinsic degradation , these materials resembles OPVs where instability mostly arises from the materials components itself such as photo - oxidation , change in morphologies over time , and interfacial degradation . [ 273 ] We therefore believe that stability protocols of PSCs are more likely to follow the consensus being developed for OPVs [ 274 ] and DSCs [ 12,243 ] as the device degradation involves chemical modifications . For a detailed overview of the protocols that may be adopted while reporting stability of PSCs , we refer to the comprehensive reports highlighting various ISOS protocols to be adopted while measuring and reporting operational stability ( indoor and outdoor ) . [ 12,243,274 ] Although so far , not many reports have followed any standard protocol while reporting stability of PSCs , we recommend that the perovskite community should follow few considerations while reporting such data . Most importantly the overestimation in PV performance of PSCs due to anomalous hysteresis and their erroneous efficiency reporting ( missing IV data for reverse and forward scan , stabilized maximum power output and statistical analysis ) must be carefully looked at . [ 275 ] For a reliable device characterization , we suggest a measurement protocol developed by Zimmermann et al . [ 276 ] The protocol is derived from standard J - V measurements , power point tracking and stabilized PV parameters as well as characteristics extracted from time resolved current density - voltage measurements . The PSCs research community needs to report stabilized PV performance for both scan directions and preferably the J - V curves at various scan conditions ( delay time , scan rate etc . ) in order to provide a clearer picture of device performance . We recommend a recently published checklist while reporting the PV performance , [ 275 ] ( ii ) while reporting the stability of PSCs , the protocols such as those for dark or indoor testing ( ISOS - D-1 , shelf - life , ISOS - D-2 , high temperature storage , and ISOS - D-3 , damp heat ) or those for outdoor ( ISOS - O-1 - 3 ) [ 273 ] must be followed so that a consensus on the stability is made and a true picture of device performance is obtained .	56562220	no
In this context , there emerges the following question : Should companies not offer both a paid version of their applications that does not collect user data , and a free or freemium version , based on the profitability of studying , analyzing and selling customer data ?	233029680	no
where O i is the observed values of bin i and F i is the simulated values of bin i. In this work , the bins were introduced for the chi - square test and can be operated through bin setting in the simulated distributions in any given data set . The bins were chosen to achieve equal probabilities for both observed frequency and expected frequency . The total number of bins was calculated automatically based on input data set . The chisquare test results of all three simulated distribution are shown in Table 1 .	232377838	no
Our findings emphasize the need for government agencies and local communities to work together to be more strategic in infectious disease containment policy implementation , and enhance health infrastructure in less developed regions to alleviate negative effects on these groups . Despite improvement in tracing measures and privacy regulations , there is room for additional enhancement in public health emergency response system to balance the twin goals of maximizing disease containment and minimizing the negative impacts on individuals . For example , policy makers can consider incorporating the HIPPA regulations during disease control implementation , and provide training to data collectors at government and community levels to promote ethical practices , privacy awareness , and sensitivity to confidentiality issues .	237412522	no
"The recent release of the WMAP three year data [ 1 ] illustrates the extent to which cosmological model - building is now contrained and guided by precision data . It also emphasizes the extent to which a Standard Model of cosmology has emerged . This concordance model is denoted the "" power - law ÎCDM model "" in [ 1 ] ; a slightly more theory - loaded designation is the "" inflation - assisted ÎCDM model "" . In this model the universe on large scales is homogeneous , isotropic , and spatially flat . The universe contains matter ( dominated by dark matter ) , radiation , and dark energy . The dark energy consists either of a cosmological constant or of a quintessence field whose equation of state parameter w(t ) is close to â1 now . Primordial density perturbations have a nearly scale invariant spectrum . At scales comparable to the current Hubble radius , the scalar perturbations have a slightly negative spectral tilt [ 1 ] ."	16436678	no
In the first phase of the COVID-19 pandemic , antibody testing was proposed by several countries as a means of gathering data on the spread of the virus and/or , to inform strategies to ease restrictive measures , and test and trace programmes ( Baraniuk 2020 ) particularly to identify the source of clusters of infections ( Normile 2020 ) . In the UK , the Prime Minister said antibody testing was a potential ' game - changer ' ( BBC 2020 ) . The presence of antibodies indicates an individual 's immune system has responded to the virus . Antibody tests differ from antigen tests that determine whether someone is currently infected . In the case of this virus , at the time this study was conducted in April / May 2020 , scientists and the public had little understanding of the longevity of antibodies , and whether they provided immunity to reinfection or transmission . The current ( January 2021 ) knowledge is that antibodies are maintained for at least eight months ( Dan 2021 ) and for at least three months in those who had mild COVID-19 symptoms ( Rodda 2020 ) . There is evidence that people can be re - infected ( Parry 2020;Hall 2021 ) and work continues to gain a greater understanding of antibodies and immunity . Interim findings from a large cohort study of COVID-19 antibody - positive and antibody - negative UK health workers found antibodies , produced in response to a previous infection , provided 83 % protection against reinfection for five months ( Hall 2021 ) . Although the findings have been welcomed , the sample consists primarily of women under the age of 60 and it is too early to determine immunity against the new variants of the virus ( Ledford 2021 ) . The cohort study will follow participants for 12 months to provide further data on how long immunity lasts and the degree to which someone with immunity can transmit the virus to others ( Hall 2021 ) .	231929099	no
To evaluate the significance of the commonly methylated genes ( n = 1187 ) , categorization was implemented . The commonly affected pathways were prominently plasma membrane - associated receptors and components , cytoskeleton and adhesion / junction - related proteins , ion channels / transporters and energy homeostasis ( Figure 3H ) . Considering the distinct physicochemical properties between AgNPs and GO , pathway analysis was further performed for the differentially methylated genes ( Figure 3I , J ) . A multitude of genes were found differentially methylated between AgNPs and GO in both A549 and 293 T cells , including genes responsible for gap junction ( e.g. , LPAR1 and GNAI3 ) [ 24 ] upon AgNPs exposure and genes encoding proteins involved in substance metabolism ( e.g. , PDE5A and GFPT1 ) [ 25 ] upon GO exposure . These differences between AgNPs and GO could be attributed to their distinct physicochemical properties and their different mode of interaction with cells including differential subcellular localization . [ 26][27][28][29 ] For example , AgNP dissolves ions , and Ag ions play a major role in AgNP - induced toxic effects ; [ 26 ] GO have different lateral sizes and surface functional groups and have strong association with biomolecules . [ 27 ] Therefore , we looked into the changes of 5 - mC levels responding to Ag ions and GO with different lateral sizes and surface modifications . Previous studies demonstrated that Ag particles and Ag ions simultaneously existed inside the cells with a release rate of Ag ions around 10 % . [ 28,30 ] Thus , Ag ions at 0.4 Âµg mL â1 were used to treat cells , and different from Ag particles , Ag ions did not induce a significant change in 5 - mC content in A549 , 293 T , and THP-1 cells ( Figure S14 , Supporting Information ) . In order to answer whether length / size contributes to the influence on DNA methylation induced by ENMs , we deliberately prepared an array of GO with different lateral size , i.e. , S - GO ( smallest ) , I - GO ( intermediate ) , and L - GO ( largest ) , as described in our recent report . [ 28 ] As shown in Figure S18 ( Supporting Information ) , no significant difference could be found among these sized - GO in increasing 5 - mC levels in A549 and 293 T cells . Furthermore , we scrutinized the effect of surface modification on DNA methy lation changes using GO - NH 2 and GO - PEG ( polyethylene glycol coated GO ) , as described in our recent study . [ 31 ] As shown in Figure S19 ( Supporting Information ) , compared with the parental GO and GO - NH 2 , GO - PEG induced a milder increase of 5 - mC levels in A549 and 293 T cells , in agreement with the greater biocompatibility of GO - PEG . [ 31 ] Taken together , these data revealed new insights into the structure - activity relationship for AgNPs and GO : Ag nanoparticles rather than dissolved Ag ions were responsible for the DNA methylation changes ; the surface activity of GO rather than its size played the major role in GO - induced DNA alternations . However , further studies should be considered to identify the physicochemical determinants and nanobio interactions ( e.g. , distinct subcellular localizations ) in inducing different signatures of DNA methylation for diverse ENMs in the future .	32288127	no
Understand the effect of low value lists on clinical practice and patient outcomes - Although Choosing Wisely , the most publicly visible effort to limit overuse ,   has publicized the problem , its impact on patient care is not well described . This should be studied , probably in cross sectional and cohort studies with patient level or administrative data .	2075892	no
Data sources . Almost all residents in Scotland are registered with a general practice and have a unique Community Health Index ( CHI ) number used by NHS Scotland . We used the CHI number to deterministically link all datasets with vaccination records in Public Health Scotland ( Extended Data Fig . 4 ) . Vaccination information was extracted from the general practice records and the Turas Vaccination Management Tool system ; together , these captured all vaccination records , including those vaccinated in general practices , community vaccination hubs and other settings , such as care homes and hospitals in Scotland 40 . Further details on the data sources used in this study are available in a published project protocol 24 .	235393684	yes
Here , instead of sharing a low - dimensional structure , each data vector can now reside in a separate low - dimensional subspace . Therefore , together the data matrix admits a union - of - subspace model . As a result of this additional flexibility , DL finds applications in a wide range of signal processing and machine learning tasks , such as denoising , image inpainting ( Mairal et al . , 2009 ) , clustering and classification ( Ramirez et al . , 2010;Rambhatla and Haupt , 2013;Rambhatla et al . , 2016;2017;2019b;a ) , and analysis of deep learning primitives ( Ranzato et al . , 2008;Gregor and LeCun , 2010 ) ; see also Elad ( 2010 ) , and references therein .	67856138	no
This paper is based on data collected from the Nutrient Platform . Primarily , it draws on 27 interviews with members of the platform . These data are triangulated with over 3000 internal documents created within the platform during the period 2008 - 2015 . These documents range from meeting agendas to strategic documents and marketing materials . Most of the documents are internally focused , though some - such as marketing materials and official communication materials - are aimed specifically at external audiences . The internal documents are especially insightful for examining conflicting views , while the externally aimed documents provide insights into some of the outcomes of these conflicts . We have reconstructed in detail the collaboration 's timeline from its inception in 2008 through to 2015 . This data is supplemented by publicly available information about specific platform - related developments as well as broader socioeconomic developments that have affected the collaboration during the period from 2015 to 2017 .	254375579	no
Specifically , we draw on longitudinal data from qualitative interviews conducted as part of the ' Solidarity in times of a pandemic ' Consortium ( SolPan ) with a total of 482 respondents in Germany , Italy , Ireland , Austria , German - speaking Switzerland and the UK . In contrast to public debates over how the pandemic should be handled which often position public health against public wealth , our data illustrates that oppositions between saving lives or saving livelihoods fail to capture the entangled , long - standing nature of structural inequalities revealed through the pandemic . We complicate such dichotomies through a qualitative understanding of the pandemic as a lived experience , and conclude that the current moment presents an opportunity to address the structural inequalities which have emerged with greater force as a result of COVID-19 .	244902343	no
After the relevant results at the regional and departmental scale , we also monitored smaller watershed by collecting samples in Parisian sewers , to allow for a more precise description of the viral dynamics and allow for the detection of clusters . Viral concentrations in samples collected from the sewer system of the city of Paris are plotted in Fig . 3 . Results showed that the median of data taken from the sewer visually correlated with the city trends , emphasizing the possibility to refine the virus spreading in the area . Monitoring of individual sampling points showed some specific dynamics before the start of the second wave , demonstrating the possibility to detect local cluster using sewer monitoring ( lower panel ) . For example , an important concentration was locally detected during week 22 ( October 14 , 2020 ) , at the beginning of the second wave , probably due to local clusters . Same trend could be easily observed before the second lockdown .	245007358	no
To investigate the influence of ligand clustering on receptor mediated uptake , a series of eight micelle formulations were used : 0%F-100%mix , the untargeted control containing unfunctionalized LDP ( 0%F ) used as 100 % of the micelle and 10%F-100%mix , 20%F-60%mix , 30%F-40%mix , 40%F-30%mix , 60%F-20 % , 70%F-20%mix and 100%F-10%mix are formulations presenting a similar amount of folate in total . UV - Vis data show statistically similar numbers of folate per micelle by one way ANOVA analysis between the different groups at the 95 % confidence interval ( Figure 2c ) . We used FR overexpressing KB cells to evaluate targeting and binding of the micelles to receptors on the cell surface . After a 24 h period of incubation , the highest cell associated fluorescence was observed for cells incubated with the 20%F-60%mix formulation ( Figure 3a ) . The measured EC50 ( concentration producing 50 % binding ) was observed to be the lowest for the 20%F-60%mix micelle . To facilitate discussion , we approximated the apparent dissociation constants of the tested micelles ( K D ) by fitting the experimental data to a 1:1 binding model for site - specific binding . The apparent micelle K D is given in Table 1 . EC50 and K D values are similar , indicating that there is a direct relationship between binding and the measured fluorescence . The measured dissociation rate constant ( k off ) of the different micelles also show that the optimal 20%F-60%mix formulation had the longest dissociation time ( 2Ã10 â5 s â1 ) ( Figure 2d , Table 1 ) . To examine the apparent rate of association ( K on ) relationship between the micelles , we used the following equation : k on = k off /K D and found that the calculated values were not significantly different ( less than 1 order of magnitude apart , Table 1 ) . Confocal analysis and competitive binding experiments confirmed that our observations for binding and targeting are FR mediated and that the mechanism for internalization of targeted LDP is dependent on both energy driven endocytosis and the presence of folate receptors ( Supplemental Figure 5 ) .	17489848	no
There are some other , less directly relevant issues which we have relegated to Appendix C : namely , generalized model averaging ( C.2 ) , mixture components a.k.a . sub - classes ( C.3 ) , input data normalization ( C.4 ) , parameter initialization ( C.5 ) , sequence training ( C.6 ) , and online decoding with iVectors ( C.7 ) .	15370378	no
We have seen in section 4.1 that with positive kinematic data all the solutions we obtain are real . This means we can analyze them by counting bounded chambers in RP 2 space when |147| , |257| and |367| vanish . We expect to find 12 bounded chambers , which would correspond to the 12 solutions for each of the 15 existing configurations . The bounded chambers come in the following way . First , we use the same gauge fixing for the first four particles as explained in section 4.1 . This creates 5 repelling lines , one of them crossing the diagonal of the square [ 0 , 1 ] 2 created by particles 1 and 4 . It is precisely on this line where the soft particle 7 must be . We can have solutions where particle 7 is outside the square [ 0 , 1 ] 2 , since particles 5 and 6 can simultaneously create bounded chambers for each other . We represent this situation in figure A.9 . Left : the first four particles are gauge - fixed . This creates 5 repelling lines , drawn in black , and particle 7 must be on the line that passes through 1 and 4 . Center : we now consider the situation in which the soft particle 7 is in the outside - right(left ) of the square [ 0 , 1 ] 2 . Right : particles 5 and 6 must lie on the blue dashed lines created by particles 7 , 2 and 3 . This only happens if both particles bound each other through particle 4(1 ) ( red and orange lines ) . The two grey bounded chambers are those where particles 5 and 6 can be . This configuration gives rise to 2 different solutions , since particles 5 and 6 can bound each other through particles 1 and 4 when particle 7 is outside the square [ 0 , 1 ] 2 .	207847913	no
The pursuit of good quality FIO data does need to be complemented with continued efforts to understand the differential behaviour of FIOs and pathogens , and the associated implications for modelling the efficacy of mitigations designed to reduce microbial watercourse pollution . Thus , while we have focussed our discussion on FIO modelling it is important for resource managers and policy makers to recognise that FIO models do not necessarily inform on specific pathogen behaviour . However , the nexus of FIO modelling and risk assessment is gaining significant momentum and the use of quantitative microbial risk assessment ( QMRA ) offers another modelling framework with which to estimate human infection risk from exposure to pathogen contaminated waters ( Soller et al . , 2015 ) . Benefits of FIO modelling will be further enhanced if the research community promotes a consistent message to model developers calling for any future model performance criteria to include , as a minimum , an uncertainty analysis of modelled predictions . Thus , the pedigree of uncertainty associated with model outputs needs to be transparent and included as standard in the reporting of any FIO modelling . There are mechanisms that can help deliver this drive for greater awareness of model uncertainty . For example , there are more frequent opportunities to promote knowledge exchange ( KE ) across the science - policy interface enabling scientists and policy - makers to debate the role and impact of model uncertainty . Research Councils in the UK , and in other nations too , are increasingly funding policy - placement opportunities whereby scientists are embedded within government departments thus providing an important route for aiding KE . This should be encouraged in the general field of environmental decision - making using models . In addition , those responsible for funding research could improve model transparency by ensuring that projects with a modelling component fulfil basic uncertainty analysis criteria . Indeed , several academic journals , whose remit includes environmental modelling , now stipulate uncertainty analysis of any modelling as a prerequisite for publication . This template should also be adopted at the funding stage for research projects .	2276402	no
Relative quantitation of drug levels within caseum and cellular lesion regions was performed using MSiReader 37 . The proprietary Thermo * RAW data format was converted to imzML using Raw to imzML converter to enable importation into MSiReader 38 . Regions of interest ( ROIs ) were drawn in each image covering either cellular lesion or caseum and the mean drug signal intensity within that region ( normalized to the corresponding drug internal standard ) was calculated following exportation of the ROI peak list into Excel .	16787954	no
By introducing the concept of genetically encoded BRET - activated PDT , we propose a viable solution of the bottleneck problem of limited treatment depth of PDT , while avoiding problems of currently available chemically assembled BRET complexes . For the demonstration of the concept , we designed a genetically encoded NanoLuc - miniSOG platform , which can be delivered by a properly selected carrier to a tumor , and then triggered by the injection of furimazine substrate . To assess the efficiency of this pair , we expressed NanoLuc - miniSOG BRET - pair in breast ductal carcinoma BT-474 cancer cells and then examined its operation in vitro and in vivo . Spectroscopic characterization of BT-474 / NanoLuc - miniSOG cell line confirmed that BRET between NanoLuc and miniSOG    c Tumor - growth curves for control group ( mice treated with PBS only ) , as well as for groups carrying NanoLuc or NanoLuc - miniSOG LVs particles and treated with furimazine . Data are presented as the mean Â± SD ( n = 6 ) . d In vivo bioimaging of animals bearing HER2 - positive tumors and injected i.t . with LVs - NanoLuc - miniSOG or LVs - NanoLuc . Three mice from each group on the 13th day after LVs injection are presented indeed occurs with the BRET ratio reaching 0.74 Â± 0.05 ( Fig . 1d ) . The recorded ratio is in agreement with our previous data 23 , as well as with data for other BRET - based genetically encoded sensor systems 33,34 , confirming a high efficiency of the pair . We demonstrated by MTT assays that NanoLuc - miniSOG efficiently kills the cancer cells in the presence of furimazine ( Fig . 1e ) , while other tests confirmed that the endogenous bioluminescence can serve as a light source to activate the miniSOG for ROS generation ( Fig . 1f ) . Using the model of mice bearing engineered BT-474 cells expressing NanoLuc - miniSOG , we recorded TGI exceeded 72 % after the injection of furimazine without external light irradiation ( Fig . 2 ) . It means that the inhibition of tumor growth occurs due to BRET - induced PDT , although cytotoxicity of oxidized product of furimazine could also partially contribute to the cell death ( Fig . 2b ) . It is also important that bioluminescence imaging can be used in our case to assess BRET efficiency in vivo . The differences of the average luminescence signal with or without Rf in animals evidenced an efficient process of energy transfer from the donor ( oxidized NanoLuc luciferase - substrate ) to the acceptor ( miniSOG ) in the case of tumor Rf saturation ( Fig . 2c , d ) . Finally , genetic nature of proposed NanoLuc - miniSOG BRET - pair allowed us to use targeted viral system for gene delivery precisely into tumor ( Fig . 4 ) . Using HER2 - specific LVs carrying NanoLuc - miniSOG gene we achieved significant regression ( TGI 67 % ) of HER2 - positive xerograph tumor in the animal model , confirming a high efficiency of the proposed concept . We foresee several major advantages of the proposed concept of genetically encoded BRET - activated PDT over currently present chemically assembled BRET - based systems for PDT . First , the genetic nature of functional PDT elements provides an ideal spatial architecture of the BRET construct , conditioning optimal distance between the internal triggering source and the PS , which is obviously very difficult or impossible in the case of chemical assembling . Second , the proposed approach does not require any sophisticated and costly chemical conjugation protocols to generate functional BRET pair for PDT . Third , as showed in our studies , despite certain local toxic effects in organs due to furimazine injection , genetic encoding nature of synthesized protein complexes makes them safe and easily excretable from the organism , which is not the case for many chemically assembled structures . Finally , as probably the main advantage , the used principle of genetic encoding opens up novel appealing prospective for future improvements of PDT systems profiting from on genetic engineering approaches . In particular , the expression of used NanoLuc - miniSOG pair can be controlled on the genetic level by properly designed promoters ( e.g. , telomerase promoters ) , which are specific to some tumors . In addition , by fusing with a well - known protein localization motif ( nuclear , membrane , mitochondrial ) or a whole protein , the genetically encoded pair can be easily directed to any cell compartment ( or even sub - compartment ) . Furthermore , the use of different targeting molecules in the composition of lentiviruses or other carriers renders possible an easy re - direction of a genetically encoded BRET - activated system on any tumor type , while the therapeutic action will address not only the primary tumor , but also its metastasis distributed in the organism . Thus , the employment of genetically encoded constructs provides novel opportunities to direct BRETinduced generation of active forms of oxygen to different cellular compartments or particular cell lines , which is hardly possible with chemically assembled BRET systems .	247013429	no
"At County Health System , providers and staff often struggled to recognize SOGI data 's relevance for care , further informed by anticipation of patient expectations when discussing gender and sexuality . Despite acknowledgement of "" openness , "" several health care workers still expressed discomfort around asking patients the SOGI items , suggesting the questions broached a previously unacknowledged boundary of topics appropriate for clinical discussion ( Cruz , 2020 ) . Patients typically did not expect to discuss such issues when seeking care in this clinical setting , as described by one staff member :"	237292347	no
( D ) WT and ( E ) p23KD HeLa cells were treated with 40 Âµg / mL of cycloheximide ( CHX ) for 6 h in the presence or absence of 40 ÂµM CQ for 12 h ( 6 h pre - treatment and then co - treated with CHX for another 6 h ) . The degradation of AHR in both cell lines was inhibited by CQ . For ( D , E ) , the below images are representative of the replicate data ( means Â± SD , n = 3 ) . Conditions with no addition as no treatment ( NT ) were arbitrarily set as one ( with no error bar ) for data normalization . Multiple t - tests corrected with the Holm - Sidak method for multiple comparisons were performed to determine statistical significance .	218657907	no
where P pr ( EOS ) represents the set of the priors on the EOS , which we describe above . Because of the high accuracy in the measurement of the chirp mass , we fix it to the observed value , and use that to set m 2 for any given m 1 . Then , equation ( 13 ) can be written as   ( 9 ) . We find excellent agreement between our Î â R prediction and the full Bayesian inference . Middle : Same as left panel , but showing , in addition , the marginalized posteriors over the neutron star radii for a fixed grid of masses . These marginalized likelihoods are shown in blue . By marginalizing the posteriors in this way , the results are skewed to higher radii and away from the maximum likelihood solution . Right : Marginalized likelihoods for an inference with only the priors and no data . These marginalized posteriors are nearly identical to the marginalized posteriors from the inference that incorporated data from a Î = 400 centered Gaussian . This method of marginalization over - weights the prior on the EOS pressures imposed by the observation of a 1.97 M neutron star . The results of the marginalization are less sensitive to the input data and are not reliable .	73561032	no
But the problem here is not publication bias per se . Any experimental activity ( including but not limited to publication ) that involves preferentially following up on one 's most statistically promising initial results presents the same challenge . For example , a standard study design in genetics is to scan the genome , one position at a time , for statistical evidence of a genetic variant with an effect on some phenotype in one or more families , in order to find the best - supported genomic position ; and then to follow up with additional data , e.g. , using a new set of families , in order to corroborate the result at that position . This procedure seems scientifically unassailable , but any attempt at evidence amalgamation across the two stages of the study violates the same statistical assumption as does publication bias . When following up on our most promising findings , we can expect the p value to regress to the mean regardless of whether the evidence is going up or down , by virtue of having selected a location for follow - up on the basis of a notably small p value .	255063864	no
We arrive at novel and valuable insights into the relation between identification processes and ethical decision - making in family firms . In terms of the generalizability of our research - it was our primary focus to obtain an insightful and rich understanding of ethical behavior in family firms . Therefore , we started with a well - selected data set , which is in line with current standards ( e.g. , Salvato and Corbetta 2013 ) . However , we acknowledge the interviews conducted with a sample of 19 family firm employees allow only limited interpretations of the connection between identity and ethical behavior . Given that our study is limited to German family firms , our findings could be subject to bias due to the single - nation focus . Each nationality and culture has different values , and individuals ' ethical awareness could be influenced by their cultural background . To gain a more detailed understanding , we suggest taking our research as a basis to explore further the family firm 's unique characteristics and ethical behavior against other cultural settings . For instance ,   has recently revealed contradictions between family and external expectations of Corporate Social Responsibility reporting measures in Latin American family businesses . From an ethics perspective , we did not assess examples of ( un)ethical behavior . An ( objective ) assessment and evaluation of actual ( un)ethical behavior is an important next step to interpret whether or not the approach to an ethical situation is congruent with the underlying value system . We also call for future research to examine the temporal dimension of identification , an important facet which is rarely studied . As our results show , identification is not static but dynamic in nature . Identification processes involve many aspects , both on the individual and organizational level . Identifying with an organization and its values is an ongoing journey for employees . Some parts of an individual 's identity even evolve along with the sense of belonging to an organization , which needs further investigation ( Knapp et al . 2013;Kreiner et al . 2006 ) .	233832665	no
"Rather than distributing the "" sub - classes "" evenly , we allocate more sub - classes to the more common classes . We allocate them proportional to the 1/3 power of the count of that class in the training data ; this is based on the rule we use to allocate Gaussians in our GMMs ."	15370378	no
This study is not without limitations . First of all , data collection started about a month before any COVID-19 vaccine was officially approved , that is , in a period in which accurate information was not available on the characteristics of the candidate vaccines , in particular about their efficacy , safety , and the possible side effects . With the start of the vaccination campaign , the intention to get vaccinated may likely have changed in light of the clearer information about the vaccines , the experiences of people who have already received them , and , not less importantly , government decisions and the daily news broadcast by the media . As specified above , the data on the time course of the vaccination campaign in Italy are in line with those of the neighbouring countries of the EU ( around 60 % of fully vaccinated people ) . However , the percentage of people still hesitant about the vaccine should not be underestimated , particularly in the older age groups ( e.g. , over 60s and 70s ) , where there is currently the lowest adhesion to vaccines ( Italian Ministry of Health , 2021b ) . For this reason , further studies are needed to verify whether the type of persuasive message that we have identified as the most effective in promoting intention to receive the future COVID-19 vaccine also works in increasing intention to get the currently approved vaccines and the consequent behaviour and its impact on different socio - demographic groups . Secondly , since we used a convenience sample recruited by advertising the study through various online channels ( e.g. , Facebook groups ) , we can not conclude that our results are generalisable to the general population and , above all , that participants did not already have high levels of vaccination intention . However , the heterogeneity of participants in terms of socio - demographic characteristics may have partially reduced this bias . Thirdly , although in the literature there is no convincing evidence that affective attitudeunlike anticipated affective reactionscan predict vaccination intention , future studies with larger samples could simultaneously manipulate both components of the attitude ( cognitive vs affective ) plus anticipated affective reactions to clarify better if and how these processes are mutually exclusive in the context of the decision - making process related to COVID-19 vaccination . In addition , it should be noted that we have not focused on all the variables of the TPB model but only on attitude and intention . Future studies should also consider , for example , the possible effect of subjective norms on the intention to get vaccinated against COVID , since the literature shows that subjective norms , after attitude , are the strongest predictors of vaccination intentions ( e.g. , Askelson et al . , 2010 ) . Injunctive norms , i.e. what significant others ( family , friends ) think the person should do ( to get vaccinated or not ) , and descriptive norms , i.e. what they do themselves ( they intend to get vaccinated or not ) , are both aspects that could have a substantial impact on the decision to get vaccinated , especially in consideration of the context of uncertainty ( e.g. , doubts about the safety and efficacy of the vaccines ) in which this decision is taken . Furthermore , considering that many countries are starting to vaccinate or consider vaccinating children and young people , studying the impact of social influences is even more relevant . Indeed , younger people 's attitudes toward vaccines appear to be heavily influenced by social norms ( Rambout et al . , 2014 ) ; in this perspective , learning that most people significant to them ( e.g. , parents or friends ) get vaccinated can represent , for the youngest , an important motivational factor .	237576621	no
Similar observations were also made by Stopar et al . who investigated the enzymatic cleavage of the DO scaffold by several restriction endonucleases at their respective recognition sites . [ 114 ] They found that these sites can be either active or strongly resistant toward enzymatic cleavage , d epending on the local mechanical and topological properties in the vicinity of the individual site . [ 114,115 ] Theb ulk of these data suggests that DN can be rationally designed for increased serum stability and cell uptake , f or instance , b ym aking them mechanically very rigid to suppress nuclease binding . However , t he desired performance of ag iven DN depends not only on its stability and uptake but also on other aspects such as drug loading efficiency and release kinetics , w hich are affected by the same design factors . I ndividual design - related properties will thus have to be weighed against each other , favoring , f or instance , e fficient drug intercalation over serum stability .	211565594	no
Given the findings , certain caveats of this study are notable . First , we conducted the study in the unique setting of Matlab , Bangladesh , so findings may not be more widely generalizable . Still , unlike many non - population - based randomized controlled trials , our probability - based sample allowed for inferences to a defined population . Second , the analysis was based on cross - sectional , observational data , which limited our ability to make causal inferences . To improve our ability to make causal inferences , we established a clearer temporal ordering between treatment and outcomes by including a lifetime measure of microfinance participation and outcomes measured at interview , in the prior week , or in the prior year . We also leveraged pre - program and exogenous characteristics to model the propensity for participation in microfinance . These characteristics included circumstances in childhood ( religious affiliation , maternal schooling , economic standing , natal - home location ) , at marriage ( age in years , own schooling , partner 's schooling ) , and exogenous location of residence ( inside / outside embankment ; fixed neighborhood cluster ) . Empirically , we achieved balance in observed pre - program characteristics across groups and found no evidence of bias due to unobserved endogeneity .	231628354	no
Simulations : The optical response was simulated of cavity systems using Comsol Multiphysics with the Wave Optics module , using a p - polarized plane wave as the source with normal incidence . A 2D periodic model with a period of 300 nm and a symmetric mesh with a maximum size of 40 nm was used . The refractive index data for T34bT were taken from the experimental ellipsometric determination .	238528126	no
In this study , we utilized an alternative design principle and revealed that the metagratings based on extraordinary optical diffraction ( EOD ) can achieve arbitrary wavefront shaping with extreme angle tolerance in a broadband spectral range . The meta - atoms in the EOD metagratings were formed by uniformly sized plasmonic nanorods , and the local periodicity between the meta - atoms determines a discrete set of diffraction channels . Based on EOD 17,19,47 , an architecture , in which plasmonic nanorods were placed on top of a dielectric spacer with a metallic background , was employed to funnel the impinging light into the desired diffraction channel with near - unity efficiency . By further continuously displacing the nanorod within each unit cell according to the strategy of a detour phase 48 , customized phase profiles for molding arbitrary wavefronts of light can be generated . Because the phase modulation rule for a EOD metagrating is intrinsically independent of the incident angles and wavelengths , the wavefront shaping capabilities are robust for a broad bandwidth and for an extremely large range of incident angles ( close to the grazing incidence ) . Our proposed EOD metagrating does not rely on complicated and asymmetric meta - atom inclusions [ 49][50][51][52][53][54 ] and thus significantly simplifies the metasurface design procedures and lowers the fabrication demand , which is highly desirable for various holographic applications , including high - fidelity three - dimensional displays , data encryption , and anti - counterfeiting . Figure 1a shows an illustration of the proposed EOD metagrating composed of periodic arrays of identical plasmonic nanorods with width w and length L , which are placed above a dielectric spacer of thickness h and a metallic background . The facile binary EOD metagrating achieves near - unity efficiency light steering without the necessity of spatially varying meta - atoms to mimic a blazed grating ( Supplementary Fig . S1 ) . The EOD metagrating works in specific diffractive regimes , where only zeroth and âfirst ( or first ) diffraction orders are allowed to propagate in free space . Those EOD regimes can be determined by the following conditions , 2Ï	53020841	no
Missing values in junction coverage ratios were imputed using missMDA R package . PCA analysis was then performed using prcomp R package . We regressed out principal components ( PCs ) accounting for 95 % of the variation in our imputed dataset ( 176 PCs ) . We then put back original missing values in the dataset and derived Z - scores used in the outlier analysis . We looked at the correlation pattern between the 10 first PCs and known covariates from our dataset . In brief , PC1 was mainly separating the source of the data ( UDN , CGS , CHEO or PIVUS ) . PC2 was highlighting differences between the first batch and the other batches . Overall , we observed some level of correlation between all known covariates and the PCs that were regressed out from the data .	173993955	no
The biotin functionalised spin labelled nanoparticles could be simulated using the data shown in   Figure S16a ) . The nanoparticles with avidin - peroxidase could roughly be fitted with a particularly broad component with a rotational correlation time of 10 ^ -8.0 s , indicating that the label was in a hindered motion environment ( Figure S16b ) . However , due to the significant broadening , it was difficult to obtain an exact fit , as the smaller peaks are lost in the noise . In contrast to the Con A binding , there was a significant broadening of the peaks , most likely due to the tight binding of the avidin - peroxidase leading to significantly reduced molecular motion . Using these two components , it is possible to create a simulated titration , to demonstrate how the line shape would be influenced by an increasing population of the protein - label complex ( Figure S17 ) . When the simulations were not normalised , we observed that the line heights were significantly smaller than those of the free spin label . It is likely that it would be difficult to detect the changes in the line height for   To further rule out viscosity as a source of the binding profile observed in Figure S7 , a viscosity study was conducted with 100 ÂµM spin labelled mannose 4 with varying amounts of glycerol , the viscosity of the solution increases , there is a reduction in tumbling rates of the nitroxide spin label , and a broadening of the resonances . As before , the ratio between the high field and central field resonance heights may be plotted against the % glycerol to give a binding profile ( Figure S18 ) . Figure S18 : The change in relative line height between the high field and mid field resonances against % glycerol for 100 ÂµM solutions of the nitroxide radical 4 in 0.01 M potassium borate buffer with various amounts of glycerol .	26504117	no
Coding interesting features of the data in a systematic fashion across the entire data set , collating data relevant to each code .	244236462	no
Diseases that spread through aerosols , droplets , or fomites are often transmitted widely in crowded environments . Therefore , social distancing has been a key feature of prevention strategies for coronavirus disease 2019 . Despite these efforts , as of July 2021 the COVID-19 pandemic directly led to over 600,000 deaths in the US according to Johns Hopkins Center for Systems Science and Engineering 's continually updated dashboard ( Dong et al . , 2021 ) . One important aspect of outbreak prevention involves targeting locations with increased transmission rates with information , testing , and other preventative or assessment measures . Although transmission rates of novel diseases are generally estimated on a population level , an emerging epidemic of such a disease can be challenging to characterize because the key analytic parameters estimated by early studies are specific to the initial outbreak 's population . If ungeneralizable data are used to model transmission rates , it is possible that inadequate resources will be allocated to locations with greater disease burden ( Jewell et al . , 2020 ) .	245015747	no
From the other potential intermediates for which adsorption geometries and AFM images have been calculated we can with high confidence rule out structures 20 , 21 , 22 , 23 , and 25 which do not fit to the experimental AFM data . In the simulated AFM images of structures 20 - 23 , at the onset of repulsive interaction ( 4 th column ) , the entire outline of the molecule appears with dark contrast , in contrast to the experiment . In addition , the range of tip - sample distances to simulate AFM images from the onset of repulsive / bright contrast at the highest part to repulsion on the lower laying parts of the molecule is smaller than in the experiment . The simulated contrast of structure 25 is significantly different to any of the measured molecules .	239027923	no
only and activated T cells post - washed with fresh media after pre - treated with chrysophanol for 30 min or 1 h. As shown in Figure 3E , pre - treatment with chrysophanol for 30 min and 1 h of T cells exerted significant decrease of mRNA level of il2 but removal of chrysphanol after pre - treatment did not show any attenuation in mRNA level of il2 . Interestingly , decrease of mRNA level of il2 is dependent on the time of pre - treatment with chrysophanol , meaning that pre - treatment with chrysophanol for 1 h exhibited more inhibitory effect on T cell activation than pre - treatment for 30 min . These data imply that T cell activity is irreversibly restrained by pretreatment with chrysophanol in Jurkat T cells stimulated by antibodies against CD3 / CD28 and SEE - pulsed Raji B cells .	221358689	no
Neural data compression . Learned image compression methods are commonly based on hierarchical variational autoencoders [ 2,24,20 ] with a learned prior and latent variables being discretized for the purpose of entropy coding . In a similar vein to work in the latent variable model literature [ 14,19,16,22 ] , several works [ 5,12,38 ] attempt to close the amortization gap [ 8 ] by performing   iterative gradient - based optimization steps on top of the use of amortized inference networks . [ 38 ] additionally identify and attempt to close the discretization gap stemming from the quantization of the latent variables , also by inference time per - instance optimization . [ 37 ] take the idea of perinstance optimization of the model further : they perform per - instance finetuning of the decoder and transmit the quantized decoder parameter updates along with the latent code , leading to improved rate - distortion performance . In this paper , we take a different , and even more extreme from the per - instance optimization perspective , approach : we optimize an MLP to overfit a single image and transmit its weights as the compressed description of the image .	232110691	no
Direct single cancer cell to normal cell comparison . To validate and further explore this proposition , we performed single - cell RNA - sequencing ( scRNA - seq ) analysis ( 10x Genomics ) of diagnostic specimens from six infants with KMT2A - rearranged infant B - ALL , including a relapse presentation ( case 3 ) and additional day 8 specimens from responding ( case 1 ) and nonresponding ( case 2 ) patients . We compared these to four other leukemias : NUTM1 - rearranged infant B - ALL ( n = 1 ) , KMT2A - rearranged infant AML ( n = 1 ) , megakaryoblastic neonatal AML ( n = 1 ) and childhood ETV6 - RUNX1 B - ALL ( a common subtype of standard - risk childhood B - ALL ; n = 1 ) ( Supplementary Table 3 ) . From these 12 diagnostic leukemia samples , we obtained a total of 30,242 cells , including 23,286 cancer cells that we identified based on gene expression matching patient - specific diagnostic flow cytometric profiles ( Supplementary Table 4 and Extended Data Fig . 2 ) . Using a published cell - matching method based on logistic regression 12,16 , we directly compared leukemia transcriptomes with mRNA profiles of human fetal bone marrow cells to determine which normal cell type the cancer cells most closely matched . We found that KMT2A - rearranged infant B lymphoblasts overwhelmingly resembled ELP cells at diagnosis and relapse and in nonresponding disease ( Fig . 2a - c ) . By contrast , non - ELP cell signals predominated in other types of leukemia , precisely as predicted from the We assessed the differentiation state of KMT2A - rearranged infant ALL by measuring signals of human fetal bone marrow cell types across the entire spectrum of childhood leukemia in data derived from two different cohorts ( St Jude 's and TARGET ) . We then validated cell signals by single - cell mRNA sequencing for direct comparison of cancer and normal cells . b , Heatmap showing mean cell signals of human fetal bone marrow cells ( y axis ) in human leukemia bulk transcriptomes subdivided by genetic subtype ( see labels underneath , KMT2A rearrangements shown in red text ) , age ( gray circle , infant ; black circle , noninfant ) and source ( S , St Jude 's ; T , TARGET ) . Numbers next to labels refer to case load per subtype . Subtypes with only one case were excluded from analysis . baso , basophil ; CMP , common myeloid progenitor ; Eo , eosinophil ; LMPP , lymphoid - primed multipotent progenitor ; MEM progen . , ; MK , megakaryocyte ; mono . , monocyte ; MOP , monocyte progenitor ; MPP , multipotent progenitor ; Neut . , neutrophil ; NK , natural killer ; Promono . , promonocyte . c , Top : box and whisker plots showing proportional contribution of signals ( lymphomyeloid - primed progenitor , ELP and later B - cell stages combined ( i.e. , pre-/pro - B , pro - B , pre - B and naive B ) ) to the transcriptome of leukemias ( see x axis labels ) . Bottom : box and whisker plots summarizing the ratio of ELP to later B - cell stage signals . Center lines represent the median , box limits represent 25%/75 % quartiles and whiskers represent minimum/ maximum ( top ) and 1.5Ã interquartile range ( bottom ) . n is the number of biologically independent variables , as listed below each group of plots . Risk refers to the clinical cytogenetic risk as defined in the protocol of the current European ALL trial ' ALLTogether ' ( EudraCT 2018 - 001795 - 38 ) .	247453162	no
Overall , the SHAPE data support our original model ( Figure 1A ) ; this is particularly the case for SLs 1 - 4 . The loops of these four regions contain the most highly reactive , exposed nucleotides . The remainder of the most highly reactive nucleotides are situated in bulges , internal loops , single - stranded regions linking SLs and the closing pairs of helices , with the exception of G 90 , U101 and A320 . The tip of SL5 contains mainly unreactive nucleotides , possibly indicating kissing - loop interactions involved in dimer initiation . Nucleotides that were predicted to be base - paired in SL1 were unreactive to 1M7 , with the exception of A131 . As the A residue 3 0 of this was predicted to be bulged , and is unreactive , it is likely that the bulge forms consistently at A131 and not at A132 ( shown in Figure 2 ) . Predicted base - paired nucleotides in SL2 are relatively unreactive , except for closing pairs and G - U pairs . The exceptions are nucleotides U244 - G246 , which are highly reactive ; this may indicate that the internal loop 3 0 of this is larger and includes these nucleotides . Structural predictions using the RNA structure programme ( 44 ) and 1M7 reactivities as pseudo free - energy constraints suggest that this is the case in the alternative structure ( shown in Figure 2 ) . Minimal free energy predictions suggested that the SL2 structure is maintained independently of adjacent sequences . To validate this hypothesis and search for LRIs that the single - stranded regions of SL2 may form with other areas of the packaging signal , we transcribed SL2 RNA independently , examined its 1M7 reactivity , and compared the data with SL2 in the context of the 511 - nt RNA ( Figure 1B ) . Nucleotide reactivities are broadly similar across SL2 , whether analysed alone or in the context of the extended 5 0 and 3 0 structure , suggesting that SL2 forms independently of 5 0 and 3 0 sub - domains , i.e. independent of LRIs . Subtle differences in nucleotide reactivity were noted between the structures shown in Figure 1A and B , which may reflect minor experimental variation .	8169492	no
Since a general point in phase - space is the restriction to the hypersurface Ï = 0 of the general solution we can identify the space S C of ( complexified ) solutions with ( complexified ) phasespace P â C . Furthermore , the subset S V C â S C of solutions satisfying Virasoro and static gauge conditions can be identified with the second class constraint surface P V C â P â C defined by these conditions . We can describe the map ( 4.1 ) as an embedding M ( 2g+2 ) C Öâ P V C . If we further impose reality conditions by restricting the algebro - geometric data M ( 2g+2 ) C to real algebro - geometric data ( see [ 13 ] for a detailed discussion of reality conditions ) then finite - gap integration describes an injective map [ 35 ]	17330396	no
Differences between inspectors and data analysts It was already assumed that inspectors and data analysts represent distinct knowledge sources , in this case about risks . During our workshops and interviews the differences showed in a surprising fashion . First , they had different views on what ' working risk - oriented ' means . The data analysts viewed working risk - oriented almost solely as working datadriven . It appeared that inspectors viewed working risk - oriented in a broader perspective , including soft coordination and individual mental models . Second , the data analysts mostly focused on the inner working of the risk model , while the inspectors focused more on the practical use of the model and its implications for the organisation .	239658990	no
To allow for a pooled analysis of data , studies dosing BDNF levels on samples different from plasma or serum ( i.e. , histological samples ) , lacking of a control group , including a study population with a clinical condition other than obesity were excluded .	51929381	no
where Î¸ 0 is the initial angle of the platelet ( Figure S6 , Supporting Information ) . By comparing the predictions of this geometrical model with the experimental data , we find that the theoretical analysis slightly overestimates the absolute Î¸ values but captures   reasonably well the dependence of the platelet angle on the applied global strain . A more detailed analysis of the platelet angle as a function of the imposed strain can be obtained by performing finite element simulations of the platelet - laden composite ( Figure 3B and Movie S4 , Supporting Information ) . To enable a direct comparison with the experimental observations , a composite containing platelets aligned out - of - plane was first strained along the direction that was mechanically loaded in the experiment ( x axis ) . Top and side views of the platelets at an applied strain of 100 % show a good qualitative agreement between the simulations and the experimental microscopy images ( Figure 3A , B ) . With the help of these simulations , we also studied the response of the platelets when the global strain is applied parallel to the alignment plane ( y axis ) . Our simulations indicate that this loading configuration does not lead to any significant rotation of the platelets , which explains the anisotropic nature of the strain - induced color change ( Figures 2E and 4A ) . A quantitative comparison between simulations and experiments for composites loaded along the color - changing direction reveals that the finite element analysis correctly captures the experimentally observed trend between the platelet angle and the applied strains .	238582485	no
Context bias detection with grid saliency . In the last column of Fig . 4 ( b ) , we report the context bias detection results for our perturbation - based grid saliency method , described in Sec . 3.1 , using the CBD metric ( see Eq . 6 ) . The mCBD values are visualized with respect to networks trained on data biased to different digits DS s / w - bias ( y - axis ) and for the different digit classes ( x - axis ) in the biased test set . The only exception is the first row ( labeled as N ) , where for comparison we show the results with no bias , for the network trained on DS no - bias . We observe that our grid saliency shows substantial evidence of context bias for digits with induced bias ( diagonal elements ) , both strong and weak . Even for the weak bias in Fig . 4 ( b ) the grid saliency still clearly differentiates between biased and unbiased digits ( diagonal vs. non - diagonal elements ) . Note that the bias detection using the grid saliency does not require an unbiased test set . In the suppl . material , we also study the influence of the bias texture as well as the choice of hyperparameters .	198986162	no
These offerings include personally identifiable genetic and phenotypic data resulting from biomedical research projects - an area of growing importance as healthcare systems embrace genomic medicine . Managing access to these data sets is a high - priority activity at EMBL - EBI .	16455049	no
and then used the magnetization the equation of motion ( 2 ) to compute the current data point according to	236175782	no
Results of CV experiments for the third to fifth cycle of Na/ NiCr 2 S 4 ( see Figure S17 for cycles 1 - 5 , Supporting Information ) , for the third cycle of Na / Cr 3 S 4 and of Na / NiS are shown in Figure 7a . The third to fifth cathodic CV profiles exhibit two pronounced reduction peaks around 0.75 and 0.42 V ( Peaks 1 and 2 ) , whereas two distinct oxidation peaks occur at 1.24 and 1.56 V ( Peaks 3 and 4 ) in the anodic CV curves . For Na / NiS and Na / Cr 3 S 4 , only one major reduction and oxidation peak occur together with less distinct features . The Na / NiS CV agrees with literature data , [ 57,81 ] while no data are available for binary Cr sulfides used in SIBs . The comparison of the CV data recorded for the three different cells does not imply identical Na storage mechanisms , but allows assignment of CV peaks for Na / NiCr 2 S 4 to redox processes involving Ni and Cr as shown in Table 4 .	237443435	no
One possible explanation for the increased AÎ² production in the Aph1 L30F / T164A mutant is that the mutations increase complex formation . To test whether the Aph1 L30F / T164A mutants form a complex with other components , Î³ - secretase in yeast microsomes was immunoprecipitated with a PS1 antibody against the loop region ( GIL3 ) ( Figure 5 ) . NCT , PS1 , and Aph1 were coimmunoprecipitated with wild - type Aph1 or the . Aph1 mutations activate Î³ - secretase in yeast microsomes . Microsomes were prepared from yeast transformants expressing Aph1 WT or Aph1 L30F / T164A mutants , PS1 , NCT , FLAG - Pen2 , and the C55 fragment of APP ; they were then subjected to Î³ - secretase assays . CHAPSOsolubilized microsomes ( 40 Âµg protein ) were incubated at 37 â¢ C for 24 h in the presence or absence of phosphatidylcholine ( PC ) ( 0.1 % ) and Î³ - secretase - specific inhibitor ( L685 , 458 ) . ( a , b ) Total AÎ² production was analyzed by immunoblotting using the antibody 82E1 . ( c , d ) AÎ² species were separated by urea / SDS - PAGE and analyzed by immunoblotting with 82E1 . Synthetic AÎ²38 , AÎ²40 , AÎ²42 , and AÎ²43 ( 30 pg ) were loaded as controls in the left - most lanes ( a , c ) . Amount of AÎ² ( b , d ) and the ratio of AÎ² species ( e ) were quantified from three independent assays ; data are shown with standard deviations . Statistical analyses were performed using one - way ANOVA followed by Dunnett 's multiple comparison test . Asterisks on each bar indicate p < 0.01 ( * * ) or p < 0.05 ( * ) with respect to Aph1 WT ( b , d , e ) . l. Sci . 2022 , 23 , x FOR PEER REVIEW Figure 5 . Aph1aL L30F / T164A mutant forms Î³ - secretase complexes in ye pared from yeast transformants as in Figure 4 and solubilized with buffe The Î³ - secretase complex was purified from extracts using an antibody a ( G1L3 ) or rabbit pre - immune serum , as indicated . Immunoprecipitants a analyzed by immunoblotting using specific antibodies . The input represe extract .	245819537	no
The land - use / cover data were extracted from the pan - European component of the Copernicus land monitoring service ( CLMS , 2020 ) . In particular , the CORINE land cover ( CLC ) dataset for the year 2012 was used ( Corine Land Cover , 2012 ) . To better understand the urban surface characteristics surrounding each monitoring station , a squared buffer zone of 1 km 2 spatial resolution was created and the dominant CLC category within each buffer zone was computed and assigned to the respective site . The 45 land classes available in CLC were aggregated to form the following 4 main categories : ( i ) continuous urban fabricroad and rail networks and associated land -port areas ( LC1 ) ; ( ii ) discontinuous urban fabric -industrial or commercial units -mine , dump and construction sites -artificial , non - agricultural vegetated areas ( LC2 ) ; ( iii ) agricultural areas -wetlands -water bodies ( LC3 ) ; and ( iv ) forest and semi natural areas ( LC4 ) . Additionally , the high resolution layers of tree cover density ( TCD , 2015 ) , imperviousness density ( IMP , 2015 ) and European settlement map ( ESM , 2016 ) were accessed from the same source ( CLMS , 2020 ) . The digital elevation model ( Digital Elevation Model Over Europe ( EU - DEM ) , 2017 ) product was downloaded from the EEA website .	236291671	no
Therefore , seeking to identify available surveillance options to track the infections generated by COVID-19 using user data , the present study conducts an original Systematic Literature Review ( SLR ) of previous studies published thus about strategies , technologies , and actions to track and geolocate data from users ' mobile devices . The results are then analyzed from the point of view of user privacy .	233029680	no
Herein , we present the synthesis of ac ubic ferric catecholate framework material coined Fe - HHTP - MOF . TheF e - HHTP - MOF is obtained in as olvothermal reaction as ad ark black powder consisting of intergrown tetrahedral crystallites in the 300 - 500 nm size range . T he structure was solved from powder X - ray diffraction data using aM o - K a source by indexing and as ubsequent simulated annealing step . T he unit cell obtained was subjected to aD FT optimization and Rietveld refinement to give af inal structure model with the cubic space group F23 . Thes tructure of Fe - HHTP - MOF is composed of iron - connected supertetrahedra to give ad iamond - like topology . T he tetrahedra are composed of four triphenylene units that form the facets and are interconnected by ad efined trinuclear iron - oxo cluster . T he Fe - HHTP - MOF is microporous with aB ET surface area exceeding 1400 m 2 g Ã1 .M oreover , F e - HHTP - MOF combines this high surface area with electrical conductivity of about 10 Ã3 Scm Ã1 , t hus establishing an exceptionally high intrinsic conductivity for a3 D - connected framework . Thed eep black appearance of the material was studied by reflectance measurements , g iving ar emarkably low degree of reflection up to 1.5 % i nt he visible spectral regime for ap orous framework . Then ature of the ferric repeat unit was elucidated by means of XPS , E PR , SQUID , a nd 57 Fe MÃ§ssbauer measurements , i ndicating the presence of ap urely ferric , high - spin Fe III framework . To gain further insights into the electrical conductivity of Fe - HHTP - MOF , w ep erformed quantum mechanical calculations , w hich suggest the Fe - HHTP - MOF to be an efficient electron conductor that exhibits continuous paths through the conducting framework atoms . T his work sheds light on the subtle interplay of the structure , p orosity , e lectronic properties , e lectrical conductance , and broad - band optical absorption of novel framework materials , which serves as ablueprint for the future design of electrically conducting metal - organic frameworks . T he combination of the substantial porosity of Fe - HHTP - MOF with high electrical conductivity and an arrow direct band gap offers exciting opportunities for the design of novel chemical sensors , o rganic optoelectronics , a nd for electric control of mass transport in porous systems , such as microfluidics . Figure 7 . A ) Calculated hole - and B ) electron - transport paths . Isocontour plots for 8time steps ( 24 fs each ) of the electron ( green to blue ) and hole density ( green to red;c ontour level = 1.2 10 Ã5 e - Bohr Ã3 ) . The initial Gaussian functioni sshown as transparentsphere . Isocontour plots of C ) the PM6 local electron affinity ( contour level = 0kcal mol Ã1 ) a nd D ) local ionization energy ( contour level = 330 kcal mol Ã1 = 14.3 eV ) .	232408466	no
A single splice - site variant ( 12 - 40626187 - T - C ) , found in 77 gnomAD carriers , was identified in an individual with RNA - seq data in the GTEx project . The RNA - seq reads were manually inspected to look for any effect on splicing . Assessing the read distribution of a linked heterozygous variant in this individual showed convincingly that the variant has no discernible effect on transcript splicing ( Extended Data Fig . 3 ) . All available tissues were assessed with reads from lung tissue shown in Extended Data Fig . 3 . The variant was also identified in eight UK Biobank carriers and in 23andMe and was similarly excluded from these cohorts .	218912587	no
To establish strong privacy guarantees , it is important to limit the student 's access to its teachers , so that the student 's exposure to teachers ' knowledge can be meaningfully quantified and bounded . Fortunately , there are many techniques for speeding up knowledge transfer that can reduce the rate of student / teacher consultation during learning . We describe several techniques in this paper , the most effective of which makes use of generative adversarial networks ( GANs ) ( Goodfellow et al . , 2014 ) applied to semi - supervised learning , using the implementation proposed by Salimans et al . ( 2016 ) . For clarity , we use the term PATE - G when our approach is combined with generative , semisupervised methods . Like all semi - supervised learning methods , PATE - G assumes the student has access to additional , unlabeled data , which , in this context , must be public or non - sensitive . This assumption should not greatly restrict our method 's applicability : even when learning on sensitive data , a non - overlapping , unlabeled set of data often exists , from which semi - supervised methods can extract distribution priors . For instance , public datasets exist for text and images , and for medical data .	8696462	no
"We also compared PAL levels for "" top-10 "" lists of the most and the least correlated molecular pathways in Lung Adenocarcinoma biosamples ( Figure 14 ) for the transcriptomic and proteomic data . All of the most and the least correlated pathways showed common activation or inhibition trends for the RNA and protein expression data ."	247184795	no
Concern for Wellbeing The Cocoa Plan aims to contribute directly to farmers ' material wellbeing through the price premiums paid for UTZ - certified cocoa . These amounted to 12 , 17 or 18 GHS ( 2.42 - 3.64 Euro ) in the communities visited in 2017 , depending on the community and supplier ( Focus groups : D1 - 5 ) . The cash premium thus accounts for a sup - plement of 2.5 - 3.8 percent on top of the standard price per bag of 475 GHS ( 96 Euro ) in the 2016/2017 and 2017/2018 seasons . However , certified farmers in most of the visited communities only received a premium for bags that they sold during the main harvest period - locally referred to as the ' bumper season'-which usually runs from October to December or January ( Focus groups : D2 - 8 ; Interviews E2 - 5 ) . Anecdotal evidence provided by individual farmers and purchasing clerks suggests that certified farmers only receive a cash premium for 30 to 50 percent of their annual cocoa production . The data is inconclusive as to the scale and reasons for this phenomenon .	234832730	no
Fig . S1a represents the theoretical momentum - space polaritonic dispersion of the ring with a diameter of 3 ï­m , in good agreement with the experimental data of Fig . 1c of the text . The polaritonic energy separates into multiple discrete coupled orbital modes ( COMs ) . This is obtained from a Fourier transform of the wavefunction ( , , ) into the energy domain in reciprocal space ( , , ) . Theoretically , the reciprocal - space dispersion is given by = | ( , , = 0)| 2 , which is a function of and E at = 0 .	232088558	no
This work has introduced a new family of loss functions for the direct minimization of the top - k error ( that is , without the need for fine - tuning ) . We have empirically shown that non - sparsity is essential for loss functions to work well with deep neural networks . Thanks to a connection to polynomial algebra and a novel approximation , we have presented efficient algorithms to compute the smooth loss and its gradient . The experimental results have demonstrated that our smooth top-5 loss function is more robust to noise and overfitting than cross - entropy when the amount of training data is limited .	3384895	no
The bulk of the literature is focused on the first step . In Section 3 , we show how to efficiently implement both steps in a single - pass over the data and provide the details of a MapReduce implementation .	1669303	no
The large spin - down power of the new - born magnetar would produce Î³ - ray emission due to magnetospheric activities and interactions between the pulsar wind and the surrounding medium ( likely the nebula itself ) . It would be then interesting to search for possible Î³ - ray signals from the source using the archival Fermi Large Area Telescope ( LAT ) data . This paper reports the results from such a search .	119091008	no
We use the mean here as a robust estimate of all sample pairs as with a low amount of samples ( e.g. 20 ) , we do n't observe enough data for inferring outliers or cluster Further , we identify the j th sample signal intensity with the Euclidean norm d ij 2 , and the signal intensity S i for the i th variable with the norm of the expected sample signal	14791360	no
The ( 2 , 1 ) metric can be calculated in two parts . The first part is due to the ( 2 , ) monopole . This metric includes the effects of the ( , 1)-monopole on the ( 2 , ) -monopole but does not include the ( , 1)-monopole itself . The second part of the metric is due to the ( , 1)-monopole . This is described in Section 2 . First , the Nahm data are introduced along with the groups acting on them . Gauge - invariant coordinates on M ( 2,1 ) are then defined from the Nahm data and a set of one - forms defined from the exterior derivatives of these coordinates . Tangent vectors dual to these one - forms are calculated and the metric expressed in terms of the tangent vectors . The calculation of the explicit metric is presented in Section 3 . In Section 4.1 another way of calculating the metric is discussed in which the physical description given above is very apparent . In this Section , the hyperKÃ¤hler quotient construction is used to construct the metric on M ( 2,1 ) from the direct product of the ( 2 , [ 1])-monopole and 1 - monopole metrics .	10918546	no
"A weakness of this study is the retrospective data collection of residential address history , which can be prone to recall bias . We were also limited by the numbers available for the analysis sample due to the criteria for eligibility being based on continued lifetime residence in a small geographic area . It was necessary to dichotomise OSC as to provide greater statistical power for stratified models ( i.e. to keep cell sizes to an appropriate size ) . This dichotomisation was also appropriate when this variable was used as a covariate , as previous research found that significant differences in health outcomes were only found between "" professional or managerial occupations "" compared to the rest ( Gale et al . , 2016 ) . We dichotomised other covariates ( e.g. smoking status ) as they were not recorded in the same way for childhood and adulthood and therefore dichotomisation was used to aid interpretation of change over time . The analysis sample was broadly similar in terms of selected characteristics compared with the full cohort at age 70 , but selection bias may have caused a higher number of participants from lower socioeconomic groups being included . The issue of selection bias was partly addressed by running the sensitivity analysis using a sample with different assumptions . For addresses within the Edinburgh area , the precision of the addresses supplied varied and therefore , for a small number of addresses that did not have a house number , the error between actual participant residence and geocoded address was larger as we took the centre of their street . In addition , by geocoding using contemporary sources , we have assumed that the street layout was the same as it is today for the majority of the addresses , with only minor changes to the street content . However we acknowledge that these small changes could have affected the precision of the park exposure estimate for the earlier time periods . Given that we were geocoding a relatively small number of addresses , we were able to employ a system to detect information lost compared with what was supplied , so that if the results were unsatisfactory they would be geocoded manually . This ensured that addresses that had changed significantly ( e.g. demolished ) would be geocoded to the same accuracy as those that were able to be geocoded with contemporary sources ( < 3 m ) . Given the complexity of the existing analysis , with multiple exposures from different time points , we were unable to include the examination of non - linearity . However , we would encourage this in future analyses , especially using the forthcoming cognitive data waves in the LBC1936 ."	4135248	no
Mice bearing orthotopic MCF10CA1a tumors were injected intravenously ( i.v . ) with targeted ( LinTT1 or RPAR ) and non - targeted DiRlabeled PS ( 80 mg / kg ) . The mice were anesthetized with 3 % isoflurane ( Forane , 99.9 % w / w , Abbvie ) blended with O2 at 1 mL / min flow , and imaged using IVIS Spectrum In Vivo Imaging System ( IVIS ; PerkinElmer , US ) at different time points ( 0 ; 1 ; 3 ; 6 ; 24 ; and 48 h postinjection ) . The parameters for in vivo imaging were as follows -exposure time : 0.5 sec ; pixel binning : medium ; F / stop : 4 ; excitation filter : 745 nm ; emission filter : 830 nm ; and stage temperature : 37 Â° C . After the last imaging , the animals were sacrificed by perfusion with 10 mL PBS , the tumors and organs were excised and preserved in PFA 4 % in PBS at 4 Â° C . The signal from DiR - PS in tumor was measured selecting the region of interest ( ROI ) and quantified using Living Image 4.5.2 . The area under the curve ( AUC ) in tumor was constructed from the in vivo quantification data . For the ex vivo analysis of tumors treated with LinTT1 - UTO - PS , UTO - PS and free DOX , the MCF10CA1a tumor - bearing mice were i.v injected with the PS samples at a dose of 5 mg of drug / kg . After 24h the mice were terminated , tumors extracted and the immunofluorescence microscopy was performed as described below .	233427024	no
We then surveyed what turned out to be a massive literature in order to assess G7 performance with respect to Summit commitments , and the health implications of the policies reflected by those commitments . The literature comprised : quantitative data assembled by organizations including the World Bank , OECD , and several United Nations agencies ; an extensive body of research by civil society organizations ( CSOs ) such as Oxfam and Jubilee Research ; and an expanding research literature on determinants of population health in the developing world . These categories tend to overlap , in particular as the work of key CSO - affiliated researchers is published by '' mainstream '' agencies ( Third World Network , 2001;Pettifor & Greenhill , 2002 ; . We carried out our own calculations and policy evaluations using these data , but did not check on their accuracy beyond the identification of clear inadequacies in the data as published . It must be noted that at least as many questions have been raised about the accuracy of data generated by agencies such as the World Bank and the World Health Organization ( e.g. Musgrove , 2003;Reddy & Pogge , 2003 ) as about the research and policy recommendations of CSOs .	22386928	no
ing that GW170817 produced a successful jet ( Duffell et al . 2018 ) . Using these new data we can also derive robust constraints on the smoothness parameter ( s ) and therefore the sharpness of the light curve peak , something which has not been possible with previously - reported data . Together with the sharpness of the peak , the steep decline indicates that the jet is extremely narrow and that most of the outflow energy of GW170817 resides in the jet . Through simple analytical arguments we are able to place a constraint on the geometry , Î¸ v 8Î¸ j ( Î¸ v 6Î¸ j with semi - analytical modeling ; Î¸ v is the viewing angle and Î¸ j is the jet half - opening angle ) , and implies Î¸ j 5 o if we further use the viewing angle constraint provided by the LIGO - Virgo Collaboration . Using Î 4 close to the peak of the light curve ( estimated from the observed superluminal motion in GW170817 ) gives Î¸ j 3 o and Î¸ v 15 o .	85443564	no
As noted previously , the likelihood of the data are unchanged by adding a constant to the selection coefficient s d in each frequency bin d. We enforce the condition D d=1 s d = 0 to achieve a unique maximum likelihood parameter set . We enforce the constraint by adding the appropriate constant at each iteration . ( Absent any enforcement of the constraint , the MM iterates settle on an arbitrary value ofÅ that indeed satisfies Eq . S13 , but the particular valueÅ depends on the initial condition s ( 0 ) . )	232380291	no
As PNIPAM is temperature - responsive , [ 16 ] siRNA - SS - PNIPAM copolymers can self - assemble into nanoparticles upon heating , with al ower critical solution temperature ( LCST ) of 30 8 8C , 31 8 8C , and 32 8 8Cfor PNIPAM components of 7kDa , 13 kDa , and 19 kDa , respectively ( Supporting Information , Table S2 ) . This enables nanoparticles to control drug loading during the self - assembly process . G el retardation assays show that after siRNA - SS - PNIPAM heating , no free siRNAw as released and all siRNAs tayed in the initial position ( Figure 1a ) , further confirming successful nanoparticle formulation . Dynamic light scattering ( DLS ) measurements show that the formulated nanoparticles ranged in particle size from 126 nm to 135 nm ( Figure 1b and Supporting Information , Table S2 ) while exhibiting very narrow polydispersity index ( PDI ) . Tr ansmission electron microscopy ( TEM ) images further confirmed the particle size . M ore importantly , aclear vesicular morphology , w ith an empty interior and as olid layer , was observed in nanoparticles derived from PNIPAMs of three different molecular weights ( Figure 1cand Supporting Information , Figure S4 ) , indicating the successful formation of siRNAsome . F urthermore , t he siRNAsomes are very stable under physiological condition , their particle size was constant and no siRNAr elease was observed even after up to 7days of storage ( Supporting Information , Figure S5 ) . Thes iRNAsomes derived from PNIPAMs of 19 kDa in molecular weight showed the best dilution stability ( lowest critical aggregation concentration , CAC ; Supporting Information , Table S2 ) . Using PNIPAM of this molecular weight , the drug - loading utility of siRNAsome was confirmed by performing an encapsulation experiment using the hydrophilic drug doxorubicin hydrochloride ( DoxÂ·HCl ) , the hydrophobic drug docetaxel ( DTX ) , and the hydrophilic protein bovine serum albumin ( BSA ) . As shown in Tables S3 in the Supporting Information , successful encapsulation of DoxÂ·HCl , DTX , and BSA was achieved during the siRNAsome fabrication process . U sing siRNA - SS - PNIPAM copolymer , upon heating , loading efficacies of approximately 37 % , 43 % , and 33 % ( for DoxÂ·HCl , DTX , and BSA , respectively ) were achieved at at heoretical drug loading content of 20 wt.% . These data confirm that the siRNAsome Scheme 1 . Illustration of siRNAsomef ormation , composition , and function . T > LCST = Temperatureg reater than the lower critical solution temperature . nanostructure can serve as au niquely versatile carrier for therapeutic agents with diverse chemical properties and types .	73445501	no
. This type of surrogate does not assume Gaussianity and preserves the whole statistical structure of the original time series . We use a nonparametric kernel distribution representation of the probability density function of the surrogate values of C , and compare the fraction of area of that distribution above the value of the NDTE flow of the original data , C original I , with the total area , and compute the corresponding P value . Supplementary Fig . 2 shows all the P values for all the pairs of time series across all the participants in each of the eight conditions coming from the surrogates .	230509029	no
Since the order s 4 - avor results are comparable to the order 2 s ones at energy scales close to the threshold in both cases ( and for other values of x ) , it is reasonable to choose the transition scale at a relatively low value , as mentioned earlier in the paper . The band representing the 3 - avor calculation does become wider at large Q for x = 10 2 ( where the absolute values also are lower than the 4 - avor calculation and data ) ; but for x = 10 4 , it remains quite narrow . Thus , the theoretically infra - red unsafe logarithms , ln 1;2 ( = m c ) , do not seem to cause serious problems , at least for very low x.	15351369	no
Using archival data retrieved from a proprietary database for an international sample of 199 large listed companies , we hypothesise that each of the stakeholder attributes ( power , urgency , and legitimacy ) is positively related to the level of public environmental disclosure . Even though univariate results affirm the hypothesised relationships , multivariate analysis reveals that the influences of power and urgency are in fact mediated by legitimacy . Hence , only legitimacy is directly associated with environmental disclosure , while the influences of power and urgency are of an indirect nature . These findings also hold when controls for company size , institutional context , industry , environmental performance , and institutional shareholdings are included in the model .	254384414	no
The data have been collected from fieldwork and extensive archival analysis of videos and documents . In total , I undertook three field trips to Mariana from the start of 2019 , resulting in 48 days of content for analysis . Before this , the first research visit to Mariana was in December 2012 , when I conducted 18 interviews almost three years prior to the disaster event while researching community perceptions on mining . During this first visit , it became immediately apparent that the community was highly dependent on Samarco for its livelihood and economy in general . This visit significantly aided me in becoming acquainted with the local cultural context and making key contacts for future field 1 3 research six years later , thus facilitating access to further interviewees in mid-2016 and during consequent visits in January , August and December of 2019 and in January 2020 . Since mid-2016 , I have been in contact with one atingida woman leader from Bento Rodrigues , having interviewed her and requested her for video testimony for a conference on human rights defenders . Since then , I have analysed archival documents comprising videos , media reports and Brazilian academic publications on the disaster .	254384500	no
It is hard if not impossible , without knowing the underlying truth , to get good estimates of detection sensitivity and specificity or other direct accuracy measures , so we evaluated the rankings of potential pairs by related validation data for comparison and assessment of different methods . Using related Hi - C data , we created Aggregate Peak Analysis ( APA ) plots and found that the ranking of potential pairs by ChIAPoP is better than those by other methods . We used FDR - adjusted P - values to rank the pairs for each method , except for ChiaSig which only outputs P - values .   In a parenthesis is the proportion of the corresponding significant pairs in all significant pairs detected by the more conservative method ( either ChiaSig or mango ) .	73420392	no
"In economics literature , the notion of output - oriented plant capacity has been informally defined as "" the maximum amount that can be produced per unit of time with existing plant and equipment , provided that the availability of variable factors of production is not restricted "" ( Johansen ( 1968 , p. 362 ) ) . FÃ¤re et al . ( 1989a ) and FÃ¤re et al . ( 1989b ) published relevant articles and provided a formal definition according to a nonparametric frontier framework . Their measure of plant capacity utilization leverages data about observed inputs and outputs , using two output - oriented efficiency measures . Their work also prompted a series of empirical applications in diverse sectors , such as of fisheries ( e.g. , Felthoven , 2002;Tingley and Pascoe , 2005 ) and health care ( e.g. , Karagiannis , 2015;Magnussen and Rivers Mobley , 1999 ) ) , as well as banking ( Sahoo and Tone , 2009 ) and a macroeconomic application to trade barriers ( Badau , 2015 ) ."	231706096	no
We used SAS ( version 9.1 ) for univariable data analysis and to generate a multivariable logistic regression model . We used Student 's t test , Wilcoxon rank sum test , or Ï 2 test for comparing characteristics in the study population and pregnancy outcomes between women who did and did not develop pre - eclampsia . Stepwise logistic regression was used to determine independent risk factors for pre - eclampsia in both datasets . The order of variable selection was determined by the Ï 2 statistic for each potential variable and the forward selection step could be followed by removal of variables in one or more backward elimination steps . We calculated receiver operating characteristics curves and determined screening test characteristics at a 25 % , 10 % , and 5 % false positive rate . For internal validation we evaluated the calibration and discrimination ( 10 - fold cross validation ) of the model using methods described by Altman et al . 30 Calibration was assessed by plotting the observed proportion of events against the predicted probabilities . For the cross validation , participants were stratified by region ( New Zealand , Australia , Ireland , and UK ) , pre - eclampsia status ( positive or negative ) , and gestation ( < 260 days or â¥260 days ) and randomly allocated to one of 10 groups . Tenfold cross validation was then performed , with 90 % of the data used to generate a model , and estimation of disease risk was performed in the 10 % remaining . These predicted values were then combined across the 10 runs and summarised by the C statistic ( AUC ) . This entire procedure was repeated 10 times .	12885268	no
An alternative strategy is to use an unsupervised approach , which defines relevant regions across the genome first , independently of any phenotype information , and then tests methylation levels in these predefined regions against a phenotype ( 19,20,26 ) . In this study , we propose a new unsupervised approach for testing differential methylation in regions against continuous phenotype such as age , tumor size or marker protein concentrations . Note that in the proposed mixed effects model ( Supplementary Text , Section 1 ) , the phenotype variable is included as an independent variable and the methylation values as the outcome variable . Therefore , no distributional assumptions ( e.g. normal distribution ) are made for the continuous phenotypes . Table 1 lists several previously proposed unsupervised methods . A challenge with unsupervised approaches is their lack of specificity . Unlike gene expression data , the regional boundary of DNA methylation is often not well defined . Therefore , currently available approaches that summarize methylation levels in a region using mean or median methylation levels of the CpGs within the region may have results that vary depending on the boundaries of the region . In addition , when testing associations between phenotype and the summarized methylation levels in a genomic region , the spatial correlations between CpG sites within the region is ignored .	195880945	no
The situation has swayed back after the LEP2 results . The lack of discovery of a Higgs boson below 114 GeV or of any new states has forced supersymmetry into fine - tuning territory , partially undermining its original motivation . Moreover , new theoretical developments , mostly influenced by extra dimensions and by the connection between strongly - interacting gauge theories and gravity on warped geometries , have led the way to the construction of new models of electroweak symmetry breaking [ 1][2][3][4][5][6 ] . Still , the complete replacement of the Higgs sector with strongly - interacting dynamics seemed hard to implement , mostly because of constraints from electroweak data . A more promising approach is to keep the Higgs boson as an effective field arising from new dynamics [ 7,8 ] which becomes strong at a scale not much larger than the Fermi scale . There has been various attempts to realize such scenario , including the Little Higgs [ 2 ] , Holographic Higgs as Goldstone bosons [ 5,6 ] or not [ 9 ] , and other variations .	15292325	no
Probably the environment is the only sector that got an immensely positive impact form this COVID-19 scenario . International energy agency reported that global coal use was 8 % lower in the first quarter in 2020 . Due to the Locked down , transport , industry , and all non - essential sectors were closed , which reduced emission significantly . NASA ( National Aeronautics and Space Administration ) and ESA ( European Space Agency ) published recent data ( Fig . 9 ) declaring that compared to last year , NO 2 emission reduced by 30 % ( Dutheil et al . , 2020 ) . The decline in PM2.5 was significant in the US , UAE , Italy , and Spain , in the month of March , due to cumulative lockdown ( Chauhan and Singh , 2020 ) . Noticeably , in China , the overall air quality improved as NO 2 reduced by 22.8 Î¼g / m 3 , PM 2.5 decreased by 1.4 Î¼g / m 3 particularly in Wuhan ( Zambrano - Monserrate et al . , 2020 ) and by 18.9 Î¼g / m 3 in 367 other cities ( Lal et al . , 2020 ) . However , some cities also witnessed the air quality index over 100 . These reductions accounted for lowering the particle loadings ( Wang et al . , 2020f ) . Air quality showed improvement near the Yangtze River Delta ( YRD ) region , which is one of the economic city - clusters in Eastern China . However , the percentage of PM 2.5 attributed to residences and long - range transport . Additionally , 44 cities of northern China marked 69.5 % reduction in human mobility improving the air quality as SO 2 , PM2.5 , PM10 , NO 2 , and CO decreased by 6.76 % , 5.93 % , 13.66 % , 24.67 % , and 4.58 % , respectively ( Bao and Zhang , 2020 ) . In 2017 , the energy sector in Italy ( industry and transport ) contributed 80 % of the total country GHG emissions . COVID-19 related lockdown caused an overall 20 % reduction of GHG emission , lower than emissions of March and April in 2015 - 2019 ( Rugani and Caro , 2020 ) . In Milan , Italy , partial lockdown restricted the people movement , and total lockdown terminated industry and transport activities . Reduction of PM10 , PM2.5 , BC , benzene , CO , and NOx level was observed because of a decrease in road transport ( Collivignarelli et al . , 2020 ) . In Barcelona , PM10 reduced by 31 %   and NO 2 by 50 % ( Baldasano , 2020 ) . Initially , Madrid and Barcelona contributed 55 % and 56 % of NO 2 emission from traffic . However , due to the COVID-19 scenario - based lockdown , since March , Barcelona and Madrid ( Spain ) , emitted 50 % and 62 % less NO 2 respectively ( Baldasano , 2020 ) . In the continental USA , PM2.5 reduced during the lockdown , especially in urban counties and wherever non - essential businesses were closed ( Berman and Ebisu , 2020 ) . During the lockdown period ( March 19th to April 14th , 2020 ) , reduction in PM2.5 , NO 2 , and CO concentration by 21 % , by 35 % , CO by 49 % , was noticed in Almaty , Kazakhstan ( Kerimray et al . , 2020 ) . Sao Paolo Brazil also encountered a reduction in CO and NO 2 emission by 64.8 % , and 77.3 % ( Nakada and Urban , 2020 ) . Further , PM10 , NO 2 , and SO 2 emissions decreased by more than half during the COVID-19 lockdown period in SalÃ© City , Morocco ( Otmani et al . , 2020 ) . India , every year battles more than 350,000 new cases of childhood asthma and 16000 premature death attributed to air pollution , mostly NO 2 and PM ( 2.5 - 10 Î¼m ) generated from fossil fuels and transportation sector ( CREA , 2020 ) .	236247702	no
In this context , the main objective of the present work was to develop parametric and nonparametric statistical models useful to determine the entire SARS - CoV-2 infected population , including symptomatic and asymptomatic people , by tracking the viral load present in the wastewater of the Bens wastewater treatment plant that serves the metropolitan area of A CoruÃ±a with near 370,000 residents , without the need of health system data or the number of positive people reported , and obtaining information from population - based seroepidemiological surveys developed in Spain ( this represents a contribution with respect to other models ) . The pursuit of this objective has a public service motivation . At this regard , it is important to note that this research , in the framework of the COVIDBENS project , had high social impact and it was one of the precursors of this type of monitoring in Spain , for the surveillance of SARSCoV-2 in wastewater . COVIDBENS currently provides a public service through weekly reports to municipalities , public health and regional administrations ( SERGAS , Xunta de Galicia ) for surveillance and early warning tasks .	245145432	no
All data and complete replication code for this aggregate - level study will be shared immediately following publication , with no end date , for public access and replication . Data are available indefinitely on the Harvard Dataverse at https://doi.org/10.7910/DVN/JTTNKO .	236321831	yes
Intuitively , f t , k is simply the indicator of whether arm k was pulled at time t ; the crucial part is g t , k , which specifies which arm is selected when arm k is not , and the IIO condition requires that g t , k ignores the data from arm k in order to determine which j = k to pull instead .	204924545	no
: Location map of the pilot test . The direction of groundwater flow is shown with the blue arrow . Figure S2 . Measured changes in water table depth during the injection of nanoparticles . Time 0 is the starting time of the pre - flushing phase ( same 0 as Figure 6 in the main text ) . Figure S3 . Adsorption isotherms of Zn to Goethite nanoparticles in ultrapure water ( circles ) and groundwater ( diamonds ) as well as to bulk goethite in ultrapure water ( squares ) at pH 7 . Data points and error bars show means and standard deviations of three replicate incubations . The lines depict fittings of the data with Langmuir adsorption isotherms .     	239215438	no
In this paper , we investigate a complementary method where we train models to detect unmodeled data by learning cues for whether an input is unmodeled . While it is difficult to model the full data distribution , we can learn effective heuristics for detecting out - of - distribution inputs by exposing the model to OOD examples , thus learning a more conservative concept of the inliers and enabling the detection of novel forms of anomalies . We propose leveraging diverse , realistic datasets for this purpose , with a method we call Outlier Exposure ( OE ) . OE provides a simple and effective way to consistently improve existing methods for OOD detection .	54558282	no
where we have marginalized the nuisance parameter Î± C . Here N S is the number of solar data points ( N S = 4 in the Rates Analysis and N S = 41 in the Global Analysis ) and N C = 14 is the number of CHOOZ data points . X 2 S is the solar least - squares function and V S is the corresponding covariance matrix , whose calculation in the Rates Analysis and in the Global Analysis is explained , respectively , in Sections 2.1 and 2.2 . X 2 C is the CHOOZ least - squares function and V C is the corresponding covariance matrix , whose calculation is explained in Section 2.1 .	8532813	no
We superimposed the X - ray structure of 23 - bound HIV-1 protease ( wild - type ) with the three most highly mutated drugresistant proteases . [ 51 ] These structures showed minimal rootmean - square deviation of the a - carbon backbone atoms ( 0.5 to 1.1 ) suggesting inhibitor 23 should retain good to excellent contacts with the backbone of the mutant proteases . As it turned out , inhibitor 23 exerted very potent activity against HIV-1 isolates ( HIV-1 LAI and HIV-1 Ba - L ) in both MT-2 cells and PHA - PBMC ( Table 10 ) . Furthermore , as evident in Table 9 , inhibitor 23 retained significant antiviral activity against a panel of HIV-1 drug - resistant viral strains . Inhibitor 23 displayed the most potent activity ( IC 50 = 3 nm ) against HIV-1 clinical strain HIV-1 ET , which had been isolated from a drug - naive patient . Furthermore , six drug - resistant clinical strains containing 10 - 12 amino acid substitutions associated with protease inhibitor resistance ( HIV-1 B , HIV-1 C , HIV-1 G , HIV-1 TM , HIV-1 EV , and HIV-1 ES ) were isolated from patients with HIV-1 infection having received 7 - 11 different antiviral agents for 24 to 81 months . [ 82,105 ] All tested approved PIs were highly resistant . However , inhibitor 23 exerted highly potent activity against all of these six variants with IC 50 values ranging from 4 nm to 52 nm . Inhibitor 23 was also highly potent against HIV-1 K with an IC 50 value as low as 3 nm . This data indicate that inhibitor 23 is highly active against a wide spectrum of drug - resistant variants . [ 51 ] 6.2 . Design of meso - Hexahydrocyclopenta-1,3 - dioxolane as a P2 Ligand	1252686	no
N-13 C - correlation experiment shown Figure S7 was performed using a 1 H-15 N CP step of 1 ms and a SPECIFIC - CP [ 10 ] 15 N-13 C step of 2.5 ms . The center frequencies were 50 ppm and 120 ppm for 15 N and 13 C dimensions , respectively . Acquisition times were 10 ms ( 800 data points used-497 ppm spectral width ) and 3.4 ms ( 25 data points-90 ppm spectral width ) for the direct and indirect dimensions , respectively . 384 scans were acquired . the 2D spectra were processed using a 0.33 Ï shifted sine squared window function in both dimensions .	195327158	no
WHO and the Center for Disease Control ( CDC ) assess risk and preparedness for a pandemic on a continuum of four pandemic phases ( alert , pandemic , transition , and interpandemic phases ) ( CDC 2016 , WHO 2010 ) . The time frame of our study corresponds to the alert and initial pandemic phases . During such a period , there is limited data about the accurate estimates of the virus transmissibility and severity , which are crucial parameters in understanding and predicting the course of a pandemic in epidemiology . Thus , we use available real - time data as proxy measures of consumers ' perceptions of risk severity and susceptibility to understand drivers of consumer mobility . The outcomes from our predictive model could be used as strategic inputs to improve several retail decisions even when there is limited data about virus transmission and severity .	255441206	no
Genomic surveillance of SARS - CoV-2 basically relied on the sequencing of clinical Corona Virus Disease 2019 ( COVID-19 ) samples . However , clinical genomic surveillance is expensive , inefficient , lacks community representation and has sampling bias due to testing of only symptomatic individuals and to systemic healthcare disparities , particularly in poor and underserved communities ( Kaplan et al . , 2021;Karthikeyan et al . , 2021;Peccia et al . , 2020;Smith et al . , 2021;Wolfe et al . , 2022 ) . Variants of SARS - CoV-2 can also be tracked in community wastewater ( wastewater genomic surveillance ) which offers cost - effective , unbiased and real - time capture of virus spread and dynamic ( Ahmed et al . , 2022a;Karthikeyan et al . , 2021;Michael - Kordatou et al . , 2020;Smith et al . , 2021 ) . In addition , wastewater genomic surveillance tracks existing and new emerging variants , for which targeted assays do not exist as yet . These data are valuable for transmission network analysis and interpretation , as well as an emerging technology for tracing viral evolution ( Karthikeyan et al . , 2021;Vo et al . , 2022 ) . However , wastewater genomic surveillance remains a challenge , since low viral loads , matrix effect , heavily fragmented RNA , poor enrichment or amplification of SARS - CoV-2 genome and PCR inhibitors could lead to poor sequencing quality ( Karthikeyan et al . , 2021;Wolfe et al . , 2022 ( Heijnen et al . , 2021 ) while Lee et al . applied RT - qPCR assays that detect mutations present in Alpha to wastewater samples ( Lee et al . , 2021 ) . Jahn et al . used wastewater genome sequencing to detect Alpha , Beta and Gamma variants ( Jahn et al . , 2021 ) . Yaniv et al . developed RT - qPCR assays for Alpha , Beta , Gamma and Delta ( Yaniv et al . , 2021a(Yaniv et al . , , 2021b . In addition , in our previous studies ( Avgeris et al . , 2021;Galani et al . , 2022 ) , we showed that wastewaterbased epidemiology ( WBE ) can predict hospitalizations and ICP admissions , whereas using our novel Nested - Seq assay for SARS - CoV-2 mutation / variant analysis we provided real - time monitoring of SARS - CoV-2 variants and identified those strains with selective advantage to become dominant in community / population level .	252621182	no
A causal parameter is said to be identified in a causal model if it is a function of the observed data distribution p(V ) . Otherwise the parameter is said to be non - identified . In any causal model of a DAG G , all interventional distributions p(V \ A|do(a ) ) are identified by the g - formula [ 18 ] :	54092990	no
We attempted to validate our models in independent cohorts but were limited by a lack of publicly available cohorts with all the molecular features and relevant clinical data on previous ipilimumab therapy and biopsy timing used in our integrated model . In a limited validation , we tested predictive models incorporating individual features where data were available in an independent validation cohort 44 ( Methods ) , and found concordant predictions of primary resistance with low MHC - II HLA expression in ipilimumab - treated tumors and higher heterogeneity in ipilimumabnaive tumors ( Extended Data Fig . 10 ) , although neither of these predictors was significant in this small cohort ( empiric P = 0.21 and P = 0.066 , respectively ; Methods ) .	208539915	no
In order to assess whether and how armed conflict intensity impacts maternal deaths , we link the survey data from Demographic Health Surveys ( DHS ) with conflict data from the Uppsala Conflict Data Program 's ( UCDP ) Georeferenced Event Dataset ( GED ) ( Sundberg and Melander , 2013 ) . The UCDP - GED includes information on the location of conflict events , as well as the number of deaths caused by each event . Events are included for all conflicts for dyads and actors that have crossed the 25 deaths threshold in any year of the UCDP annual data .	202573591	no
â¢ Negative interactions between the tip and sample ( e.g. , tip shielding and tip sweeping effects ) should be carefully considered when analyzing data obtained by AFM and related SPM techniques . For small samples and features , tip convolution , that is , imaging artefacts due to the tip radius being larger than the feature being imaged , can cause particular problems . This can also occur when the tip size / shape subtly changes during electrochemical cycling . As studies of nanoscale battery materials , materials with important nanoscale changes , or those examined during charge / discharge processes that produce detachable products become more common , it is important that authors carefully examine their data for these effects before drawing more complex conclusions .	237552462	no
As we want to calculate the correlation between clinical and wastewater data over a period where they are supposed to be similar and thus where the WWI is supposed to mainly capture a majority of people also likely to be diagnosed , we decided to focus on the period corresponding to the second and third waves of the epidemic in France . To avoid being biased by the movements of individuals during the 2020 summer vacations , we consider the start date of the second wave as September the 1st , 2020 , from which the majority of holidaymakers returned to their residence city . We consider that the last point of the interval of interest is the date from which the signal undergoes a new growth phase following the decay of the second peak of the epidemic .	245007358	no
Cifar10 is a widely used dataset for image classification , which contains 60k RGB images of size 32 Ã 32 categorized into 10 classes . The dataset is partitioned into a training set with 50k images and a test set with 10k images . Furthermore , data augmentation is applied to every training image , with padding 4 pixels to each side and randomly sampling a 32 Ã 32 crop . ResNet ( He et al . , 2015 ) , a well - known effective CNN model for image recognition , is adopted to perform classification on CIFAR-10 . Concretely speaking , we use ResNet32 and ResNet110 models , respectively containing 32 and 110 layers . The code is based on a public Lasagne implementation 3 . The mini - batch size is set as M = 128 and Momentum - SGD Sutskever et al . ( 2013 ) is used as the optimization algorithm . Following the learning rate scheduling strategy in the original paper ( He et al . , 2015 ) , we set the initial learning rate as 0.1 and multiply it by a factor of 0.1 after the 32k - th and 48k - th model update . Training in this way the test accuracy reaches about 92.4 % and 93.2 % , respectively for ResNet32 and ResNet110 .	13687188	no
There may be alternative approaches to scoring matches , especially in the case of immunotherapy , as one drug may be used in some circumstances to theoretically target multiple genomic alterations . It is becoming increasingly evident that immune checkpoint blockade and genomics are not separate silos , but rather linked to each other . This is because abnormalities in DNA damage repair and DNA replication can result in increased rates of somatic mutations in tumors . In turn , the presentation of neo - antigens generated by the mutanome in combination with immune system activation by checkpoint blockade can distinguish normal from tumor tissue . Based on studies demonstrating a relationship between TMB and immunotherapy response ( i.e. , the higher the TMB , the greater the response rate ) and between other gene alterations , such as PDL1 amplification and response , genomics is directly relevant to selecting patients for immune checkpoint blockade . 17,43 Furthermore , the FDA has approved the immune checkpoint inhibitor , pembrolizumab , for any solid tumor with alterations in DNA mismatch repair pathway genes ( e.g. ,MSH2 , MSH6 , MLH1 , PMS2 ) due to associated large increases in TMB . 35 Moreover , TMB increases correlate with a higher neoantigen load based upon somatic mutation data from the TCGA . 44 In turn , these would be expected to be more immunogenic and therefore responsive to immunotherapy . 17 In a retrospective fashion that was unblinded to outcomes , we developed an alternative approach for scoring immune checkpoint blockade matches . In a histology agnostic fashion , we previously reported objective response rates ( ORR , % ) for patients receiving immunotherapy in the setting of low , intermediate , and high TMB . 17 Therefore , we adopted these ORRs as the matching scores for intermediate TMB ( given under the I - PREDICT protocol ( PFS2 ) ; ( iii ) PFS2 versus PFS1 ( immediate prior line of therapy using patients as their own control ) , 7,46 ; ( iv ) percent of patients with a PFS2 / PFS1 ratio â¥1.3 ; 7 and ( v ) overall survival ( OS ) . SD , PR , or CR was initially determined per the assessment of the treating physician . Patients with ongoing SD for less than six months at the date of data cut off were considered inevaluable for the DCR . However , they were evaluable for PFS and OS . PFS was defined as the time from the beginning of therapy to disease progression , or the time to last follow up for patients that were progression - free ( patients that were progression - free on the date of last follow up were censored on that date ) . OS was defined as the time from the beginning of therapy to death , or last follow - up date for patients who were alive ( the latter were censored on that date ) . The cut - off date of the analysis was August 15 , 2017 and cut - off date for patients included was consent by end of June 2017 .	126405094	no
Strand transfer reactions were initiated by addition of the target DNA to preformed , Tn5 paired end complexes ( analogous to synaptic complexes ) containing two protomers of Tnp and two end sequence containing 40 - mer DNAs . The 5 0 -end of the NTS contained either a hydroxyl or a phosphate as indicated . The reactions were performed in the presence of Mg 2 + and were terminated at the indicated times . Strand transfer products were visualized through agarose gel electrophoresis . Two types of products are observed in this reaction : single end strand transfer events , in which one labeled 40 - mer DNA is covalently linked to the one strand of pUC19 DNA ( migrating as a relaxed circle ) , and double end strand transfer events in which a linear form of the target is generated ( Figure 2 ) . In our experiments the double end strand transfer products formed in the strand transfer assays with the 5 0 phosphate substrate are detected 5 min after the target DNA and Mg 2 + have been added . In contrast , double end strand transfer products formed with the 5 0 -hydroxyl substrate were evident no earlier than after 1 h incubation . The results of these assays demonstrated that , in the presence of the phosphate group on the NTS 5 0 -end , the completion of the transposition process ( characterized by the double end strand transfer band ) occurs $ 30 times faster compared to the data for 5 0 hydroxyl DNA ( Figure 2B ) . Qualitatively similar results are obtained by summing the single end transfer and double end transfer products . This finding clearly indicates that the 5 0 phosphate on the NTS plays an important role in the target capture and/or the DNA strand transfer reaction ( because we measure these two events through a strand transfer assay , we will use ' strand transfer ' to refer to the combination of both events ) .	7074899	no
We further tested the effect of the initial eccentricity of the orbit , varying it from e = 0 to e = 0.9 . Up to an eccentricity of â¼ 0.6 , the results did not appreciably change , but higher eccentricities suppress the ripples at larger distance from the star . This is because the stars spend most of the time near apocenter . In the high - resolution simulations some appreciable deviations from the spiral structure is noticeable when viewed directly from pericenter as respect to other viewing angles , but the effect is much smaller than the    Montes et al . ( 2000 ) to the radio data of Weiler et al . ( 1991 ) . As indicated in the topright corner of the figure , we vary the companion mass of 1 M , 6 M and 15 M and for circular orbits as well as for one with an eccentricity of e = 0.75 . All simulated binaries had an orbital period of 2000 yr , were perfomed at a resolution of 10 â5 M per SPH particle and adopted a viewing angel in the plane of motion and along the binary 's long axis ( from apocenter ) .	119365002	no
The six countries under study are categorized in two groups , countries with a shorter period of lockdown and countries with a longer period of lockdown : Firstly , data are analyzed with descriptive statistics , applying a comparative approach between countries with a longer and a shorter period of lockdown , considering arithmetic mean and standard deviation of confirmed cases ( standardized with population ) and fatality rates ( i.e. , average values from April to August 2020 between countries ) , of indexes of the quarterly national accounts of GDP level in 2019 and 2020 , of healthcare expenditures in 2018 and median age of population in 2019 . In addition , the effects of different duration of lockdown on COVID-19 infected people and deaths are also investigated with average variation of confirmed cases standardized with population and average variation of fatality rates from 15 April 2020 to 30 August 2020 , a period indicating the first wave of the COVID-19 pandemic crisis in Europe . The descriptive statistics are also applied categorizing countries having high / low investments in healthcare ( % of GDP ) , using as cut - off point the arithmetic mean of this variable among countries under study to detect the effects of different duration of lockdown in countries considering their level of investments in healthcare sector .	231884775	no
We represent in fig.3 .12 ) ] . Hence the existing shift between each adjacent dashed and full line represents the small change in the sterile neutrino component , proportional to cos 2 Î± , resulting from introducing in the scheme aÎ½ X component up to its 95 % CL upper bound . This shows that the possible sterile neutrino flux is hardly sensitive to the presence of antineutrinos , a fact whose origin becomes clear on examination of the denominator in eq.(2.13 ): the multiplier of sin 2 Î± is very close to unity for any value of Ï owing to the fact thatr d â 1 . From fig.3 it is also seen that in the absence ofÎ½ x ( x = e , sin 2 Ï = 1 ) the fraction of solar neutrinos oscillating to active ones is greater than 0.59 ( SNO II ) and 0.63 ( SNO I ) at 2Ï of the non - Î½ e flux . Allowing for non - electron antineutrinos up to their 2Ï upper bound this fraction becomes respectively 0.62 and 0.66 . This result is consistent with the result of ref . [ 15 ] where the authors also included KamLAND data in their analysis but were restricted to the case sin 2 Ï = 1 .	35110	no
The program packages ATHENA [ 19 ] , ARTEMIS [ 19 ] , IFEFFIT [ 20 ] , FEFF [ 12,21 ] , PySpline [ 22 ] , Sixpack [ 23 ] , and PyMCA [ 24 ] were applied for the XAS data analysis . Initially careful radiation damage studies were performed by studying spectra collected at different time intervals . Only spectra that showed no signs of decomposition were further processed .	7537230	no
We limited our analysis to patients who , in 2005 - 6 , presented to a participating centre within 12 hours of symptom onset with laboratory and electrocardiographic evidence of ST elevation myocardial infarction and subsequently underwent primary percutaneous coronary intervention ( n=64 676 ) . We excluded patients who were transferred from other hospitals ( n=17 992 ) because we could not evaluate their status on admission . We also excluded patients who first received fibrinolytic therapy and were subsequently referred for primary percutaneous coronary intervention ( n=3313 ) . Patients under 18 years or over 99 years ( n=9 ) were excluded to focus analysis on adult   patients suitable for primary percutaneous coronary intervention . Finally , to minimise data coding errors , we excluded patients treated at hospitals that reported fewer than five primary percutaneous coronary interventions ( n=29 ) . A total of 18 989 patients met one or more of the above exclusion criteria , leaving 45 687 patients eligible for analysis .	9026419	no
Detailed MTR data were provided by the Hong Kong MTR Corporation . The data , from 1 January to 31 March 2020 , included masked card/ ticket ID ( the ID after masked and processed , not the original ID on cards ) , entry / exit station , entry / exit time , ticket type ( smartcard / ticket ) and card type of each passenger . The MTR system has five card types : adult , child ( ages 3 - 11 years ) , student ( ages 12 - 25 years and enrolled in a primary / middle / high school , university or institution of higher education ) , senior ( ages 65 years and above ) and others ( e.g. , disabled , MTR staff ) . The MTR data excluded airport express lines and the light rail systems .	231880553	no
Human data are scarce . For example , a positive correlation was observed between umbilical cord blood PBDEs levels and placental expression of insulin - like growth factorbinding protein 3 ( IGFBP-3 ) , the major IGF-1 transport protein in the blood [ 175 ] . In addition , a significant positive correlation was observed between BDE-154 , BDE-209 , and IGF-1 mRNA levels in the placenta . A cord blood log of IGF-1 levels was also positively correlated with the log of BDE-196 level in breast milk and negatively with the log of BDE-85 in breast milk [ 176 ] .	253698187	no
"We thoroughly evaluate DCA - GMM on synthetic data generated with different variance level and noise level . The higher of these two levels , the harder the clustering task is . The results are reported in Figure 3 , the detailed procedure generating data and evaluation metrics are given in the caption . On all metrics , DCA - GMM shows a phase transition property , i.e. , the algorithm will overwhelmingly success below a curve of noise and variance level . This property verifies the robustness of DCA - GMM to data noise and variance within a cluster . In addition , when increasing the number of sub - problems ( layers from bottom to top ) , the accuracy of DCA - GMM soon saturates on a value close to 1 , this indicates that a small number of sub - problems in DCA - GMM is sufficient to produce a promising clustering result , which is highly preferred in practice . Moreover , the time cost of DCA - GMM is significantly small and thus exhibits its competitive efficiency . Furthermore , error is more robust to data noise than accuracy , because most false anchors detected in the noise case are close to the true ones , which leads to small error .   Figure 3 : DCA - GMM on synthetic data . On a 30 Ã 30 grid of different noise level and variance level , for each noise and variance pair , we randomly generate data of k = 5 clusters with 300 , 500 , 400 , 300 , 500 samples respectively , and 3 - view features of 200 , 120 , 160 dimensions respectively . Mean vector of each cluster is added into the data as "" anchor "" we expect DCA to find out . In particular , each view of points in each cluster are drawn from a multivariate Gaussian distribution with the variance level , and then Gaussian noises of magnitude equal to the noise level are added to the points . We run DCA - GMM using different number of sub - problems , and report their performance by anchor accuracy , clustering accuracy , anchor error ( 2 relative recovery error ) , mutual information and rand index . The CPU seconds are reported too . Each point on each 3D plot is a result of averaging 10 random trials in the same setting , and its height is the value of metric . Each 3D plot includes layers of surfaces associated with different number of sub - problems , we also report the top layer as a 2D plot below each 3D plot .   Figure 4 : Clustering accuracy ( higher is better ) and CPU seconds vs. Number of clusters for Gaussian mixture model on CMU - PIE , YALE , and UMIST human face datasets , UPSP handwritten digit dataset , CIFAR-10 image dataset , and COIL-20 object image dataset . We randomly split the raw pixel features into three groups , each associates to a view in our multi - view model . Baselines : K - means [ 29 ] , EM algorithm , spectral method ."	16504810	no
Our findings highlight a variety of implications for pandemicinformed housing , social and urban policy and research . First , the research revealed high levels of turbulence among share households , with 39 % reporting that either they or another member of their household had moved homes between April and June 2020 . That figure is in comparison to the 14 % of Australians and 35 % of Australian renters that move each year on average ( Australian Bureau of Statistics , 2016 ) . Our data point to a broad range of reasons for these movements , including caring responsibilities ; work opportunities ; returning to family homes ; moving to reduce housing costs when housemates moved out ; leaving to avoid mounting tensions and conflict between housemates ; and returning to countries or states of origin before borders closed . These movements , mostly instigated by the pandemic , represent a dramatic pattern of migration among this cohort and additional research is needed to track the short and long - term impacts of these movements . The geographic clustering of share houses , and low - income rental households more generally , is likely to cause clusters of vacant homes and/or clusters of households in high housing stress in the short to medium term . Similarly , given that 16 % of respondents were living in overcrowded households and 24 % reported feeling stressed by their lack of control over their domestic space , there are clear implications for greater risk of virus transmission in crowded spaces and mental health outcomes for households coping with spatial and interpersonal conflicts . Such challenges are likely to be common to share households internationally .	237663595	no
In summary , we have developed DiLFM , an algorithmenhanced LFM technique that can substantially reduce reconstruction artifacts and maintain high contrast without any hardware modification even in extremely noisy conditions . To optimize the performance of the proposed DiLFM , we thoroughly discuss the appearance and mechanism of three different kinds of LFM reconstruction artifacts and intake them all into a dictionary patching model to correct them . Furthermore , the proposed dictionary patching increases the reconstruction resolution and contrast by supplying high - resolution and high - contrast information from the training stage . We validate our DiLFM through In the functional imaging experiment , we show DiLFM can discover two times more neurons with improved ÎF / F and reduced artifacts disturbance with low light dosage . We hope the scheme can help LFM become a promising and reliable tool for high - speed imaging biological tissues in 3D. The proposed DiLFM achieves superior performance compared to traditional LFM but with full advantages of LFM in other aspects . For example , the volume acquisition rate of DiLFM is independent of the size of the sample and only limited by camera frame rate , compared to other 3D imaging technology . Introducing the dictionary only affects the downstream data processing speed without any sacrifice of capturing rate . It is straightforward to extend DiLFM to a larger FOV or a compact head - mounted LFM 27 . Furthermore , by introducing photon - scattering models into dictionary priors 34 , it is possible to exceed the depthpenetration limitation of DiLFM in in vivo mouse - brain imaging 23 . Borrowing the thoughts from DiLFM of using the versatile dictionary to adopt different imaging environments , other deconvolution energized volumetric imaging methods 22,35 can also use such a prior for better performance in various applications .	236461231	no
Single - crystal X - ray structure of Ag(C 75 H 12 N 2 O 4 ) 2 ] ( PF 6 ) Â· 5(C 6 H 6 ) ( Ag(BPCF ) 2 ( PF 6 ) ) . X - ray intensity data from a dark brown tablet were collected at 100(2 ) K using a Bruker D8 QUEST diffractometer equipped with a PHOTON 100 CMOS area detector and an Incoatec ' highbrilliance ' microfocus source ( Mo K Î± radiation , Î» = 0.71073 Ã ) . [ 3 ] The raw area detector data frames were reduced and corrected for absorption effects using the SAINT+ and SADABS programs . [ 3 ] Final unit cell parameters were determined by least - squares refinement of 9354 reflections taken from the dataset . The structure was solved by direct methods with SHELXS . [ 4 ] Subsequent difference Fourier calculations and full - matrix least - squares refinement against F 2 were performed with SHELXL-2014 [ 4 ] using OLEX2 . [ 5 ] The compound crystallizes in the monoclinic system . The pattern of systematic absences in the intensity data was consistent with the space group P2 1 /c , which was confirmed by structure solution . The asymmetric unit consists of one silver atom , one PF 6 anion , two independent Computational Details . Several DFT computational codes were employed to solve different tasks . Optimization of the molecular and periodic structures was performed at PBE / DZVP level of theory using CP2 K code [ 8][9][10][11 ] with Î - point approximation for the solid state . Single point band structure calculations were performed at the PBE / DZ level of theory with the GPAW code . [ 11][12][13 ] The electron density was converged with k - mesh 4Ã4Ã1 for Zn 2 ( ZnTCPP ) and 2Ã2Ã1 for 1 . The	34026935	no
One may make a number of comments regarding these plots . Firstly , the symmetry of the function under the interchange of u and v is apparent ( and is manifest in the actual data ) . Secondly , for the values of w considered , for small u , v the remainder function takes a large negative value for w large , and increases as w decreases . The order of these hyper - surfaces reverses as u or v increase , and for large values of these variables , the remainder function becomes increasingly negative ( as of course required by the symmetry property and the behaviour at large u ) . For all three variables large , the remainder function approaches a constant which is equal to the asymptotic value of F 6 ( u ) ( about â0.67 ) . In general , it is apparent from Figures 8 - 10 that the remainder function is rather smooth for all values of the cross - ratios .	11095725	no
Importantly , the beta value of a genomic segment is independent from its log2 ratio and the two measures can be used to infer the allele specific copy number and the clonality state of each segment of a tumor genome . CLONET alos provides a space transformation from the beta vs log2 ratio to the cnB vs cnA ( Supplementary Notes , Supplementary Fig . 14 ) , where each segment is visualized at coordinates representing the number of copies of allele NanoString assay - We employed a custom NanoString assay for cases without sufficient material for RNA - seq to evaluate for expression of AR signaling genes , TMPRSS2 - ERG fusion transcript , and neuroendocrine associated genes . FFPE samples were cut onto 10Î¼M thick slides , annotated by the study pathologist , and RNA was extracted using the Ambion RecoverAll â¢ Total Nucleic Acid Isolation Kit . RNA quality control was performed on the Agilent 2100 Bioanalyzer system by annotating total RNA concentration and percentage of RNA greater than 300 nucleotides ( nt ) in length . For samples with more than 50 % of total RNA greater than 300 nt , 100ng input RNA was used ; for samples with less than 50 % of total RNA greater than 300 nt , the input RNA was proportionally increased according to the level of degradation . Samples were run on the NanoString nCounter Â® Analysis System according to the manufacturers directions . Briefly , total RNA was hybridized overnight at 65 Â° , then run on the Prep Station at max sensitivity . Cartridges were then scanned on the Digital Analyzer at 555 fields of view . Raw count data was normalized using the nSolver â¢ analysis software version 2.0 , which normalizes samples according to positive and negative control probes and the geometric mean of the 6 housekeeping primers .	14131683	no
"Further , to allow for greater context richness , the second analysis was based on the titles and abstracts of selected articles ( VanEck and Waltman , 2010 ) . Similar to the procedure based on keywords and with the same criteria , the minimum number of occurrences of words was set to three . The data was also cleaned by elimination or grouping ( VanEck and Waltman , 2010 ) . For example , generic or irrelevant words , such as "" article , "" "" item , "" "" author , "" and "" study , "" were eliminated . However , similar terms were grouped together , as in the case of "" covid , "" "" covid-19 , "" and "" pandemic . "" Fig . 6 shows the results of the co - occurrence analysis based on titles and abstracts ."	237412508	no
The business of company M in manufacturing industry involves daily maintenance of engineering equipment at sites . Thus , the primary goal of its transformations in the pandemic period is to ensure operations continue through remote solutions . First , it has implemented AR to safeguard the virtual presence of safety engineers at its maintenance sites all over the globe . The concept of AR was not new to the company before the pandemic , but the company only had limited experience . Since the start of the pandemic , the company has prioritized the roll - out of this technology and scaled up the adoption throughout the company . Second , WFH has been adopted , however , at the cost of efficiency , as IT equipment in manufacturing industry requires specific adjustments to allow remote access and such adjustments are usually not optimal . For example , before the pandemic , most software in company M would only be used on local networks for security reasons and employees manually connect local databases to enterprise resource planning ( ERP ) systems . In the pandemic period , such a manual connection was impossible as engineers could not go to sites to get the offline data . Thus , the company has developed an interface which connects ERP to a part of its offline databases . Due to partial database availability , several standard business procedures of the company have been delayed . Third , the company has adopted IoT at its production sites , that is to collect critical production data and use cloud analytics to turn this data into valuable insights about the efficiency of the operations . It is worth mentioning that the adoption of IoT has already been underway for 2 years in the company , and the pandemic has just accelerated the roll - out of this technology . Fourth , using data on the state of its equipment , the company has adopted ML to find patterns that help predict and ultimately prevent equipment failures .	245617006	no
Similarly , our in vitro anti - inflammatory bioassay data was corroborated by in vivo improvement in inflammatory milieu observed in FPF - treated ischemic wounds ( Figures 6 and 7 ) . The incessant and elevated presence in proinflammatory cytokines CINC-1 , CINC-2 , CINC-3 , LIX , and IL-6 , being crucial neutrophil traffickers , cause exacerbated levels of neutrophil incidence , resulting in further tissue damage [ 27,[41][42][43 ] . Unlike FPF - treated wounds , control animals exhibited a significant increase in neutrophil chemoattractants that correlated with the upsurge in neutrophils to the wound bed ( Figure 6B ) . Downregulation of genes , including Ccl12 , Cxcl1 , Cxcl3 , IL-1Î² , IL-6 , Ptgs2 , and TNF , that contribute to inflammatory responses were observed in FPF - treated animals [ 44][45][46][47 ] . Furthermore , adhesion molecules L - selectin and JAM - A that are critical in neutrophil migration and activation were reduced upon FPF treatment . Both L - selectin and JAM - A heavily influence neutrophil extravasation and infiltration into the ischemic tissue environment [ 48][49][50 ] . Levels of eotaxin , which induces recruitment of not only eosinophils , but also basophils , neutrophils , and macrophages , were significantly reduced in FPF - treated animals [ 51 ] . We also saw significantly lower levels of MIP-1Î± , RANTES , TREM-1 , and activin A , which are critical macrophage chemoattractants in wound repair [ 52][53][54][55 ] . TWEAK signaling further modulates inflammatory responses and enhances the production of proinflammatory cytokines , including RANTES [ 56 ] . While the expression of RANTES and its functional response to MIP-1Î± are enhanced during differentiation of monocytes to macrophages , activin A alters macrophage polarization by promoting a proinflammatory M1 phenotype and inhibiting the acquisition of anti - inflammatory M2 macrophage markers [ 55,57 ] . Although we did not find significant differences in the total number of macrophages , we detected a substantially higher number of M2 macrophages in FPF - treated animals ( Figure 6C ) . Concurrently , we also found that FPF treatment led to an increase in fractalkine / CX3CL1 , which induces VEGF - mediated angiogenesis potential in CX3CR1 - expressing M2 macrophages [ 58 ] .	235784676	no
During the structured interview as part of the cognitive testing appointment at age 70 , respondents provided the information required for all the covariates except for father 's social class , which was obtained via a questionnaire , and BMI , which was obtained during the physical examination . Covariates were selected a priori based on previous literature ( Deary et al . , 2009 ) , including sex , Occupational Social Class ( OSC ) ( Office of Population Censuses and Surveys , 1980 ) of participant 's father , people per room in childhood household , childhood smoking status , OSC of participant , smoking status and alcohol consumption . OSC of the participant 's father was used as a measure of socioeconomic status from childhood and dichotomised into Professional - managerial ( I and II ) and Skilled , partly skilled , unskilled ( III , IV and V ) . Additionally , we used childhood overcrowding as a secondary measure of socioeconomic status , defined as the number of people per household room . Participants were asked at what age they started smoking and were categorised as a childhood smoker if they responded that they had started before age 16 , as per convention ( Hopkinson et al . , 2014 ) . Smoking status at age 70 was dichotomised as smoker or non - smoker . Similarly , alcohol consumption was dichotomised as drinks alcohol or does n't drink alcohol . BMI at age 70 was calculated as weight divided by height squared . Socioeconomic status during adulthood was defined by OSC of the participant 's main job from their career and dichotomised in the same way as their father 's OSC . For females , husband 's OSC was used if higher than their own . We selected a number of variables as effect modifiers a priori including sex , adulthood OSC and APOE e4 allele . Sex and adulthood OSC at age 70 were operationalised as above . Blood samples were taken during examination and participants were genotyped for APOE allele status using TaqMan technology at the Wellcome Trust Clinical Research Facility Genetics Core ( Deary et al . , 2012a ) . Participants were dichotomised into having at least one APOE e4 allele or having none . In addition to the variables above , we selected several variables to act as auxiliary variables in the imputation of missing data . Due to the association with cognitive ageing , these included the Hospital Anxiety and Depression Scale score ( Zigmond and Snaith , 1983 ) , history of stroke ( Yes or No ) and family history of heart disease , stroke , or problems with blood vessels ( Yes or No ) .	4135248	no
Proof . ( of Lemma 10 ) ( 1 ) Given a confidence - rated predictor with inputs hypothesis set V k , unlabelled data U k , and error bound Ç« k /64 , the outputs { ( Î¾ k , i , Î¶ k , i , Î³ k , i ) } n k i=1 must satisfy that for all h , h â² â V k , [ I(h(x k , i ) = h â² ( x k , i ) ) ( Î¾ k , i + Î¶ k , i ) ] â¤ Ç« k 32	851184	no
"Events are selected using the single - lepton , dilepton , or trilepton triggers [ 57,58 ] listed in Table 2 , where the trigger efficiencies are in the plateau region above the offline T thresholds . Dilepton ( trilepton ) triggers are used only when the leptons in the event fail T -threshold requirements for the single - lepton ( single - lepton and dilepton ) triggers . The trigger efficiency for events with four ( three ) electrons / muons in signal SUSY scenarios is typically > 99 % ( > 96 % ) . For signal SUSY events with only two electrons / muons , the trigger efficiency is typically > 95 % and decreases to â¼ 90 % for events with only two muons . Table 2 : The triggers used in the analysis of 2015 - 2018 data . The offline T thresholds are required only for reconstructed charged leptons which match to the trigger signatures . Trigger thresholds increase across the years due to the increase in beam luminosity , and "" or "" denotes a move to a higher - threshold trigger during data - taking ."	232306993	no
To assess each methods tendency to overfit across the range of rates , we also report the rate - distortion results for CIFAR-10 training sets in Appendix F. While beta - VAEs do find points along the ratedistortion optimal frontier on the training set , we found that they overfit more than delta - VAEs , with delta - VAEs dominating the rate - distortion frontier on heldout data .	57825665	no
On the other hand , the value of the spectral index and its running at the larger scale k = 0.002Mpc â1 is given by 12 ) which leads to the condition Î· 2 â¼ 0.25 ( 1.13 ) and r 2 ( k ) â¼ 0.4 at k = 0.002Mpc â1 . Of course , there are several ambiguities in this naive calculation . In addition to the ambiguities in the above data for the value of the spectral index and the running , the ambiguity may also arise in the value of the scale parameter k. In any case , we may conclude that the spectral index and the running at the scale k = 0.002Mpc â1 can be generated by the shooting - star moduli , with the cost of tuning parameters and the initial condition . 7 Note also that the jump in the spectral index may occur several times during inflation , if there are many shooting - star moduli(or flat directions ) in the theory .	14155886	no
Furthermore , it is interesting to note that our predictions for B(B â ÏK * , ÏK ) , A CP ( B â ÏK * ) and A mix CP ( B 0 â Ï 0 K S , Ï 0 K S ) , listed in Tables 2 , 3   with the experimental data within 2Ï .	15592388	no
As seen in Table 2 , sample size N = 1201 for all dependent variables while as seen in Table 1 , sample size varies for different independent variables . Distance to city center is measured only for Athens and Thessalonikifor which the analysis on the built environment and health/ well - being is appliedso the sample size for this variable is considerably smaller . The sample size for the other independent variables slightly varies due to missing data : missing geospatial data , missing area socioeconomic data , and missing or invalid responses to certain survey questions .	238530423	no
The accounts of many of participants suggested that socio - economic disadvantage is a big risk factor for contracting COVID-19 ; this is supported by studies illustrating that socio - economic disadvantage is both a social and medical risk factor . Disadvantaged and underserved groups are : ( 1 ) at a higher risk of getting infected with COVID-19 ; ( 2 ) if infected , at higher risk of developing severe conditions ; ( 3 ) if facing severe infection , at higher risk of not receiving adequate medical assistance . This has resulted in disproportionally high infection and death rates among certain segments of the population , both across and within countries ( Marmot et al . , 2020;Center for Disease Control , 2021;Ray , 2020 ) . Those who have fewer opportunities to isolate themselves from others , those with pre - existing health conditions , those who have lost jobs or must work even if infected , are at greater risk from suffering the cumulative effects of the pandemicpoints that our participants illustrated through their own lives and their observations of those around them . In this sense , our data empirically illustrate the ways that the mutually - reinforcing , overlapping forms of disadvantage , combine and reverberate through the COVID-19 syndemic . The reduction of poverty and the mitigation of inequalities emerges as a crucial elements of any strategy to increase pandemic preparedness , a point that was made in calls by participants to use this COVID-19 pandemic as a moment to work for structural change .	244902343	no
We firstly investigated the efficacy of QSI ( 1)-loaded SqNPs on PA strain PA14 wild type ( wt ) . Figure 1A shows an improvement by a factor of four in pyocyanin inhibitory efficacy when using QSI ( 1)-loaded SqNPs compared to free QSI ( 1 ) , whereas the control drug - free SqNPs did not display any activity ( Figure S6 ) . This is a result of the better availability of hydrophobic drug in an aqueous environment , which encourages the use of SqNPs for the delivery of QSI ( 1 ) . controls , human mucus concentration 0.5 and 0.1 % ) . D ) Comparison of pyocyanin production levels of PA14 wt grown in PPGAS medium ( proteose peptone glucose ammonium salt ) , in the presence of mucin 0.1 % and mucus 0.025 % , treated with 2 ÂµM QSI ( 1 ) as either free form or loaded in SqNPs ( * p<0.001 ) . All control samples were grown in PPGAS medium which was also used as diluent for mucin and human mucus . All data are presented as mean Â±SD , at least three independent experiments performed in triplicate each .	214768807	no
"Functional status - The World Health Organization Disability Assessment Schedule 2.0 ( WHO DAS ) is a 12 - item questionnaire that serves as a cross - cultural measure of functional status in six domains : cognition , mobility , self - care , social interaction , life activities , and participation in the community . This instrument is broadly useful for measuring functional impairment from acute and chronic illnesses , physical disabilities , cognitive disorders , and mental illness ( Sosa et al . , 2012 ) . It has been validated in 19 countries , including three sites in India . Reliability scores are high ; both Cronbach 's alpha and test - retest reliability coefficients are 0.98 ( Ustun , Kostanjsek , Chatterji , & Rehm , 2010 ) . For our analyses , we converted raw WHO DAS scores into item response theory ( IRT)-based scores ranging from 0 - 100 using statistical coding from the WHO . IRT - based scoring differentially weights answers to WHO DAS items based on level of difficulty ( Ustun et al . , 2010 ) . We define "" some "" functional impairment as any WHO DAS score greater than 0 and "" severe "" functional impairment as any score greater than 17 , which corresponds to functional impairment greater than the 75 th percentile for the WHO DAS 's international population norms . While the WHO DAS provides a global assessment of functional status , we also collected data on specific physical disabilities , including deficits of vision , hearing , speech , paralysis , and loss of limb . For comparability , these questions were worded using language similar to that used in the Census of India and India 's National Sample Survey ."	37115168	no
Due to the limitations of laboratory capacity , fewer samples were tested for virus neutralization than were tested using the quicker multiplex assay . Imputation on censored immune marker data in main analysis . Immune marker values were log 10 -transformed prior to analysis . Values that were censored at the lower limit of quantification ( LLOQ ) were imputed with the value LLOQ/2 . Approximately 10 % of the pseudovirus neutralization titer was censored at the LLOQ , and sensitivity analyses were conducted by imputing these values using a Gibbs sampler .	235613413	no
Remark 3.12 This lemma together with the remaining arguments of the proof below shows that , in all dimensions n â¥ 3 , the vanishing of m ( 0 ) implies that the data set arises from the anti - de Sitter space - time whenever the subspace of KIDs generated by those arising from spinors contains a KID satisfying ( 3.38 ) .	118275825	no
Several groups including us have performed large scale affinity purification experiments coupled to mass spectrometry ( AP - MS ) using antibodies specific against dCenpA ( 17,19 ) , HMR ( 18 ) or HP1a ( 45,46 ) to identify putative interactors of these proteins . However , in contrast to other well characterized nuclear protein complexes such as the nucleosome remodelers or the histone acetyltransferases ( 47,48 ) , these three proteins have been refractory to classical biochemical purification . In fact , when comparing the AP - MS data from different laboratories the overlap in pro- teins identified is marginal ( 17)(18)(19)45,46,49 ) . We reasoned that this is due to the fragility of the interactions that do not withstand the harsh condition of cell lysis and subsequent purification . We therefore generated stable cell lines expressing HMR , dCenpA and HP1a fused to APEX2 that enables biotin labelling of factors surrounding the fusion protein ( Figure 2A ) . Upon treatment of APEX2 expressing cells with biotin phenol and hydrogen peroxide , a localized burst of diffusible biotin - phenoxyl radicals is gener - ated . These radicals then react with nearby ( < 20 nm ) electron rich amino acid side chains leading to the biotinylation of neighboring proteins that can be subsequently purified and identified using shot gun mass spectrometry ( 23,(50)(51)(52)(53)(54)(55 ) . We confirmed the expression of ectopic proteins by Western blotting using antibodies against HMR , dCenpA , HP1a ( Supplemental Figure S2A ) and APEX2 ( Supplemental Figure S2B ) . The APEX2 protein was fused to a double nuclear localization signal to determine the non - targeted nuclear proteome . Since the fusion proteins are expressed under a copper inducible promoter , we were able to tune their expression to match the endogenous levels ( Supplemental Figures S2A - D and S1B ) . Hence , we performed the biotinylation reaction under non - inducing conditions for HMR AP and dCenpA AP expression but induced the expression of HP1a AP ( Supplemental Figure   S2B - D ) . For the APEX2 NLS cell line we induced the expression of APEX2 NLS to match HP1a AP expression levels ( Supplemental Figure S2D ) . At the expression level used , HMR AP and dCenpA AP localize to centromeres , marked by the staining of centromere - specific histone variant dCenpA ( Supplemental Figures S2C and S1B ) , HP1a AP occupies a domain in the nucleus , which coincides with endogenous HP1a staining and APEX2 NLS localizes to the nucleus ( Supplemental Figure S2D ) , showing a proper nuclear localization of the fusion proteins under the conditions used .	212751883	no
All parameters in Equation S1 have previously been defined in the main text . From the data in Figure S9 , we have extracted a HDMI of 120 mT , which for the material parameters of the [ Co(0.7 nm)/Ni(0.5 nm)/Pt(0.7 nm)]2 sample corresponds to DDMI = -0.63 mJ / m 2 . The left - handed DDMI is inferred from the configuration ( i.e. , â to â versus â to â ) of the DWs and the Âµ0Hx direction . Figure S9 . Expansion velocity as a function of in - plane magnetic field Î¼0Hx of â to â and â to â domain walls in the [ Co(0.7 nm)/Ni(0.5 nm)/Pt(0.7 nm)]2 sample . Data was collected using 5 mslong perpendicular field pulses of Î¼0Hz = +15 mT. Blue arrows indicate the commonly - attributed measure of the effective magnetic field generated by the iDMI ( Âµ0HDMI ) .	231934121	no
In this section , clustering results with ARI of ANM - MM close to avgARI 9 shown in Table 1 are visualized . Results of comparing approaches on the same data are also given .	52813647	no
"In this appendix we discuss what can be learned from the cumulative eigenvalue distribution ( CED ) . We consider both the eigenvalues in 4D generated for the main part of this paper and data from dedicated runs in the quenched Schwinger model ( QED with massless fermions in 2D ) to elucidate the effects that filtering and changing Î² have on the spectral density of the hermitean Wilson operator H W = Î³ 5 D W,â1 . Fig . 17 presents the cumulative eigenvalue distribution ( CED ) of the 15 smallest eigenvalues of |H W | on the ensembles discussed before . We show it both in standard form and in double logarithmic form , and the scale on the ordinate follows from the requirement that it would extend up to 1 , if all eigenvalues were calculated ( cf . Fig . 18 below ) . For the two intermediate couplings ( Î² = 5.84 , 6.00 ) we see the expected linear rise of the CED near the origin , which soon gets complemented by a higher order piece . The coefficient of the linear part is a measure for the spectral density of the hermitean Wilson operator at the origin , Ï |H W | ( 0 ) . That density being non - zero means that there is a finite probability to encounter arbitrarily small eigenvalues . The main effect of smearing is to reduce this spectral density , as is evident from the double logarithmic plots -here the initial slope 1 piece gets shifted downwards , and this corresponds to a smaller coefficient in front of the linear piece in the standard representation . Our data at Î² = 6.26 are of lesser quality -here we definitely can not identify a linearly dominated regime . The situation is far more favorable in Fig . 18 where quenched Schwinger model data are shown . Apart from the statistics , the main difference is that all eigenvalues ( extending up to â¼ 3 in 2D ) are included . The higher the filtering level or Î² , the more pronounced is the "" jump "" in the CED at Î» â 1 . Note that with a chiral kernel all eigenvalues of |Î³ 5 D kern | would be there , i.e. the CED would be a step function at Î» = 1 . Finally , to come back to Fig . 17 , the situation at the strongest coupling ( Î² = 5.66 ) is different , since here the linear piece in the unfiltered CED is not larger than in the filtered versions . This is , because our choice Ï = 1 lets us "" loose "" the fermion -at this coupling our projection point is somewhere "" in "" the physical branch or "" to the left "" of it , while for the filtered version Ï = 1 is still appropriate . One might avoid such a situation by choosing a larger Ï with the unfiltered kernel , but an even safer option might be to refrain from simulating unfiltered overlap quarks on such coarse lattices . It looks like this is a situation where the filtered overlap may help a lot , since it allows simulations on coarser lattices than the unfiltered operator , but in order to really be useful such simulations should be in the scaling regime ( and not just in the right universality class ) , and this is , of course , not yet clear ."	1765194	no
The Pearson correlations analyses between NDVI and hydro - climatic variables were conducted at catchment and pixel scales . The correlation coefficient ( r ) and significance ( p ) were used to determine the degree of correlation between the two variables . The correlations at catchment scale were obtained by calculating on a per - pixel basis and then aggregated in the study area . During aggregating the data , the pixel cell was treated in isolation and the spatial autocorrelation was not taken into account , which was a simple way to detect the relationships between vegetation dynamics and hydro - climatic variables and widely used in previous studies . To further improve the trust of significant / nonsignificant results , the autocorrelation needs to be taken into account . The correlation between groundwater and river flow at the catchment scale was also analyzed . Furthermore , the linear regression analysis was used to determine the quantitative relationship between catchment NDVI and river flow , and those between NDVI and water table depth as well as between water table depth and river flow . The coefficient of determination ( R 2 ) and significance of the regression equation were obtained . Fig . 2 illustrates the inter - annual variations in precipitation , mean temperature , river flow at YLX station , river flow difference between YLX and ZYX stations , river flow at LXS and EJL stations , and average catchment water table depth in the study area . Annual precipitation had no significant increase before ( 0.19 mm yr â1 , p = 0.54 ) and after 2000 ( 0.03 mm yr â1 , p = 0.97 ) , with the mean value of 35.8 mm and 29.3 mm , respectively ( Fig . 2a ) . Mean annual temperature increased significantly during 1961 - 1999 ( 0.05 Â° C yr â1 , p b 0.01 ) with the mean value of 8.6 Â° C , whereas the increase was not significant after 2000 ( 0.03 Â° C yr â1 , p = 0.21 ) with the mean value of 9.9 Â° C ( Fig . 2b ) . In general , the climate tended to be warmer and drier after 2000 .	3899415	no
While several studies have linked higher levels of ambient greenery surrounding schools to better school - wide test performance and inclassroom child behavior for both primary and secondary school students ( Hodson and Sander , 2017;Kuo et al . , 2018;Kweon et al . , 2017;Li and Sullivan , 2016;Matsuoka , 2010;Sivarajah et al . , 2018;van den Berg et al . , 2017;Wu et al . , 2014 ) , few studies have examined individual child cognitive outcomes in relation to residential neighborhood greenness . Two studies from Spain have reported positive associations between residential neighborhood greenery ( measured through satellite - imagery ) and child performance on attention and working memory tests , assessed cross - sectionally at ages 4 - 5 and 7 ( Dadvand et al . , 2017 ) , and longitudinally across one year around age 8 ( Dadvand et al . , 2015 ) . An additional study in the UK recently reported positive associations between residential neighborhood greenery ( assessed through land use data ) and child performance on a single spatial working memory task , assessed cross - sectionally at age 11 years ( Flouri et al . , 2018 ) .	140286082	no
Using these complexes we wanted to check whether the peptidyltransferase activity is regulated by the functional state of the ribosome . In order to do this the kinetics of the puromycin reaction were performed with Pi and POST complexes at different temperatures , ranging from 0 to 37 C ( Figure 2 ) . As expected , the rate of transfer of the AcPhe moiety of the P site bound tRNA to puromycin , forming AcPhe - Puro , slows as the reaction temperature is decreased . Furthermore , the data for Pi and POST complexes were almost identical at all the temperatures measured , providing the first hint that the peptidyltransferase activity is not regulated by the ribosome functional state , nor in this case the presence of an E - tRNA .	15343972	no
We also found that a higher prevalence of HIV was associated with a higher mortality rate in the first pandemic wave . HIV has been associated with severe COVID-19 during the pandemic ; a large population - based study in South Africa found that HIV doubled ( HR = 2.14 ) the risk of COVID-19 mortality 20 . A meta - analysis of 22 studies worldwide also found that HIV - positive status was associated with an increased risk of COVID-19 mortality 21 . The underlying reasons might include a high prevalence of comorbidities in patients with HIV and severe COVID-19 and persistent immune suppression in severe COVID-19 ( ref . 20 ) . In our study , statistical models replacing HIV with other common comorbidities - tuberculosis ( which is strongly correlated with HIV ) , chronic obstructive pulmonary disease , hypertensive heart disease and obesity - fitted the data less well , although it is possible that HIV status acts as a marker for a basket of these and other comorbidities . Alternatively , any link could be wholly or partially indirect if HIV prevalence is correlated with behavioral , lifestyle or socioeconomic variables not included in our analysis .	237410999	no
The interaction between Cdk2 and Pol l also fits with the proposed role of Pol l in non - homologous end joining ( 14,15 ) . In fact , Cdk2 has been recently shown to regulate DNA DSB repair when associated to cyclin A1 . Cyclin A1 is a second A - type cyclin abundantly expressed in testis ( 32,33 ) . Since Pol l is also known to be abundant in testis ( 34 ) one could propose a role of Pol l in DSB repair in germ cells . Additional observations of Cdk2 localization at the telomeric ends of chromosome from leptotene to diplotene stage of meiosis ( 35 ) could support a role of Pol l by its terminal transferase activity ( 7 ) in germ cells . In addition , our data are supported by the recent findings that Pol l is selectively involved in NHEJ processing DNA with complementary overhangs , which occur upon DNA damage , whereas Pol m seems to be mainly involved in NHEJ of DNA with non - complementary ends ( 36 ) . In this context , phosphorylation of Pol l may be one of the factors influencing selectively the recruitment of Pol l on places where its activity is needed .	16724266	no
The phase ÎÏ hence changes with În eS . For a sufficiently slow continuous variation in the phase shift during a binding experiment , ÎÏ can be extracted from the measured data by unwrapping the Clarke phase arg s mono Ã° Ã ,	232365767	no
The method followed six stages : defining the research question ( as described in the study aims ) and inclusion criteria , study selection , quality appraisal , extraction and presentation of data , analysis of the data and presentation of the synthesis ( Lachal et al . , 2017 ) . The published protocol is available on PROSPERO ( Registration ID : CRD42020181444 ) . The review is reported following PRISMA guidelines ( Moher et al . , 2009 ) .	237538344	maybe
Supplementary data to this article can be found online at https://doi . org/10.1016 / j.scitotenv.2022.155580 .	248434895	yes
This section presents the conceptualization of SC and discusses the exploitation of OSN in SC and their privacy and security risks , which undermine their significant contribution as urban data sources .	158903122	no
Most of these steps generated large amounts of data in their foreign data types , which had to be transferred , managed , and converted by the module 's respective expert , making the individual execution of each module slow and unwieldy . The necessary complex modeling solutions were rendered into an easy - to - use , market - ready workflow for SimStack . Thus a novel organic semiconductor with a predicted three orders of magnitude improvement in electron mobility could be designed by systematically screening potential candidates , and the prediction was subsequently experimentally confirmed . [ 52 ]	245315824	no
"Humphreys argues that opaqueness is a unique feature of computer simulations . We disagree : experiments are often analogously opaque . A scientist can provide you with her "" raw "" data , but those data do not provide you with any information about how or why the experiment produced a given result . Further , raw data are often the output of some detectors , the observations of a lab assistant , etc . , and one who lacks knowledge of the data gathering procedures will likewise lack knowledge of why the experiment produced a given result ."	221900965	no
However , there is an equally compelling real - world issue for our not having provided detailed ( mainly dietary ) treatment recommendations in the absence of proof - of - principle demonstrations . Had we proposed a recommended diet or groups of diets ( as shown above ) in 2007 without demonstration that it / they worked , who would have followed it ? Had Dr. Wahls proposed her recommended diet in 2007 without demonstration that it worked , who would have followed it ? It is difficult enough to convince people to change their behaviors and eating habits when hard data is available . Twenty - one percent of adults still smoke , half the number that smoked when the Surgeon General 's Report on smoking was issued 48 years ago . This 50 % reduction follows strong consensus within the scientific community on the harmful effects of smoking , and the imposition of countless additional taxes on smoking and many no - smoking mandates . Most people have become heavy users of cell phones and WiFi , despite increasing evidence that serious harm can occur , especially for children [ 16 ] . Most people would have regarded such diet recommendations in 2007 as just another list to ignore .	154997156	no
"3.1.3.2.1 . Webpage use . 18.5 % ( n = 265 ) of survey respondents indicated a flood risk related interest in the webpages ( Fig . 5 ) . Of these , half mentioned using them every time in a personal capacity ( which was considerably lower than the other two user groups ) . Information for flood risk interest was deemed mostly ' very ' and ' extremely ' important . To most respondents , the graph ( Fig . 2A ) was the most important part of the webpages ( almost three quarters considered it extremely relevant ) , but the bar indicator ( Fig . 2C ) was also highly valued . 35 respondents would like to see an expansion of the graph 's timescale and 32 respondents more frequent and regular updates ( i.e. less delay ) . As one online survey respondent wrote : "" As a household that has experienced flooding , and still has unresolved problems with the SEPA flood warning system , I prefer to be able to make my own judgements on the likelihood of high water , but I can only do that when SEPA keeps its river level data current "" . Webpages for the larger Scottish rivers were the most visited ones . They were visited throughout the year ( with less of a drop in the winter as compared to the other user groups ) and with generally frequent checks ( more than one a day ) ."	121630870	no
The appearance of sharp bands during electrophoresis of both the 18HB and the HR on 2 % agarose gels suggests that the structures were folded and purified successfully ( Figure   S4 , Supporting Information ) . To create Cy5 - labeled 18HB ( Cy5 - 18HB ) and HR ( Cy5 - HR ) , we attached eight Cy5 molecules designed to point towards the inner cavity of the structures ( Figures S1 and S2 , Supporting Information ) . The rationale behind this was to decrease any potential unspecific interactions in cell experiments due to Cy5 . [ 18 ] Both Cy5 - 18HB and Cy5 - HR presented sharp and clean bands before , and after , washing away excess staples , under both UV and Cy5 channels ( Figure S4 , Supporting Information ) . Transmission electron microscopy ( TEM ) imaging , under which the structures were dry , showed that dry 18HB were straight and relatively identical rod structures , while some dry HR presented bending and shrinking ( Figure 1B ) . Cryogenic electron microscopy ( cryo - EM ) imaging , which shows the real state of structures in buffer , showed similar differences ( Figure 1C , D ) . This could be explained by the relatively loose DNA helical arrangements in polygonal HR . Estimated persistence lengths , which reflect the deformability of the structures , [ 19 ] of HR and 18HB ( Figure S5 , Supporting Information ) were 0.9 Â± 0.2 Âµm and 2.3 Â± 0.5 Âµm respectively , indicating that the 18HB has a lower tendency to deform compared to the HR . Examples of the TEM data used for this analysis is available in Figures S6 and S7 , Supporting Information ) . To further analyze the sizes of the objects in solution , we performed dynamic light scattering measurements ( Figure 1E ; and Figure S8 , Supporting Information ) . This experiment revealed that the HRs and the 18HBs had very similar hydrodynamic sizes in a variety of buffers . In cell culture medium ( DMEM with 20 % FBS ) , the sizes for both structures increased â20 nm , possibly caused by structure - protein corona formation . [ 20 ] In their own folding buffers , zeta potentials of 18HB and HR were slightly different . Once the structures were diluted in the same buffer however , the differences became negligible ( Figure 1F ) .	235361113	no
show the XPS O 1s signal , the middle panel shows the XPS Cu 2p3/2 signal , and the bottom panel shows the Auger Cu LMM signal . The three horizontal lines correspond to 95 % ( ~1 / e 3 , ~3ÃIMFP if X - ray attenuation is not been considered ) , 90 % , and 63 % ( ~1 / e , ~IMFP if X - ray attenuation is not been considered ) of the total signal . The depths for which these intensities are reached for the different photon energies and core - levels and Auger Cu LMM are presented in Table S3 . It is observed that the short IMFP of the Auger Cu LMM electrons makes the impact of X - ray attenuation so low that depth profiling of the state of copper using Auger Cu LMM is not possible . Figure S7 . Percent of total signal from surface to depth d [ Ã ] for different photon energies and electrons from O 1s , Cu 2p3/2 , and Cu LMM . These data assume even oxygen concentration with depth and a perfect copper lattice . a uniform oxygen distribution is obtained . â is the difference between the deepest and narrowest probing depth . Also , the attenuation depth , 1 / e of the signal , is added .	243988319	no
If we look at the distribution of counties per the urban - rural classification receiving health grants , Fig . 1 shows that almost 100 % of all large central metropolitans received some health - related grants from corporate foundations . Around 20 - 40 % of large fringe metros , medium metros , and small metros received some grants , and the numbers are lower for micropolitans and non - core areas . Over the 3 years of analysis , some trends are worth mentioning . First , our data from Candid shows that 2013 was the year where more ( health ) grants were made . In 2017 , the number of corporate foundation ( health ) grants fell quite dramatically , and the major losers of this overall decline were not large central metros . Rather , from 2013 to 2017 , the proportion of recipient counties in each of the groups characterized as large fringe metros , medium metros and small metros dropped by almost 20 percentage points . Examining the average value of health grants ( including zero ) per capita by type of county , our calculations show , in Fig . 2 , that large metropolitan counties receive a significantly higher amount than all other types of counties . In 2013 , for example , on average large central Fig . 1 Proportion of counties per the urban - rural classification , that received health grants metros received $ 2.50 per head in health grants from corporate foundations . This figure drops to under $ 1.00 for large fringe metropolitans , while medium , small metros receive approximately $ 0.25 per head , while micropolitans , and noncore counties receive even lower amounts per head . Again , there is a time trend over the years . In terms of value , even large central metros received less in 2017 compared to 2013 . Health grants per capita dropped from $ 2.50 per head to just over $ 1.00 per head .	233211151	no
Next , we tested whether the imino acid proline imposes the requirement for eIF5A. 80S initiation complexes were assembled on an mRNA encoding MPPPK and polyproline synthesis was monitored in reactions containing canonical Pro - tRNA Pro . In contrast to the MFF and MFFF peptides , which were well resolved during electrophoretic TLC , MPP and MPPP peptides co - migrated during TLC . Addition of a C - terminal Lys residue on the MPPPK peptide enabled resolution during TLC of the full - length tri - proline peptide from incomplete C - terminally truncated products ( Supplementary Figure S1 ) . As expected , polyproline peptide synthesis showed a strong dependence on eIF5A. In the absence of eIF5A very little MPPPK was synthesized , and addition of eIF5A stimulated polyproline peptide synthesis â¼6.1 - fold ( Figure 1C , lane 6 versus lane 5 ; and Supplementary Figure S1C and D ) . Similarly , when misacylated Pro - tRNA Phe was tested for MPPPK peptide synthesis using 80S initiation complexes assembled on an mRNA encoding MFFFK , polyproline synthesis was stimulated â¼3.7 - fold by adding eIF5A ( end level = 0.08 in the absence of eIF5A and 0.30 in the presence of eIF5A ; Figure 1C , lane 8 versus lane 7 , and Supplementary Figure S1C and D ) . In control reactions , no peptide formation was detected when misacylated Pro - tRNA Phe was used for elongation of initiation complexes assembled on mRNA encoding MPPPK ( Supplementary Figure S1C ) , demonstrating that the observed peptide synthesis was not due to contaminating canonical Pro - tRNA Pro . It is interesting to note that the end level of the MPPPK peptide formation using misacylated Pro - tRNA Phe is lower than that obtained with canonical Pro - tRNA Pro ( 0.30 versus 0.49 , respectively ) , suggesting that the body of tRNA Phe is less effective for eIF5A - stimulated polyproline synthesis than is the body of tRNA Pro . Taken together , these data indicate that the imino acid proline and not tRNA Pro imposes the primary eIF5A requirement for polyproline peptide synthesis .	22626104	no
The results of this study raise questions of the mechanisms behind the low levels of nitrification and resulting low N 2 O emissions from the urine patches in upland organic soils . Possible explanations for a lack of nitrification include a small or functionally inactive population of nitrifiers , high soil acidity , limited O 2 concentrations ( Allen et al . , 1996 ) , or some combination of the above . The detection of nitrification in the soil solution in one chamber suggests that the potential for nitrification exists in these upland peat soils . Nitrification rates , however , have been found to be lowest in moorlands and bogs in comparison to grasslands and woodlands , and are highest in arable and improved grasslands ( Yao et al . , 2013 ) . We suggest plant and microbial uptake were likely to be the main cause of the decline in soil solution NH 4 + concentrations in the urine treatments , with the decline occurring faster in the summer compared to the autumn treatments . The potential for NH 3 volatilisation was low due to acidic soil conditions , and leaching losses unlikely due to the limited build - up of NO 3 â in the soil solution . Complete denitrification to N 2 was also unlikely to occur due to production of N 2 O reductase being sensitive to low soil pH ( b6.1 ; Liu et al . , 2010;Liu et al . , 2014 ) . Soil acidity can influence the community composition of organisms capable of nitrification . At low soil pH , the protonation of NH 3 to NH 4 + occurs , and typically ammonia oxidizing archaea ( AOA ) dominate in environments with low NH 3 concentrations ( StopniÅ¡ek et al . , 2010;Zheng et al . , 2017 ) . Indeed , AOA have contrasting NH 3 acquisition systems and Fig . 5 . Dissolved organic carbon ( panels a and b ; mg C l â1 ) and total dissolved nitrogen ( panels c and d ; mg N l â1 ) in soil solution , measured from Rhizon soil water samplers located within the GHG monitoring chambers . Amendments were made on day 0 , symbols represent means ( n = 3 or 4 ) , error bars represent SEM and legends are specific to each column of panels . For panels a and c , asterisks represent significance levels of the analysis of variance . For panels b and d , black asterisks represent significance levels of t - tests for artificial urine compared to the control and red asterisks represent significance levels of t - tests for the NO 3 â and glucose compared to the control . ( For interpretation of the references to colour in this figure legend , the reader is referred to the web version of this article . ) possess energy - dependent NH 4 + transporters , compared to ammonia oxidizing bacteria ( AOB ) which have NH 3 transporters ( Offre et al . , 2014 ) . In addition , low soil pH has a greater negative impact on the abundance of AOB in comparison to AOA ( Yao et al . , 2013 ) . Extensively grazed acidic soils are likely to harbour greater numbers of AOA adapted to low NH 3 concentrations , as they do not receive fertiliser applications and inputs of excreta are minimal and ' patchy ' due to low stocking densities . The addition of urine to intensively managed grassland soils has been found to stimulate AOB , rather than AOA growth ( Di et al . , 2009;Podolyan et al . , 2014 ) , yet the response of AOA and AOB to urine events in extensively grazed systems are less well understood . We suggest that the high concentrations of urea within urine , which rapidly hydrolyses to produce high concentrations of NH 4 + in the soil , do not favour AOA growth , and the acidic conditions hinder AOB growth , resulting in limited nitrification from either prokaryotic domain . Soil hydrology can influence N 2 O sources and sinks ( Rubol et al . , 2012 ) , e.g. the higher the soil moisture , the lower the O 2 content , which would hinder the aerobic process of nitrification . In the individual chamber where nitrification was detected , the N 2 O - N EF was still only 0.06 % of the N applied , therefore , we suggest that the magnitude of nitrification may have been limited by additional factors . It is clear from our data that understanding the causes of spatial variability in nitrification rates are key to understanding the magnitude of N 2 O emissions from these upland organic soils . Enhanced understanding of the soils hydrology and the interactive effect of soil pH , aeration status and other soil characteristics on nitrification of urine - N would be useful to investigate the upper limits of urine - N 2 O - N EFs from extensively grazed peat soils .	201062411	no
The SM prediction for the anomalous magnetic moment of the muon ( see [ 41,42 ] for reviews ) depends on the evaluation of QED contributions ( see [ 43 ] for a recent update ) , the hadronic vacuum polarization and light - by - light ( LBL ) contributions . The former have been evaluated in [ 44][45][46][47 ] and the latter in [ 48][49][50][51 ] . The evaluations of the hadronic vacuum polarization contributions using e + e â and Ï decay data give somewhat different results . In view of the additional uncertainties associated with the isospin transformation from Ï decay , we use here the latest estimate based on e + e â data [ 52 ] :	15722621	no
The QCD multijet production has a large cross section in pp collisions but a tiny acceptance in the phase space used in this analysis . Therefore , a very large sample of simulated QCD multijet events would be needed in order to retain a sufficient event yield surviving our selection criteria to ensure a reliable description of this background . In the absence of simulated event samples of the required size , an alternative approach is followed by defining an SB in data enriched in QCD multijet events . The SB is obtained by requiring the selected muon to have 0.2 < I rel < 0.5 and the selected electron to fail the tight identification criteria . The underlying assumption here is that the description of kinematic variables for QCD multijet events in the SB is similar to that in the signal region . We have verified this assumption using simulated samples . Shapes for QCD multijet events are derived by subtracting the total non - QCD con - tribution from data in this SB . As such , the SB data contain 93 ( 70)% QCD multijet events for the muon ( electron ) final state . The QCD multijet contribution in the signal region is estimated by means of a binned ML fit to the m T distribution with two components : QCD and non - QCD . As the QCD multijet background has a larger contribution in the 2J0 T category , this category is used to validate the above method . The procedure is then applied in the signal - enriched 2J1 T category where the background estimation is performed separately for positively and negatively charged leptons , as well as inclusive of the lepton charge in the final state .   and 2J1 T ( lower ) categories for the muon ( left ) and electron ( right ) final states . To account for possible differences between QCD multijet m T shapes obtained from the SB and that in the signal region , a separate 50 % systematic uncertainty is assigned to that background rate and shape ( see Section 8.1 ) . This propagated uncertainty is twice the maximum difference between the data and the prediction found in the tail of the m T distributions .	245547826	no
The final proposed 3D structure of 3 is shown in Figure S9 .    Tables    Table S1 . NMR data for 3 . All spectra were recorded in CD3CN .       Rfactor = ïï¯ï¯Fobsï¯ ï­ ï¯Fcalï¯ï¯/ïï¯Fobsï½ , where Fcalc and Fobs are observed and calculated structure factor amplitudes c Rfree = Rfactor , but using a random subset of the data ( 5 % ) which is excluded from the refinement . Figure S10 . Multiple sequence alignment of the polyether epoxide hydrolases , limonene epoxide hydrolase ( LEH ) and SalBIII . The catalytic amino acid dyad is marked by red star and highlighted in yellow . The following proteins were used for alignment : Lasalocid LasB [ 20 ] ( contains two domains LasB - N and LasB - C ) , nanchangmycin NanI [ 21 ] ( contains two domains NanI - N and NanI - C ) , monensin MonBI and MonBII , [ 22 ] nigericin NigBI and NigBII , [ 23 ] tetronomycin TmnB , [ 24 ] tetronasin TsnB ( Dr. F. Huang , personal communication ) , LEH , [ 25 ] salinomycin SalBI and SalBII . [ 6 ] Alignment was compiled by the Multalin program . [ 26 ] Figure S11 . Phylogenetic analysis of polyether epoxide hydrolases . Lasalocid LasB , [ 20 ] nanchangmycin NanI , [ 21 ] monensin MonBI and MonBII , [ 22 ] nigericin NigBI and NigBII , [ 23 ] tetronomycin TmnB , [ 24 ] tetronasin TsnB ( Dr. F. Huang , personal communication ) , and salinomycin SalBI , SalBII , and SalBIII [ 6 ] epoxide hydrolases are shown . PhyML 3.1/3.0 program was used for the phylogenetic tree construction . [ 27 ] Figure S12 . Sequence alignment of SalBIII and Cyc11 domain from indanomycin [ 28 ] biosynthesis . Amino acid residues proposed to constitute the active site cavity are shown in boxes . Asp38/28 and Asp104/94 are proposed to be a catalytic dyad ( marked by red star ) . Alignment was compiled by the Multalin program . [ 26 ] Figure S13 . Schematic illustration of the in - frame deletion of the salBIII gene in the salinomycin biosynthetic gene cluster . SalBIII and its truncated sequence are shown in blue . control . Lanes 9 , 10 , 11 , 12 , 13 , and 14 correspond to the PCRs with gDNA of of the same potential double mutant colonies , but PCR salC_f / r [ 6 ] primer pair was used to confirm that salC gene was deleted , lane 7negative control , lane 8 -positive control ( plasmid pMYâsalC [ 6 ] was used as a DNA template in the PCR ) . If the salC gene has been deleted , a band of 532 bp is expected , whereas for the WT strain , a band of 1,825 bp is expected . 1 kb Plus DNA Ladder ( Fermentas ) was used as a molecular DNA size marker . Figure S15 . Chemical structures of the metabolites from S. albus âsalE mutant . [ 4,29 ] Figure S16 . Proposed general structure for the metabolites observed in S. albus âsalBIII mutant . The structure is drawn in fully uncyclized form as no conclusion about cyclization pattern and differences between two isomers ( B-8 , B-11 ) can be made from MS n analysis . Ring A is not present .                            	2318672	no
The sample selection , observing strategy , reduction , and properties of the full 74 galaxies in PHANGS - ALMA survey is presented in A. K. Leroy et al . ( in preparation ) . Here , we use the first data sets , including three literature maps , where the CO surface brightness and line - width have been calculated by Sun et al . ( 2018 ) . See that paper for a detailed presentation of masking , map construction , and completeness .	119343853	yes
Behavioural data acquisition and processing . A key issue when comparing different groups in neuroimaging studies that measure changes over learning is that participants might learn at different rates depending upon their group assignment . To examine this possibility , digital callipers were used to take measurements on cores and flake debris from both knapping tasks during the final neuroimaging session to determine whether one of the learning groups produced stone tools with greater skill than the other group ( see Supplementary Discussion ) . All core and debitage pieces were collected after the completion of each finished core during the neuroimaging session . Any debitage that passed through a 6.35 mm screen was discarded . The remaining pieces were labelled and measured . Each piece was weighed to the nearest tenth of a gram and allocated to a metric size category continuum as defined by the smallest of a series of nested squares on centimetre graph paper into which the piece would completely fit ( that is , 1 cm 2 , 2 cm 2 , 3 cm 2 , ... , and so on ) . The maximum thickness was recorded for each piece . All non - core debitage was coded as a flake ( either complete , proximal or distal ) or nonflake debitage shatter 55 . Any flakes with an intact striking platform underwent measurements for the maximum platform width and thickness .	19830296	no
We further investigate the properties of this galaxy using the spectroscopic and photometric data . The data show the AGN contribution to the LyC emission is negligible . We derived from the SED fitting that the average age of the stellar populations is about 50 Myr , and the SFR is 52.1 Â± 4.9 M yr â1 . These results show that the source of the LyC photons is more likely to be the massive young stars .	244478078	no
To conclude , we consider devices prepared in the n - i - p configuration that most state - of - the - art PSCs have adopted . [ 5,12,19,64 ] Figure 6 g shows a schematic illustration of the energy level diagram of the devices , where a nanoparticle SnO 2 /PCBM bilayer is used as the ETL and poly[bis(4 - phenyl)(2,4,6 - trimethylphenyl ) amine ( PTAA ) as an HTL . Analysis of the PCE data , Figure 6h , and other device characteristics , Figure S15d - f , Supporting Information , show the aerosol treatment significantly improves device . In addition to the average PCE values increasing from 18.2 Â± 0.9 % ( champion 19.2 % ) to 20.2 Â± 0.3 % ( champion 21.0 % ) following aerosol treatment , the spread in all characteristics are also reduced , that is , aerosol treatment creates better performing devices with statistically less variance in performance . One drawback of the n - i - p structure is that hysteresis is generally more problematic than in p - i - n analogues . Figure 6i shows J - V curves for the champion untreated and aerosol treated devices , where it is apparent that hysteresis is reduced in the aerosol treated device , indicative of a reduction in ionic defects . Despite the moderate J - V hysteresis even after aerosol treatment , the steady - state power output measurement ( inset in Figure 6i ) shows a stabilized PCE of 20.5 % when the device is held near the MPP ( 0.952 V ) .	237802796	no
"For some organizations or in some conditions , these promises may prove enough to meet their ends . However , sometimes the promises of big data come with assumptions about organizational life that are more theoretical than practical . In fact , the promises feel functional , even a bit machine - like . If all elements work properly , it will produce better information for decision - makers . The promises rely on predefined mechanisms that potentially produce predefined results . As far as human activities are involved , humans are assumed to behave according to a common goal , being better decision - making informed by better information . Vydra and Klievink ( 2019 ) call this stream of literature "" techno - optimists "" that "" focus on humans turning data into insight and humans making decisions in bureaucratic structures ( with the help of that insight ) "" ."	239658990	no
"The mass - to - light ratio of NGC1052 - DF2 is compatible with that of other nearby dwarf galaxies . For instance , IC 1613 shares the luminosity of NGC1052 - DF2 , has a radius that is only half as small and a velocity dispersion of 10.8 +1.0 â0.9 km s â1 from which Kirby et al . ( 2014 ) inferred M / L V ( r half ) = 2.2 Â± 0.5 . The M31 companions Cas III and Lac I , albeit somewhat fainter , share similar properties to those of NGC1052 - DF2 : their large half - light radii ( â¼ 1.5 kpc ; Martin et al . 2013 ) and velocity dispersion â¼ 10 km s â1 imply mass - to - light ratios ( M / L V ( r half ) = 8 +9 â5 and 15 +12 â9 , respectively ; Martin et al . 2014 ) that are entirely compatible with the constraint on NGC1052 - DF2 6 . The well - study Milky Way satellite dwarf galaxy Fornax also shares similar properties ( Irwin & Hatzidimitriou 1995;Walker et al . 2009 ) . Finally , NGC1052 - DF2 's velocity dispersion and mass , despite being poorly constrained , fall perfectly on the Walker et al . ( 2009 ) universal mass profile proposed for Local Group dwarf galaxies . It also follows the locus of most dwarf galaxies in the M / L vs. M plane , contrary to the peculiar dwarf galaxy Dragonfly 44 that appears exceptionally massive ( van Dokkum et al . 2016 , their Figure 3 ) . A conservative and cautious approach would therefore be to conclude that the mass - to - light ratio of NGC1052 - DF2 appears to be the low end of that measured for other dwarf galaxies , but share the properties of other local dwarf galaxies and relies on a noisy measurement . Other "" ultradiffuse dwarf galaxies "" studied with data sets of similar quality also yield only weak constraints on the darkmatter content ( Toloba et al . 2018 ) . Significant additional proof is required before claiming a lack of dark matter in NGC1052 - DF2 , even more so since rotation could also be present and its contribution to the dynamics of the galaxy could further increase its dynamical mass . An independent study by Laporte et al . 2018 shows that NGC1052 - DF2 can comfortably live in a dark matter halo of 10 9 M â or even 10 10 M â within the uncertainties ."	56381823	no
The following section will show how we used the MRIO model in order to establish the methodology for this study . The paper will then account for the data sources , and provide the results with analysis and comparison with others . Conclusions and policy recommendations will be promoted at last .	153326547	no
Subsequently , the binding behavior of azachalcone to the ternary catalyst complex was investigated . Both 1 HNMR and fluorescence measurements suggested the inclusion of each of the amino acids and 1a in the presence of Cu 2 + , y ielding CB [ 8]Â·dÂ·Cu 2 + Â· 1a and CB [ 8]Â·eÂ·Cu 2 + Â· 1a . T he analysis of the aromatic region of the 1 HNMR spectra revealed that the signals from both the amino acids and 1a were shifted upfield when CB [ 8 ] and Cu 2 + were both present ( Supporting Information , Figures S7 - S10 ) . Furthermore , t he emission of both d and e were blue - shifted . However , as azachalcone 1a was present , quenching was also observed in the study of the full catalytic system ( Supporting Information , Figure S12 a , b ) . These data suggest that the amino acids and 1a are indeed in close proximity and included in the CB [ 8 ] cavity .	14527477	no
( 2 ) w here B , L and s denote baryon , l epton num ber and spi n of the parti cl es , respecti vel y , i s one possi bi l i ty to forbi d the coupl i ngs Eq . ( 1 ) . From the de ni ti on , R -pari ty i s + 1 for al lSM parti cl es and 1 for al l thei r superpartners . H owever , R -pari ty i s not the onl y possi bl e choi ce to forbi d the i nteracti ons . M atter - or l epton - and baryon - pari ty [ 13]can be al so a possi bi l i ty . O n the other hand , w i thoutR -pari ty , these coupl i ng constants have to be stri ctl y constrai ned notto con i ct w i th experi m ental data . C onstrai nts on the R -pari ty vi ol ati ng coupl i ngs have been obtai ned by m any authorsfrom LFV processes [ 14,15,16,17,18,19 ] , neutri no m ass [ 14,20,21,22,23 ] , neutralm eson system [ 24,25,26,27,28,29,30,31,32 ] , proton decay [ 16,33,34 ] , and so on [ 12,35,38 ] . Fam i l y sym m etri es al so constrai n the form ofR -pari ty i nteracti ons [ 22,33,36,37]as wel las the Yukawa m atri ces . In the m odel that we consi der [ 1 , 2 ] , the Q 6 fam i l y sym m etry reduces the 45 tri l i near coupl i ngs to three : , 0 1 and 0 2 . T he baryon num ber vi ol ati ng coupl i ngs 0 0 ijk U c i D c j D c k are forbi dden by the sym m etry i n our m odel , so i t i s guaranteed by the sym m etry that the R -pari ty vi ol ati ng operators do not i nduce proton decay .	118912148	no
The thermal gradient ïT was applied along the ab - plane of the sample , while the magnetic field was applied along the c - axis . Another gold - plated flat copper wire was attached to the puck clamp for the heat sink . In order to measure the temperature gradient , two gold - plated copper leads were attached directly to the sample using a silver - filled epoxy along the thermal gradient direction . The distance between the thermometers was ~3.5 mm . In the Seebeck and Nernst measurements , ïT was typically set to ~1 - 3 % of the base temperature . Two copper wires were attached using the silver epoxy , orthogonal to the thermal gradient direction , to measure the transverse voltage . In order to correct the data for contact misalignment , the measured data were field - symmetrized and antisymmetrized . The thermal conductivity measurement was carried out in the PPMS using the thermal transport option .	143422224	no
The seedlings of peanut were cultivated in hydroponic nutrient solutions added with 10 ÂµM ( control group ) or 300 ÂµM ( Mn toxic stress treatment group ) MnSO 4 as described above . After 20 days , root and leaf samples were respectively obtained for extraction of total RNA and formation of mRNA library , and transcriptomic sequencing analysis was performed according to a previous report [ 76 ] . Three biological repetitions were employed for each sample . For RNA extraction , the TRIzol reagent ( Invitrogen , Waltham , MA , USA ) was used . The samples of RNA were concentrated using ferrite beads containing dT ( oligo ) , followed by fragmentation and reverse - transcription using randomized primers . After being purified , cDNA was handled with terminal modification . Meanwhile , the entire library was generated via polymerase chain reaction ( PCR ) amplification . The library made sequence determinations by adopting the Illumina platform and the method of PE150 sequencing . Data quality was assured by filtering the raw sequencing results to generate high - class sequences ( clean data ) . The clean data were then aligned with the reference genome of peanut ( Arachis hypogaea PGR ) by application of the system version of TopHat 2.0.12 [ 77,78 ] .	255680589	no
In Figure 4 , we present our fiducial set of images ( in a uniform scale ) from synthetic data surveys carried within each method . In each panel we report a correlation coefficient Ã¡ Ã± I I 0 Â· between recovered Stokes ï and the ground - truth ï 0 images ,	233715159	no
The paper ' Direct fiber vector eigenmode multiplexing transmission seeded by integrated optical vortex emitters ' by J Liu 1 has successfully demonstrated that different data - carrying vector modes can be used to increase capacity through data - carrying , full - vectorial fiber eigenmode multiplexing communications in circular optical fibers . This work uses compact , integrated optics to achieve capacity scaling by directly exploiting orthogonal spatial vector eigenmodes .	52132715	no
This is one of the first studies to investigate relationships between cities , health , and well - being before and during COVID-19 using GISderived measures of the built environment in combination with quasilongitudinal data on health and well - being . The study contributes to knowledge on COVID-19 and quality of life in cities by assessing changes in health and well - being before and during COVID-19 and by examining how urban planning and built environment characteristics in specific may have contributed to these changes .	238530423	no
"Safety of patients is an international problem : reviews of case notes have established that 4 - 16 % of patients admitted to hospital experience an adverse event . 1 - 3 Definitions of safety vary but usually encompass the "" avoidance , prevention , and amelioration of adverse outcomes or injury from the process of health care . "" 4 With growing international interest in patient safety , there is increasing need to monitor the safety of organisations and evaluate safety initiatives . Measuring the scale and impact of safety incidents , however , is a major challenge , and estimates of deaths caused by such incidents vary widely . 5 Relevant studies are costly to undertake , and the findings depend on thresholds used for including events . 6 7 There has been considerable investment in local and national reporting systems , and , although these are a valuable resource for learning , voluntary reporting systems are unlikely to provide systematic and reliable information for monitoring patient safety because many incidents go unreported . 8 Routine data sources have potential for identifying patient safety incidents , with the advantage of no additional data collection costs and burden ."	16191971	no
Finally , following the crucial moment of observation detailed next , we critically analysed and interrogated our interview data in order to understand how particular assumptions were deployed , in order to defend and sustain practices that might be potentially troublesome to our participants . This is the justification for privileging the presentation and analysis of our interview data in this article , because we are interested in how vets articulate and account for their own taken - for - granted practices and actions , together with what is not said . In engaging with different literatures , we began to see how these assumptions reflected and reproduced discourses or ideologies of adiaphorization , anthropocentricism , speciesism , and humanism . For example , making the animal more productive became a pervasive story , in terms of milk yields , boosting farmers ' profits , and feeding the population , which obscure any morally dubious concerns that might be raised around perpetual cow pregnancies , or hormone and antibiotic treatments that are designed to prevent any disruption in the ( re ) productive process .	234287184	no
However , because of the under - determined term Âµ * ( x ) , we can not recover the distribution density p data exactly from either c * 2 or c * ent if the data support is finite . Whether this ambiguity can be resolved is beyond the scope of this paper , but poses an interesting research problem . 3 . Finally , let 's consider consider a degenerate case , where K(p gen ) is a constant . That is , we do nt provide any additional training signal for pgen at all . With K(p gen ) = const , we simply have	13619197	no
To examine the domains of rapid - response COVID-19 innovations and the human needs they correspond to , we adopt a two - stage approach . First , we identify the arising innovation trends during the first two months of the COVID-19 crisis utilizing machine learning to construct a topic model ( Maier et al . , 2018 ) based on web - scraped text data of 707 innovation projects related to the COVID-19 crisis ( henceforth , COVID innovations ) . In doing so , we contribute a novel procedure for characterizing large - scale innovation activities by employing the text mining technique of topic modeling using text data of innovation projects . Subsequently , we estimate the time trend of the identified domains of innovations over the two - month observation span using simple regression analysis to identify the rising and falling dynamics of the rapid - response COVID innovations . Second , and based on the derived structural model of innovation activities , we connect the different identified domains of innovations to a more latent classification of fundamental human needs , which is based on the contribution of Max - Neef et al . ( 1989 ) . Employing this two - stage approach , each crisis - driven domain of innovations is thematically characterized , and its occurrence is estimated over time . Each domain is also classified according to the needs it addresses on the side of the consumers and producers of the innovations . Our results show that this perspective may help to identify points of intervention to move toward achieving a systemic reaction to such crises . This paper is structured as follows . Section 2 substantiates our theoretical underpinning by connecting crisis - driven innovations with the notion of fundamental human needs and a perspective on innovation systems . Section 3 presents our data and methodology , including our topic modeling process , the regressions to estimate time trends , and the classification scheme to map fundamental human needs to our sample of innovations . Section 4 presents a synthesis of the derived clusters of our topic model , describing the time trends as well as human needs addressed by various domains of innovations . Section 5 discusses our findings against the backdrop of the unfolding crisis and dedicated innovation systems . Section 6 offers some concrete practical implications of our results . Finally , Section 7 concludes the study and presents some limitations and promising avenues for future research .	235513294	no
There were minor losses of the reduced / omni - directional data products during the mode change , which manifest as the white gaps in Figure 2 panels a and d.	119229854	no
In contrast , the discriminative objective in Eq . ( 1 ) does not directly model the input distribution p(x ) but learns a representation that discriminates between input samples . The representation is not required to reconstruct the input , which is unnecessary in a recognition or matching task . This leaves more degrees of freedom to model the desired variability of a sample . As shown in our analysis ( see Eq . ( 12 ) ) , we achieve partial invariance to transformations applied during surrogate data creation by forcing the representation g(T Î± x i ) of the transformed image patch to be predictive of the surrogate label assigned to the original image patch x i .	3244218	no
Data Availability Statement : All supporting data generated for this manuscript are freely available here together with a short commentary : https://zenodo.org/record/4541573#.YCrckWj0lPY ( accessed on 7 July 2021 ) .	236209619	yes
To test the hypothesis that the identified mutants indeed affect binding selectivity by favoring a specific substate along the pincer mode , the change in binding free energy was calculated for six complexes . Three complexes with ubiquitin predominantly in the open substate ( PDB : 1xd3 , 2fif , and 4un2 ) , two with ubiquitin predominantly in the closed substate ( PDB : 1nbf and 2g45 ) , and one complex without preference for either the open or closed substate ( PDB : 2hth ) were chosen for this assessment . The accuracy of the procedure was ensured by using closed thermodynamic cycles , as well as by comparing to known experimental data ( see Sections S2.1 - S2.3 in the Supporting Information ) . Seven ubiquitin mutations were performed on each of these complexes , three preferring the open substate ( I13F , I36A , I36Y ) , two preferring the closed substate ( L69S , L69 T ) , and two that populate the complete ground - state ensemble similar to the wild - type ( V5L , I36L ) . The V5L and I36L mutants , although initially identified as stabilizing the closed substate , were revealed by umbrella sampling simulations to have almost no effect on the substate populations ( Figure S8 ) .	14293045	no
"While the ECDC ( 2008 ; cf . Raffle , 2007 ) had similarly raised concerns about possible lower attendance to screening programs as a result of vaccine introduction , Kdolsky 's stance presents a somewhat idiosyncratic interpretation of these concerns . She contested the message communicated by medical professionals and patient associations , such as the Krebshilfe , that "" this vaccine could prevent cancer "" , as , in fact , it was the virus that caused cancer , and the vaccine would protect against the virus , rather than cancer . But more importantly , she asserted : "" Efficacy and safety form top priorities , and no evidence - based data and long - term studies are available at this point . We do not know [ â¦ ] the effects of administering retro - viral , that is , gene - technology based inactive cells "" ( BMG , 2007 ) . Against the background of a history of resistance against genetic modifications in Austria ( Felt , 2013;Prainsack et al . , 2010 ) , Kdolsky 's reference to genetic technology carried some weight in this context and was likely to provoke more criticism than support for the vaccine ."	1579735	no
Step 1 -2 - D Data Re - construction : The first step of the proposed CFS is to break down the cleaned high - dimensional data set U into n 2 - D planes , which is implemented by combining all input attributes , F i ( 1 i n ) , and the output y. Thus , U can be decomposed to n 2 - D planes , represented as P ( F i , y ) .	231573178	no
3.1 . Direct RT - qPCR Omicron variant of concern ( B.1.1.529 ) detection Whenever a new variant of concern emerges , there is an obvious need for rapid and direct detection of variant positive cases in the population . In most countries , the employed strategy is to sequence all COVID-19 positive patients entering the country along with random sequencing of COVID-19 positive patients in the population for the detection of new variants . Next generation sequencing ( NGS ) retrieves the most data and therefore applies to all variants . While NGS can reveal the appearance of a new variant , once revealed it is costly and time - consuming to keep using sequencing methods for the detection of any previously detected variants . The current infrastructures around the world can not provide rapid NGS analysis in terms of large - scale sampling and produce immediate results . It is for these reasons that current NGS analyses are performed on a significantly smaller sub - group of samples and may result in overlooking variants distribution . When focusing on specific , known variants , RT - qPCR can overcome such limitations . Therefore , a specifically designed RT - qPCR assay for variant detection provides an important tool for broad , existing variants survey in the population with immediate results .	248452802	no
Responding to hydrogenation , the rutile structure of metallic VO 2 distorts , as depicted in Fig .    23 , and the lattice expands . The simulated diffraction pattern associated with this theoretical structure agrees well with the electron diffraction data . [ 162 ] The most important question , of course , is why does hydrogenation favor the metallic ( pseudo-)rutile structure over the insulating monoclinic one . Both the DFT and DFT+U methods predict a range of concentrations over which the pseudo - rutile structure is thermodynamically more stable than the monoclinic one at absolute zero temperature , [ 162 ] corroborating the experiments . From the chemistry point of view , this can be understood by considering that the H .. O bond formation will lead to electron transfer from hydrogen onto oxygen atom , therefore reducing the electronegativity of the latter . As a result , the V .. O bond will become less ionic , meaning that less electrons will be donated by vanadium atom , making V d - level more populated and hence resulting in a more metallic behavior . This schematic argument can be tested rigorously with first - principles calculations , and we found that indeed , the vanadium d - orbital occupancy rises monotonically with hydrogen concentration , up to as much as 0.16 electrons for 100 mol% ( in HVO 2 ) . Since the density of states at the Fermi level comes primarily from V d - electrons , this translates directly to doping the system away from half - filling and from Mott metal - insulator transition , which is what the experiments demonstrate .	197195637	no
We optimize the CVaR of a loss at level Î± = 0.1 , hence k = 0.1N , where N is the size of the data set . In classification tasks , we consider the cross - entropy loss as a surrogate of the 0/1 loss , and in regression tasks , we consider the squared loss .	204904863	no
Sivakumar Gowthaman : designed the experimental program , performed laboratory experiments and wrote the manuscript . Moeka Yamamoto : performed the laboratory experiments and analyzed the testing results .. Kazunori Nakashima : supported in data analysis , interpretations and reviewed the manuscript .. Volodymyr Ivanov : supported in data interpretations and reviewed the manuscript .. Satoru Kawasaki : contributed primary supervision , reviewed and approved it for publication , All the authors listed have made direct and intellectual contribution to the presented work .	238728277	no
Taken together , we have data from 20,176 individuals from 10 LMICs and 24,084 from the United States and Russia , for a total of 44,260 respondents . We report data missingness patterns in Supplementary Table 13 .	236000413	maybe
The last decade has witnessed the emergence of novel technologies in computer science , ranging from big data , cloud computation , and machine learning to artificial intelligence . These require increasingly powerful electronic or photonic devices to enable important applications , such as augmented reality , point - to - point medical electronics , and wearable devices . In all these applications , there is a strong need to create or collect data all over space , i.e. , to enable point clouds . A point cloud refers to a set of data points in space , usually in three dimensions , based on which a growing number of important applications have recently been achieved , such as motion detection and facial recognition using commercially available products such as Kinect ( Microsoft Corp. ) 1 and iPhone X ( Apple Corp. ) . Common methods to generate a point cloud or , equivalently , spot arrays in optics use diffractive optical elements ( DOEs ) 2,3 or light detection and ranging ( LIDAR ) 4,5 , on which the two aforementioned commercial products are based . The different depths etched on DOEs can create a phase profile , enabling the diffracted beam to form spot arrays on one side , either the transmission or reflection side , similar to a Lambertian surface 6 . Once the scattered beams are captured by the sensors , the computer program can search the encoded information and determine the morphology of the detected objects . However , this approach leads to several disadvantages , such as fabrication difficulty , the inherent limitation of spots spanning only a 2Ï space , and fundamental limits on the thickness of these devices ( at least comparable to the wavelength ) , which may seriously hinder various applications . Even though the point cloud generated by LIDAR can cover the full space by scanning the azimuth and elevation , the complex and bulky scanning system obstructs the miniaturization of the point cloud generator , which is critical for light portable devices . Thus , to further improve and commercialize novel technologies based on point clouds , apart from the software , new devices must be developed . These should meet demanding requirements : compatibility for integration into traditional silicon - based semiconductor devices , ultrathin form factors to ensure compactness and miniaturization for future trends in light portable devices , commercially viable fabrication and , most importantly , functionality to generate millions of data points to increase the information capacity in full space .	52313933	no
Using a single - stage transcription protocol , interviews were transcribed verbatim into English ( McLellan et al . , 2003 ) . Assisted by NVIVO 10 analysis software ( QSR International Pty Ltd , 2012 ) , through constant comparison of the properties of the data a coding frame was developed which included themes identified a priori as well as those that emerged from the data . Separate coding frames were developed for intervention and control schools . Supported by the query function in NVIVO 10 , charts of data summaries were developed so that comparisons could be drawn within and between cases and between intervention and control schools ( Green and Thorogood , 2004;Ritchie and Spencer , 2004 ) . This also helped to ensure that data was systematically reviewed to reduce anecdotal inclusion of data and improve transparency . Through further interrogation and comparison , concepts were further refined from which a model of the findings was developed as described below .	4621216	no
Generating the sequence using a preferential attachment based model . We apply a preferential attachment based model to generated topic tuple sequences with power - law distributed usage of each topic tuple [ 32,37,38 ] . In the model , an individual 's activity is randomly chosen from the two actions . One is to explore a new subject and publish a paper with a new topic tuple . The other is to return to a previously studied subject and publish a paper with a topic tuple already used . The probability to explore is defined as Ïn âÎ³ in which the term n âÎ³ captures the decreasing trend to explore a new subject as the number of papers increases . Consequently the probability of return , i.e. to reuse an old topic tuple , is 1 â Ïn âÎ³ . If one returns , the choice of existing topic tuples is governed by preferential attachment : the probability p i to use a specific topic tuple i is proportional to the tuple i 's current usage , so p i = n i / j n j where n i is the number of times that the tuple i is used . The parameters applied are Ï = 0.4 and Î³ = 0.1 . Each individual 's time step is controlled by the number of papers published , following distribution P ( n ) â¼ n â1.5 with a cutoff n max = 150 . These variables make the sequence generated similar to those in real data . We generate totally 20,000 independent sequences , a comparable number to the size of real data . See Supplementary Discussion 4 for more about the preferential attachment based model . Data availability . The Physical Review dataset is available upon requested from the APS at http://journals.aps.org/datasets . The name disambiguation procedure and the associated data are described in Ref . [ 6,43 ] .	6911864	yes
Let T ( x ) be a pretrained teacher network , which maps some input image x to a probability vector t. Similarly , S(x ; Î¸ ) is a student network parameterized by weights Î¸ , which outputs probability vector s. Let G(z ; Ï ) be a generator parameterized by weights Ï , which produces pseudo data x p from a noise vector z â¼ N ( 0 , I ) . The main loss function we use is the forward Kullback - Leibler ( KL ) divergence between the outputs of the teacher and student networks on pseudo data , namely	162183830	no
We also perform an evaluation on a dataset composed of the three most popular categories : apparel , diaper , and feeding . We construct this dataset , composed of three large disjoint categories of items , with a catalog of 100 items in each category , to highlight the differences in how nonsymmetric and symmetric DPPs model data . In particular , we will see that the nonsymmetric DPP uses positive correlations to capture item co - occurences within baskets , while negative correlations are used to capture disjoint pairs of items . In contrast , since symmetric DPPs can only represent negative correlations , they must attempt to capture both co - occuring items , and items that are disjoint , using only negative correlations . 2 . UK Retail : This is a public dataset [ 8 ] that contains 25,898 baskets drawn from a catalog of 4,070 items . This dataset contains transactions from a non - store online retail company that primarily sells unique all - occasion gifts , and many customers are wholesalers . We omit all baskets with more than 100 items , which allows us to use a low - rank factorization of the symmetric DPP ( D = 100 ) that scales well in training and prediction time , while also keeping memory consumption for model parameters to a manageable level .	170078866	maybe
For cell cycle analysis , cells were fixed dropwise with 70 % ice cold ethanol for 30 min on ice and suspended in PBS containing 10 Î¼g / ml of propidium iodide ( PI ) and 10 Î¼g / ml of RNase A. PI - stained samples were analyzed for cell cycle progression by flow cytometry using a FACScalibur ( Becton and Dickinson ) apparatus , followed by data analysis using the FlowJo software ( TreeStar ) . For apoptosis analysis , apoptotic cells were detected using BD FITC Annexin V Apoptosis Detection Kit followed by flow cytometry analysis .	14226227	no
3D APT reconstruction ( Figure 4a ) of the deformed region in Vitreloy 105 clearly shows Cu - and Zr - rich zones along the SB , while the undeformed bulk shows no significant chemical fluctuation ( Figure 4b , d ) . The concentration profile ( Figure 4c ) , extracted from the cylinder in Figure 4a ( perpendicular to the SB plane as schematically shown in Figure 4e ) , exhibits a high asymmetry perpendicular to the SB , that is , on one side the SB is rich in Cu â23 at% ( depleted in Zr ) and on the other side the SB is rich in Zr â57 at% ( depleted in Cu ) , while the concentration of the other elements remains unchanged . An obvious elemental fluctuation occurs within â12 nm , which agrees with the SB width observed by STEM - PDF ( Figures 2 and 3 ) . To analyze the atomic distributions in the immediate vicinity around each atom in the SB and SBAZs , a fifth nearest neighbor ( 5NN correlation shell ) distribution analysis was performed on the   experimental APT data and compared to the randomized distribution of the atoms in the bulk . [ 44 ] The investigation is restricted to the inter - atomic distances of the 5NN to enhance the statistics and is displayed in Figure 5 . The bulk is well represented by the random model , however , obvious deviations are observed between the SB / SBAZ and the bulk ( Figure 5a , b ) . The peak position reflects the elemental - specific atomic density in the vicinity of an atom and a peak shift to smaller distances correspond to clustering of Zr and Cu atoms as seen in Figure 5a , b. The red SBAZ shows a higher degree of Cu clustering compared to the blue SBAZ , which shows a higher degree of Zr clustering ; the SB shows the highest degree of elemental segregation . These results are in agreement with the STEM - PDF findings . Moreover , random NiîNi , AlîAl , and TiîTi 5NN distributions in the bulk , SBAZs , and SB ( Figure 5c - e ) confirm that Ni , Ti , and Al have not segregated . Hence , the observed variation in the STEM - PDF can be attributed mainly to variations of CuîCu , CuîZr , and ZrîZr pairs , and IC2 can be related to CuîCu and CuîZr correlations .	231962657	no
A particularly related UVF extension is hindsight experience replay ( HER ) Andrychowicz et al . ( 2017 ) . Both HER and our method retroactively relabel past experience with goal states that are different from the goal aimed for during data collection . However , unlike our method , the standard UVF in HER uses a single temporal scale when learning , and does not explicitly provide for a connection between model - based and model - free learning . The practical result of these differences is that our approach empirically achieves substantially better sample complexity than HER on a wide range of complex continuous control tasks , while the theoretical connection between modelbased and model - free learning suggests a much more flexible use of the learned Q - function inside a planning or optimal control framework .	3514022	no
According to the results of real - time PCR , treatment of HepG2 cells with sorafenib at a concentration of 3Âµg / mL for 24 h and 48 h ( Figure 7 ) contributed to a decrease in the expression of a number of key kinases to one degree or another . Thus , a more than 2 - fold decrease in the expression of serine - threonine protein kinases RIPK1 and RIPK3 was observed , as well as a decrease in the expression of mRNA of the pseudokinase MLKL . These data may indicate that sorafenib inhibited the activation of TNF - induced necroptosis . In addition , a decrease in the expression of Raf serine - threonine kinase , as well as MAPK1 and MAPK3 kinases , was observed after 48 h of treatment of HepG2 cells with So ( Figure 7B ) , which may also indicate inhibition of the kinase cascade . Additional evidence for this can be reduced expression of the receptor tyrosine kinase KIT and FLT3 ( fms - like tyrosine kinase 3 ) , which are also involved in the stimulation of the Ras - mediated signaling pathway , including MAPK1 and MAPK3 , even against the background of practically unchanged Ras expression ( Figure 7 ) . In addition , treatment of cells with So led to a significant decrease in PI3 K kinase , which may indicate inhibition of the intracellular signaling pathway PI3K / AKT / mTOR , and , consequently , disruption of the cell cycle , reduced cell growth , and survival ( Figure 7 , green columns ) . The action of SeNPs and SeSo led to a significantly significant decrease in the expression of almost all the studied genes encoding the aforementioned kinases already after 24 h of exposure to HepG2 cells ( Figure 7A ) , which turned out to be even more pronounced 48 h after their application to cells ( Figure 7B ) . Thus , already 24 h after exposure of the cells to SeNPs and SeSo , the expression of mRNA of RIPK1 , MAPK1 , and mTOR kinases decreased by 5 - 10 times compared with the control .	249720084	no
Due to the widespread utilization of polymers ( both synthetic and natural polymers ) in controlling and fighting the COVID-19 crisis , there is an obligation for getting data and gathered information concerning polymers . In this study , the importance and role of synthetic and natural polymers in controlling and counteracting COVID-19 are expressed .	231965805	no
All participants visited the pulmonary function laboratory of the Radboud University Nijmegen Medical Centre at baseline , 12 months , and 24 months . At six months and 18 months , a trained lung function technician visited patients at home . During all study visits , data were collected on smoking habits , respiratory drugs , spirometry , 10 health related quality of life , and self efficacy . The data collected were not provided to the practices .	8768295	no
In a model of endotoxin - induced ( LPS ) autoimmune uveitis ( ocular inflammation ) in C57BL/6 WT mice , administration of PEPITEM with LPS into the eye reduced the number of T cells in the ocular infiltrate ( Fig . 4e ) . PEPITEM also reduced T cell trafficking into the salivary glands of C57BL/6 WT mice challenged with a virally induced model of tertiary lymphoid organ formation , which mimics changes observed in the autoimmune rheumatic disease , SjÃ¶gren 's syndrome 39 ( Fig . 4f , g ) . In both uveitis and SjÃ¶gren 's syndrome models , as well as in the zymosan - induced peritonitis ( data not shown ) , B cells were recruited to the sites of inflammation and the number of B cells recruited was not affected by PEPITEM ( Supplementary Fig . 8d , e ) . In addition , in the in vivo model of acute , resolving inflammation ( peritonitis ) , the recruitment patterns of F4/80 macrophages and CD11c + cells were not affected at the time point used to assess T cell trafficking ( Supplementary Fig . 8f , g ) .	13769956	no
We further extended the concept of macrophage - dependent erythropoiesis to pathological conditions associated with elevated erythropoietic activity , such as Polycythemia vera or Î²thalassemia . Polycythemia vera is a clonal stem cell disorder in which the somatic JAK2 V617F mutation 36 - 41 leads to a hyperproliferative phenotype . While our data do not question the importance of the JAK2 V617F mutation for Polycythemia vera , it provides an additional degree of complexity to this disorder . We clearly demonstrate that , macrophagedepletion in mice carrying the Jak2 V617F mutation reversed some of the key features of Polycythemia vera , including splenomegaly , reticulocytosis , erythrocytosis and elevated hematocrit . Furthermore , we show that proliferation of cells derived from JAK2 V617F patients is increased when they were co - cultured with macrophages . Thus , we propose a new model for Polycythemia vera progression in which the JAK2 V617F mutation functions as primer for the Polycythemia vera phenotype , but a permissive niche and SEMA are required for full manifestation of the erythroid phenotype in vivo ( Fig . 6 ) . This model represents a clear parallel to the current understanding of tumor biology . Also in this case , an oncogenic mutation is considered to be the primary event leading to tumorigenesis . However , the role of tumor associated macrophages supporting tumor progression and metastatic spread is now uncontested 54 . This is the first description of what we believe to be an important mechanism contributing for the pathophysiology of Polycythemia vera that could have significant therapeutic implications for the management of this disorder .	12637294	no
which can also be referred to as the OAM power spectrum 37 . Thus , the SMART allows us to accurately characterize the OAM components from multiply scattered light , thereby enabling data transmission .	71715926	no
The training and validation sets contain seven and one million randomly selected stars , respectively , both with G < 13.5 and T eff â [ 3550 , 6900 ] K. This is intended to parallel the subset of Gaia data with full 6D information ( Katz et al . 2019 ) . The test set consists of â¼ 10 million stars of any magnitude and temperature .	232380032	no
The advantage of this technique is that the device is maintained under conditions close to realistic operating conditions with an illumination intensity always close to 1 sun and under constant bias , as opposed to other transient techniques , such as   TOF , [ 5a ] time - resolved electric - field - induced second harmonic generation ( TREFISH)/TOF , [ 6b , c ] and transient photocurrent ( TPC ) , [ 11 ] which are based on pulsed light . Keeping the device under illumination and bias close to the maximum power point ensures that the charge carrier densities [ 12 ] and the electrical field , [ 12b ] which can influence the charge carrier motion , will be similar to those observed in a working solar cell leading to a characterization of the transport properties closer to what happens under steady - state conditions . Secondly , to validate the assumptions made above a transient 1D drift - diffusion simulation was set up . In this simulation , the active layer of the BHJ solar cell is modeled using an effective medium approximation that considers the BHJ as a onephase semiconductor . The highest occupied molecular orbital ( HOMO ) of the effective semiconductor is taken as the HOMO value of the donor , and the lowest unoccupied molecular orbital ( LUMO ) of the effective semiconductor is taken as the LUMO value of the acceptor . The model describes the movement of the charges by drift due to the electric field and diffusion due to the gradient of charge carrier concentration , more details can be found in ref . [ 13 ] . The simulations also account for bimolecular recombination within the active layer , calculated using reduced Langevin law , [ 14 ] as it is commonly seen as the main recombination pathway limiting the performance of high - efficiency OPV devices . [ 15 ] One should also note that the drift - diffusion equations use the steady - state mobilities as an input and do not include any effects of charge carrier dispersion . So the dispersion in photocurrent observed in other reports [ 6b , c ] can not be reproduced by the drift - diffusion simulation . However , these simulations are suitable in our case as this study aims to show that steady - state mobilities are the relevant parameters for OPV devices . In addition , if the drift - diffusion simulation can reproduce the experimental data , then dispersion does not play a significant role .	34671020	no
Simultaneously , calibration models were constructed using the chromatographic data . Linear ranges of calibration curves were evaluated with seven analytical standards ( measured in triplicates ) . Areas of peaks representing BPA and BPF were computed using chromatograms extracted from HPLC - DAD signals at 225 nm , and HPLC - FLD signals recorded for excitation at 230 nm and emission at 300 nm . Calibration data for BPS were extracted from HPLC - DAD signals at 275 nm . Peak areas were computed using an in - house routine with Matlab 2012 software . The summary of obtained results is in Table 2 .	238740800	no
By fitting the data points with an exponential function that describes the solution of af irstorder rate master equation with time as avariable ( top axis in Figure 2d , e ) , we found that isomerization occurs rather fast with time constants of 457 sf or trans!cis isomerization and an even smaller value of 154 sf or cis!trans switching ( Figure 2d , e ) . Forb oth processes , t he total number of molecules at the surface remained constant . Am ore precise measure for the photoinduced switching , r eferring to the photon density ( bottom axis in Figure 2d , e ) and thus including the spot size on the surface ( see the Supporting Information ) , are the cross - sections s(trans!cis ) = ( 1.37 AE 0.71 ) 10 Ã21 cm 2 ( Figure 2d)a nd s(cis!trans ) = ( 1.41 AE 0.44 ) 10 Ã21 cm 2 ( Figure 2e ) . These values are larger than for azobenzene derivatives adsorbed flat on am etal surface ( about 10 Ã22 cm 2 ) , [ 30 ] in agreement with the relatively small time constant , thus revealing that the upright standing azobenzene is partially decoupled from the metallic surface . On the other hand , they are smaller than those for azobenzene derivatives on an insulator surface ( 10 Ã18 and 10 Ã20 cm 2 ) [ 15 ] and in solution ( about 10 Ã19 cm 2 ) , [ 13 ] thus indicating only partial decoupling . Other tripod systems have shown more efficient decoupling with cross - sections between 2.5 10 Ã19 cm 2 and 4 10 Ã18 cm 2 for a(p - cyano)azobenzene - tripod system [ 17 ] or about 10 Ã18 [ 31 ] and 10 Ã17 cm 2 [ 32 ] for azobenzene chains in self - assembled monolayers on Au(111 ) , where the distance between the azobenzene unit and the metal surface is larger . B esides photoswitching , i somerization could also be induced in ac ontrolled fashion by STM manipulation , and	52160661	no
"Next , we examine whether the country - of - origin treatment effect is moderated by one 's feeling towards the foreign country and one 's fear of Covid-19 . After all , the treatment coefficient estimates and the substantive simulations suggest noisiness which might stem from heterogeneity of treatment effects . Following an approach proposed by ( Bansak , 2021 ) , we first subset the data by the "" domestic "" and "" foreign "" vaccine treatment status and then calculate the effect of the moderator on the outcome ( for each treatment / country subset ) ; for details , see ( Bansak , 2021 ) . This strategy lets us calculate the changes to vaccine uptake due to feelings toward the foreign country and one 's fear of Covid-19 , respectively , under each treatment , as we introduced and discussed earlier in the paper . In Section B , we show the empirical distribution of the moderators for reference ."	235441227	no
In what follows we will describe our two main analysis methods employing first the conventional SUSY search methods and then taking advantage of the displaced vertex technique . As already mentioned all the SUSY particle decays , both R - parity violating as well as R - parity conserving , are calculated using a generalized version of the SPheno code [ 40][50 ] . Given a point in SUGRA parameter space , SPheno searches for a set of Ç« i and Î i that leads to neutrino masses and mixings compatible with current neutrino oscillation data . In general , there is a range of R - parity violating parameters that satisfy the above neutrino constraints . As already mentioned , both SUSY spectra and production cross sections are well approximated by the conventional R - parity conserving mSUGRA ones , in view of the smallness of R - parity violation parameters required to fit the neutrino oscillation data . However , for consistency , our version of SPheno calculates spectra and branching ratios including BRpV effects .	119282820	no
The number and appearance of mitochondria seen by TEM of VR islets were qualitatively similar to control islet cells ( Fig .   4a , bottom ) . Similar to the TMRE findings , overall ATP levels in    Fig . 4 | Viability and morphology of mouse , porcine , human and SC - beta islets following cryopreservation . a , Morphology of mouse islets from live control , VR ( cryopreserved by VR ) and conventional ( cryopreserved by conventional slow freezing ) was evaluated by brightfield microscopy , hematoxylin and eosin ( H&E ) histology , and TEM . For the conventional group , a mixture of intact and disrupted islets was observed . Examples of disrupted islet gross morphology due to ice formation are shown in the brightfield and H&E histology . b , Viability ( percentage of live control ) of mouse , SC - beta , porcine and human islets from treatment groups including live control , VR , VR 9 months ( islets stored in LN 2 for 9 months before rewarming ) , conventional ( cryopreserved by conventional slow freezing ) and dead control ( treated by 75 % ethanol ) . ND , not done . One - way ANOVA with Games - Howell post hoc test was used to compare groups , and P values from informative pairwise comparisons are shown ( n = 3 - 34 per group ; exact number in Supplementary   Table 3 ) . c , Confocal microscope images ( AO / PI ) of mouse , SC - beta , porcine and human islets from treatment groups , including live control , VR and conventional . d , TUNEL - stained images of mouse , SC - beta and human islets from treatment groups , including live control , VR and conventional . Bottom panel is Annexin V staining of mouse islets from the same treatment groups . Scale bars represent 2 Âµm for TEM , 50 Âµm for brightfield images , 70 Âµm for histology and TUNEL images and 100 Âµm for all fluorescence images . Data are shown as individual data points and mean Â± s.d .	247453331	no
Bioinformatic prediction of potential off - target sites for HBB ( R-02 ) was carried out using the webtool COSMID 69 with up to 3 mismatches allowed in the 19 PAM proximal bases and the PAM sequence NRG . GUIDE - Seq was used for experimental identification of potential off - target sites . Briefly , a plasmid expressing R-02 and Cas9 was nucleofected into U2OS cells as previously described 10 . Genomic DNA was extracted 3 days after nucleofection , sheared using a Covaris M220 focused ultrasonicator to an average size of 500 bp . The DNA was prepared and sequenced on an Illumina MiSeq and the resulting sequencing data analyzed using the standard pipeline 10 with a reduced gap penalty .	51934001	no
This data screening eliminated 1.4 % of the overall data . More than 272 million records of passenger movement through the MTR were considered valid . Passenger flow from time point A to time point B is defined as the number of passengers leaving the MTR station between A and B. To filter regular daily commutes from these movements , we defined consecutive round trips between the same two stations as regular commutes . We defined the pandemic and non - pandemic weeks to analyse the local travel behaviour during and before the COVID-19 pandemic . Between January 1 and March 31 , pandemic week ( March 25 to 31 ) is defined the week when the most weekly confirmed COVID-19 cases were reported . The non - pandemic week ( January 6 to 12 ) is a week without either holidays or any reported COVID-19 cases , and is regarded as a control group . We used the effective reproduction number R t ( Appendix A ) , to indicate the severity of virus transmission .	231880553	no
Finally , to confirm a stabilin - mediated mechanism of hepatic RES targeting , srLNPs were administered ( i.v . ) within established stab2 â/â KO mice . [ 87 ] Phenotypically normal stab2 â/â mice were specifically selected as stab1 â/â /stab2 â/â DKO mice suffer from premature mortality and develop severe glomerular fibrosis . [ 34 ] Therefore , we first confirmed the primary significance of stabilin-2 over stabilin-1 in the recognition and clearance of srLNPs , in single KO ( stab1 â/â or stab2 â/â ) mutant zebrafish embryos ( Figure S9 , Supporting Information ) , as was expected . [ 38 ] Following i.v . injection within stab2 â/â mice , srLNPs yielded an â80 % reduction in srLNP targeting to LSECs and an â50 % reduction in LSECspecific mRNA expression ( Figure 6h , i ) . By contrast , loss of stabilin-2 resulted in only a small targeting reduction to KCs ( which expresses stabilin-2 but likely involves other receptors in LNP recognition and uptake ) and had no significant effect on srLNP recognition and/or processing within hepatocytes ( which do not express stabilin-2 ) . Overall , these data not only confirmed the importance of stabilin receptors in the recognition and uptake of srLNPs within mammalian LSECs but , importantly , highlighted the translational and predictive potential of the embryonic zebrafish as an early stage in vivo screening platform for new LNP designs .	247129065	no
For the link prediction task , we also try to split the data in a different way and compare the performance of different models . Specifically , we randomly select 80 % of the observed links ( rather than nodes ) as the training set and use the others as the test set . The results are consistent with those for the original data - splitting method .	7037272	no
To study the effect of proteasome inhibition on osteoclast differentiation , osteoclast progenitors were differentiated into osteoclasts by culture with M - CSF and RANKL in the presence or absence of proteasome inhibitors MG132 and bortezomib . Proteasome inhibitors suppressed osteoclast differentiation in a dose - dependent manner , as indicated in the reduced number of tartrate - resistant acid phosphatase ( TRAP)-positive multinucleated cells ( Figure 1A , B ) . MG132 ( ranging from 0 to 150 nM ) and bortezomib ( ranging from 0 to 2 nM ) did not affect cell proliferation or cause apoptosis of osteoclast progenitors ( Figures S1 and S2 ) . M - CSF and RANKL are expressed on osteoblasts and their respective receptors , c - Fms and RANK , are expressed on the surfaces of osteoclasts . RANKL / RANK and M - CSF / c - Fms induce essential osteoclastogenic signalling . To explore the mechanisms underlying the suppressive effect of proteasome inhibitors on osteoclasts differentiation , we first analysed the expression levels of c - Fms and RANK in osteoclast progenitors exposed to proteasome inhibitors . The c - Fms protein level was significantly reduced after MG132 and bortezomib treatment , but that of RANK was not altered ( Figure 1C , D ) . These results suggest that the suppressive effect of proteasome inhibitors on osteoclast differentiation is a result of the downregulation of c - Fms . To definitively determine the mechanism underlying c - Fms downregulation mediated by proteasome inhibitors , it was necessary to define the optimal concentration and time for proteasome inhibitor treatment that resulted in the marked decrease or complete disappearance of c - Fms . In Figure 2A , B showing time - and concentration - dependent c - Fms downregulation by MG132 in osteoclast progenitors , c - Fms protein completely disappeared 4 h after treatment with 10 ÂµM MG132 and was not detected after treatment with 2.5 ÂµM or more concentrations of MG132 for 4 h. Thus , all of the other in vitro experiments were performed with MG132 treatment at a final concentration of 10 ÂµM for 8 h , which showed no significant cytotoxic effects ( Figure S3 ) . In contrast with the MG132 - induced reduction of c - Fms protein , the c - Fms mRNA expression did not change in response to MG132 ( Figure 2C ) . These data indicate that c - Fms downregulation by proteasome inhibition was a result of post - translational regulation . but that of RANK was not altered ( Figure 1C , D ) . These results suggest that the suppressive effect of proteasome inhibitors on osteoclast differentiation is a result of the downregulation of c - Fms . To definitively determine the mechanism underlying c - Fms downregulation mediated by proteasome inhibitors , it was necessary to define the optimal concentration and time for proteasome inhibitor treatment that resulted in the marked decrease or complete disappearance of c - Fms . In Figure 2A , B showing time - and concentration - dependent c - Fms downregulation by MG132 in osteoclast progenitors , c - Fms protein completely disappeared 4 h after treatment with 10 Î¼M MG132 and was not detected after treatment with 2.5 Î¼M or more concentrations of MG132 for 4 h. Thus , all of the other in vitro experiments were performed with MG132 treatment at a final concentration of 10 Î¼M for 8 h , which showed no significant cytotoxic effects ( Figure S3 ) . In contrast with the MG132 - induced reduction of c - Fms protein , the c - Fms mRNA expression did not change in response to MG132 ( Figure   2C ) . These data indicate that c - Fms downregulation by proteasome inhibition was a result of posttranslational regulation .    Figure 3B ) . These results clearly indicate that c - Fms degradation by MG132 is mediated by RIPping , and not through the lysosomal degradation pathway . RIPping of c - Fms has been reported to be associated with the MAPKs and PKC signalling pathways [ 7,10 ] . To assess the signalling pathways involved in c - Fms degradation by proteasome inhibitors , we next analysed the activities of MAPKs in response to MG132 . MG132 treatment resulted in the activation of all three MAPKs : ERK , JNK , and p38 ( Figure S4 ) . Using specific inhibitors , we showed that MG132 - induced c - Fms degradation via the RIPping process was suppressed by p38 inactivation , but not by the inactivation of ERK , JNK , PKCÎ± , and PKCÎ´ ( Figures 3C and S5 ) . To analyse the relationship between p38 and TACE activation in the MG132 - induced c - Fms RIPping process , osteoclast progenitors were treated with MG132 in the presence or absence of a specific p38 inhibitor , and the activity of TACE was measured . Inactivation of p38 suppressed MG132 - induced TACE activation ( Figure 3D ) . Together , these results indicate that c - Fms degradation by MG132 is mainly achieved through RIPping by activating p38 - mediated TACE signalling .	6154085	no
Reaction ( 1 ) represents intercalation of AlCl 4 â into polypyrene during its oxidation . [ 57 ] Reaction ( 2 ) shows electrodeposition of Al on the anode side . The charge - storage mechanism proposed in Reaction ( 1 ) assumes that the only active intercalant species is AlCl 4 â . As follows from X - ray photoelectron spectroscopy ( XPS ) measurements , intercalation of AlCl 4 â ions into polypyrene was evident from the appearance of both Al 2p and Cl 2p peaks after electrochemical charging ( Figure S4a , b , Supporting Information ) . Additionally , energydispersive X - ray spectroscopy ( EDX ) analysis of charged polypyrene electrodes revealed the appearance of Al KÎ± and Cl KÎ± peaks ( Figure S4c , d , Supporting Information ) . However , taking into account that chloroaluminate ionic liquid contains a mixture of AlCl 4 â , Al 2 Cl 7 â , and free Cl â ions , intercalation of all three ions into polypyrene network during charge is possible . Figure 2 shows the electrochemical performance of electrodes composed of pyrene and polypyrene as cathode materials in aluminum batteries at a high current density ( 200 mA g â1 ) . In the case of polypyrene , the capacity initially decreases , but then remains stable for 300 cycles at â70 mAh g â1 , which corresponds to more than half of the theoretical value based on a one - electron redox process at the pyrene unit ( 133 mAh g â1 , see calculations of theoretical capacity in the Supporting Information ) . Galvanostatic chargedischarge curves reveal that the storage capacity corresponds to a relatively high discharge voltage of â1.7 V ( Figure 2b ) . It has to be noted that electrochemical performance of polypyrene depends on the acidity of chloroaluminate ionic liquid ( molar ratio of AlCl 3 : [ EMIm]Cl ) . As electrochemical data indicate ( Figure S5 , Supporting Information ) , the optimal molar ratio of AlCl 3 : [ EMIm]Cl is â1.3 . In comparison to polypyrene , the performance of monomeric pyrene is quite poor . In particular , the initial discharge capacity of pyrene is only 20 mAh g â1 and decreases rapidly to â10 mAh g â1 in subsequent cycles . Such a Adv . Mater . 2018 , 30 , 1705644    Figure 2 . Electrochemical performance of aluminum batteries with pyrene and polypyrene as cathode materials : a ) capacity retention upon cycling and b ) corresponding charge - discharge voltage profiles for the 100th cycle . Cells were cycled at room temperature at a current density of 200 mA g â1 ( referring to the mass of the polymer ) in the potential range of 1.05 - 2.2 V. c ) Schematic representation of the structural differences between pyrene ( crystalline , e.g. , dense molecular packing ) and polypyrene ( amorphous , porous , and flexible ) , which impact their AlCl 4 â storage behavior .	205285014	no
In Italy , several researchers analyzed the relationship between COVID-19 pandemic and particulate pollution , starting from the observation that the course of the infection was very different throughout the country regions ( Setti et al . , 2020a;Setti et al . , 2020b ) . Several data highlighted the possible association between elevated concentration of air pollutants and the high spread of COVID-19 in northern Italian regions ( Coccia , 2020;Martelletti and Martelletti , 2020 ) . A first observational study based on initial epidemic diffusion reported a relationship between exceeding the legal limits of PM10 concentrations and the number COVID-19 cases ( Setti et al . , 2020a ) . The analysis showed a direct relation between COVID-19 cases and PM10 pollution concentrations , in agreement with the previous literature on other viral infections ( Setti et al . , 2020a ) . An analysis conducted by the University of Bergamo concluded that SARS - CoV-2 RNA might be present in PM , suggesting it as a possible indicator of epidemic recurrence ( Setti et al . , 2020b ) . Another study investigated the correlation between the degree of accelerated diffusion and lethality of COVID-19 and surface air pollution in the metropolitan area of Milan , the greatest city of northern Italy ( Zoran et al . , 2020 ) . The results showed that high levels of urban air pollution had a significant impact on increasing the rates of total cases of COVID-19 , new daily cases and total deaths ( Zoran et al . , 2020 ) . In particular , daily PM mean levels were reported to influence the number of COVID-19 cases . Furthermore , still in Milan the average temperature correlated positively , while the relative humidity negatively with cases of COVID-19 ( Zoran et al . , 2020 ) .	231689955	no
This angle should then be in the LSND range which can be easily accommodated by choosing Î´m eÂµ . Notice that such a small Î½ e -Î½ Âµ mixing can also generate a small mixing between the electron neutrino and the towers of sterile neutrinos associated with Î¨ Âµ,Ï , heavier than the one we have used to deplete the solar neutrino flux . Due to the large mass splitting between the lightest electron neutrino and the lowest mode of the heavy towers , such a small mixing can not be MSW - enhanced and consequently does not affect the solar neutrino phenomenology . However , it may give rise to a non - negligible contribution to the light electron neutrino mass . It is clear , that a parallel discussion can be carried out for L Âµ â L Ï breaking induced by bulk Majorana mass terms . However , the above example is sufficient to show that all oscillation data can be explained in terms of our model . We , therefore , will not carry this out explicitly .	5841186	no
In order to obtain deeper insight into the underlying binding energies ( BE ) and heights of the activation barriers , as et of quantum - chemical data was calculated . TheB E obtained from energy decomposition of the individual reactants ( Table S1 ) are in good agreement with the trends mentioned above . F or example : comparison of the BE of the leaving chlorido ligands resulted also in the order 5 % 4 > 6 > 1 ( in the case of 4 the weaker - bound chlorido ligand was considered ) . Furthermore , B Eo ft he ammine ligands in complex 1 , 2,a nd 7 were in line with the experimental data , although the BE of the acetato ligands are quite different . These results were also verified by extended transition state combined with natural orbitals for chemical valence ( ETS - NOCV ) [ 19 ] analysis and average local ionization potential ( ALIP ) maps . [ 20 ] Additionally , t he calculated heights of activation barrier of the hydrolysis ( Scheme S1 ) of the equatorial ligands correlate very well with the HPLC - MS experiments ( Table 1 ) . As summarized in Table 3 , the activation energies for the hydrolysis in the case of 3 and 4 are distinctly lower than those for 1 and 2.T his confirms that the higher s - donor properties of asecondary amine compared to simple NH 3 ligands are important for an accelerated reaction , which explains the differences observed in the HPLC - MS experiments . [ 21 ] Furthermore , a lso the second hydrolysis step DE(TS2 ) of 3,w here the monodentate - bound oxalate ligand is finally released , possesses ad istinctly lower activation barrier than that of 4 with two chlorido ligands;this is in exact agreement with the HPLC - MS studies ( Table 1 ) . Thec alculations in the case of 4 further revealed ahigher trans - effect of the CHA ligand compared to NH 3 explaining the two peaks observed with HPLC - MS.T his is in accordance with areport on the respective Pt II complex JM118 . [ 22 ] To test how the hydrolysis alters the chemical and biological properties , t he two derivatives of 3 were synthesized . This was achieved through incubation of 3 at pH 8 - 9 and 37 8 8Cand subsequent purification via preparative HPLC . Theh ydroxido ( 3a)a nd the dihydroxido ( 3b)s pecies were characterized by 1 Ha nd 13 CN MR , mass spectrometry , a nd  	78094888	no
Currently , prioritization of vaccines is usually based on a rigid stratification of age or occupation ( 34,50,53 ) , and set for the state or country as a whole . In contrast , our framework enables the design of flexible distribution strategies that are aware of the joint effects from mobility behaviors and demographic profiles , which can be tailored to local conditions . Moreover , our framework possesses the following two benefits . First , our method provides as meso - scale policy guidance by achieving a balance between effectiveness and ease of implementation . With awareness of heterogeneous risks faced by different CBGs , we can maximize the benefits to society with limited vaccination dosages . Meanwhile , because vaccine priorities are determined on the CBG level , people within the same CBG are not discriminated against , providing local administrations with greater flexibility in the actual vaccine roll - out . Second , our method is privacy - preserving . For both demographic features and mobility records , we only make use of aggregate data on the CBG level , without revealing any individual information , presenting only a minimal invasion of personal privacy . Therefore , our framework is not only theoretically informative , but also instructive for real - world practice .	244102867	no
First , while earlier review work ( Millar et al . , 2013 ) highlighted the research attention being paid to Boards , it also exposed the paucity of studies that have focused specifically on quality and safety ( as compared to broader measures of performance , including financial performance in US studies especially ) . Second , relatively few studies have explored Board competencies , focusing instead on the make - up of the Board ( for example , looking at size , composition and the concentration of clinical expertise ) and/or examining the processes through which Boards operate . Finally , extant empirical studies have largely been under - theorised , leaving unspecified the pathways or mechanisms through which Boards impact on patient care . This study focuses attention on these research gaps by exploring the relationships between ( self - assessed ) Board competencies and a raft of patient safety and quality of care measures . To enable these analytic tasks , we needed first to validate the data structure of the leading Board assessment tool e the Board Self - Assessment Questionnaire ( BSAQ ) .	4007096	no
"For years we 'd say to the CDC , where do trans women go , and they 'd say male , and we 'd be -that 's fucked up , because they 're not â¦ And it did change , so we sort of function as an informant . I think that 's part of our responsibility to the larger structure , to say , "" We know this better than you . "" You look at EHRs now in the next session everyone has to capture SOGI data , but for years , we did n't upgrade because we did n't have any place to put trans patients that felt even remotely respectful â¦ And now suddenly everyone has to have SOGI data , and being at risk of losing grants because you ca n't meet requirements because they ' re dumb ."	237292347	no
This reveals a paradox : on and off rates should be balanced for this case , since according to the titration data ( Figures 2C and 3C ) it is at the apparent non - specific K d . A possible resolution of this paradox is that there is quite strong binding cooperativity of clusters of HU on long DNAs , allowing rapid formation followed by strong stabilization of the bound complexes . Evidence for cooperativity of HU binding has been reported using FRET techniques even at HU : DNA molar ratios near 1:1 ( 12 ) . We are developing single - DNA - based tools for determination of binding cooperativity of DNA - bending proteins to test this hypothesis . On top of this there may be appreciable sequence - dependence of affinities and kinetics of HU - DNA binding and unbinding . We are studying other proteins to determine the generality of the ' on - off paradox ' ; we have already reported similar effects for HMG box proteins ( 32 ) as well as for the E. coli nucleoid protein Fis ( 54 ) .	2764235	no
The original dataset consisted of 46,769 individuals across 67 countries / territories , with nationally representative samples from 30 countries , convenience samples from 34 countries , and a combination of both sampling approaches from 3 countries . The present analysis comprised 45,772 individuals from 66 countries / territories ( Mean Age = 43.08 yrs , SD = 16.05 ; range : 18 - 100 years ; 51.95 % females ) . 833 individuals ( all from Taiwan ) were excluded from the present analysis due to missing HDI data . In addition , data from 139 individuals were not included as they reported gender as ' other ' , and we did not have sufficient statistical power to analyze this category across countries .	237246535	maybe
For Figure 2 , filament angles were calculated using first the RidgeDetection plug - in from ImageJ ( https://zenodo.org/badge/latestdoi/18649/thorstenwagner/ij-ridgedetection ) that is based on the ridge / line detection algorithm by Steger . [ 8 ] The settings used were : line width ' 1.5 ' , high Contrast ' 300 ' , low contrast ' 100 ' and method for overlap resolution : ' slope ' . The coordinates for the traced filaments were then exported to MATLAB via the ImageJ ROI tool for further automated analysis . We ( 1 ) calculated filament angles with respect to the GUV axis ( Figure S7 ) and assigned whether they were positioned in the ' neck ' region of the elongated GUV or not ( Figure 2b ; this region was manually defined around trap feature using the bright field image ) and ( 2 ) analysed filament lengths and plotted the distribution of filament lengths for trapped ( elongated ) and released ( spherical ) vesicles ( Figure 2 g ) . Calculation of relaxation times ( Figure 2c ; S8a ) was done manually by counting frames between trapping / releasing GUVs and complete resolution of FtsZ filaments or rings / protrusions . Filament and ring detection in experiments with non - trapped vesicles ( Figure S9 ) was done by collecting Z - stacks images from different positions selected in a tile image of the whole sample well . Z - stack spacing 2 Âµm was selected to optimize the vesicle visualization . The same procedure is repeated after the addition of the higher osmolarity fresh buffer to deflate the vesicles . Addition of new buffer involves a vesicle movement that makes difficult to track single vesicle state before and after the osmotic change . Filament and Ring detection was done manually using ImageJ. Further data analysis was done using MATLAB and Excel .	220908687	no
Although we are aware of the many promising digital technologies available today to fuel epidemic management in the healthcare ecosystem , we decided to restrict our analysis to the following technologies : Internet of Things , big data analytics and artificial intelligence .	234046079	no
The synthesized beam sizes ( spatial resolution ) of the data obtained on August 20 and 30 , 2016 were â¼ 0 . â²â² 9 Ã 0 . â²â² 7 and 0 . â²â² 7 Ã 0 . â²â² 4 , respectively . The total on - source time at each epoch was about 19 min . The visibility data were imaged using task CLEAN of the Common Astronomy Software Applications ( CASA 4.7.0;McMullin et al . 2007 ) with a cell of 0 . â²â² 12 , natural weighting and channel width of 23.44 MHz ( â¼80 and 70 km s â1 in the lower and upper receiver sidebands , respectively ) . We run CLEAN with a taper parameter of 1 â²â² to reduce noise fluctuations . To identify emission lines , we created intensity maps by sequentially averaging five nearby frequency channels of data cubes . Each map covered â¼400 km s â1 , which is the typical widths of the CO lines detected from the host galaxies of high - redshift quasars ( Wang et al . 2010 ) . The maps were calculated using CASA task IMMOMENTS with MOMENTS=-1 . We checked the maps for emission peaks with signal - to - noise ratios ( SNRs ) > 3 at the expected frequency range of either CO(6 - 5 ) or CO(7 - 6 ) . We then searched for the corresponding emission line regardless the SNR of the latter .	195820710	no
There was no significant correlation between passenger volume changes before and during the pandemic and the daily passenger volumes of the MTR station on weekdays , whilst a significant correlation ( p = 0.027 ) was observed on the weekend before and during the pandemic . This implies that Hong Kong citizens intentionally avoided going to densely crowded public places during the COVID-19 pandemic ( Fig . 4a ) . In the pandemic week , there was a greater reduction in MTR use at the weekend than for weekdays , however , the correlation was not very significant ( p = 0.082 ) . No such trend was seen before the pandemic ( Fig . 4b ) . The number of passengers at Quarry Bay station during the pandemic week , a business district , decreased by approximately 68 % compared to that of the non - pandemic week ( Fig . 4b ) . In the nonpandemic week , the borders and amusement areas have 10%-70 % more visitors on Sunday than during the rest of week . The detailed spatial distribution of daily MTR ridership is shown in Fig . S6 . Fig . 5 shows that the modularity of the MTR network and the proportion of the population flow within communities on weekends are both higher than those on weekdays , with the exception of the CNY holiday . These data suggest that people travelled more locally ( within communities ) on weekends . After CNY , both figures tended to decrease overall , possibly suggesting that increasing awareness of the pandemic led people to reduce unnecessary travel , whilst daily commutes for work , which normally occur across communities , were not heavily influenced . The detailed network information is found in Fig . S5 .	231880553	no
Similarly , we applied DeepTACT to identify true interactions from all candidate promoter - enhancer ( P - E ) pairs derived from the PCHi - C dataset of B cells , yielding a Deep - TACT P - E group of 8960 promoter - enhancer interactions . Again , we found that the promoter and enhancer of a predicted interaction pair are more likely to be co - opening than those of other candidate interaction pairs ( Supplementary Figure S3B ) . As in the analysis of P - P interactions , we generated a co - opening P - E group , a candidate P - E group and a random P - E group as controls . We calculated the overlaps between interactions of each group and interactions derived from ChIA - PET data or eQTLs . We found that interactions predicted by DeepTACT were supported by the databases significantly more often than interactions of the other groups ( Figure 4A ; P values < 2.2 Ã 10 â16 , onesided Wilcoxon rank - sum tests ) , this again indicating that inferred interactions were more biologically significant than interactions derived based on chromatin accessibility or directly derived from PCHi - C data . Studies have shown that genes regulated by distal enhancers tend to have higher expression level ( 40 ) . Here , we asked whether genes with distal enhancers defined by interactions in the DeepTACT P - E group tended to have higher expression levels than those defined by the co - opening P - E group or the candidate P - E group . We collected four RNAseq replicates of B cells from ENCODE ( 41 ) , and used transcripts per million ( TPM ) to value gene expression level . We compared the expression level of regulated genes defined by different P - E groups . As shown in Figure 4B , regulated genes defined by DeepTACT tend to have significantly higher expression level than those defined by co - opening P - E interactions or candidate interactions ( P values < 0.005 , one - sided Wilcoxon rank - sum tests ) , indicating promoter - enhancer interactions inferred by DeepTACT are more related to gene expression than those derived based on chromatin accessibility or directly derived from PCHi - C data .	76660369	no
"Strengths of our study include the thorough randomised , placebo controlled design of the individual included trials , the large number of trial participants for whom data on ischaemic and haemorrhagic stroke were available , and our adherence to the standardised guidelines on the reporting of systematic reviews according to the PRISMA statement . 21 The following limitations of our meta - analysis should be considered . First , we decided a priori to include only trials that investigated the effect of "" pure "" vitamin E supplements on stroke and excluded those using fixed antioxidant vitamin combinations or multivitamins . 28 Trials of combinations preclude conclusions regarding the sole effect of vitamin E , since interactions between single components can not be predicted ."	20199155	no
Different types of analysis can be used to explore stock volatility . Uncertainty analysis models consider that dependent variables are affected by exogeneous variables under certain sets of assumptions in an output model ( Saltelli et al . , 2008 ) . Sensitivity analysis and scenario analyses are generally carried out to examine the effect of uncertain factors . However , these methods bring difficulties in calculating the probability of outputs when all inputs vary at the same time . Indeed , neither sensitivity nor scenario analysis can determine the likelihood of stock price which falls between the extreme points ( Brealey et al . , 2011 ) . Further , they produce only single - point estimate results and could give inaccurate outcomes , particularly in high uncertainty contexts and when using historical data to predict the future stock price . Alternatively , Atsalakis et al . ( 2020 ) use a quantile approach to explore the effect of natural disasters and economic indicators .	236254989	no
The ubiquitination profile of Tau4RD protein obtained in ubiquitination assays in the presence or absence of full - length HSc70 was obtained by mass analysis of protein fragments after trypsin digestion . SDS - PAGE bands corresponding to ubiquitinated Tau were excised and subjected to reduction with TCEP , alkylation with methyl methanethiosulfonate ( MMTS ) , and in - gel trypsin digestion . LC - MS / MS analysis was carried out using a nano- Gly - Gly modification of lysine residues ( indicative of a ubiquitination site ) and the oxidation of methionine residues were set as variable modifications , while methylthio - cysteine was set as fixed modification . Data were filtered using a False Discovery Rate â¤ 0.01 both at the protein and peptide level . The results of the MS analysis are reported in MS_ubTau_minusHSC70.xlsx and MS_ubTau_plusHSC70.xlsx files . Due to the partially stochastic nature of the data dependent acquisition mode applied in the analysis , there is the possibility that some of the ubiquitination sites identified in Tau protein ubiquitinated either in the presence or absence of Hsc70 might be missing in the other sample simply because the parent ion was not selected for fragmentation or because MS / MS spectra were of too low quality to pass the filtering criteria . To consider this possibility the extracted ion chromatograms relative to the ubiquitinated peptides that were identified in only one sample ( incubated with or without Hsc70 ) were used to assess the presence / absence of the same modified peptides in the other sample ( supplementary_MSdata ) .	246475137	yes
Overall , the main benefits resulting from the use of an intervention cookstove amongst Malawian households are through time savings achieved on the basic household tasks of fuel collection and cooking , see Table 4 . Table 6 presents three interpretations of the financial gain from the time savings . Depending on the approach to shadow pricing outlined in the methods section , the benefits range from $ 0 to $ 127 per year . As all respondents cited time saved was used in domestic activities , and not income generation , the first method does not result in a monetary benefit for time saved . The second method assumes that 25 % of time saved can be converted to income generation based on GNI . Using Malawi 's GNI per capita MWK170 , 625    Table 5 suggest the intervention cost $ 227 per household , with stoves and pots lasting between 2 and 5 years depending on intensity of use and attention to repair and maintenance . Compare this to a possible indirect benefito fu pt o$ 1 2 7 ( Table 6 ) per year in non - health related benefits . If the CAPS trial had shown there to be an effect on pneumonia we would also be able to present here possible direct health care savings . During interviews , a minority of households reported a decrease in household symptoms of common smoke - related illnesses with use of the stove . These perceptions were supported by clinical trial data which showed that the effect on pneumonia was non - significant .	4701798	no
A sensing platform for monitoring patients ' conditions and strategies for therapeutic neuromodulation are needed to rehabilitate patients who suffer from neurological disorders . [ 44 ] For an ideal treatment with respect to pathology , it is necessary to find the exact lesions contributing to a neurodegenerative disease with pinpoint stimuli in the same area . However , the conventional monofunctional device simply has one function of neural sensing or stimulation ; therefore , extra supplementary equipment for integrated drug delivery , optoelectronics , and an electrode array for electrical activation are necessary , as shown in Figure 2f . Furthermore , the supporting equipment creates a complicated experimental environment due to the external wire connections , thereby contaminating biological data with user discomfort . The separation of sensing and stimulating devices also requires a calibration process that adjusts the time difference between them . Thus , it is impossible to create a closed loop ( feedback system ) that applies to the stimulation at the exact time . The decrease in spatial resolution also originated from the positional difference between the sensing site and the modulating point . Accordingly , neuronal activity inhibition or excitement occurs in an unwanted area , and not where the electrophysiological signals are acquired . Consequently , this	235242145	no
The drastic reduction of human activity has reduced the level of air pollution depending upon the efficacy of lockdown . It suggests that by adhering to sustainable transport plans and policies , air pollution in the urban environment could be minimized to a certain extent . The periodic and temporary lockdown ( e.g. , odd / even transport scheme ) can also be implemented in polluted cities if no other alternatives found appropriate . The Stringency index , Containment and Health index demonstrated that the efficacy of lockdown could be adopted on a city scale at least a day during the weekend to decrease air pollutions without compromising economic progress . The analysis also suggests that the intersection of urban design , health , nature , and environment should be promoted by policy - makers in the city environment to safeguard public health , societal well - being , and clean air ecosystem services . The existing clean air policies have been successful to minimize air pollutions in highly polluted cities . Besides those policies , emerging urban policies ( i. e. core services , public spaces , urban design , city - level geospatial data , etc . ) could be adopted to build urban resilience against any future pandemics and emergencies .	235382144	no
On the other hand , the application of Backfeed , and in fact any similar system of evaluation , poses certain challenges to the internal relations in productive communities , related to trust , reciprocity and intrinsic motives . Moreover , the technology is still at a very early stage and more empirical data are necessary to support its real life application . More generally , there are well - justified doubts on the extent that the blockchain can help communities solve issues concerning power and influence . At the same time , with the technology yet to reach a dominant design , it is too early to predict how it could operate on large scale . In any case , regardless of the development of blockchain technology or the eventual success of Backfeed as a project , its conceptual model allegedly presents an interesting scenario for the sharing economy and the role the latter can play in societies .	3655015	no
The motivation for this study was to quantify plastic material flows to help inform material supply risks within the South African economy pre - and during the COVID-19 pandemic . The focus was not on cradleto - grave life cycle impacts of products . MFA was selected as the most common method to map resource flows and optimise resource management ( Montangero , 2007 ) . It allows wastes to be monitored , the efficiency of the use of material resources and material flow management within a defined system and boundary to be evaluated and material supply risks to be assessed . MFA can contribute into life cycle assessment by providing an in - depth snapshot in time of the material inventory . In this study the mass flows of COVID-19 related PPE were evaluated during the 2020 pandemic , and also plastics for the reference year of 2019 within the system boundaries of production , procurement , consumption , imports , exports and waste management in South Africa , using the MFA approach . The reference year 2019 for the plastic flow was selected for analysis on the basis that it had the most recent reported material flow data before the advent of the COVID-19 pandemic .	236362437	no
We start from the observation that , while the Gramians are expensive to recompute at each iteration , we can maintain PSD estimatesÄ u , Ä v of the true Gramians G u ( Î¸ ) , G v ( Î¸ ) , Algorithm 1 SAGram ( Stochastic Average Gramian ) 1 : Input : Training data { ( x i , y i , s i ) } iâ{1, ... ,n } , learning rate Î· > 0 . 2 : Initialization phase 3 :	49881601	no
Other strengths of the study included the use of a large sample of unselected patients with newly diagnosed type 2 diabetes and the long follow - up period , with regularly recorded diagnostic , measures , and outcome codes . Prescription data were accurately captured by using the same database software as that used to generate prescriptions by general practitioners . These results , therefore , reflect true associations in the real world setting . Furthermore , our analyses were adjusted for several baseline characteristics that could plausibly be related to treatment or mortality .	2042823	no
"We report in Figure 5 the measured mobilities for the different molecules in the set , and compare them with a full calculation of the mobility using transient localization theory , [ 15 ] based on the parameters in Tables S5 and S7 , Supporting Information . For the experimental values we have selected the most reliable [ 44,45 ] reported mobilities based on robust four - point - probe measurements and further validated by Hall effect measurements ( see Table S3 , Supporting Information ) , which was possible for all compounds except BTBT , due to its high contact resistance . For the theoretical mobilities we show values calculated along the highest mobility direction , taking into account both off - diagonal and diagonal energetic disorder ( Experimental Section ) . The data show a good correlation with the experiments , especially considering the large / known / documented sample - to - sample variability characterizing OSCs . Quite expectedly the actual experimental values are lower than predicted , because the calculations disregard extrinsic effects that limit the experimentally achievable mobility values , such as contact resistance limitations , chemical impurities , and structural defects . C8 - BTBT - C8 singles out as having a mobility that is higher than the main trend , actually very close to the theoretical value ; this may be because this molecule is known to have self - assembling , liquid crystalline properties , which facilitate growth of thin films with a very low number of extrinsic defects . [ 46][47][48 ] Also , as mentioned above , our simulations do not take into account the dispersion of phonon frequencies away from the Brillouin zone center , in particular , the effect of the zone boundary phonon that involves a sliding motion of the a molecular pair , this is expected to increase the amount of disorder , hence lowering further the theoretically predicted values as recently reported . [ 31,32,49 ] We can now understand how the effects of the structure on the intermolecular vibrations and thermal disorder are ultimately reflected in the mobility of the materials . Based on the transfer integrals alone , alkylation of DNTT should therefore boost the mobility by a factor of 2.5 : in DNTT the combination of J x has the wrong sign , while it becomes ideally isotropic in alkylated DNTT . [ 15 ] However , the enhancement of thermal disorder by the long - axis sliding "" killer "" mode is so strong that it cancels much of this expected gain ; as a result alkylated DNTT is predicted to have only about 30 % higher mobility than DNTT , which is consistent with experimental observations on single crystals . An analogous compensation is predicted for the other pair of molecules , BTBT and C8 - BTBT - C8 . Following the same line of reasoning , the exceptionally high mobility value of rubrene can be attributed to its small energetic disorder due to its reduced sensitivity to the long - axis sliding motion , which compensates for its unfavorable anisotropic transfer integrals ."	85518403	no
We then prove if condition ( 139 ) holds , then every data point on G : = âª r k=1 ( â¦ * k \ S k ) is correctly classified . From Eqn.(137 ):	173991089	no
GANs transform white noise through a deep neural network to generate candidate samples from a data distribution . A discriminator learns , in a supervised manner , how to tune its parameters so as to correctly classify whether a given sample has come from the generator or the true data distribution . Meanwhile , the generator updates its parameters so as to fool the discriminator . As long as the generator has sufficient capacity , it can approximate the CDF inverse - CDF composition required to sample from a data distribution of interest . Since convolutional neural networks by design provide reasonable metrics over images ( unlike , for instance , Gaussian likelihoods ) , GANs using convolutional neural networks can in turn provide a compelling implicit distribution over images .	6221084	no
Policy information about availability of data All manuscripts must include a data availability statement . This statement should provide the following information , where applicable :	235609133	maybe
Implementation Details . Following the framework in [ 27 ] , for training , we crop a 384 Ã 288 bounding box around each person and use it as input to our model . During training , we use ground truth person bounding boxes . We also employ random rotations , scaling , and horizontal flipping to augment the data . To learn the network , we use the Adam optimizer [ 54 ] with a base learning rate of 10 â4 , which is reduced to 10 â5 and 10 â6 after 10 , and 15 epochs , respectively . The training is performed using 4 Tesla M40 GPUs , and is terminated after 20 epochs . We initialize our model with a HRNet - W48 [ 27 ] pretrained for a COCO keypoint estimation task . To train the deformable warping module , we select Frame B , with a random time - gap Î´ â [ â3 , 3 ] relative to Frame A. To compute features relating the two frames , we use twenty 3 Ã 3 residual blocks each with 128 channels . Even though this seems like many convolutional layers , due to a small number of channels in each layer , this amounts to only 5.8 M parameters ( compared to 39 M required to compute optical flow in [ 29 ] ) . To compute the offsets o ( d ) , we use five 3 Ã 3 convolutional layers , each using a different dilation rate ( d = 3 , 6 , 12 , 18 , 24 ) . To resample the pose heatmap f B , we employ five 3 Ã 3 deformable convolutional layers , each applied to one of the five predicted offset maps o ( d ) . The five deformable convolution layers too employ different dilation rates of 3 , 6 , 12 , 18 , 24 . During testing , we follow the same two - stage framework used in [ 27,23 ] : first , we detect the bounding boxes for each person in the image using the detector in [ 48 ] , and then feed the cropped images to our pose estimation model .	182952684	no
To generate a NuSTAR spectrum for XTE J1810â197 , we analyzed data separately from the five available star tracker configurations for this observation , to allow for a noticeable â¼2 â² shift in the source location on the focal plane , periodic on an orbit timescale . However , these star tracker configurations break each orbit into five pieces , adjacent in time , and the drift is not noticeable over these relatively short intervals . Thus , we computed the source centroid on a per orbit , per star tracker configuration basis , to center the extraction region based on the drift . This allows us to use a smaller extraction aperture of 0 . â² 75 radius as compared to the 2 â² radius of our previous analysis ( Gotthelf et al . 2018 ) , greatly reducing the relative background contribution in the source aperture at higher energies .	119354518	no
"Beyond converting between data formats , there are efforts to address semantic interoperability , for example , linking data entities with different names and the same meaning . An even more difficult problem is to map relationships between data entities into different representations . It remains an open challenge for the materials modeling domain due to the high heterogeneity , variety , complexity , and dynamics of materials . [ 80 ] Currently , the EMMC ( European Materials Modeling Council -www.emmc.info ) makes efforts to develop a materials ontology that can help different programs to "" understand "" the data scheme of input data from a large variety of sources , both simulation and experimental characterization of materials . [ 9 ] In the future , such an ontology can give rise to domain - specific languages for data in materials science , similar to , for instance , the chemical markup language developed in the past . [ 81 ] In this context , a notable standardization effort that is worth mentioning is the OPTIMADE consortium ( www.optimade . org ) . OPTIMADE involves more than ten of the major materials databases worldwide and is open to further participants . The consortium has developed a standard REST API specification [ 82 ] to allow to query and extract crystal structures and related metadata from any server using the same syntax , and is actively working to further extend the specifications to more data types that are relevant in materials science ( like moleculardynamics trajectories and computer simulations , for instance ) ."	245315824	maybe
The identified technologies were classified based on the following aspect of data and data management : ( 1 ) security ; ( 2 ) destruction ; ( 3 ) voluntary access ; ( 4 ) time span ; and ( 5 ) storage . In addition , in order to understand how these technologies can affect user privacy , we identified 25 data points that these technologies could have access to if installed through mobile applications .	233029680	maybe
Our second approach used modelled injury rates , assuming the rates of cycle hire injury were the same as for cycling in general in the cycle hire zone between 2005 and 2011 . For the numerators we used routinely collected police data 32 to identify the number of men and women aged 16 - 60 who were killed , seriously injured , or slightly injured in road collisions in the cycle hire zone . To these we added additional non - intentional fatalities and major injuries on London 's public transport . 23 For the denominators we estimated total travel time by each mode for men and women aged 16 - 60 travelling within the cycle hire zone . 24 27 We then used scaling factors to estimate risks for different age groups and to capture , for example , the observation that the risks of injuries from cycling increase with age . 34 To have samples large enough to produce reliable estimates at the oldest age groups ( see tables 21 - 22 in appendix 3 ) , we created these scaling factors using data from the Netherlands for 2002 - 09 . 35 The shape of the age associations was similar to those reported for London 36 and the United Kingdom . 34 In both approaches we applied London specific scaling factors to account for under - reporting of injuries to the police . 25 We then estimated the number of deaths , serious and slight injuries that would be expected among cycle hire users in the past year , and also the number that would be expected to be averted by reductions in times spent in other modes . We converted these to estimates of DALYs and premature deaths .	11392397	no
Low - rank Matrix Regression . Low - rank matrix regression is similar to sparse estimation as presented above except that each data point is now a matrix i.e. X i â R p 1 Ãp 2 , the goal being to estimate a low - rank matrix W â R p 1 Ãp 2 that minimizes the empirical loss function on the given data .	1162245	no
The curvaton scenario can lead to non - gaussianity , and also to isocurvature perturbations which are generated by the curvaton field and hence are fully correlated with the curvature perturbation ( residual isocurvature perturbations ) . Whether these are possible depends on the fraction r , that the curvaton contributes to the energy density by the time that it decays . The regime r < 10 â2 is forbidden , because it gives non - gaussianity above the level permitted by present WMAP data . In the regime 10 â2 < r âª 1 there is significant non - gaussianity , which can be detected by by the PLANCK satellite or even by future WMAP data . On the other hand , isocurvature matter perturbations in this regime are either zero ( if the matter is created after curvaton decay ) or else bigger than is allowed by observation .	15522732	no
When there is undesirable output ( CO 2 ) , the DEA data domain can be expressed as follows ( Seiford and Zhu , 2002 ):	158288388	no
Cell Staining and Viability Calculation : Printed tissues were incubated with 2.5 ÂµM calcein - AM ( Cambridge Biosciences Ltd ) and 5.0 ÂµM propidium iodide ( Sigma Aldrich ) for 30 min before imaging . Four randomly selected fields of each printed network at different z - heights were imaged with â30Ã magnification by using fluorescence confocal microscopy ( Leica SP5 ) . Dead cells were counted manually due to their low number . Live cells were counted using Fiji [ 36 ] by setting a threshold that matches the Calcein AM ( CAM ) fluorescence of the live cells , followed by particle analysis ( size setting : 2 micron 2 -Infinity ) . The cell number of clusters of cells was determined by using the area of a cluster divided by the area of an average cell . The live / dead cell numbers from the four images of one sample were averaged to give each data point and five samples were used to determine the viability as shown in Figure 2c ( n = 5 ) .	219704613	no
In this paper , we have applied data from various sources . A detailed list of the variables , their definitions and sources is provided in Table 1 . Our dataset , including daily price indices , daily trading volumes and the daily CBOE VIX index cover the period 1 July 2019 to 14 August 2020 . We have collected these capital market , resilience and macroeconomic data for 34 economies based on the data availability and comprehensiveness of the market . A description of our sample by country is presented in Table 2 . There are an equal number of observations for each country and thus we have a balanced panel .	233547943	yes
Despite our fundamental need for mastering the interfacial processes in battery technologies , up until now researchers still overwhelmingly rely on an array of data / information to build a posteriori a coherent picture regarding battery interfaces , where the investigative power of each technique is largely hampered by their inherent limitations . From a chemical point of view , the identification of major species has proved difficult and has given rise to many controversies , mainly due to the low thickness of the SEI and its extreme sensitivity to air and/or impurities . Indeed , the majority of SEI studies are based on ex situ characterization protocols involving cell manipulation in an inert atmosphere ( glove box ) , transfer vessels , and specific washing processes , all of which tend to contaminate the sample , thus limiting useful data acquisition . Additionally , most of the laboratory characterization techniques employed , either post mortem or operando , lack the time resolution necessary to study events associated with the charge transfer at the interface , and instead probe the interphase that grows upon reactivity of the electrode with the electrolyte . In contrast , electrochemistry is the technique of choice to quantify charge transfer at interfaces but by itself is chemistry blind when not associated with the use of model electrodes or coupled with complementary physical characterizations . Hence , simultaneously visualizing both electron and ion dynamics still presents a major experimental challenge . From a theoretical point of view , the advent of computational approaches , such as density functional theory ( DFT ) or molecular dynamics ( MD ) , critically widened the scope of possibilities to comprehend phenomena at the atomic or electronic level . However , DFT calculations suffer from the large computing cost associated with the introduction of explicit electrolyte or interphase components , whereas classical MD simulations so far lacked the inclusion of charge transfer . Finally , the dynamics of the solid interphases under external stimuli such as cycling , temperature , etc . over prolonged operational periods is still poorly characterized , hindering our ability to predict battery performance based on our understanding of the interfacial charge transfer or the chemical / physical properties of the solid interphases . To overcome these limitations , the development of a continuum model is indispensable .	245338204	no
Survival curves , obtained using the Kaplan - Meier method , were first used to compare the cumulative death rate between 26 and 60 years for those in the most socio - economically disadvantaged groups in childhood and adulthood with the rate for the most advantaged group . Cox 's proportional hazards models were used to investigate the relationships between socio - economic conditions and adult mortality rates in the whole sample , and in men and women separately . Those with missing data were included as a separate group but were excluded in the analyses stratified by sex because of the small number of deaths in these groups . In all analyses , the highest socio - economic group was taken as reference . The proportional hazards assumption was checked . Follow - up time ( in months ) was from the cohort 's 26th birthday until the first of death , emigration , or the end of March 2006 , the cohort 's 60th birthday . If death had not occurred , follow - up was treated as censored . For adult socio - economic indicators , the most recent measure recorded for each individual before death or censoring occurred was used in analyses .	5719675	no
To further evaluate the apparent fit between SARS - CoV-2 RNA concentrations in wastewater and the COVID-19 cases in the city of Porto , simple linear regressions were performed ( Fig . 5 ) . We found significant positive relationships between the SARS - CoV-2 copy numbers and the weekly moving average of COVID-19 cases in both phases of both WWTPs . Similar relationships have been observed in previous studies in different world regions during the current pandemic ( Medema et al . , 2020;Peccia et al . , 2020 ) . The strongest associations were found in the liquid phase , especially in the Freixo WWTP , where 42 % of the variation in the data was explained by this linear relationship . However , no substantial differences were observed between the WWTPs , when compared to the differences associated with the different phases . The lowest correlation observed in the solid phase , when compared to the liquid phase , may be explained by the large variation observed over time in the total suspended solids of the untreated wastewater analyzed ( Table 1 ) .	235612903	no
The modified insulin suppression test is a clinically important direct measure of peripheral insulin resistance but is expensive , laborintensive , and requires six hours . The two - hour OGTT is a sensitive test for diabetes and is less expensive , but still inconvenient . Thus , we evaluated how well multi - omics measurements could predict the results of these tests . Using a Bayesian network algorithm , we first identified highly predictive features followed by ridge regression modeling using these features 25,26 . The SSPG prediction model using all omes achieved a cross - validated R 2 of 0.87 ( final model mean square error ( MSE ) 0.16 ) compared to an R 2 of 0.59 ( MSE 0.55 ) using clinical data only ( Fig . 3f , Table S20 ) . We also compared predictive models using clinical data plus each single ome and found that the transcriptome ( R 2 0.88 , MSE 0.15 ) , metabolome ( R 2 0.80 , MSE 0.31 ) and microbiome models ( R 2 0.78 , MSE 0.26 ) had the best predictive accuracy for SSPG . Similarly , the multi - omic prediction model for OGTT ( R 2 0.71 , MSE 0.24 ) was superior to the clinical data only model ( R 2 0.42 , MSE 0.71 ) ( Fig . 3f , Table S21 ) . The transcriptome had the best predictive accuracy of the single ome models ( R 2 0.62 , MSE 0.30 ) . Molecules that were found to be consistent across multiple SSPG models included the TGL / HDL ( high - density lipoprotein ) ratio , the protein IL-1RAP ; the lipid Hexosylceramide ( HCER)(24:0 ) , the MAP3K19 transcript and a Ruminococcaceae family microbe . The relationship between insulin resistance and TGL / HDL ratio has already been described 27 and other measures are emerging [ 28][29][30 ] . There was little overlap between SSPG and OGTT predictors supporting that these measures reflect different underlying biology . The increased predictive performance with multi - omics measurements compared to clinical labs alone illustrates the benefit of multi - omics data .	148568585	no
â¢ P.7 - The authors claim that the SSIs took 20 - 30 minutes ; how was this determined ? Are there data available to determine the mean / median duration of each SSI ?	242291039	no
Our experimental results are further supported by theoretical calculations ( see Section 10 , Supporting Information ) , elucidating that the ZnQ guest molecule could adopt different geometrical configurations under pore confinement . Figure 3a shows the optimized structure of ZnQ with two    [ 17 ] of the OX-1 crystal structure incorporating NEt 3 + charge - balancing cations ( R wp = 0.084 ) , and crystallographic view along the c - axis showing 1D porosity ( inset ) . Color scheme : zinc in yellow , nitrogen in blue , oxygen in red , carbon in gray , and hydrogen in white . The traces indicate data as follows : red : experimental data , blue : calculated from structural refinement , and green : observed Bragg peak positions . b ) PXRD of nanosheets , with and without confinement of the ZnQ guest molecules , compared with the simulated diffraction pattern from ref . [ 15 ] Asterisks mark the positions of the ZnQ peaks . c ) Undulating pore architecture of 1D channels along c - axis , solvent accessible volume is denoted by yellow surfaces . d ) Emission tests under 365 nm UV irradiation , for sample 1 : pristine OX-1 nanosheets without ZnQ is nonemissive ; 2 : ZnQ DMF @OX-1 ; and 3 : ZnQ DMA @OX-1 , are optically active . e ) UV - vis electronic absorption spectra of the OX-1 host framework , ZnQ guest emitter , and guest@OX-1 composite systems . Inset depicts conformational changes of the neat ZnQ guest emitter molecule , after losing two DMA coordinated solvent molecules from its axial positions . f ) Band gap values determined from diffuse reflectance spectra and photon energy intercepts , signifying host - guest interactions . g ) Raman spectra revealing intensity and peak alterations arising from the host - guest confinement effects .	24851754	no
Background . Popular recommendation systems such as collaborative filtering are based on a partially observed ratings matrix . The underlying hypothesis is that the true / latent score matrix is lowrank and we observe its partial , noisy version . Therefore , matrix completion algorithms are used for learning , cf . [ 8,14,15,20 ] . In reality , however , observed preference data is not just scores . For example , clicking one of the many choices while browsing provides partial order between clicked choice versus other choices . Further , scores do convey ordinal information as well , e.g. score of 4 for paper A and score of 7 for paper B by a reviewer suggests ordering B > A. Similar motivations led Samuelson to propose the Axiom of revealed preference [ 21 ] as the model for rational behavior . In a nutshell , it states that consumers have latent order of all objects , and the revealed preferences through actions / choices are consistent with this order . If indeed all consumers had identical ordering , then learning preference from partial preferences is effectively the question of sorting .	14368114	no
Conversely , hepatic pro - inflammatory cytokines , such as Il-6 , Il-1Î² , Ifn - Î³ , and Tnf - Î± , were significantly reduced in CCR5 - deficient obese mice ( Figure S2 ) . Expression of STAT3 activators , such as IL-6 and granulocyte - colony stimulating factor ( G - CSF ) , is significantly elevated in the NAFLD microenvironment . Theoretically , CM prepared from fatty livers should capture these cytokines and mediate STAT3 responses . Indeed , our unbiased ex vivo liver - CM system , inspired by Male 's group [ 41 ] , recaptured a similar CCR5 - KO phenotype described above in primary hepatocytes under the NAFLD microenvironment . Most importantly , we showed that CCR5 modulated hepatic lipid metabolism by regulating STAT3 signal transduction . Interestingly , while the role of STAT3 signaling was described in several liver diseases [ 42 ] , the impact of direct STAT3 down - regulation in primary hepatocytes is still undefined so far . Our results provide a glimpse of the relationship between STAT3 signaling and lipogenic gene expression in hepatocytes . Our data also suggest that CCR5 signaling may indirectly regulate STAT3 protein expression and phosphorylation in hepatocytes . A previous report showing that the blockade of CCR5 inhibits the IL-6 - STAT3 pathway via up - regulating suppressor of cytokine signaling 3 ( SOCS3 ) [ 43 ] is consistent with an indirect role of CCR5 in STAT3 regulation . Regardless , STAT3 signaling may be critical in connecting g - MDSCs and hepatocytes during NAFLD progression .	253213492	no
"The test set accuracy on the synthetic data is â94 % , while on the real experimental data which was not used for training , we obtain an accuracy of 86 % , that is , 91 of 106 samples were classified correctly ( see Supporting Information for further discussion ) . All wrong classifications were pure phases which the CNN model predicted as mixed . All CNN predictions are associated to a classification ( un)certainty , which can be used in a semi - autonomous system to decide if manual post - processing and analysis is required . Furthermore , we used SHAP analysis to generate intuitive insights into the predictions of the neural network . [ 88 ] A second machine learning model ( logistic regression ) was trained on the 106 experimentally measured data points with only the HEO compositions plus logical "" and "" combinations of the compositions as an input . Analysis of the logistic regression coefficients shows the importance and influence of the input features with respect to the prediction ."	237495418	no
It is important to note that we only examined deaths from acute myocardial infarction , and not all coronary heart disease . We did not attempt a similar analysis of determinants of trends in deaths from coronary heart disease because we could not reliably identify all new coronary heart disease events ( other than acute myocardial infarction ) using just hospital and mortality data . Extrapolation of results presented here to all coronary heart disease should be made with caution . Age standardised mortality rates from causes of non - acute myocardial infarction coronary heart disease in England declined less than acute myocardial infarction mortality over the study period ( data not shown ) . This could be driven by the decreasing severity of coronary heart disease in the population , with fewer people developing the acute manifestation of the disease as an acute myocardial infarction . However , the precise reasons behind these trends merit further research but lie beyond the scope of this study .	40755829	no
"NUE ( the ratio of N output to N input ) can be directly derived from the N budget as a functional value and allows for comparison between agricultural systems . Based on the national OECD N gross balance records for Austria 's farming system , NUE is estimated ranging between 67 and 77 % for the years 2010 - 2014 ( data extracted from http://stats . oecd.org/ , Feb. 2018 ) . MogollÃ³n et al . ( 2018 ) estimate 67.5 - 70 % for the year 2005 . These estimates do not distinguish between different kinds of land - use . Compared to the national values , regional calculated NUEs appear to be notably high . Regarding manure , again , there are different boundaries of the accounting methods ( as within the EF method , compare to Section 3.3 ) , primarily explaining divergences . The OECD gross balance calculation considers N in manure equal to N in excretion ( gaseous N losses during accumulation , storage , and application are integrated ) while the soil N budget calculation considers N in manure being equal to N entering the soil . Apart from this , OECD utilizes country totals for input quantities , here we are limited to adapt input values according to farming practice recommendations . Uncertainties of the regional established N budgets are mainly linked i ) to the amount of applied manure and its N content , ii ) to assumed BNF rates , and iii ) to fertilization of single fields after high - yield harvests . An Austrian report on N balances on the level of groundwater bodies estimates the overall ( additive ) uncertainty for the established N budgets with Â±28 % ( BMLFUW , 2013b ) . That study mainly uses the same N in - and output flows as we do . 4.1.1.1 . Arable farming . Based on the established NUEs , we compare the common land uses in the region . Within the three arable CRs compared , the implementation of soya beans ( CR 2 ) to arable crop rotations leads to the highest NUE . The harvest of soya beans is rich in protein ( leading to high N output ) , and N input via plant - based N 2 -fixation is comparatively low ( i.e. , soya beans compared to sugar beets in CR 1 : crop yield C : N ratios are 9 vs 250 ; N input via BNF or as fertilizer is 111 vs 130 kg N ha â1 yr â1 for soya bean and sugar beet , respectively ) . N input incrementally achieved via BNF is successfully picked up by the plants . In contrast , classic "" fertilization events "" lead to higher losses of N , primarily as nitrate . However , specific local data on BNF is not available and had to be derived from external literature . The BNF rate of soya beans used for the N budgets here ( 111 kg N ha â1 ) is based on the average value of a meta - analysis of 637 data sets according to Salvagiotti et al . ( 2008 ) . In this meta - analysis , for 80 % of these data sets the amount of N fixed was not sufficient to replace N export from the fields . The mean net soil N mining was â40 kg N ha â1 ( this value equals the difference of N fixed in aboveground biomass minus N removed with grains ; the value of our study : â22 kg N ha â1 ) . Other Austrian N balances for the agricultural sector use different values for BNF ( e.g. , 125 kg N ha â1 ( Environment Agency Austria , 1998 ) , or 65 kg N ha â1 ( BMLFUW , 2013b ) ) . Therefore , NUE for the cultivation of soya beans described in literature may differ distinctly but ultimately should tend towards a neutral or negative soil N balance ."	73487265	no
The cluster Markets as Practice ( C3 ) views market innovation as the result of practices of actors in a market system ( Geiger et al . , 2012;Hietanen & Rokka , 2015 ) . Markets emerge from the performances of a variety of actors at a particular moment in time , they are constantly in the making and never finished . Studies in this cluster are rooted in two main theoretical traditions : actor - network theory and service - dominant logic ( SD - logic ) . A key concept derived from actor - network theory is performativity in market practice . Performativity suggests that markets are continuously enacted and both humans and artifacts ( such as technologies and models ) influence market innovation ( Kjellberg , Azimont , & Reid , 2015;Kjellberg & Olson , 2017 ) . Scholars in this cluster thus explore how both artifacts ( such as technologies and models used by actors ) and calculative agencies ( i.e. , market and non - market actors ) come together to act as a whole . Artifacts and calculative agencies together are involved in the creation of markets - as - networks by framing , negotiating , and finding compromises regarding the nature , value and meaning of innovations ( e.g. , Azimont & Araujo , 2007 , 2010 . A typical context in this cluster is business - to - business ( B2B ) . Here , research has , for example , shown how artifacts employed by retailers and manufacturers such as presentations , data , metrics , definitions , and maps facilitate the creation of markets for beverages ( Azimont & Araujo , 2007 ) . This cluster therefore emphasizes the co - creation of value and markets , as well as the recursive nature of how actors , artifacts and markets interact and influence each other in networks or ( service ) ecosystems ( Vargo et al . , 2015 ) . This cluster has the largest number of purely conceptual contributions , and the empirical studies are mostly qualitative case studies . Regarding terminology , many of the articles take a more constructivist perspective and use ' market emergence ' as a term to signify how markets come into existence , and ' market shaping ' as a way to indicate that markets change through purposive action . Market innovation ( e.g. , Kjellberg et al . , 2015 ) is also used as a term in this cluster .	225133234	no
Convolutional neural networks ( CNNs ) have demonstrated groundbreaking results on a variety of different learning tasks . However , on tasks where high dimensional structure in the data needs to be preserved , per - pixel regression losses typically result in unstructured outputs since they do not take into consideration non - local dependencies in the data . Structured prediction frameworks such as graphical models and joint CNN - graphical model - based architectures e.g. CNN - CRFs have been used for imposing spatial contiguity using non - local information ( Lin et al . , 2016;Chen et al . , 2018a;Schwing & Urtasun , 2015 ; . The motivation to use CNN - CRF models stems from their ability to capture some structured information from second order statistics using the pairwise part . However , statistical interactions beyond the second - order are tedious to incorporate and render the models complicated ( Arnab et al . , 2016;Kohli et al . , 2009 ) .	68046158	no
We have given evidence that cosmic censorship survives the challenge from collapsing bubbles of Breitenlohner - Freedman mass scalar fields in AdS. In particular , the existence of negative mass for the initial data is consistent with black hole formation since the mass becomes positive rather early in the evolution . In the case of Dirichlet boundary conditions there is still a possibility of violating cosmic censorship since we have not exhausted the full parameter space . However , we should point out that if one truly wishes to form a naked singularity in string theory then we are presumably restricted to the standard boundary conditions ; being a quantum theory of gravity , string theory only admits asymptotic boundary conditions and not Dirichlet conditions at finite locations . There have been a number of previous numerical studies of the dynamics of scalar fields coupled to gravity in AdS spacetimes [ 19 ] [ 20 ] . In these papers the main focus was on massless scalar fields . The study of gravitational collapse and black hole / singularity formation using numerical techniques is a very interesting problem in general .	15062215	no
To gain insight into whether GOs affect DC - T - cell interactions , CD8Î±+ T cells from OT - I TCR transgenic mice were cocultured with GO - pretreated and OVA 257 - 264 -bearing DCs . The dynamic interaction between T cells and DCs was recorded by confocal imaging for a period of more than 100 min ( Figure 2a and Videos S1 - S3 , Supporting Information ) . The contact area between DCs and T cells and period of interaction were calculated . The direct DC - T - cell contact area in the L - GO - treated group was approximately fourfold higher than that in untreated DCs and approximately twofold higher than that in S - GOtreated DCs ( Figure 2b ) . Moreover , > 80 % of DC - T - cell clusters persisted for over 100 min in the L - GO - treated group , compared to 46 % in the untreated group and 17 % in the S - GO - treated group ( Figure 2c ) . These data demonstrated that the pretreatment of DCs with L - GOs dramatically increased contact with T cells and synapse formation .	237095533	no
In this section we illustrate the rodeo on some examples . We return to the examples later when we discuss estimating Ï , as well as a global ( non - local ) version of the rodeo . , and bandwidths on a single run of the algorithm ( center ) . In the top plots the regression function is m(x ) = 5x 2 1 x 2 2 with d = 10 , n = 500 , and Ï = .5 and in the lower plots the regression function is m(x ) = 2(x 1 + 1 ) 3 + 2 sin(10x 2 ) , d = 20 , n = 750 , and Ï = 1 . The figures show that the bandwidths for the relevant variables x 1 and x 2 are shrunk , while the bandwidths for the irrelevant variables remain large . x 2 2 ( left ) and m(x ) = 2(x 1 + 1 ) 3 + 2 sin(10x 2 ) right . For each plot , the left six boxplots show the risk in different dimensions ( d = 5 , 10 , 15 , 20 , 25 , 30 ) when using a single bandwidth , chosen by leave - one - out cross validation . The right six boxplots show the squared error on the same data with bandwidths selected using the rodeo .	1911421	no
We first describe the detailed step of our gradient estimator in Algorithm 2 . We also provide the sampling algorithm 1 with detail . Assume that we have access to the right LSH function h , and its collision probability expression cp(x , y ) = P r(h(x ) = h(y ) ) . For linear regression , we can use signed random projections , simhash [ 8 ] , or MIPS hashing . With normalized data , simhash collision probability is cp(x , y ) = 1 â cos â1 ( xÂ·y x 2 y 2 ) Ï , which is monotonic in the inner product . Furthermore , we centered the data we need to store in the LSH hash table to make the simhash query more efficient . Get x i train , y i train from preprocessed data 10 :	3284367	no
The ionizing photon emissivity of z â¼ 6 quasars is calculated from the QLFs derived in the previous section , following the framework given in Bolton & Haehnelt ( 2007 ) . In this paper , we assume a broken power - law for the rest - frame SED of a quasar : f Î½ â Î½ â0.6 ( Î» â¤ 912Ã ) and f Î½ â Î½ â1.7 ( Î» rest > 912Ã ) , which is given in Lusso et al . ( 2015 ) . We integrate the QLF from M 1450 = â30 to â18 mag using the best - fit double power - law at Figure 2 . z â¼ 6 QLF . The binned QLF from K15 and this study is shown in brown ( case 1 ) and red ( case 2 ) open symbols , respectively , with the re - binned QLFs with the faintest bin of the CFHQS ( Willott et al . 2010 , magenta ) shown in filled symbols . The SDSS data points ( Main , Overlap , Stripe82 ) from Jiang et al . ( 2016 ) are shown in green ( squares , diamonds , and triangles ) . AGN luminosity functions from Parsa et al . ( 2017 , cyan ) and Giallongo et al . ( 2015 , blue ) are scaled to z = 6.0 using k = â0.47 . The best - fit double power - laws ( using all the filled symbols ) are shown in solid lines , while those fitted without the Parsa et al . ( 2017 ) bin are shown in dashed lines . The shaded grey line shows the UV luminosity function of i - dropout galaxies from Ono et al . ( 2017 , lensed Schechter function ) , which intersects with the QLFs at M1450 â â23 . each frequency to derive the monochromatic emissivity . Based on our best - fit QLFs , we findá¹ ion = 1.63 Ã 10 49 s â1 Mpc â3 ( case 1 ) andá¹ ion = 1.34 Ã 10 49 s â1 Mpc â3 ( case 2 ) . The required emission rate to balance with the hydrogen recombination at z = 6 isá¹ ion = 10 50.48 ( 3 / C ) s â1 Mpc â3 ( Madau et al . 1999 ) , where C is the IGM clumping factor . Therefore , the contribution of z â¼ 6 quasars to the ionizing photons is 5.4 % in case 1 and 4.4 % in case 2 , if we assume the fiducial value of C = 3 ( e.g. , Shull et al . 2012 ) . In Figure 3 , the ionizing photon emissivity at each Î± -M * 1450 plane is indicated with solid lines assuming case 1 . The shades show the corresponding photon budget , which indicates that the 2Ï confidence range falls at â¼ 1â12 % contribution in either case . The error estimate is based on the two - dimensional confidence range of Î± and M * 1450 ( Fig . 3 ) . Meanwhile , if the QLF is integrated further down to M 1450 = â13 , where the recent studies of z > 6 UV luminosity function of galaxies exploiting gravitational lensing have reached ( Livermore et al . 2017;Bouwens et al . 2017 ) , the pho - ton budget is still small ( 9.8 % and 7.0 % for case 1 and 2 , respectively ) . Taking systematic uncertainties due to the choice of the clumping factor ( C â¼ 2â5 , Jiang et al . 2016 ) , the escape fraction , and the minimum magnitude of the QLF into account , we place a stringent upper limit of 20 % ; thus , our result supports the scenario that quasars are likely the minor contributors of the ionizing background at z â¼ 6 .	119373429	no
where Îº 2 x = 8ÏG/(1 + x 3 ) and Ï r and Ï m are the radiation and matter energy densities , respectively . It thus reduces to the standard equation when x = 0 and the self - tuning one ( 1.1 ) when x = 1 . Guided by the CMB data , we assume the curvature term in H 2 to be absent .	10432010	no
Potential limitations of these results include the observational nature of the study and the bias in patient characteristics . To partly mitigate these potential biases , we performed a multivariate analysis , demonstrating the clear benefit of ACT for reduction of recurrence risk in ctDNA - positive patients 4 weeks after surgery . Another limitation of the study is the nonfeasibility of conducting a randomized trial of ACT versus the observation arm in postsurgical ctDNA - positive patients in Japan . However , our results are supportive of the benefit of ACT and may need further investigation in a prospective randomized trial with adequate follow - up to evaluate the noninferiority of the observation arm versus ACT in ctDNA - negative patients . Our data are supported by the results of the recently published prospective randomized DYNAMIC trial 22 . Of 455 patients with stage II colon cancer , 294 underwent ctDNA - guided adjuvant therapy , and 147 underwent standard management ( median follow - up of 37 months ) . ctDNA - guided management reduced the proportion of patients receiving adjuvant therapy ( 15 % in the ctDNA - guided arm versus 28 % in the standard management arm ) , without compromising 2 - year recurrence - free survival ( 93.5 % in the ctDNA - guided arm versus 92.4 % in the standard management arm ) , implying that ctDNA - guided ACT is not inferior to standard management . Interestingly , patients who were ctDNA negative were not treated , and the 3 - year recurrence - free survival for ctDNA - negative patients was 92.5 % compared with 86.4 % for ctDNA - positive patients 22 .	255940585	no
We hypothesized that a combination therapy consisting of two distinct PCTs using ABX and IFG may be an option because of the apparent partial difference in mechanism of action . A cell culture experiment showed that ABX / IFG combination - treated GM00852 and GM00372 cells displayed additive drug effects on Î² - Glu enzyme activity elevation compared to monotherapy with either treatment ( Supplementary Materials Figure S3 ) . Even though the exact mechanism of action of ABX remains unclear , our data suggest that additional intracellular factors are required to achieve the ABX effect , e.g. , by utilizing gene regulatory function and exploiting endogenous molecular chaperones that exert a positive effect on Î² - Glu [ 19,[23][24][25][26][27]50 ] . This peculiarity of ABX also makes it a potential drug candidate for other LSDs . Conversely , this aspect should be appreciated in future studies on the utility of ABX as PD therapy , as its putative direct effect on the correct folding of Î² - Glu may be overestimated .	247727580	no
In the Drnt rph-1 double mutant , all of the sequenced hisR , cysT and leuX transcripts ( 119 total ) had immature 3 0 -ends ( Figure 6 ; data not shown ) . Furthermore , the percentage of transcripts with poly(A ) tails of up to 5 nt in   Table 4 . length increased to 80 % ( 48/61 ) for hisR and 53 % ( 17/32 ) for cysT ( Figure 6 ) . For the majority of the transcripts , the poly(A ) tails were at least 1 - 2 nt downstream of the mature CCA termini ( Figure 6 ) . The origin of the single adenine 2 - nt downstream of the CCA determinant ( a 1 in Figure 6 ) in the hisR clones could not be unequivocally determined because of the presence of a chromosomally encoded A at that location ( Figure 6 ) . Interestingly , some of the sequenced transcripts ( 5/61 for hisR and 4/32 for cysT ) had poly(A ) tails added immediately following the CCA determinant , which had not been previously seen in either wild - type ( Figure 6 ) or rph-1 strains ( 3,4 ) . Again , none of the poly(A ) tails added to the CCA determinant were > 5 nt . It should also be noted that although > 50 % of the clones were mature tRNAs in the wild - type control , no mature tRNAs were isolated from the Drnt rph-1 double mutant ( Figure 6 ) . We also sequenced 5S rRNA species derived from wild - type , Drnt and Drnt rph-1 strains ( Figure 7 ) . This stable RNA is generated endonucleolytically by RNase E cleavages of a larger 9S rRNA precursor ( 50 ) , creating a p5S RNA species that contains an extra 3 nt at each end ( 51 ) ( Figure 7 ) . Although the 5 0 maturation process is still unknown , the 3 nt at the 3 0 -end are removed by RNase T ( 16 ) . Fifty percent ( 10/20 clones ) of the transcripts in the wild - type strain had both 5 0 and 3 0 mature ends ( Figure 7 ) . The rest of the clones had an additional 1 - 3 nt at both ends . As expected , all the transcripts derived from the Drnt single mutant ( 22/22 clones ) had immature 3 0 -ends , although 41 % ( 9/22 clones ) had mature 5 0 -ends ( Figure 7 ) . Additionally , all of the transcripts had poly(A ) tails that were 1 - 4 nt in length . While the first three As following C ( A ) may have been encoded , at least 9 % ( 2/22 clones , small a ) of the transcripts had poly(A ) tails that were post - transcriptionally added . The number of post - transcriptionally added tails increased to 56 % ( 15/ 27 clones , small a ) and the length of the poly(A ) tails increased from 4 to 7 nt in the Drnt rph-1 double mutant ( Figure 7 ) . It should also be noted that none of the pre - tRNAs ( with or without poly(A ) tails ) and pre-5S rRNAs were defective based on their primary nucleotide sequences .	6264366	no
In this study , we defined that the mobility change by MTR use to be the percentage difference in average daily subway - use at time t , compared to the average of that in a non - pandemic week ( January 6 to 12 ) . Some studies that used mobile phone data to evaluate human movement , defined the mobility change to be the percentage difference in average daily distance travelled in an area at time t , compared to the average of that on the same weekday before the COVID-19 pandemic ( Engle et al . , 2020 ) .	231880553	no
The paper is structured as follows . The QOF is described in section 2 . The data and descriptive statistics are outlined in section 3 . Section 4 contains a graphical analysis . Section 5 describes the empirical strategy and section 6 discusses the results . Section 7 concludes .	9439523	no
Contributors : DL and FF designed the study . QS performed the statistical analysis . QS , DL , and FF drafted the manuscript . All authors analysed and interpreted the data and approved the final version . QS and DL contributed equally to the work , had full access to all the data in the study , and take responsibility for the integrity of the data and the accuracy of the data analysis . FF is guarantor . Competing interest : All authors have completed the Unified Competing Interest form at www.icmje.org/coi_disclosure.pdf ( available on request from the corresponding author ) and declare that : no support from any company for the submitted work ; no relationships with any company that might have an interest in the submitted work in the previous three years ; no financial relationships with any organizations that may be relevant to the submitted work ; and no other relationships or activities that may influence the submitted work .	10480084	no
To measure the ESG integration performance , we use Asset4 ESG ratings . Asset4 uses publicly available and traceable sources such as websites , SEC filings , sustainability reports , media sources , and NGO reports to derive more than 700 non - financial firm - level data points . Every data point is the firm - specific expression of a single ESG - related or sustainable characteristic . These data points are aggregated in several stages into 18 categories that cover general ESG themes within the environmental , social , and corporate governance pillars . Asset4 generates a rating for each category . A rating ranges from 0 to 100 points , with 100 indicating a very strong ESG integration performance relative to other firms . Our study focuses on the ESG integration of the UN PRI signatories in their investment and product development processes since the UN PRI explicitly addresses these business activities . Therefore , our major rating is the product innovation rating ( ENPI ) . The ENPI rating reflects a firm 's efforts toward the research and development of environmentally friendly products or services and it considers the reporting on the implementation of screening criteria in the investment selection process . Moreover , we examine whether UN PRI signatories increase their ESG integration in general , i.e. , in all their business activities , by including a more general rating , which is an equally weighted aggregation of the ratings of the three pillars environment , social , and corporate governance ( henceforth EWR rating ) . 7 We argue that an increase in the more general EWR rating subsequent to signing the UN PRI is a further indication for a serious commitment to the initiative since it suggests a general commitment to sustainability issues . 8 In the following , we use ESG as the general term to indicate specific or aggregated ESG integration activities , and refer to the ENPI and EWR ratings as our specific measures for ESG integration performance . We chose Asset4 as our main ESG rating provider because it best fits our study in terms of coverage , scope , methodology , and output , and thus overcomes limitations of other ESG rating databases . Firstly , and in contrast to other ESG rating providers like MSCI - KLD , Asset4 covers a global sample of firms for a time series starting in 2002 . Thus , Asset4 ESG ratings are available for the whole duration of the UN PRI initiative since its launch in 2006 . Moreover , ratings prior to the signature year are important for our methodological setting . Thus , the access to ESG ratings from 2002 to 2005 are critical for our study . Secondly , in contrast to the MSCI - KLD , FTSE4Good , and Dow Jones rating approaches , the scope of Asset4 ESG ratings is comparatively granular . This granularity in the ratings ensures a high level of transparency by providing both the characteristics and the expressions of these data points for every firm in the Asset4 universe ( Chatterji & Levine , 2006 ) . Finally , the Asset4 methodology guarantees a high level of integrity and comparability of the ratings since every data point is cross - checked by at least one additional analyst and by means of statistical analysis tools . Moreover , there was no critical change in the methodology of the Asset4 ESG ratings for the entire observation period , which makes the output of Asset4 ESG ratings comparable in our long time series of Asset4 ESG ratings . 9 Panel A of Table 2 contains descriptive statistics on the ESG ratings for the UN PRI signatories at the end of the matching year ( t â1 ) , i.e. , the year before the signature year . It becomes apparent that UN PRI signatories have the possibility to improve their ESG integration performance after signing , since the ENPI and the EWR ratings are well below the maximum rating of 100 .	244651817	maybe
missing values ) and a data normalisation phase ( e.g. bounding all the values within the interval of [ 0 , 1 ] ) may be applied on U to obtain U â R mÃn s.t . n < n. In this work , we adopt the Min - Max ( MM ) normalisation technique :	231573178	no
The main idea is to first learn from observational data a Gaussian process over dose - response curves , then compose it with a nonlinear transformation biased toward the identity function . The fundamental innovation is the construction a non - stationary covariance function from observational data .	8091601	no
The battery community continues to make strides toward Industry 4.0 with the aim to achieve smart manufacturing processes with greater intelligence , sustainability , and customization . This approach facilitates the interaction , integration , and fusion between the physical and cyber worlds of manufacturing . [ 26 ] Digital Twins ( DTs ) are attracting growing attention from academic researchers , as well as industrial players in recent years , as a promising means to achieve the cyber - physical fusion of both manufacturing processes and products . [ 27][28][29][30 ] Through high - fidelity modelling , real - time interaction and data fusion , DTs can reproduce a physical asset or process accurately in the digital world and enable more effective monitoring , optimization , and prediction of the physical counterpart through its lifecycle . [ 31][32][33][34 ] Inspired in the work of Bazaz , [ 35 ] which presented a five - layer digital model to replicate the physical object as a virtual object and to collect and convert data within a manufacturing plant , the present paper considers hypothetical three - layer DTs that will enable covering all requirements to represent the physical space in the virtual space . The proposed 3 - layer structure of the DT of the gigascale LIB manufacturing , [ 36 ] which includes the main steps of 1 ) electrode preparation , 2 ) cell assembly and 3 ) activation by formation steps , is depicted in Figure 1 .	245112757	no
As in the MSSM in the decoupling regime ( see Ref . [ 28 ] for a review ) , the heaviest CPeven , CP - odd and charged Higgs states form a practically degenerate SU(2 ) multiplet with a common mass above 500 GeV. The mostly SM - like CP - even state has a mass increasing slightly with M 1/2 from 115 GeV up to â¼ 120 GeV. This mass range is only slightly above the lower limit of 114.4 GeV on the SM Higgs boson mass , and is compatible with the Higgs mass range favored by electroweak precision data as recently obtained from a global fit ( in which the central mass value is 116 GeV ) [ 29 ] .	16855715	no
The remainder of the study is structured as follows . Section 2 presents the theoretical background while Section 3 presents the conceptual model . Sections 4 , 5 and 6 provide the data and methods , results and discussion . The study concludes with implications , future research areas and limitations .	245008959	no
Almost all of the arsenolipids identified so far contain the dimethylarsinoyl group Ã As(O)Me 2 , w hich gives rise to two characteristic fragment ions , o ne with m / z = 105 ( C 2 H 6 As + ) and one with m / z = 123 ( C 2 H 8 OAs + ) , when subjected to collision - induced - dissociation . Owing to their mass defects , these fragment ions can be uniquely identified by ah igh- resolution mass spectrometer even from ac omplex matrix . Searching the fragmentation spectra for these two fragment ions exposed am ultitude of precursor ions , f rom which six known arsenic fatty acids ( AsFA334 , AsFA362 , AsFA388 , AsFA390 , AsFA436 , AsFA448 ) and five known arsenic hydrocarbons ( AsHC 330 , AsHC 332 , AsHC 358 , AsHC 360 , AsHC 404 ) could be expressly identified ( Supporting Information , Table S2 and Figure S2 ) . This procedure similarly implied an ion with [ M+ + H ] + at m / z = 529 . Theaccurate mass and fragmentation data of this ion were consistent with ah itherto unknown arsenic fatty acid with eight ethylene groups ( AsFA528;F igures 3a nd S3 ) .	499486	no
We resample a given timestep by choosing at each timestep transitions x i â x i from that timestep in the data uniformly with replacement . We determine the number of transitions to include at each timestep by iteratively including another transition sample with probability max(1 , p â c / e â c ) where c is population size of the types included thus far , p is the observed population size in the original data , and e is the expected population size increase by including one more transition sample . This guarantees that the expected resampled population size is equal to the observed population size , but allows statistical variation in population size from generation to generation . This resampling scheme is equivalent to a multinomial resampling of independent observations which accounts for robustness of the estimator to sampling noise , but also preserves the frequency interpretation of the original count data . The frequency associated with a given count is allowed to vary around its expectation in the bootstrap , and thus the bootstrap also represents robustness of the estimator to the inclusion or omission of observations due to sampling of the data , since such sampling omissions would cause the frequencies in observed data to fluctuate . The bootstrap CIs are conservative estimates of the true 95 % CI .	232380291	no
The QC report is generated by MultiQC [ 47 ] , by aggregating data from multiple sources within the pipeline , and in particular FastQC ( https://www.bioinformatics.babraham.ac . uk / projects / fastqc/ accessed on 24 October 2022 ) , statistics generated by samtools [ 45 ] , bamtools stats ( https://github.com/pezmaster31/bamtools accessed on 24 October 2022 ) , and Qualimap [ 48 ] .	253162526	yes
We have carried out a FAST Extragalactic H I Survey ( FEHIS ) , which is a new survey for H I emission in the northern sky ( 61 Â° > Î´ > â10 Â° ) over the velocity range â2000 - 20,000 km s â1 , using FAST 's focal - plane 19 - beam receiver system ( Jiang et al . 2019(Jiang et al . , 2020 , which is set in a hexagonal array and works in dual polarization mode , with a frequency range from 1050 MHz to 1450 MHz . For the backend , we choose the Spec(W ) spectrometer that has 65,536 channels covering a bandwidth of 500 MHz for each polarization and beam , with a velocity spacing of 1.67 km s â1 and a spectral resolution , after Hanning smoothing , of 4.8 km s â1 . The FAST H I survey is carried out with the drift scan mode and the 19 - beam receiver was rotated by 23 Â° .4 so that the beam tracks are equally spaced in decl . with 1 14 spacing . The FEHIS will eventually cover the entire northern FAST sky at least two times for full sensitivity . The data presented here come from the drift scan observations conducted in 2020 September 25 - 29 to 2021 July for a total of 12 hr . We have also used the Multibeam on - the - fly ( OTF ) mode to map the M106 filament regions to confirm the weak detections . The system temperature ranges between 18 - 22 K for all beam/ polarization channels . The half - power beamwidth ( HPBW ) was about 2 9 at 1.4 GHz for each beam . The pointing accuracy of the telescope was about 10â³ ( rms ) .	244486059	maybe
In order to understand the impacts of the crisis caused by COVID-19 in relation to single - use plastic waste in households , a quantitative approach is used . The data collection for the self - report study followed a structured questionnaire survey ( see Appendix A ) , made available through the online platform Google Forms between February and April 2021 . The survey consisted of a total of twelve closed - ended questions on demographic details and aspects of consumption of single - use plastic waste in households . The survey instrument was then shared with a global audience via various scientific mailing lists , the networks of the European School of Sustainability Science and Research ( ESSSR ) , and the Inter - University Sustainable Development Research Programme ( IUSDRP ) .	235660228	maybe
At day 3 p.i . with influenza , mice were injected with 200 Î¼g CD8 - specific mAb ( Clone 2.43 ) , 500 Î¼g CD4 - specific mAb ( Clone GK1.5 ) or 200 Î¼g CD8 - specific mAb plus 500 Î¼g CD4 - specific mAb i.p . We confirmed the specific depletion of the mAb by flow cytometry ( data not shown ) .	7808645	no
For the pulse - profile modeling technique to deliver tight constraints on mass and radius , rapid spin ( ï100 Hz ) is desirable Miller & Lamb 2015;Stevens et al . 2016 ) , and one needs high - quality phase - and energy - resolved pulse profiles with time resolution 10 Î¼s and a large number of photons . The precise number of photons needed to deliver constraints on mass and radius at levels of a few percent - and by extension tight constraints on EOS models - depends on the geometry of a given source , but is â¼10 6 pulsed photons ( Lo et al . 2013;Miller & Lamb 2015 ) . For the brightest of the rotation - powered MSPs targeted by NICER , it is feasible to collect sufficient data with observation times â¼1 Ms. The hot regions on rotation - powered MSPs in theory arise as 18 Or measurements , or estimates ; in any case , this means some probabilistic measure that is a function of , or otherwise pertains to , model parameters . See Section 2.3 for the probabilistic measures that we consider in this present work . 19 In a Bayesian context , by truncating the mass likelihood function only far in the tails , leading to a finite but small marginal posterior density for EOSs that do have substantially smaller maximum supported masses . 20 Note that PSRï J1614â2230 was initially reported as having mass 1.97ï Â±ï 0.04 ( Demorest et al . 2010 ) ; the inferences have since been updated via analysis of newly acquired data . 21 Note that local effective gravity in local comoving frames ( instantaneously inertial during rotation ) also enters calculation of atmospheric beaming of radiation emergent from the local comoving photosphere . 22 Where for statistical applications the surface is either self - consistently computed via matching to a numerical interior solution to the field equations , or is embedded via a quasi - universal relation in an ambient spacetime solution ( for an overview see , e.g. , Riley et al . 2018 , and references therein ) . 23 Note a key difference to the X - ray spectral modeling mentioned two paragraphs earlier : pulse - profile modeling involves phase - resolved spectroscopy ; spectral modeling is phase - averaged , and does not fully leverage the temporal dimension of information provided by the star 's rotation .	209324378	no
Firm selection continued through the analysis until theoretical saturation was achieved , when each additional firm 's data revealed consistent content of themes and consistent relationships between themes ( Charmaz , 2014;Randall et al . , 2009 ) . We did not reach theoretical saturation with analysis of the original four cases . Therefore , we added an additional manufacturer and retailer to the sample to replicate findings , achieve saturation , and improve credibility and transferability of the findings ( Miles et al . , 2020 ) . The additional manufacturer represented food production and the additional retailer represented the home improvement industry . Selection of these firms was based on Harris Poll rating total scores and product offerings that were different from the previously selected firms . Therefore , overall , we utilized data from 6 firms ( 3 retailers and 3 manufacturers ) . Selection of 6 firms ensured multiple - firm sampling adequacy , which is normally attained with 4 - 10 firms ( Barratt et al . , 2011;Eisenhardt , 1989;Eisenhardt & Graebner , 2007;Yin , 2014 ) . Firm selection efforts also ensured data source triangulation , and improved transferability through sampling of multiple , diverse firms , and by placing limits on sample selection ( Miles et al . , 2020 ) .	236943539	no
The data that support the findings of this study are available from the corresponding author upon reasonable request .	71143628	yes
This study is one of the first to describe the effect of a global health crisis in a large population sample over time . In contrast to the assumption that repeated exposure to stressors necessarily leads to worse health outcomes , overall , our data do not show a significant increase in symptoms of mental illness and that - with the exception of screen time - health behaviors reached pre - pandemic levels comparably quickly . Thus , the pattern of findings rather corresponds to habituation over the three months assessment period . Health - promoting behaviors were clearly related to indicators of mental health . More vulnerable groups were more likely to experience symptoms of poorer mental health and showed less engagement in health promoting behaviors . The crisis - related policy measures to protect the population can have unintended side effects for health with potentially long - term impact . This paper makes a unique contribution by not only describing aspects of mental health during a lockdown but also the potential for healthpromoting behaviors . This crisis will have a long - term impact on ways of life and work ; for example , a higher level of digitalization and remote work is likely to stay . In this paper , we identified behaviors that can promote health in such situations and beyond .	238220920	no
The discovery that HDACs play a role in TSG silencing in cancer supports the hypothesis that combining DNA methyltransferase ( DNMT ) and HDAC inhibition could result in improved or maintained TSG reactivation . This hypothesis is supported by preclinical data . Cameron et al . illustrated that the combination of decitabine and TSA reactivated silenced TSGs in colon and leukaemia cell lines [ 119 ] , displaying that the functional correlation between DNA methylation and histone deacetylation in gene silencing might be manipulated pharmaceutically . Briefly after , in vitro studies revealed additive or synergistic inhibition of DNA production , loss of clonogenicity , and activation of apoptosis in NSCLC cell lines medicated with decitabine and an HDI ( phenylbutyrate , depsipeptide , or TSA ) [ 120 ] . Furthermore , combining decitabine and phenylbutyrate was shown to synergistically suppress the progression of lung lesions in mice after exposure to the carcinogen nicotine - derived nitrosamine ketone ( NNK ) [ 121 ] .	240249454	no
where x â R n denotes the global variable and Î¾ i denotes the local variable , K â R m and K i â R mi are proper cones , Q i â R mÃn , R i â R mÃni , r i â R m , A i â R miÃn , B i â R miÃn , b i â R mi are the problem data such that each node i â N only have access to Q i , R i , r i , A i , B i , b i , K i and K along with its objective Î¦ i as defined in ( 1 ) .      For any x â X , and y â Y , the iterate sequence { z k } kâ¥1 defined as in the statement of Theorem 1.1 satisfies for all k â¥ 0	6546098	no
Based on scanning electron microscopy ( SEM ) images ( Figures S3 and S4 , Supporting Information ) , the coatings generally exhibit distinctly different surface topographies , which is also reflected in the stylus - based roughness measurement ( Table S1 , Supporting Information ) . Figure 2B and Figure S1B , Supporting Information , show SDAM adhesion maps on Hydrobead and UltraEverDry coatings matched with topographic data from the optical profilometer . The matching is based on mapping the approach length inferred from the SDAM force curves , that is , the length of the vertical motion of the sample stage between its initial position and the position where the droplet first contacts the surface , and thus enables tracing the approximate surface topography as experienced by the probe   ( 5 ) highlighted on a model force curve . 1 ) Sample is gradually brought closer to the droplet suspended from a sensitive force sensor ; evaporation of the droplet causes a small force gradient . 2 ) Once the surface makes contact with the droplet , the force increases steeply . The approach time will vary point by point on a rough surface , and carries information about the surface topography .	237373828	no
To strengthen the stability and validity of findings , using the NCapture facility of Nvivo pro software , we extracted 20,000 Facebook and Twitter posts from January to May 2020 that used the most frequent hashtags , according to Ipsos.com . ( 2020 ) . These hashtags are # wuhanvirus # coronavirus , # covid19 , # quarantine , # lockdown , # stayathome , # stayhomesavelives , # workingfromhome . Following recommendations for netnographic studies , it was deemed appropriate to copy publicly shared archival data comprising all posts for this period and then filter this for relevance ( Kozinets , 2010 ) . Publicly communicated online messages are open to researchers , and , legally , it is the user 's responsibility to identify what information to share publicly on social media ( Kozinets , 2010;Langer , Elliott , & Beckman , 2005 ) . Accordingly , only public posts in English were included , also to avoid redundancy , a filtration option of NVivo automatically excluded all retweeted posts . The research focuses on individual users , not firms , organizations , governments , sponsored ads , or ads ; accordingly , ads , businesses , governments , and organizations ' posts were manually excluded . Hence , we proceeded with 4000 relevant Facebook ( 800 ) and Twitter ( 3200 ) posts for analysis .	237721938	yes
Polarity is critical for many metabolic reaction processes , and abnormal polarity is related to pathological processes 37 . Studies have demonstrated that normal cells have a larger polarity of LDs compared to cancer cells . PS - CDs were used to investigate the polarity of LDs in different cell lines . As shown in Fig . 5a , LDs exhibited generally stronger fluorescence in cancer cells , suggesting that LDs possess a much lower polarity in cancer cells . As shown in Fig . 2h , a perfect linear relationship exists not only between the fluorescent intensity of PS - CDs and the polarity but also between the maximum emitting wavelength of PS - CDs and the polarity . Therefore , in situ emission spectrum can be adopted to investigate the polarity of LDs in different cell lines . As an illustration , eight in situ emission spectrums are shown in Fig . S8 . To ensure the accuracy of the experiment , we used Gaussian fitting to fit all the spectral data . From Fig . 5b , the fluorescence emission of PS - CDs redshifts significantly from that in cancer cells , consistent with the understanding that cancer cells possess a lower LDs polarity .	249855177	no
All VOCs measured by the TCEQ at both canister and autoGC samplers were compared to applicable acute and chronic HBACVs and OBACVs . A number of HBACVs and OBACVs were considered for use in evaluating the VOC data . These included :	34488278	no
which is consistent with the values in ( 2 ) obtained from global fits . For the prediction in ( 14 ) , we used Î· B = 0.551 , m M S t ( m t ) = 162.3 GeV and V ts = 0.04113 [ 24 ] . Now , inserting the CDF data in ( 1 ) and the SM prediction in ( 14 ) into ( 11 ) , we obtain	14214220	no
Data analysis was supported by NVivo to help summarize , compare and contrast emergent themes . For example , key themes such as risk management , stakeholder alignment and accounting treatment emerged from in - depth analysis and facilitated the data synthesis steps leading to a multi - dimensional framework . The data synthesis and analysis , a key valueadded element of a comprehensive review ( Crossan & Apaydin , 2010 ) , consisted of two parts .	25933828	no
"We performed a joint analysis of the two - planet system using the TESS transit light curve and the 222 radial velocities from the AAT and HARPS surveys . The orbit of planet c was assumed to be circular in the fit . 27 As noted previously , we assigned a different additive con- 27 We also tried allowing planet c to have an eccentric orbit , which resulted in an upper limit of ec < 0.3 ( 1Ï ) . All of the other orbital parameters remained consistent with the results of the ec â¡ 0 model , although naturally , some parameters were subject to slightly larger uncertainties . stant to each of the 3 radial - velocity data sets . We also allowed for 3 independent values of the "" jitter "" , a term that is added in quadrature to the internally - estimated measurement uncertainty to account for systematic effects ."	119426461	maybe
Closer inspection of the data shows that at higher loadings , the catalysts are hydrogen bonded on average by 3 - 4 hydrogen bonds , as steric restrictions prevent the full number of hydrogen bonds to be formed . As a result , the system remains sufficiently dynamic to allow rapid diffusion for oxygen radical coupling reactions to occur .	49686869	no
We used deep - sequencing data from three different experiments : ( i ) the combined C. elegans data ( accession no . GSE6282 and GSE5990 from GEO database at NCBI ) , which have been used also in ( 7 ) with a total of 205 575 unique reads , ( ii ) data from human HeLa cells ( 7 ) with accession no . GSE10829 and 319 939 unique reads and ( iii ) data from rat hepatocytes generated in our lab , available on our website ( http://web.bioinformatics.cic biogune.es/microRNA/defaultReads.txt ) with 22 086 unique reads .	9529333	yes
Using KÃ¶hler illumination with a finite aperture , the light in the illumination path can be treated as the sum of plane waves from points in the back focal plane of the objective lens . After scattering at a target , however , light propagates through the collection path optics at multiple angles due to multiple scattering frequencies . For finite , very small subimage field targets or non - repetitive , irregular structures that scatter a broad range of continuous frequency content , the normalization required to correct the experimental data for instrumentation and hardware errors becomes complex . An illumination path tool function I and a collection path tool function C must be calculated and implemented separately for each individual illumination angle   and the resulting vast spatial frequency spectrum of the scattered light .	29896319	no
"We conducted a four - wave online study in 2020 , starting on March 27 ( till March 30 ; Time 1 ) , with the follow - up studies running on April 10 ( till April 13 ; Time 2 ) , April 24 ( till April 27 ; Time 3 ) and May 8 ( till May 12 ; Time 4 ) using a Cloud Research platform with prime panel to obtain a targeted reliable online sample of participants ( Chandler et al . , 2019 ) . Following the best practices recommended by Aguinis et al . ( 2021 ) , we recruited participants through this prime panel who were employed and residing in the USA at the time of data collection . To further ensure the high quality of data , we included multiple attention checks throughout the survey ( e.g. , "" If you are reading this carefully , please select "" disagree "" option , among the scales used ) . We also screened out participants whose answers were careless based on reverse - coded items in our scales and participants who provided patterned responses to everything ( e.g. , all 4 s throughout ) . Finally , we screened out participants who did not fit the eligibility criteria ( e.g. , those who were not employed or lost the job between the data collection waves , changed their job , work unit , or supervisor ) . For the sake of the honesty of responses , participants were not aware of the eligibility criteria and were paid regardless of their answers to the eligibility screening questions . Our final sample at Time 1 comprised 276 employed participants who passed the attention checks ( response rate = 84 % ) . We invited these participants to participate at Time 2 ( response rate = 79 % ) and used the same screening questions as at Time 1 . Only those who were employed and did not change their job , work unit , or supervisor were invited to participate in Time 3 survey ( response rate = 73 % ) . We repeated the same procedure for the final data collection at Time 4 ( response rate = 72 % ) ."	238214678	maybe
"Assessing the risk of bias due to incomplete outcome data is complex and involves several considerations . Simply observing whether an analysis was described as "" intention - to - treat "" , or determining whether there are more missing data than a pre - specified threshold , are inadequate . Considerations include the extent to which intention - to - treat principles were followed ; the proportion of participants with missing outcome data , and whether there is an imbalance between intervention groups ; the reasons for missing outcome data ; the effect size , and hence the potential impact of missing outcome data on it ; and the extent to which bias can be overcome by the review author ( e.g. by re - instating excluded participants ) . Information about these issues should be collected systematically and used to inform a judgement about the risk of bias in the effect estimates presented in the systematic review ."	9635730	no
From the standard procedure for linens inventory control , the Arena simulation models are also categorized into soiled and clean linens processes and are modelled separately for accuracy of data collection and clearer visibility of linens flow . Despite the fact that the soiled and clean linens processes occur in parallel , they have two distinct flows with no interaction in any of the procedures . Figs . 4 and 5 illustrate the Arena models of soiled linens process before and after the RFID implementation . Figs . 6 and 7 show Arena models of clean linens process before and after the RFID implementation .	154267117	no
We then investigated the ability of AuMA to bind and affect the transcription of the selected D. discoideum genes . The effect of AuMA was tested using real time qRT - PCR . The D. discoideum strain HMX44A was treated by three different concentrations ( 10 , 20 and 30 M ) of AuMA and the total RNA was isolated after 24h of treatment . The IC50 ( in- hibitory concentration ) of AuMA in HMX44A was 30 M after 24 h of treatment ( data not shown ) . The expression of histone H3a gene served as a control . We already verified that these selected sequences were present in the HMX44A strain by PCR amplification followed by sequencing ( data not shown ) . AuMA decreased the expression of the different genes . The effect seemed low at 10 M , however , at 30 M , the effect of AuMA increased . The gene harboring p10 was the most affected gene with â2.7 - fold change at 30 M AuMA , followed by genes harboring p40 and p32 ( PEBP and rps20 , respectively ; Table 2 ) . Genes with p193 and p187 then the transcript levels of genes carrying p10 , p187 , p32 , p193 and p40 G4 sequences in their upstream regions were measured by using real time qRT - PCR . The histograms show the relative fold change related to the internal control H3a . The control group is the condition without ligand treatment , and the corresponding variation in relative expression is zero . The data are presented as mean Â± SD from two replicate wells and two independent experiments . The data were analyzed on GraphPad Prism and the paired Student 's t - test ( repeated measures one - way ANOVA ) was applied . Asterisks indicate significant differences between treated cells and the control group . ( * ): ( 0.001 < P - value < 0.05 ) ; ( * * ): ( P - value < 0.001 ) .	85566061	no
Model r = 0 r = 0.1 r = 0 .     Table 6 : Second Iteration of Feedback Using synthetic textual feedback of synthetic Task2 + 3 with the RBI+FP method , an additional iteration of data collection of 10k examples , varying sparse binary reward fraction r and exploration . The performance of the first iteration model was 0.478 .	164019	no
â¢ Files in SUSY Les Houches Accord ( SLHA ) format . In this case FeynHiggs adds the Higgs masses , mixings and decay widths to the SLHA data structure and writes the latter to a file inputfile.fh .	855067	no
All experimental procedures were performed by the ethical standards for animal experimentation and meticulous efforts were made to ensure that the animals suffered as little as possible and to reduce external sources of stress , pain , and discomfort . The current study has not exceeded the number of animals needed to produce reliable scientific data . This article does not refer to any study with human participants performed by any of the authors .	246975333	no
sets of parton densities , H1 2006 DPDF fit A and fit B , which differ in the parameterisation of the gluon density . A steeper fall - off in the gluon density at high z IP is obtained for fit B than for fit A , while the quark densities agree within the uncertainties . Both DPDF sets provide a good description of the inclusive diffractive DIS data .	11550911	no
As described in CHIME / FRB Collaboration et al . ( 2018 ) , the CHIME / FRB pipeline includes a system for saving buffered , channelized baseband voltage data upon a trigger by a bright FRB from the realtime search engine . To trigger a dump of the baseband buffer , we currently require the source to have a DM consistent with being extragalactic , S / N>15 , not flagged as RFI , and having a tree index ( see CHIME / FRB Collaboration et al . 2018 ) of â¤ 2 . When these conditions are met , baseband data around the pulse are stored for each of the 1024 spectral frequencies and all 2048 digital correlator inputs . Downsampling of trial DMs in our dedispersion code bonsai ( CHIME / FRB Collaboration et al . 2018 ) leads to a significant DM uncertainty for the initial trigger , which in turn induces a timing uncertainty at frequencies away from 400 MHz ( where trigger times are referenced ) . While at 400 MHz we store 100 ms of baseband data , to account for this uncertainty , we store additional data at higher frequencies , approaching a maximum of â¼300 ms at 800 MHz .	209962854	no
Recruitment of participants via Prolific was not set up to be representative of the two countries ' adult populations . Our own samples ' demographics differ in unsurprising ways from the target populations ' as we show in Figure A.3 in the appendix : our survey takers are younger and contain more left / liberal , less right / conservative , and more male people . These are well - known patterns in samples recruited via online recruitment platforms , like Amazon 's MTurk and Prolific ( Huff and Tingley , 2015 ) . However , extensive previous validation efforts show that experimental results using opt - in survey - takers almost always replicate the qualitative result of benchmark studies based on more traditional , nationally representative samples ( significant and same sign of effect ; insignificant ) ( Berinsky et al . , 2012;Mullinix et al . , 2015 ) . Further , some studies show that reweighting opt - in survey data to match its demographic moments to the target population 's can recover even the magnitudes of treatment effects ( Hainmueller et al . , 2015 ) . Therefore , we rely on entropy balancing to reweight our samples ( Hainmueller , 2012 ) . Entropy balancing is an approach that obtains ( non - zero ) weights for the survey data that make means of pre - specified , demographic variable match those of a target dataset . At the same time , it punishes large weights ( in the entropy sense ) to reduce subsequence model dependence . See also Zhao and Percival ( 2016 ) . As re - balancing demographics , we use age , gender , and indicator variables for whether one self - identifies as left / liberal or right / conservative . The target datasets are the Cooperative Congressional Election Study 2018 ( U.S. ) and the ( pooled ) 2020 January , May , and September waves of the German Longitudinal Election Study . We make use of the trimmed - weights approach offered by entropy balancing . In all analyses , we use the re - weighted data .	235441227	maybe
To ensure study selection and data analysis remained manageable by avoiding small , early phase mechanistic studies , we specified a priori the limit on patient years of follow - up and number of outcome events . We chose the specific criteria to ensure each included study was large enough to accrue outcome events and provide reliable effect estimates . These criteria assumed an incidence of the primary outcome ( falls ) of 7.8 events per 100 patient years of follow - up , which would accrue at least 50 outcome events in each study . 15 We excluded studies in specialist populations ( children , pregnant women ) , and case reports , case series , or before and after studies . At least two members of the review team ( AA , MS , BP , SF , CK , AD , JPS ) independently reviewed study titles , abstracts , and full text articles . At each stage , the entire review team screened a proportion of articles to ensure consistency of decision making . Disagreements were resolved by a third reviewer ( JPS ) .	231858004	maybe
Test Equipment and Electrochemical Measurements : All of the single cell experiments were operated using test benches that were developed in - house . High purity feed water ( 18.2 Mâ¦ cm ) was circulated through both the cathode and anode compartments in separate water circuits at a flow rate of 25 mL min â1 . All ten water circuits were equipped with compartments that contained ion exchange resin to maintain a high degree of water purity ( ASTM Type II ) . The cells were operated using a DC power supply ( TDK Lambda GEN-20 - 76 ) , which also recorded the current . A multimeter ( Keithley Model 2701 ) was then used to record the voltage . A LabVIEW - based software was utilized to control all devices and record the data . All of the cells were purged with deionized water at 80 Â° C for 4 h to remove potential ionic impurities prior to installation onto the test bench . For the duration of â4000 h , the assembled cells were kept at 80 Â° C until disassembly and operated at a cell voltage of 2 V , with the exception of some shorter time periods when experimental challenges associated with long - term operation , such as losing supply power , DI water supply , or temperature control had to be managed . Specific cell characteristics and life test conditions are displayed in Table 2 .	234216739	no
If m 1 and m 2 have opposite signs , the results are analogous , but now the splitting generated by the RGEs can vanish if the mixing angles are correlated in a particular way ( which remarkably is always satisfied by the exact bimaximal case ) . This correlation or tuning of parameters is acceptable in the SM scenario , provided the cut - off scale Î is not much larger than â¼ 1 TeV and if âm 2 atm is in the low side of its experimentally preferred range ( â¼ 5 Ã 10 â4 eV 2 ) . Interestingly , this could provide a dynamical origin for the smallness of âm 2 sol . For larger Î and/or âm 2 atm ( or equivalently , for the MSSM scenario ) radiative corrections grow in size and the required tuning of mixing angles becomes quickly unacceptable . This occurs in particular if the lower bound âm 2 atm = 5 Ã 10 â4 that we have used is increased according to the most recent data analyses [ 11 ] .	18946584	no
The PREDICT 1 study . The PREDICT 1 clinical trial ( NCT03479866 ) aimed to quantify and predict individual variations in metabolic responses to standardized meals . We integrated data from a cohort of twins and unrelated adults from the UK to explore genetic , metabolic , microbiome composition , meal composition and meal context data to distinguish predictors of individual responses to meals . We then validated these predictions in an independent cohort of adults from the USA . The trial was a single - arm , single - blinded intervention study that commenced in June 2018 and was completed in May 2019 . Ethical approval for the study was obtained in the UK from the Research Ethics Committee and Integrated Research Application System ( IRAS 236407 ) and in the USA from the Institutional Review Board ( Partners Healthcare IRB 2018P002078 ) . The trial was run in accordance with the Declaration of Helsinki ( 2013 ) and good clinical practice . Study procedures were only carried out after having received written informed consent from each participant . For the full protocol , see Berry et al . 16 . Briefly , 1,002 generally healthy adults from the UK ( non - twins and identical ( monozygotic ) and nonidentical ( dizygotic ) twins ) and 100 healthy adults from the USA ( non - twins ; validation cohort ) were enrolled in the study ( see Berry et al . 8 for the eligibility criteria ) and completed the baseline clinic measurements . The study consisted of a 1 - d clinical visit at baseline followed by a 13 - d at - home period . At baseline ( day 1 ) , participants arrived fasted and were given a standardized metabolic challenge meal for breakfast ( 0 h ; 86 g carbohydrate , 53 g fat ) and lunch ( 4 h ; 71 g carbohydrate , 22 g fat ) . Fasting and postprandial ( 9 time points ; 0 - 6 h ) venous blood was collected to determine the serum concentrations of glucose , TG , insulin , C - peptide ( as a surrogate for insulin ) and metabolomics ( nuclear magnetic resonance ) . Stool samples , anthropometry and a questionnaire querying habitual diet , lifestyle and medical health were obtained at baseline . During the home phase ( days 2 - 14 ) , participants consumed standardized test meals in duplicate varying in sequence and in macronutrient composition while wearing digital devices to continuously monitor their blood glucose ( continuous glucose monitor ; CGM ) , physical activity and sleep . Capillary blood was collected using dried blood spot cards during the clinic visit and at home to analyze fasting and postprandial concentrations of TG and C - peptide . Participants were supported throughout the study with reminders and communication from study staff delivered through the Zoe study app . A second stool sample was collected at home by participants after completion of the study ; all devices and samples were mailed back to study staff . To monitor compliance , all test meals consumed by participants were logged in the Zoe app ( with an accompanying picture ) and reviewed in real time by the study nutritionists . Only test meals that were consumed according to the standardized meal protocol ( outlined in Berry et al . 8 ) were included in the analysis .	231580367	maybe
Acquiring statistically robust data on biodiversity transported in ballast tanks has always been difficult due to the variety of organisms present , the broad biogeography sampled by uptake events , and logistical challenges associated with vessel and tank access ( David and Perkovic , 2004 ) . Nevertheless , considerable effort has resulted in growing appreciation for the biological diversity present in BW across geographic regions and taxonomic groups . The bulk of this effort has been conducted utilizing traditional morphological identification of organisms . Much of this work has thus focused on macroscopic zooplankton , which are typically amenable to this approach ( Boltovskoy et al . , 2011;Cordell et al . , 2009;DiBacco et al . , 2012 ) , although some studies have attempted broader assessments including microbial taxa ( Gollasch et al . , 2002 ) or have specifically targeted groups such as phytoplankton or potentially toxic dinoflagellates ( Roy et al . , 2012;Villac and Kaczmarska , 2011 ) . These and similar studies have consistently recognized a significant number of taxa of concern that either pose direct harm to humans and other animals via toxicity or are known to be nonindigenous to recipient regions . Taxonomic assignments in these morphological assessments have ranged broadly from species to phylum level , with significant limitations on identification of challenging taxonomic groups and many pre - adult stages ( e.g. larvae and eggs ) commonly found in BW .	221344164	no
As detailed in Ahmed et al . , 2020 , a recovery ratio of 26 % was used to estimate the original GC / L recovered by membrane filtration for influent and sludge supernatant samples . To calculate averages and standard deviations of SARS - CoV-2 of GC / L , any non - detect samples were assumed to be equal to zero ; however , 100 % of influent and sludge samples had an associated detected value . In the analysis of public health data , days with less than five new daily cases were estimated as half the maximum number of cases in that range . Although the calculation of GC / L was sufficient to make comparisons between treatment train processes within each WRF , to make comparisons between each WRF the raw data was normalized to account for average daily flow and population size by converting GC / L to million viral gene copies per capita per day ( MVGC / capita / day ) using Eq . 3 : MVGC = ( gene copies / L wastewater ) Ã ( L wastewater influent / day ) Ã ( 1 / population ) ( Ahmed et al . , 2015 ) .	235747709	no
Let us begin with intuitions behind the second and third conditions . Consider a multi - class classifier . Let g ( x ) denote its confidence gap for an input data point x. If the classifier is a single L2NNN , 1 we have a guarantee 2 that the classifier will not change its answer as long as the input x is modified by no more than an L 2 -norm of g ( x ) / â 2 . Therefore maximizing the average confidence gap directly boosts robustness and this motivates the second condition . To explain the third condition , let us introduce the notion of preserving distance : the distance between any pair of input vectors with two different labels ought to be preserved as much as possible at the outputs , while we do not care about the distance between a pair with the same label . Let d ( x 1 , x 2 ) denote the L 2 -distance between the output logit - vectors for two input points x 1 and x 2 that have different labels and that are classified correctly . It is straightforward to verify the condition 3 of g (	3695872	no
"We have described the modeling assumptions behind the STM . As detailed , the STM assumes a decomposition of the parsed corpus by a hidden semantic and syntactic structure encoded with latent variables . Given a data set , the central computational challenge for the STM is to compute the posterior distribution of that hidden structure given the observed documents , and data analysis proceeds by examining this distribution . Computing the posterior is "" learning from data "" from the perspective of Bayesian statistics ."	215824810	no
To compare SpectralNet to spectral clustering , we consider a simple dataset of 1500 points in two dimensions , containing two nested ' C ' . We applied spectral clustering to the dataset by computing the eigenvectors of the unnormalized graph Laplacian L = DâW corresponding to the two smallest eigenvalues , and then applying k - means ( with k=2 ) to these eigenvector embeddings . The affinity matrix W was computed using W i , j = exp â xiâxj 2 Ï 2 , where the scale Ï was set to be the median distance between a point to its 3rd neighbor -a standard practice in diffusion applications . Figure 4 shows the clustering of the data obtained by SpectralNet , standard spectral clustering , and k - means . It can be seen that both SpectralNet and spectral clustering identify the correct cluster structure , while k - means fails to do so . Moreover , despite the stochastic training , the net outputs closely approximate the two true eigenvectors of W with smallest eigenvalues . Indeed the Grassmann distance between the net outputs and the true eigenvectors approaches zero as the loss decreases .	3278749	no
"On the basis of these criteria characteristics , we examined the methodological quality of trials funded by different types of organisations and compared studies published in higher and lower impact journals and reported on clinicaltrials.gov . In addition , we analysed trial dissemination rates across funding categories and disease areas and compared them with clinical success rates reported previously . 31 We used descriptive statistics and data visualisation methods to characterise trial categories . We report frequencies and percentages for categorical data and use medians and interquartile ranges for continuous variables . To visualise multiple features of clinical trial design , we used radar plots with each axis showing the fraction of trials with a different property , such as reported use of randomisation , blinding , or active comparators . We converted three continuous variables to binary categories : we classified trials as "" small "" if they enrolled fewer than 100 participants , as "" short "" if they lasted less than 365 days , and as "" multi - country "" if trial recruitment centres were in more than one country . Further details are available in supplementary tables . To facilitate comparisons between several radar plots , we always standardised the order and length of axes . We used Python for all data analysis tasks ( scikitlearn , pandas , scipy , and numpy libraries ) , working with geographical data ( geonamescache , geopy , and Basemap libraries ) , as well as for data processing and visualisation ( matplotlib , Basemap , and seaborn libraries ) ."	46942203	maybe
The following section will give an overview of in vitro data obtained so far on the effects of various polyphenols on main viral protein targets . Obtained in vitro IC 50 values for different polyphenols against 3CL pro and PL pro are given in Table 2 .	244369410	yes
-A DF based on statistical data was merged with a trade footprint calculated based on two different modeling approaches : process - based LCA ( CF - BU ) and input - output - based LCA ( CF - TD ) . -The elementary flows coverage was not the same for these components in the calculation of the environmental impacts of consumption : around 2,000 ( DF ) , around 15,000 ( process - based LCA trade footprint in CF - BU ) and 78 ( input - output - based LCA trade footprint in CF - TD ) . -The top - down approach ( CF - TD ) with an input - output - based LCA trade footprint included the impacts of matter - less economic sectors ( e.g. , services ) , while these were excluded from the bottom - up approach ( process - based LCA ) . -The top - down approach ( CF - TD ) was more correlated to monetary flows while the bottom - up ( CF - BU ) one followed the trend of mass flows . Regarding CF - BU , the decrease of the environmental impact can be related to the fact that more semi - finished materials or finished products are consumed in the EU . This could be the real issue at stake , i.e. , the material footprint embedded is higher but the mass which is imported is less . This again my question the represenativness of the selected products .	198689284	no
The lagged solar wind conditions governing the cases under study are given in the last three columns of Table 1 , which have been calculated using the omnidirectional ( OMNI ) data ( available fromï omniweb.gsfc.nasa.gov ) , for a location just downstream the bow shock ( case ( a ) ) , for turbulence inside the magnetosheath ( case ( b ) ) , and finally just outside the magnetopause ( case ( c ) ) .	125403825	yes
Inflammatory profiles were also investigated in WT and Pltp - KO mice after an oral gavage of LPS under a LF diet . IL-6 was significantly increased in Pltp - KO mice ( 392.05 Â± 80.30 pg / mL ) compared to WT mice ( 10.01 Â± 3.23 pg / mL ; p < 0.05 ) ( Figure 6A ) . Higher plasma LPS levels were observed in Pltp - KO vs. WT mice ( 1.06 Â± 0.05 vs. 0.80 Â± 0.04 Âµg / mL , respectively ; p = 0.0017 ) ( Figure 6B ) . One hour after LPS gavage , free LPS ( i.e. , found in the lipoprotein - free fraction , FF ) was significantly higher in Pltp - KO mice compared to WT mice ( 0.85 Â± 0.02 vs. 0.25 Â± 0.02 Âµg / mL , respectively ; p < 0.05 ) ( Figure 6C ) . In addition , LPS concentration in the duodenum mucosa was 47.7 % higher in Pltp - KO mice than in WT mice ( 13.37 Â± 0.63 vs. 9.05 Â± 0.48 Âµg / mL , respectively ; p < 0.001 ) ( Figure 6D ) . Microscopic observations confirmed the results obtained after fluorometric assays , with a higher fluorescent signal in the proximal sections of the small intestine in Pltp - KO mice ( Figure 6E ) . Next , LPS plasma distribution was determined in portal and systemic blood at an early time point after LPS gavage ( 15 min ) . In WT mice ( Figure 6F , left ) , the level of triglyceride - rich lipoprotein ( TRL)-bound LPS was significantly decreased in systemic blood compared to portal blood ( 0.24 Â± 0.08 vs. 0.51 Â± 0.09 Âµg / mL in systemic and portal blood , respectively ; p < 0.0001 ) . The same phenomenon could be observed when considering HDL - bound LPS ( 0.30 Â± 0.11 vs. 0.56 Â± 0.11 Âµg / mL in systemic and portal blood , respectively ; p = 0.0005 ) . In Pltp - KO mice ( Figure 6F , right ) , a similar decrease in HDLbound LPS was observed from portal to systemic blood ( 0.67 Â± 0.23 vs. 0.34 Â± 0.19 Âµg / mL in portal and systemic blood , respectively ; p = 0.0008 ) . However , regarding TRL - bound LPS , no decrease was observed in Pltp - KO mice , while a significant drop occurred when considering free LPS ( 1.07 Â± 0.42 vs. 0.71 Â± 0.35 Âµg / mL in portal and systemic blood , respectively ; p = 0.0082 ) . Overall , these results indicate that a PLTP deficiency exacerbates the inflammatory status through an altered plasma transport of LPS .   Figure 3E ) . Within sphingolipids species , the ceramide levels were almost doubled in Pltp - KO mice ( 5.73 Â± 1.20 vs. 2.79 Â± 0.32 nmol / mL in WT mice ; p < 0.05 ) ( Figure 3F ) . These data confirm the prominent role of PLTP in plasma lipid homeostasis , which extends beyond phospholipids to ceramides .   The oral lipid loading test led to a higher and extended TG peak in Pltp - KO mice compared with WT mice , with a higher TG AUC ( 6.23 Â± 0.48 vs. 4.55 Â± 0.38 a.u . , respectively ; p < 0.05 ) ( Figure 4A ) . Importantly , when TG clearance was blocked with a lipoprotein lipase ( LPL ) inhibitor ( LPLi ) , no differences in triglyceridemia were observed between the two genotypes ( Figure 4B ) , indicating a key role of PLTP in TG removal from plasma .	253278896	no
"Whereas the case described may look as an "" idealized "" situation , there are many complexities which can generate exceptions or issues . For example , when it comes to political communication , there could be much deliberate ambiguity . Whereas , in relation to scientific communication , there is a relevant component of unexpected and emergent knowledge discovery . These aspects have implications on the nature of information distributed and how this is used by the "" receivers "" . Complexities may derive in terms of managing flow , fit and share dependencies . For flow dependencies , a key issue is related to how much credible and authoritative is the "" provider "" of information . In this case , the distribution ( flow ) of inappropriate data ( e.g. not verified number of infected people ) can generate a distortion in the emergency management mechanism . For fit dependencies , a problem is related to the ineffective process of merging inputs ( fit ) in order to generate sociallyrelevant knowledge ( e.g. mistaken consolidation of regional data into national statistics ) . Finally , for share dependencies , a potential issue could be the arise of opportunistic behaviors which bring some actors to profit from the availability or access to a given resource by disadvantaging other users ( e.g. business use of public / open data ) ."	231729512	no
"HF2 . The second instantiation invokes the idea that food is healthy when it is natural . This association has been well investigated by Siipi ( 2013 ) , who concludes that there are multiple meanings of naturalness connected to the healthiness of food , e.g. , "" natural "" as "" familiar , "" "" natural "" as "" authentic , "" "" natural "" as "" what satisfies needs , "" "" natural "" as "" lacking human influence "" ( Siipi , 2008 ) . The equation between healthy food and natural food never comes with an explicit reference to the kind of un / naturalness involved , making this conception of healthy food particularly problematic at its internal level . Both data and ontology are indeed dependent on the kind of naturalness taken into consideration : for "" natural "" as "" customary , "" for instance , cultural norms would be the data , and the food ontology will be ethnocentric ( e.g. , insects would not count as healthy food for individuals of a certain culture , because they are considered unnatural / not familiar ) ."	238810809	no
Additionally , no additional Ti 3 + signal is evidenced through the XPS angle dependence ( inset of Figure 2c ) . The only visible difference between the capped and uncapped sample is a slight broadening of the Ti 2p3/2 peak , which may be ascribed to potential structural damage induced by the deposition of heavy species such as Au . The data suggests that this sample does not host a q2DES , which is consistent with the Hall trace measured for this sample ( Figure 1a ) . Here , the Ti 2p3/2 peak can be fitted with a single component corresponding to Ti 4 + , so that the Ti 3 + /Ti 4 + peak area ratio is ~0 ( Figure 2i ) .	205278902	no
A series of CNT dispersions with various ionic surfactants ( SDBS , SDS , SDOC , and STDOC ) were tested for complexation with astraphloxin . A comparison of the absorption spectrum of a neat solution of astraphloxin ( with constant l M ) with those of its mixtures with different CNT micelles revealed the emergence of new absorption features of the mixtures in the range of 550 - 600 nm ( Figure 6a ) . A new explicit peak at 576 nm appeared in the absorption spectra of the mixtures with CNTs dispersed with SDOC and STDOC , whereas the spectra of the mixtures with CNTs dispersed with SDBS and SDS exhibited a shoulder in that range . The peak at 576 nm is attributed to the longer shift ( up to 36 nm ) in absorption that occurs when the dye interacts with CNTs covered with deoxycholate surfactants ( SDOC and STDOC ) . As a result , the absorption peaks of the astraphloxin monomers and astraphloxin - CNT complexes do not overlap in the case of deoxycholate - treated CNTs . This longer shift can be explained in terms of a better arrangement of the astraphloxin molecules in the J - like aggregation because of the influence of the p - electron systems in the SDOC and STDOC surfactants . For excitation in the range of the new absorption peak ( 550 - 600 nm ) , we observed enhancement of the PL from the CNT levels ( E * 11 in Figure 4b ) for all mixtures containing anionic surfactants ( Supplementary Figure S9 , Supplementary Table S3 ) . The excitation maximum for the PL amplification varied from l EX 5 555 nm for SDBS to l EX 5 565 nm for SDS and to l EX 5 570 nm for SDOC and STDOC . CNTs with the ( 7,5 ) chirality displayed the maximum PL amplification for all anionic surfactants . In the histogram presented in Figure 6b , we summarize the data for the PL enhancement of ( 7,5 ) CNTs , including the reduction of the PL intensity for CNTs dispersed with neutral surfactants due to the bundling process mentioned above . The maximum PL enhancement was observed for mixtures of astraphloxin with CNTs dispersed with SDBS ( see Supplementary Tables S1 - S3 for more data ) . Thus , this study demonstrated the different effects of the dyes on CNTs of each chirality , revealing selectivity in the sensing of CNTs of various diameters . The effect is similar to the selectivity observed when sorting CNTs using SDOC and STDOC 43 . Additionally , we observed a striking selectivity in PL amplification among CNT - dispersing surfactants .	52132954	maybe
Precautions were not focused solely on security of our system , however . Any internet - facing computer can provide an attack vector for malicious actors to compromise other devices connected to the same network , such as departmental servers storing research data . Thus a virtual local area network ( VLAN ) was created for this project , into which was placed all equipment which restricted their communication to other VLAN devices only . If a breach of our network were to occur , this set up provided sufficient isolation that no other department devices could be affected .	52894522	no
Metformin is considered a cornerstone in the treatment of type 2 diabetes and is frequently prescribed Metformin is known to induce malabsorption of vitamin B-12 and may be associated with decreased folate concentrations , which might , in turn , result in an increase in homocysteine concentrations Few and only short term data exist on the effect of metformin treatment on vitamin B-12 , folate , and homocysteine	2547323	no
The measured E value varied from~11.5 to 24.4 kPa , which is close to the physiological range of the Young modulus of pulmonary tissue ( ~2 - 10 kPa ) reported elsewhere [ 46,47,89,90 ] , and depended strongly on the cell type and experimental conditions . For cells cultured on the control substrate , the stiffness recorded for healthy cells was reduced by~15 - 20 % and 20 - 25 % , compared to IPF - and NSIP - derived fibroblasts , respectively . The observed trend in cell stiffness was in accordance with those reported before - healthy fibroblasts are softer than disordered cells [ 89,91,92 ] , which may indicate an impairment of disordered fibroblasts induced by the fibrosis process . This result also fits with the fluorescence visualization of the actin cytoskeleton architecture , where large numbers of stress fibers and their characteristic arrangement into parallel fibers which modulate cellular stiffness [ 93 ] , was observed for NSIP - and IPF - derived fibroblasts cultured on glass ( Figures 2 and 3 ) . In contrast , for cells cultured on PDMS D , the determined Young moduli were slightly higher for healthy cells , as compared to their disordered counterparts . This effect may be associated with the high responsiveness of healthy fibroblasts to the pathological elasticity of PDMS D , which may significantly alter their mechanical properties [ 45][46][47][48 ] . In turn , for PDMS A , the recorded stiffness was similar for all examined cells , except the IPF - and NSIP - derived fibroblasts examined at an indentation depth of 600 nm . The measured stiffnesses reveal that for all substrates , the Young modulus decreased for deeper cell regions , which is in agreement with the literature data [ 66][67][68 ] .	246912837	no
Prepared following general procedure 2 , 3f was obtained after purification by column chromatography ( DCM : Et3N 99:1 ) as a brown solid ( 9.5 mg , 46 Âµmol , 23 % These data are in agreement with those reported previously in the literature . 16 6 - Hydroxy-6 - phenylhexanoic acid ( 3 g )	245166752	no
Using the CMO framework for realist evaluation ( Pawson and Manzano - Santaella , 2012 ) , we coded data for factors related to changes leading to the activation of mechanisms and a range of contextual features . We differentiated context according to whether it referred to the omnibus context of factors in the wider organizational environment ( e. g. , prevailing labor market conditions ) or the discrete context of intervention implementation ( i.e. , contextual factors around the intervention or stakeholders ' attitudes to WHWPs ) ( Johns , 2006 ) .	233290880	no
A transporter can potentially mediate substrate uptake and release , and its stoichiometry is a critical factor that controls the driving force and thus the transmitter flux direction . Thus , in principle , D - serine may also be released from astrocytes by reverse transport . To date , ' alanine , serine , cysteine transporter 2 ( ASCT2 ) has been the leading candidate for the reverse uptake of D - serine by astrocytes in vitro ; however , current data indicates that this probably does not occur in vivo . In situ ASCT2 is detected on neurons and retinal glia but not in astrocytes or Bergmann glia [ 141,142 ] . In addition , triggering amino acid hetero - exchange through ASCT2 transporters in vivo did not induce significant D - serine release [ 143 ] . Finally , ASCT2 transporters have a much higher affinity for L - glutamine and L - serine and , under physiological conditions , should preferentially release these molecules [ 72,143,144 ] . The contribution of astrocytic ASCT1 to D - serine release in situ is also unclear . Although ASCT1 KO reduced extracellular D - serine , indicating a role in D - serine release , the selective activation of ASCT1 hetero - exchange in acute slices did not elicit detectable release of endogenous D - serine or glycine [ 145 ] . One possible explanation is that ASCT1 reverse uptake is maximal under resting conditions . Glycine , the other co - agonist of NMDARs , can be released from astrocytes via a non - vesicular mechanism such as reverse transport by the glycine transporter GlyT1 ( reviewed by [ 102,[146][147][148 ] . The glial glycine transporter , GlyT1b , has a stoichiometry of 2Na + /Cl -/glycine , which predicts that glycine can be exported or imported , depending on the physiological conditions [ 149,150 ] . Activation of reverse uptake occurs when there is an increase in intracellular glycine or intracellular Na + and following membrane depolarization [ 149][150][151 ] . Thus reverse - uptake could occur in response to local increases in the intracellular Na + concentrations resulting from either the activation of glia AMPA receptors [ 146,149,[152][153][154 ] or enhanced Na + /Ca 2 + -exchanger ( NCX ) activity following a pure Ca 2 + response . The release is also enhanced by lowering extracellular Ca 2 + and K + [ 150 ] . In astrocytes , receptor stimulation and activation of the G q PCR - PLC signalling cascade may also enhance glycine release via GlyT1 [ 155 ] . By estimation , reversed glycine uptake could increase extracellular glycine from a sub - saturating level ( ~100 nM ) to the low micromolar range [ 146 ] . However , the functional significance of reverse transport in vivo is unknown . Some essential biophysical details are needed to clarify the role of reverse transport , e.g. , the quantification of membrane depolarization and ion concentrations in subcellular astrocytic compartments and transmitter diffusibility . The employment of Na + imaging and genetically encoded voltage sensors will provide some illumination in the future .	236209948	no
sequencing . Since the identification of an interchromosomal insertion and an inversion in CCM2 [ 8,9 ] suggests that SVs must be considered as a possible cause of familial CCM disease , we wanted to test whether long - read sequencing could accurately detect these variants . Therefore , we reanalyzed a heterozygous 24 kb inversion on chromosome 7 ( Figure 4a ) , which covers the first coding exon of CCM2 [ 8 ] , with long - read sequencing ( Figure 4b ; Table S3 ) . We used crRNAs that were part of our CCM crRNA - panel to facilitate a dual - cut excision approach covering roughly half of the coding region of CCM2 . The crRNA located upstream of CCM2 was within the variant boundaries of the 24 kb inverted region , whereas the downstream crRNA was located in CCM2 intron 3 . The wild - type allele was present in roughly half of all reads . Two different kinds of reads covering the inversion were present . In both cases , mapping orientation flipped after passing one of the inversion breakpoints ( Figure 4b ) . Due to the different types of reads generated by sequencing the inversion allele , we were able to identify both breakpoints of the 24 kb inversion . This variant was discovered previously only using short - read WGS [ 8 ] . As the variant is copy number neutral and the breakpoints lie in non - coding regions , detection via targeted panel sequencing , whole - exome sequencing , or MLPA was impossible .   A dual - cut approach was used to re - sequence a sample with a known heterozygous 24 kb inversion in CCM2 . CrRNAs facilitated sequencing in opposing directions . One binding site was located inside of the inversion ( yellow arrow ) , and the other one was located downstream of the variant ( green arrow ) . Sequencing of the wild - type allele resulted in one type of reads localized between both crRNA cut sides . Two distinct read patterns visualizing the inversion could be observed depending on which crRNA initiated sequencing of the inversion allele ( inversion reads 1 ; inversion reads 2 ) . Read data were inspected in IGV [ 23 ] . The Locus Reference Genomic ( LRG ) transcripts are shown ( b ) .	254618758	maybe
One approach to defend from adversarial perturbations is to mask gradients . Defensive distillation [ 29 ] , which distills networks into themselves , is one of the most prominent methods . However , Carlini and Wagner [ 7 ] showed that we can create adversarial perturbations that deceive networks trained with defensive distillation . Input transformations and detections [ 40,14 ] are some other defense strategies , although we can bypass them [ 6 ] . Adversarial training [ 12,20,23 ] , which injects adversarially perturbed data into training data , is a promising approach . However , there is a risk of overfitting to attacks [ 20,37 ] . Many other heuristics have been developed to make neural networks insensitive against small perturbations on inputs . However , recent work has repeatedly succeeded to create adversarial perturbations for networks protected with heuristics in the literature [ 1 ] . For instance , Athalye et al . [ 2 ] reported that many ICLR 2018 defense papers did not adequately protect networks soon after the announcement of their acceptance . This indicates that even protected networks can be unexpectedly vulnerable , which is a crucial problem for this specific line of research because the primary concern of these studies is security threats .	3655212	no
where = ( ) 0 â . Therefore , after obtaining several data points and fitting the curve by a linear fitting model , minus half of the slope is the expected weak value .	255469914	no
"Robustness was also strengthened by our data sources . Though the study was observational in nature , we were able to capture objective data on food purchases rather than relying on subjective self - reports of consumption . By analysing secondary administrative data captured over the span of two years , our assessments reflected changes of behaviour over time rather than at a single point in time under experimental circumstances . Furthermore , we identified social connections using passively - collected purchasing data rather than directly observed or self - reported information . This allowed inference of social connections on a large scale and in an objective fashion that was not influenced by social desirability or other reporting biases that may arise in primary data collection . While the practice of inferring social connections based on objectively - assessed temporal and spatial proximity is not new , it has not generally been applied to study food - related behaviours , in a relational context , using a validated measure of tie strength derived from participant observation and survey data . The stronger associations observed when the longitudinal models were restricted to dyads with a higher probability of being "" true "" helps to support the validity of both our conclusion that we are observing prospective associations consistent with a social influence process and our evidence that ties are "" true . "" Our estimated tie probability may reflect the probability that an observed tie is present in reality , or alternatively , it may be a measure of the strength of the tie between two people . In either event , we would expect higher values to be associated with stronger estimated associations in purchasing behaviour . Similarly , if associations are real , we would expect that they would be attenuated in situations where social ties are weaker or poorly measured , which is what we found ."	233371463	no
However , to what extent these potential advantages can be realized is dependent on just how smart the technology functions ; this means that different levels of smartness may exist . If the technology is not very smart yet , employees have to expend significant time in data preparation and training of the smart thing , such that people are tethered to the supposed smart thing as a form of human assistant ( Huang & Rust , 2018 ) . Only when the things achieve a higher level of smartness , such that they can deal with messy , heterogeneous data , will the people be free to fruitfully handle their specific tasks , such as interpretation and ideation . Indeed , smart things pose many new challenges to the firm , not least the difficulties of adapting existing , and often historically successful , business models to new digital possibilities . When firms fail to develop their business models in this way , they may quickly find themselves at a disadvantage compared to their digitally savvy competitors ( Benner & Tripsas , 2012;Massa et al . , 2017 ) .	213757082	no
One limitation of learning a classifier without class labels is losing the mapping ( the identifiability ) between the output nodes and the semantic class . A simple method to obtain the mapping is by using a part of the training data with class labels and assigning the output nodes to the dominant class which activates the node ( here we obtain the optimal assignment by the Hungarian algorithm ( Kuhn , 1955 ) , which is commonly used in evaluating the clustering accuracy ( Yang et al . , 2010 ) ) . Note , however , that for unsupervised problems we do not need to do this except to quantitatively evaluate our method ; otherwise the outputs can be seen as arbitrary clusters .	57375742	no
The empirical evidence on the public effects of private reporting remains limited , because the data on private engagement dialogs are not usually made public . Focusing on incident - based private reporting , this paper seeks to contribute to several strands of existing research . First , this study is related to the large - scale studies by Dimson et al . ( 2015 ) , Barko et al . ( 2018 ) , and Hoepner et al . ( 2018 ) , which analyzed the outcomes of private thematic engagement on sustainability issues . These studies examined private ESG engagements conducted by a stand - alone large institutional investor for US or UK public companies to increase the financial returns of investee companies by improving their low sustainability performance . They found that target companies responded to the demands of the institutional investor and made satisfactory changes in their business practices . Dimson et al . ( 2015 ) reported that private thematic engagements were associated with positive abnormal returns over the year following the initial engagement . The results also documented improvements in the target companies ' operating performance , sales , employee efficiency , stock volatility , and governance . Hoepner et al . ( 2018 ) showed that thematic engagement reduced downside risk and created value for a large institutional investor . Barko et al . ( 2018 ) found that private thematic engagements increased the sales growth , financial return , and sustainability ratings of target companies with the lowest ex ante sustainability ratings , but did not change their profitability . The current paper differs from these three studies because it only considers incident - based private reporting in engagement dialogs . It also analyzes global target companies and the public effects of private reporting as reflected in the performance and transparency ratings of ESG data providers , which are available to broader stakeholders .	244844197	maybe
The position of genetic markers and their physical locations in the Arabidopsis genome were obtained from Singer et al . ( 33 ) RI map . Recombination rates were calculated as the genetic distance ( in cM/50 kb ) between pairs of neighbouring informative SFP markers and plotted versus the average physical distance between the same markers . Then , the mean recombination frequency was calculated for chromosomal sections used in the study ( with 1.5 Mb windows ) . GC level was established for particular chromosomal sections using the geecee program supplied in the EMBOSS package ( 26 ) . For an analysis of TAGs we used data from Rizzon et al . ( 34 ) , but filtered against the transposable element - related sequences , as described above . The number of TAGs for each 1.5 - Mb chromosomal section was counted and divided by the total number of non - TAG genes for the section . Methylation levels were kindly provided by Xiaoyu Zhang and Steve Jacobsen ( 35 ) . These were recalculated by adding values for particular chromosomal sections . Two groups of data corresponding to two methods of methylation site identification were applied : methylcytosine immunoprecipitation [ mCIP ; ( 35 ) ] . In all the correlations calculated in the present work we used data obtained for particular chromosomes instead of averaged records for a chromosomal arm . Statistics were performed using the WINKS SDA Software ( Texasoft , Cedar Hill , TX ) .	3101910	no
We evaluated the finite - sample performance of the proposed interaction test in a simulation study that is analogous to a real nutrition - environment interaction study . We generate two groups of input features ( x i,1 , x i,2 ) â R p1 Ã R p2 independently from standard Gaussian distribution , representing normalized data representing subject 's level of exposure to p 1 environmental pollutants and the levels of a subject 's intake of p 2 nutrients during the study . Throughout the simulation scenarios , we keep n = 100 , and p 1 = p 2 = 5 . We generate the outcome y i as :	8775835	no
The global MPI itself and its associated incidence and intensity are estimated using nationally representative survey data , accounting for sampling weights and other aspects of complex survey design . This study uses the microdata that underlies the 2020 release of the global MPI ( Alkire et al . , 2020b , c ) ; Table D.1 in the appendix presents a full list of datasets , their dates , and their use in our analysis . For our microsimulations , we use 97 out of 107 countries covered by the most recent available cross - section datasets ( ' global MPI ' ) , excluding the 10 countries lacking the nutrition indicator which is essential for our simulations . For calibrating our trajectories , predicting the simulated shock in 2020 , and the final aggregation to the global level , we use data of the 70 countries for which we have two intertemporally harmonised cross - sections ( ' Changes over time ' ) ; see also Figure A.1 on this . Across these 70 countries , the global MPI datasets collectively comprise a sample of 6.4 million individuals , representing a population of over 4.6 billion individuals .	238478212	yes
WÎ³ normalization 1.13 Â± 0.08 Table 4 . Extracted SFs and the total uncertainty obtained from the likelihood fit for the contribution from misidentified electrons for the three data - taking periods , and for the normalization of the ZÎ³ and WÎ³ background components .	245577208	no
It can be shown that score matching is a special case of MPF in continuous state spaces , where the connectivity function is set to connect all states within a small Euclidean distance r in the limit of r â 0 ( Sohl - Dickstein et al . , 2011 ) . For simplicity , in the case of a discrete state space ( Bernoulli RBM ) , we can fix the Hamming distance to one instead , and consider that data states are connected to all other states 1 - bit flip away :	6079627	no
Secondly , given the genetic overlap between traits , we observed that some signals were shared between sex hormone traits but appeared to have much stronger effects in one versus others . To help derive additional genetic risk scores that reflected this , we took all genome - wide significant signals within each sex but across traits , and performed ward - based hierarchical clustering 35 on individual variant Z scores . We used the observed clusters from these analyses to produce additional genetic instruments ( Supplementary Table 16 ): 8 . A ' male SHBG cluster ' ( N = 362 ) formed from SNPs with dominant effects on SHBG in men . Each SNP in this genetic instrument is weighted by its effect from the BMI - unadjusted SHBG analysis . 9 . A ' male testosterone cluster ' ( N = 122 ) formed from SNPs with dominant effects on both total and bioavailable testosterone in men . Each SNP in this genetic instrument is weighted by its effect on total testosterone . 10 . A ' male estradiol cluster ' ( N = 14 ) formed from SNPs with dominant effects on estradiol in men . 11 . A ' female SHBG cluster ' ( N = 373 ) formed from SNPs with dominant effects on SHBG in women . Each SNP in this genetic instrument is weighted by its effect from the BMI - unadjusted SHBG analysis . 12 . A ' female testosterone cluster ' ( N = 241 ) formed from SNPs with dominant effects on both total and bioavailable testosterone in women . Each SNP in this genetic instrument is weighted by its effect on total testosterone . Gene prioritization . We used the SMR software package 36 to systematically map associated genetic variants to genes via expression effects ( eQTLs ) . For all analyses we included expression data from liver , in addition to skeletal muscle in men and adrenal gland in women . All expression data were generated by the GTEx consortium ( v7 ) , made available from the SMR website resource section ( https:// cnsgenomics.com/software/smr/#DataResource ) . Only genes passing multiple test correction and exhibiting no statistically significant evidence of coincidental eQTL overlap ( assessed by the SMR HEIDI metric ) were considered . The same data were additionally used to perform global tissue enrichment using linkage disequilibrium score regression applied to specifically expressed genes ( LDSC - SEG ) 37 .	211074514	yes
The data collection process from 2006 followed the same guidelines each year . According to the European NACE Rev. 2 classification of the industry , the sample should have reflected the Slovenian industry structure , which we transformed according to the USA 's NAICS classification . By collapsing 22 industries into ten broader industry categories , we reduced organizations ' fragmentation across numerous industries . Second , we kept the original classification of organizational size , with small organizations having below 100 employees , medium organizations having between 100 and 1000 , and large organizations having more than 1000 employees . Organizations with fewer than 50 employees dominate the Slovenian economy ( > 90 % ) and play an important role in economic development ( Bartlett & BukviÄ , 2001 ) . Additionally , we limited the inclusion of respondents from small organizations to 50 % of the sample . Medium organizations were limited to 30 % of the sample , while large organizations were limited to 20 % . Third , to reflect the ratio between the manufacturing and service organizations , we included up to 40 % of respondents from manufacturing organizations . Finally , we tried to obtain at least 150 answers to have enough cases for analyses and ensure our data 's representativeness .	237409895	no
In the first instance our results confirm the validity of the dipole model : it does make sense to speak of a universal dipole cross - section which is able to account for both soft and hard diffraction in a wide variety of photo - processes . We also attempt to ascertain the extent to which the new data are able to discriminate between the predictions of the three dipole models we use . These models can perhaps best be described as parameterisations which incorporate certain general theoretical ideas and can be viewed as providing an indication of the uncertainties remaining in the dipole cross - section once the precise structure function data have been accounted for . Unfortunately we shall find that the new data are not quite precise enough to discriminate between the models or to add any significant evidence for saturation beyond that already present in the F 2 data . We do however find that in diffractive photo / electro - production progress is hindered by the lack of a precise enough measurement of the forward slope parameter B which determines the t - dependence of the final state proton . We take this parameter from data and its error translates into an uncertainty on the normalisation of the predicted cross - sections . A more precise measurement of this quantity would provide a significant additional constraint .	10207446	no
( i ) Integration of new user - specified data sets , such as data from next - generation sequencing studies , or additional gene expression experiments . ( User input : Gene IDs and gene - based scores ) . ( ii ) Integration of copy - number variation data . ( User input : Chromosomal regions ) , ( iii ) Improved gene ranking based on large - scale textmining . ( User input : Key words ) . ( iv ) Improved GWA data - based scoring of genes .	1088040	no
In this section we go beyond the qualitative description of the strategies developed by each method and define metrics to quantify : ( a ) how much each method was able to explore the crystallization zone and ( b ) how good the data acquired were for building a model , which is to predicting crystallization of future experiments .	9036716	no
The simplest sample geometry is that of a perovskite film on glass . Therefore , we want to use this device geometry as a starting point to recapitulate the basic theory of TPL measurements and data interpretation that is already quite well understood and briefly introduce the terminology and the physical parameters that we will use during the discussion . Furthermore , we introduce the representation of the decay time ÏTPL , which results from the derivative of the photoluminescence with respect to time that we plot as a function of the corresponding time - dependent quasi - Fermi level splitting âEF .	231942588	no
Cohen here draws a comparison between improvements in systematic uncertainties and improvements in statistics ( the amount of data ) . This also recalls the concept of creativity invoked by Barrie and Rooney in their reflections in Sect . 3 . Through the comparison of improvement due increases in the available data and systematic uncertainties , we can see how it is possible to identify and measure creative contributions . This comparison process generates an improvement not attributed to an expected increase in data but rather an improvement attributed to the collaborative effort , effectively a quantification of creativity as a process . Many of the ambiguities in understanding creativity are present in this notion of creativity . Creativity is identified through a comparison of improvements in the measurement outcome , between those attributed to increases in data and those attributed to other improvements such as a decrease in the systematic uncertainties from a transformation in the model of the measurement process . This notion also lends itself to considerations of creativity as a product : unexpected improvements to the model of the measurement process . It also permits even very small improvements to be identifiers of creativity , as long as there is a net positive change across a comparison ( all other things being equal ) . 19 This notion runs counter to other previously discussed notions of creativity , as it removes any requirement for a necessary ' level ' of , or threshold for , novelty .	238769264	no
"A dynamic and active understanding of attunement has been developed in the literature on ecological dynamics . Ecological dynamics is an interdisciplinary framework that combines ecological psychology with dynamical systems theory and the complexity sciences ( Araujo et al . , 2009;Button et al . , 2020;Seifert et al . , 2017 ) . Within ecological dynamics , skilled behavior is seen as the emergence of flexible performance solutions resulting from the interplay between a skilled agent and the affordances offered in its environment . In some recent applications of ecological dynamics , the behavioral data of ecological dynamics is complemented by reports on the phenomenology of skilled action ( Seifert et al . , 2014a , b;Seifert et al . , 2017;Rochat et al . , 2019 , see also Araujo et al . , 2005 . The point here is twofold : skilled agents actively structure their coupling with the environment and this relation to the environment is experienced . 3 Our aim in this paper is to introduce the notion of "" metastable attunement "" as a bridging concept to connect ecological dynamics to phenomenology . 4 Both perspectives - the phenomenological and the ecological dynamical - capture something important about skilled agency . Phenomenology is necessary for describing the first - person lived experience of being a skilled agent acting in a meaningful world . 5 2 This ecological conception of attunement is sometimes characterized in terms of "" resonance "" . The tuning of perceptual systems to environmental information is then understood analogously to the workings of a radio : in tuning in to a specific frequency , the radio extracts information from a wealth of background noise ( Gibson , 1979 , p. 249;Raja , 2020 ) . This metaphor leaves a lot to be desired . As Heft has noted : "" a tuning fork resonates , and indeed , can not help doing so ceteris paribus . But an individual selectively engages the environment [ â¦ ] Because knowing processes are marked by an individual selectively engaging the environment , a term with a more intentional connotation may better direct the thinking here . In this respect , attunement would seem to be more suitable . "" ( Heft , 2001 , p. 366 ) . 3 The idea that our experience is our active engagement with the world is a basic commitment of the enactive approach to embodied cognition ( Varela et al . , 1991 ) . 4 This current paper is very much in agreement with a recent proposal to bridge ecological dynamics and skilled intentionality ( Araujo et al . , 2019 ) . Araujo et al . ( 2019 ) make this bridge in the context of sports science . We use insights from ecological dynamics in sports science and phenomenology to apply it to the broad range of situations encountered in everyday life . In the latter part of the paper , we point to applications in design , architecture and art . 5 Interestingly this first - person perspective ( in agreement with the enactive approach ) provides descriptions of skills in everyday life that complement empirical questions that arise within the ecological 1 3"	238723739	no
"Single crystals of 3 , 4 , and 8 have been collected on a Bruker D8 APEX - II equipped with a CCD camera using Mo KÎ± radiation ( Î» = 0.71073 Ã ) . Crystals were mounted on a fibre loop and fixated using Fomblin oil . Data reduction was performed with SAINT , [ 5 ] Absorption corrections for the area detector were performed using SADABS . [ 6 ] Structures were solved by direct methods and refined by least squares methods on F2 using the SHELX and the OLEX2 suit of programs . [ 7 ] The data collections for 3 , 8 and 4 ( M - enantiomer , CCDC = 1905846 ) were collected at 150(2 ) K , while 4 ( P - enantiomer , CCDC = 1905848 ) was collected at 100(2 ) K. Non - hydrogen atoms were refined anisotropically . Hydrogen atoms were constrained in geometrical positions to their parent atoms . Some of the solvent molecules in 3 ( DCE ) and 8 ( DCM ) showed diffuse scattering and could not be modelled satisfactorily . Their impact were treated as diffuse contribution to the overall scattering without specific atom positions and masked by the Olex2 program similar to the SQUEEZE / PLATON . [ 8 ] Compound 4 crystallized by self - sorting in the enantiomeric pair of space groups P6(1 ) and P6 ( 5 )    Density functional theory ( DFT ) calculations were carried out to identify the most stable forms of compound 4 . The weakly coordinating BF4 â counterions were not included in the molecular models , as previous studies on analogous systems indicated that the presence of the counterion does not influence the structure of the [ N - I - N ] + halogen bonded complexes . [ 10 ] We thus assume that the relative stabilities of various conformers of the "" bare "" halogen bonded cation ( denoted as 4 2 + ) would not change in the presence of the BF4 â counterions ."	149444490	maybe
General overview S39 Figure S32 : 3D graph of the data from experimenter 1 ( left ) and experimenter 2 ( right ) . View from the reducing agent perspective Figure S35 : 3D graph of the data from experimenter 1 ( left ) and experimenter 2 ( right ) . Figure S36 : 3D graph of the data from random 1 ( left ) and random 2 ( right ) . View from the acid perspective S42 Figure S38 : 3D graph of the data from random 1 ( left ) and random 2 ( right ) . Figure S39 : 3D graph of the data from random 1 ( left ) and random 2 ( right ) .	9036716	maybe
A total of 30 fresh frozen and archive samples from long - standing UC , CAC , CRC and the corresponding adjacent normal colorectal mucosa tissue were collected from patients that were attending the Endoscopy Unit , Universiti Kebangsaan Malaysia Medical Centre ( UKMMC ) , Kuala Lumpur , Malaysia . Upon admission , informed consent was obtained from each patient . Basic clinical and demographic data were gathered and analyzed while reviewing the patient 's medical records . Prior to further processing , the tissues were collected in RNAlater ( Sigma Aldrich , St. Louis , MO , USA ) and kept frozen at â80 â¢ C. An experienced pathologist examined the confirmation of the diagnosis , the level of inflammation , and the presence of metastases based on the hematoxylin and eosin ( H&E)-stained sections . Only cancer tissues with more than 80 % tumor cell content were used in this study for cancer samples . The normal samples were confirmed to be free from tumor or inflammatory cells . The Universiti Kebangsaan Malaysia Research Ethics Committee ( UKM / PPI/111/8 / JEP-2019 - 572 ) granted approval for this study .	252631535	maybe
The mission of the animal shelter was to provide care for animals in need , i.e. to find them an adoptive ' forever home ' or be ' euthanised ' . While organisational processes were based on a utilitarian ethical framing , reflective of a rationalised , distant relationship of senior leadership to the animals , the ' care for ' relationship was formed between the frontline shelter workers and the animals . Indeed , these shelter workers ' embodied actions and feelings demonstrated a concrete human - animal relationship in which animal value was intrinsic ( core aspects for the ' care for ' framing ) . The data were saturated with acts of embodied care ( see Pullen & Rhodes , 2015 ) and interspecies communication ( Donovan , 2006 ) reflected in attempts to ' read ' the dogs and understand their interests . Such noticing , in combination with the affective moments shared by workers and dogs in difficult physical and psychological circumstances , revealed aspects of worker - dog relationality , collective action and shared solidarity , elements that Burton and Dunn ( 1996 ) and Wicks et al . ( 1994 ) suggest sit at the centre of feminist stakeholder theory . But this ' relationality ' moves beyond their conceptualisations as the affective embodiment in the following entangled experience reveals : I washed Lilly as she closed her eyes enjoying the simple bath . I never wanted to take her back and felt sad at having to put her back into her pen . Wolfgang is getting better , but he 's housed with pretty crazy dogs barking and fence - running . At the end of the day , I went again to sit with him , and he lay in my lap relaxing , even with the yapping cattle dogs behind us running up and down . It was almost meditative for us both in spite of the stress and noise . I took Millie to the exercise yard because she was frantic and she relaxed , playing a bit in the grass away from the concrete ' jail ' . Hopefully she 'll get fostered soon so she can improve and feel better . ( Researcher diary )	235188204	no
As discussed previously , most of the non - energy - related environmental impacts in the life cycle of LIBs are tied to mining and material processing operations . There are various midpoint and endpoint metrics aimed at characterizing depletion of non - renewable resources . We argue that these multipliers fail to capture the nuances of some of the key inputs to battery production , where availability itself may be a secondary or tertiary concern and the more likely outcome is a long - term shift toward more costly and energy - intensive extraction methods . Rather than attempting to quantify resource depletion in a single metric , we recommend that future LCAs develop a set of current average , marginal , and incremental scenarios for the recovery and processing of a few key material inputs ( including Li , for example ) and use these scenarios to illustrate the longterm implications of continuing to extract these materials without recovering and recycling them at the battery end - of - life . The other impact most relevant to raw material extraction we have discussed here is eutrophication potential . We hesitate to recommend that this metric be included in future studies , in part because the required data on relevant waste stream discharges may not be of sufficient quality to draw meaningful conclusions from the results . Ozone depletion potential , which we briefly touch on , is not likely to be a useful metric to quantify given the ongoing phase - out of ozone - depleting substances such as CFC-11 . [ 88 ] Human toxicity does not feature prominently in non - energy - related impacts within the studies we surveyed , but as noted earlier , published values regularly rely on data provided by large mining companies [ 86 ] and those datasets likely reflect best industry practices and fail to account for the impact of outliers , particularly in artisanal and small mining operations . Omitting such outliers is a known problem in emissions and environmental impact accounting [ 85 ] and must be mitigated in future LCAs , particularly in the context of material extraction and processing .	237792009	no
As mentioned above , MTDH could not directly bind to the RKIP promoter region . Instead , it might require other transcription factors to regulate RKIP gene . According to our recent work using weighted gene co - expression network analysis ( WGCNA ) , RKIP transcripts were functionally associated with the transcription factor VEZF1 . In particular , their expression is inversely correlated with each other [ 17 ] , which is a similar pattern to the RKIP and MTDH association shown above ( Figures 2 and 3 ) . Thus , MTDH - dependent transcriptional inhibition of the RKIP gene could require the functional connection with VEZF1 . To test this possible mechanism , we first examined the binding ability of VEZF1 to the RKIP promoter region using ChIP assay . As expected , the VEZF1 protein bound to the RKIP promoter ( Figure 5A ) , and the overexpression of VEZF1 strongly inhibited the transcriptional activity of the RKIP gene in the luciferase reporter assay . The activity of the â83/+168 RKIP promoter construct ( last bar in Figure 4D ) was very similar to the transcriptional activity exhibited in cells overexpressing MTDH . These data suggest that the transcription factor VEZF1 and MTDH could form a DNA - binding complex and subsequently repress RKIP gene expression in cancer cells . We further examined how the two proteins MTDH and VEZF1 influence the transcriptional activation of RKIP gene using quantitative PCR analysis in cells in which the expression of these proteins was perturbed . As expected , knocking down MTDH increased the transcriptional activation of RKIP gene , and overexpressing VEZF1 significantly decreased the RKIP mRNA transcripts ( Figure 5B ) . However , in the case of the double perturbation ( MTDH - knockdown and VEZF1 - overexpression ) , the amount of RKIP transcripts was similar to the value obtained from VEZF1 - overexpressing cells . This result indicates that MTDH - dependent inhibition of RKIP expression is not observed at the high level of VEZF1 protein .	232380542	no
The environmental media type is discussed in order of robustness of the data ( i.e. , soil/ sediment , dust , water , food , and air ) . Appendices B - H provide further details for the literature data used in each of the meta - analyses summarized below .	201228023	maybe
We perform independence tests on the real - valued measurements which are known to contribute numerous spurious correlations . In addition to the gene expression data , we model domain knowledge based on undirected protein - protein interaction ( PPI ) edges extracted from the Yeast Genome Database :	22123481	maybe
Additionally to the ex situ measurements , we performed ex situ and in situ Raman spectroscopy to gather further insights into the activated structure . The Raman spectra in Figure 3a confirm the surface restructuring of LiMnBPO to a K-/Li - birnessite Î´ - MnO 2 related phase ( Figure S45 , Note S1 , Supporting Information ) . [ 21 ] The PXRD and SAED data ( Figures S35 and S40d , Supporting Information ) reveal the absence of a structural periodicity capable to lead to X - ray or electron diffraction . Therefore , the newly formed phase can best be described as an amorphous phase containing a birnessite - like short - range order ( called a - Î´ - MnO 2 in the following text ) . The birnessite structure comprises of MnO 2 layers accompanied by randomly distributed charge - neutralizing cations at the interlayer . Due to these cations , some of the Mn sites are reduced from Mn IV to Mn III . [ 22 ] It has been shown previously that the transformation of Mn - based ( pre)catalysts to active catalysts can follow various ( metastable ) intermediate steps . [ 7f,20,23 ] To shed light on the dynamic change in structure , we recorded in situ Raman The essential marker bands are represented with Î½ 1 , Î½ 2 , Î½ 3 , Î½ 4 , and Î½ 5 , respectively . c ) XANES and d ) Fourier transformed EXAFS measured at the Mn K - edge of as - prepared powder , as - deposited , and the film after water oxidation catalysis further validate the results obtained from Raman spectroscopy . EXAFS simulation parameters and experimental data in k - space are shown in Tables S9 and S10 and Figure S47 in the Supporting Information . spectra of LiMnBPO / FTO at a current density of 10 mA cm â2 . Between 200 and 700 cm â1 , several Î½ 5 , Î½ 4 , Î½ 3 , Î½ 2 , and Î½ 1 at 407 , 477 , 510 , 578 , and 637 cm â1 , respectively ( Figure 3b ) , were observed within a minute , which became more pronounced with increased time intervals ( up to 24 h ) . The Î½ 2 band observed at 578 cm â1 is attributed to the in - plane MnîO stretching modes along the octahedral layers in a - Î´ - MnO 2 , while the bands at 510 ( Î½ 3 ) and 637 cm â1 ( Î½ 1 ) are associated with out - of - plane MnîO vibrations perpendicular to the layers . [ 9a,9b ] Notably , the Î½ 1 band is red - shifted ( 653 cm â1 ) from its positions in Mn IV a - Î´ - MnO 2 and matched perfectly with K - birnessite with a mixed Mn III / IV valence state . [ 21 ] The observed Î½ 3 and Î½ 4 bands are only present in intercalated Mn III / IV birnessites . The Î½ 5 band appears as a doublet peak for pure Mn IV phases and not as a singlet peak , as observed in here . [ 9a,21 ] The successive insertion of K was also indicated by the increase in Î½ 2 /Î½ 1 ratio , which is in line with the EDX and ICP - AES results . [ 21 ] The vibration at 948 cm â1 can be assigned to the symmetric stretching of PO 4 units , which decreases over time due to the successive loss of P with the growth of the active a - Î´ - MnO 2 layer ( Figure S46 , Supporting Information ) . [ 24 ] Hence , the Raman spectra show the presence of mixed - valence Mn III / IV K-/Li - intercalated a - Î´ - MnO 2 on the surface of LiMnBPO during OER . This behavior stands in contrast to the one of electrochemically synthesized birnessite , where in situ Raman studies revealed the complete oxidation from Mn III / IV at open circuit potential to Mn IV under OER conditions . [ 25 ] This demonstrates that the in situ transformation of LiMnBPO is indeed a successful strategy to form a K - containing a - Î´ - MnO 2 phase with abundant Mn III even under highly anodic potentials to efficiently catalyze water oxidation .	231700984	maybe
Need - expected utilisation was computed at the LSOA level using regression - based indirect standardisation methods ( O'Donnell et al . , 2008 ) . The following equation was estimated by OLS , separately for each year of the data :	3174407	no
The synthetic genetic interaction between exo1 and mus81 prompted us to analyze whether these nucleases interface in promoting collapsed replication fork transitions . SEEs can act on similar in vitro ( 49 ) and in vivo substrates ( 45 ) . We therefore extended our 2D gel analysis to yen1 and slx1 mutations to cover for possible redundancies in fork processing . We failed to observe differences in the replication intermediates of rad53 ( data not shown ) or rad53 exo1 cells , upon single mus81 ( Figure 3B ) , yen1 or double mus81 / yen1 deletion ( Supplementary Figure S1 ) . Similarly , slx1 ablation did not alter the 2D gel profiles of rad53 ( data not shown ) or rad53 exo1 cells , even if combined with mus81 and/or yen1 deletions ( Figure 3C ) . We also failed to detect differences in the 2D gel profiles of rad53 and rad53 exo1 cells upon ablation of rad1 or saw1 ( data not shown ) . These observations indicate that Mus81 , Yen1 , Slx1 and Rad1 SSE nucleases are dispensable for the aberrant fork transitions observed in checkpoint deficient cells . We note , however , that the synthetic HU sensitivity observed in exo1 mus81 checkpoint proficient cells points at an overlapping role for these nucleases in stalled fork metabolism , perhaps related to the resolution of fork - derived structures later in the cell cycle ( 43,50 ) .	4385694	maybe
) , all we need to know is N Ci / N Xi and F Xi . N C and N X can be measured by cell counting at the time of mixing cell cultures . Simpler still , under steady state conditions ( i.e. in exponentially growing asynchronous cultures ) N C /N X is given by W C /W X , where W C and W X are the reads assigned to genomes C and X in aliquots from our samples that have not been immunoprecipitated ( whole cell extracts or WCE ) . Meanwhile , F X = IP X /(IP X + IP C ) , where IP X and IP C are derived directly from the sequence data . As a consequence ,	18321962	no
To determine the past performance effects of water performance in particular , we used the same regression specification , replacing the high strength dummy and high concern dummy of overall CSR performance with the water performance measure derived from Trucost water data .	237756669	no
Content uniformity was tested following US Pharmacopeial ( USP ) â© 905 âª . Table S1 gives the values of % content of 6 in tablets for 26 tablets assayed during the period shown in Figure 3b . The standard procedure for USP â© 905 âª involves testing 10 random tablets from a batch ; however , no batches are defined in continuous processes . The data pass the test for most sets of 10 random tablets , but the 5 tablets produced at 200 min have systemically low % content and can cause the test to fail . This is due to all having low tablet mass , nominally 0.400 g , while the composition is correct , nominally 34.1 wt% 6 . If these underfilled tablets are removed from the dataset , the test works . If all 26 tablets are subjected to the 30 tablet version of USP â© 905 âª with and without 4 additional random tablets selected from within the list ( duplicated ) , then the set also passes . This is not a conservative modification to the test , but the deviation from 30 tablets is small so it is expected that a complete set would pass as well .   Figure S7 . Micrograph of 6 crystals formed in Cr2 .    Intensity 2Î¸ / Â° Table S5 : Levels of key impurities throughout process . Values of area% are based on peak area from HPLC . This value is close to the mol% given similar chromophore and high purity of most streams . Process position C / area% product C / area% impurity S1 to Cr1 [ a ] 89.5 4.80 D1 to M3 [ a ] 98.7 0.18 M4 to S3 [ b ] 93.0 2.30 D2 to M5 [ c ] 99.5 0.10 S7 to E1 [ c ] 99.7 0.11 Final tablet [ c ] 99.7 0.13 [ a ] Product is 4 and impurity is 1 which is not observed downstream of R2 .	24774334	maybe
where x max is the x - coordinate at the point of highest step - height ( y max ) , and N the number of data - points recoded per gait cycle . In order to prevent jittering due to cycle - to - cycle variability , the estimate of the center of rotation was iteratively updated at every gait cycle as :	279926	maybe
, then performing the first order Taylor Expansion for the second term , a term of W yi X i shows up . Therefore , minimizing Eq.3 is to minimize W yi X i to some extend , and it can be viewed as a coupling decay term , i.e. data - dependent weight decay and weight - dependent data decay . It regularizes the norm of both feature representation and the parameters in classifier layer such that improves the generalization ability of deep models by reducing over - fitting . Moreover , it is supported by some experimental results , e.g. the feature norm in Fig.2 is decreased by Virtual Softmax ( e.g. from 100 to 50 in 2 - D space ) , and the performance improvement over the original Softmax is increased when using a much wider network as in Sec.6.1 ( e.g. in CIFAR100/100 + , increasing the model width from t=4 to t=7 , the performance improvement is rising , since increasing the dimensionality of parameters while keeping data set size constant calls for stronger regularization ) .	54040264	no
The foundational idea of statistical analysis , both frequentist and Bayesian , is that data are understood through a mathematical model that mimics the data . A mathematical model is a machine that generates random values around a trend . The machine has control knobs , called parameters , that determine the location of the trend and the spread of the randomly generated data around that trend . For example , numerical data that when plotted appear as a unimodal histogram might be described as a normal distribution , which is a mathematical function that has ( 1 ) a mean parameter that specifies the trend location and ( 2 ) a standard deviation parameter that specifies the spread of random values around the trend . In this example , the data are understood through the normal distribution that mimics it . The essential goal of statistical analysis is to find a mathematical model and its parameter settings that usefully mimic the data , along with the uncertainty of those parameter settings . Therefore , every report of a statistical analysis ( whether Bayesian or frequentist ) must clearly explain the mathematical model and all of its parameters .	237149547	no
In this section , we describe the dependent and independent variables used in our econometric models . These models aim to determine the factors that significantly impact consumer mobility activities as a consequence of the COVID-19 pandemic . We combine four main sources of data : 1 ) Google Trends data , 2 ) Google Mobility data , 3 ) Data on mortality and number of infections due to COVID-19 , and 4 ) Twitter data ( tweets ) relating to the COVID-19 pandemic .	255441206	yes
The water layer on top of the sample was â15 mm thick . The absolute light absorption by the solution would lead to a decrease of 4 mA cm â2 if it is assumed that every photon leads to an electron . [ 23 ] The absorption was calculated by the Lambert - Beer relation and integrated over the solar spectrum in the range of 300 - 1200 nm , which is in agreement with the data presented by DÃ¶scher et al . [ 29 ] The data clearly indicate that water starts to absorb light from 950 nm and above . When looked at the IPCE data of our employed PV cell , [ 3 ] the top cell generates â8.6 mA cm â2 , the middle cell â9.2 mA cm â2 , and the bottom cell â17.1 mA cm â2 . The employed middle cells absorb light till â900 nm , therefore only the bottom cell is affected by the water layer , however produces more than enough current to compensate in the current matching .	132976355	no
To demonstrate the generality of our DSL approach , we trained DSL and optimized LSF for each of the two datasets separately and repeated the above comparisons . The accuracies of the two DSL models are consistently better than that of LSF ( Figs . S1 and S2 ) by approximately three times ( Table S1 ) . Even when we used data from one reference for training / optimization and tested models on the data from the other reference , DSL still outperformed LSF by more than four times ( Fig . S3 , Table S1 ) . Interestingly , the uncertainty estimated by DSL increases significantly to~10 % when the networks are tested on a completely new data source ( Fig . S3 ) , truthfully reflecting the lower confidence levels of the two networks in this situation .	181990850	no
According to predictions of the Standard Model ( SM ) the production of multi - lepton final states in electron 1 -proton collisions proceeds mainly via photon - photon interactions [ 1 ] . The clean experimental signature of leptons with high transverse momenta , P T , together with the precisely calculable small SM cross section provides high sensitivity to possible contributions of physics beyond the SM . Measurements of multi - lepton production at the HERA collider have already been performed by the H1 [ 2][3][4][5 ] and ZEUS [ 6 ] collaborations using data samples corresponding to an integrated luminosity of â¼ 0.5 fb â1 per experiment . Events with high invariant mass M 12 of the two highest P T leptons or high scalar sum of transverse momenta of all leptons P T were measured by both experiments in a region where the SM expectation is low . The yields of multi - lepton events were found to be in general agreement with the SM predictions in both H1 and ZEUS analyses .	119214612	no
As this paper covers different topics it was necessary to arrange them into a clear structure , as follows : section 2 describes the LCA methodology and the application to the present case study ; section 3 presents the experimental program including testing results and data collection for the life cycle inventory analysis ; section 4 provides the life cycle impact assessment results and discussion and section 5 reports the conclusions .	225159599	no
Here , we introduce an ambient - temperature 2D Janus monolayer synthesis technique that integrates in situ optical spectroscopy to monitor and optimize the growth to achieve quantum - quality Janus materials , with extremely narrow exciton linewidths and fewer defects , by converting them from their parent classical layers ( Figure 1a ) . The microresolution deterministic approach can handle CVD or exfoliated monolayers , with a wide range of TMDs , to experimentally realize a variety of Janus structures . The overall reaction is carried out inside a homemade glass chamber ( Figure 1b ) with a large - diameter optical window . The chamber is coupled to Raman and PL spectrometers for real - time data collection to assess how the reaction proceeds and is supported by a threeaxis micromanipulator stage for precise measurement on the desired monolayers . The prototype chamber was designed after a careful consideration of the flow dynamics and yield of the neutral radicals in the hydrogen plasma , as well as the thickness of the top glass piece that was also engineered to be compatible with the numerical aperture of the objective lens , thus improving the spectroscopic signal received from monolayer samples ( for more details , see the Experimental Section ) . N6.0 ultrapure hydrogen gas is introduced through the upstream gas port , and the plasma is generated downstream using an inductively coupled radio - frequency ( RF ) generator ( Figure 1b ) .	244528626	no
The kinematic models show that components a and b exhibit similar rotation curves : the circular velocity rises rapidly within 1 kpc and eventually reaches a plateau of â¼ 500 km s â1 . Beyond â¼ 5 kpc , the S / N of the line emission becomes too low to trace the kinematics . All disk   + c ) , showing as the PV moment-0 maps , by collapsing and summing CO J = 7 â 6 and [ C I ] 3 P2 â 3 P1 emissions along the best - fit minor axes of components a and b , respectively . The x - axis represents the spatial offset along the major axis of the disk model center for component a or b , and the y - axis is in the line - of - sight radial velocity calculated at zsys = 2.308 . Larger panels show the data , models , and residuals , with contours representing 10 , 40 , and 90 % of the peak values from the data map . The disk rotation curves are overlaid in white lines after the amplitudes are multiplied by inclination correction factors of sin(i ) . The smaller panels below show the model emission contributed by individual disk rings , labelled with their radii . models suggest V max /Ï 0 3 , where Ï 0 is the intrinsic gas dispersion 7	119235985	maybe
Both programs have the common feature that they are based on one single Fortran code ( NMHDECAY SLHA.f or NMHDECAY SCAN.f ) that does not need to be linked with any other code . However , both programs need data files in order to check against negative Higgs searches at LEP in the numerous channels discussed in section 4 . These data files are available in the directory LEPCON , that can be downloaded from the NMHDECAY home page . Note that the directory LEPCON has to be situated in the same directory that contains the executable NMHDECAY code . We now discuss the particular features of the two programs .	13871951	yes
pixel coordinates of the centroids . With the obtained pixel coordinates , our code then used the least squares method to find the astrometric plate constants with the Gaia DR2 catalogue ( Gaia Collaboration et al . 2018 ) , whereby we could then convert the pixel coordinates of 2020 XL 5 , whose image profile was simply treated as a bidimensional Gaussian , to the R.A. and decl . coordinates in the J2000 system . The astrometric measurement uncertainties were estimated via error propagation by assuming the Poisson statistics for the observing data . Our results are tabulated in Table 1 . We estimated the seeing using the full - width at half maximum ( FWHM ) of the asteroid as well as the FWHM of star trails in the cross - track direction , finding that the values varied between â¼0 . 6 and 1 . 0 from night to night .	243860678	maybe
This paper is based on literature and desk review , and discussions among a group of IT experts , epidemiologists , and microbiologists who were convened by WHO SEARO in September 2016 in New Delhi , India . The group reviewed ways in which IT might improve AMR surveillance in SEAR countries . The discussion proposed a roadmap to generate local and national surveillance of AMR trends in human health using IT in the first instance . It acknowledged the importance of good quality laboratory data , their representativeness and antibiotic resistance in other contexts , such as AMR surveillance in animals and surveillance of antibiotic usage in both humans and animals used for food .	11584755	no
However , w hen the BCC phase evolves to form aH EX phase ( at an intermediate PhBD 80 -PBzMA 33 composition ) , the mean inter - cylinder distance within the 2D hexagonal phase is significantly smaller - by up to 2nm - than the intersphere distance within the co - existing HCP phase ( and indeed the precursor BCC phase ) . Park et al . reported similar observations for PS - PI diblock copolymers dissolved in diethyl phthalate ( a selective solvent for the polystyrene block ) during at hermally induced transition from aB CC/ HCP phase to ahexagonal lyotropic phase . [ 57 ] These findings suggest that the spherical micelles fuse to form cylinders along the BCC h111i direction during the BCC - to - hexagonal cylinder phase transition . [ 65 ] If this is correct , then the mean distance between columns of spheres that fuse along the h111i directions should be equivalent to the inter - cylinder distance . Thevalue calculated for the BCC phase just prior to the phase transition ( 22.0 nm ) agrees rather well with the inter - cylinder distance of 22.2 nm determined after the transition . The observed transformation of spheres into worms during the PISA synthesis is favored because of the crystallographic relationship between BCC and HEX phases . H owever , spheres packed in another ( e.g. H CP ) phase maintain their particle morphology until the BzMA polymerization is complete . A sf ar as we are aware , t his is the first demonstration that such aphase transition can be induced during the synthesis of diblock copolymer chains . I nt his context , it is noteworthy that Hillmyer and co - workers reported using RAFT polymerization in the absence of solvent to drive microphase separation in the solid state , b ut the resulting Figure 5 . A ) Reaction phase map recorded during the PISA synthesis of PhBD 80 -PBzMA 40 diblock copolymer nano - objects at 40 % w / w solids in n - dodecane . Colored symbols denote domain spacingsw ithin different phases calculated from time - resolved SAXS data , while black crosses indicate the mean degree of polymerization ( x)ofthe insoluble PBzMA block calculated from in situ 1 HNMR studies . The two dashed lines shown on the left indicate the approximate time points at which the disorder - order and order - order phase transitions occur . B ) Schematic cartoonsi llustrate the inter - sphere distances for the hexagonally close - packed ( HCP ) and body - centeredcubic ( BCC ) phases and the inter - cylinder distance for hexagonally packed cylinders ( HEX ) . The green spheres and cylinders represent the PBzMA cores of nanoobjects that form structured arrangements within acontinuousphase comprising PhBD 80 chains and n - dodecane . diblock copolymers did not form such highly ordered structures . [ 88][89][90 ] Conclusion Time - resolved SAXS has been used to monitor the evolution in copolymer morphology that occurs during the PISA synthesis of PhBD 80 -PBzMA 40 diblock copolymer worms at 90 8 8Ci nn - dodecane when targeting 40 % w /w solids . Asthe structure - directing PBzMA block grows during this PISA synthesis , t here is ag radual evolution from molecularly dissolved copolymer chains to spheres to closepacked spheres ( BCC / HCP phases ) to afinal mixture of HEX and HCP phases ( where HEX denotes hexagonally packed cylinders - or partially aligned worms - and is the major phase ) . SAXS analysis suggests that this HEX phase is generated via sphere - sphere fusion within the BCC phase . T o the best of our knowledge , this is the first time that any longrange order has been observed for block copolymer nanoobjects during their PISA synthesis . Itisemphasized that this is achieved using an amorphous core - forming block , rather than a(liquid ) crystalline block . [ 49 ] Serial dilution of the HEX/ HCP phase leads to the formation of ad isordered phase comprising mainly non - interacting worms at 1.0 % w /w . Thermal annealing of the as - synthesized 40 % w /w PhBD 80 -PBzMA 40 dispersion induces acylinder - to - sphere transition at 150 8 8Ct op roduce ad isordered sphere phase . O nc ooling to 25 8 8C , the spheres form an HCP lattice , j ust like the minor phase that co - existed with the HEX phase during PISA . The observation of al amellar phase for the near - symmetric PhBD 80 -PBzMA 40 diblock copolymer in the solid state indicates that selective swelling of the PhBD 80 block by ndodecane results in myriad ordered morphologies that are generated during the BzMA polymerization and/or upon thermal annealing . F inally , t he basic principles of block copolymer self - assembly suggest that our observations should also apply to other PISA formulations . [ 11,46,48 ] However , further work is required to confirm such generic behavior .	232262823	no
The authors declare no conflict of interest . The funders had no role in the design of the study ; in the collection , analyses , or interpretation of data ; in the writing of the manuscript , or in the decision to publish the results .	220850522	no
From the time series observations obtained between 2005 and 2019 , we have built eight different light curves . Additionally , we used data published in the literature by Jewitt & Sheppard ( 2002 ) ; Lellouch et al . ( 2002 ) and Hicks et al . ( 2005 ) , thus incorporating three additional light curves to our study from previous years ( figure 1 ) . All the light curves were corrected from light travel time . Because Varuna 's body is assumed to have an ellipsoidal shape ( e.g. , Jewitt & Sheppard 2002;Lellouch et al . 2002 ) , data from each light curve were fitted to a Fourier series m = Î£ i [ a i sin(2iÏÏ ) + b i cos(2iÏÏ ) ] , where m is the theoretical value of the relative magnitude obtained from the fit , Ï is the rotational phase ( calculated as the fractional part of ( JD â JD 0 ) /P , where JD is the Julian Date , JD 0 = 2451957.0 is the initial Julian Date , and P is the rotation period in days ) , and ( a i , b i ) are the coefficients of the Fourier function ( with i = 0 , 1 , 2 , ... ) . In our specific case , we used up to secondorder ( i = 2 ) or up to fourth - order ( i = 4 ) Fourier functions . The second order is the minimum order that allows a double - peaked fit ; however , higher orders take into account small deviations on inhomogeneous objects and can be used to fit light curves that are highly sampled . The 2001The , 2002A , 2011The , 2018 and 2019 light curves were fitted to a fourth - order function , while the remaining light curves were fitted to a second - order Fourier function , because the number of data points in those runs was not large enough to use a higher order . Data were folded using Varuna 's rotation period of 6.343572Â±0.000006 h , which is obtained using the Lomb periodogram analysis of all our data , in agreement with the previous one reported in Belskaya et al . ( 2006 ) . The peak - to - valley amplitudes âm ( amplitudes in the following ) of each light curve are given by the absolute maximum and minimum produced by the fits . Table 1 contains the results from the fit to each light curve , i.e. , the amplitude and the dispersion of the residuals of the Fourier function fit to the observational data . One of the evident results is that the amplitude has changed considerably along these 19 years , with an increase of â¼ 0.13 mag . Online table 2 presents all the relative photometry observations from 2005 to 2019 .	202558865	yes
"Early in 2020 , media coverage emphasized the "" unprecedented "" nature of the COVID-19 pandemic : memes depicted humanity , caught in a single boat out at sea ; others celebrated solidarity as people sang from balconies or clapped for healthcare workers . While there are many novel aspects to the COVID-19 pandemic , it has also exacerbated familiar fault lines of inequality and socio - economic disparities , and created new ones . This paper offers a unique perspective on the lived experience of the pandemic from a qualitative interview study drawing from data in six European countries as part of an emerging field of cross - national research on social inequalities in health ( Health Inequalities , 2020 ) . We explore how health - and wealth - related inequalities reverberate through the lives of our participants , and intersect to produce the "" second pandemic , "" a term used by a participant to explain the entangled social and economic devastation that runs in parallel with the virus ."	244902343	maybe
Providing confidence estimates on causal predictions is extremely helpful in practice , and can significantly boost reliability of the output as perceived by researchers . Although standard methods to do so , like bootstrapping ( C)FCI , already provide reasonable estimates , having a global optimization method that take into account all confidences in the input causal and independence statements is likely to lead to further improvements of the reliability of causal relations inferred from data .	949525	no
"Finally , we apply the "" history method triad "" ( Bucheli & Wadhwani , 2014 ) including : ( i ) source criticism , i.e. , acknowledging the potential intrinsic biases in the source material ; ( ii ) hermeneutic approach , i.e. , contextualize the actions and motives of individuals emerging in the empirical material as "" temporally "" embedded and constrained ; ( iii ) triangulation , i.e. , cross - checking data for convergent or divergent interpretations ."	237212641	no
We have found that center - projected lattices are more sensitive to finite size effects than are unprojected lattices , and precision results for center - projected Creutz ratios require lattice sizes which are large compared to one fermi . If accurate numbers ( rather than just qualitative results ) are required , then center - projected data from numerical simulations must be tested for convergence with respect to : ( i ) increasing the lattice size ; ( ii ) increasing the number N copy of gauge copies used for center gauge fixing , and ( iii ) strengthening the gauge - fixing convergence criterion . Our work was stimulated by the recent findings of BKPV [ 16 ] , who have demonstrated a significant N copy -dependence for center - projected Creutz ratios obtained on relatively small lattice volumes . In the large N copy limit , a large deviation ( â 30 % ) was found between the string tension on unprojected and projected lattices . Our result in the present article is that this N copy dependence is greatly reduced as lattice size increases , and center projected Creutz ratios Ï cp ( I , I ) appear to converge to values which are quite close to the asymptotic string tension obtained on unprojected lattices .	17072099	no
In exploring the mechanisms by which RA suppressed the production of pro - inflammatory cytokines in zymosan - treated DCs , we observed an increase in the expression of Socs3 in zymosan - treated DCs , relative to the untreated DCs in our microarray analysis ( data not shown ) . This was confirmed by RT - PCR ( Fig . 3d ) . Addition of retinol to the culture further increased Socs3 expression to approximately 20 fold ; in contrast , addition of the RAR antagonist significantly reduced the Socs3 mRNA expression ( Fig . 3d ) . Thus Socs3 is inducible upon zymosan stimulation and is partly dependent on RAR - mediated signaling . Consistent with this , knock - down of Raldh2 in DCs using siRNA significantly reduced the induction of Socs3 in response to zymosan ( Supplementary Fig . 9 ) . Furthermore , IL-10 also enhanced the induction of Socs3 expression by zymosan ( Fig . 3e ) . DCs from Il-10 â/â mice stimulated with zymosan showed a significant reduction in Socs3 expression , relative to wild type DCs ( Fig . 3d , e ) , but this defect could be corrected by the addition of exogenous IL-10 or retinol to the culture ( Fig . 3e ) . Consistent with these in vitro observations , zymosan induced a significant increase in Socs3 expression in DCs within 3 hours in vivo ( Fig . 3f ) . Furthermore , treatment of mice with disulphiram or LE135/540 reduced the level of Socs3 expression in vivo upon zymosan injection ( Fig . 3 g ) . Induction of Socs3 was dependent on TLR2 , as zymosan induced much lower levels of Socs3 in Tlr2â/â mice , relative to wild type mice ( Fig . 3h ) .	13330925	no
Transcripts were entered into NVivo 10 and analysed using thematic analysis . Following the method described by Braun and Clarke ( 2006 ) , each transcript was first read over by a researcher and an initial set of codes was generated and applied to the transcripts on subsequent readings . Codes that shared similar meanings were grouped together , and these groupings were reviewed and revised until the coded data had been organised into a set of internally consistent themes . The final set of themes were reviewed by another researcher familiar with the transcripts to check that they accurately reflected the content . Participants are referred to with pseudonyms throughout the reporting of the results .	145052332	no
While these methods can be also used in a RCT framework to complement the primary cost - utility analysis- , an increased use of available secondary data in NE 's is likely to justify further use of CBA , CCA and MCDA ( item 5.2 ) .	56178677	no
Having optimized the CPV performance for a true value sin 2 2Î¸ 13 = 0.1 in the previous subsections , we now relax this assumption 6 and discuss the sensitivities of these optimized configurations as a function of Î¸ 13 . We consider the upgraded beams for T2 K and NOÎ½A combined with reactor data , and show results for CPV as well as for the neutrino mass hierarchy . Fig . 12 shows the discovery potential as a function of true sin 2 2Î¸ 13 and fraction of true Î´ CP for times from 2015 to 2025 . The upper row of this figure shows the discovery potentials at the 90 % CL . These results can be compared to Fig . 8 ( upper panels ) , where one should note the different scales on the vertical axes . Obviously , with the optimal upgrade plan , there is a significant improvement of the MH and CPV discovery potentials . At the 90 % confidence level , there will be hints for the MH and CPV for sin 2 2Î¸ 13 0.05 for most values of Î´ CP around 2025 .	2658041	no
Supplementary Figure 3 : Workflow to simulate ChIP - seq data . First , unassembled and repeated regions are marked and ignored in the further progress . We then uniformly place domains of proteins in the genome . Here , domain D 1 contains proteins P 11 , P 12 , P 13 and P 14 , and Domain D 2 contains proteins P 21 , P 22 and P 23 . The spacing between two proteins of a domain , e.g. b 2 between protein P 12 and P 13 , is sampled from a mixture normal distribution . Next , fragments are assigned to a protein , e.g. fragment F 148 is associated to protein P 14 . In the next step , fragments are assigned to both biological conditions ( S1 , S2 ) as well as replicates ( black , white ) . We add noise to the data and define reads as the beginning or ending part of the fragments . We find a DP gaining S1 and another DP gaining S2 in domain D 1 .    = 100 , H = 1000 ) . We evaluate the initial parameter setting of THOR , that is , t 1 â { x .95 , x .99 } and t 2 â { 1.3 , 1.6 } where t 1 is the fold change criteria and t 2 the minimum difference between signals based on percentile estimates ( see main document Section 4.3.4 for details ) . The analysis is restricted to chromosome 1 . For each metric , the methods are displayed in decreasing order with their respective Friedman ranking .       Table 5 : Friedman - Nemenyi test results based on the AUC statistic of simulated data for all scenarios . The asterisk and the cross , respectively , mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1 .   Table 6 : Friedman - Nemenyi hypothesis test results for the AUC metric . We consider the case with 2 replicates , low within condition variance , and moderate peak size variability . The asterisk and the cross , respectively , mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1 .   Table 7 : Friedman - Nemenyi hypothesis test results for the AUC metric . We consider the case with 2 replicates , medium within condition variance , and moderate peak size variability . The asterisk and the cross , respectively , mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1 .   Table 8 : Friedman - Nemenyi hypothesis test results for the AUC metric . We consider the case with 2 replicates , high within condition variance , and moderate peak size variability . The asterisk and the cross , respectively , mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1 .   Table 9 : Friedman - Nemenyi hypothesis test results for the AUC metric . We consider the case with 2 replicates , low within condition variance , and high peak size variability . The asterisk and the cross , respectively , mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1 .          H = 10000 ) . The asterisk and the cross , respectively , mean that the method in the column outperformed the method in the row with significance levels of 0.05 and 0.1 .	16233871	maybe
Normalization of wastewater data neither changed the mutation frequencies nor their dynamics but slightly modified the reported concentration ( Fig . 4 , panels A , B and C ) .	251179599	no
"We adopted a case study methodology ( Yin , 2009 ) based on ethnography , semi - structured in - depth interviews with key informants ( Yin , 2009;Robinson and Shumar , 2014 ) and a survey . A case study is preferred when the research questions are "" how "" or "" why "" and require a simple observation of the social phenomena and an interpretation by the researchers ( Ryan et al . , 2009 ) . Consequently , different possibilities are generated according to the researchers ' different perspectives ( Glaser and Strauss , 1967 ) and results may be predicted by looking for a literal replication ( Yin , 2009 ) . Ethnographic Case Study research is defined as the application of the ontological , epistemological and methodological features of ethnography to a theoretically selected set of business cases ( Visconti , 2010 ) . This methodology is useful for the events that can not be controlled and to support researchers in collecting qualitative data for building theory ( Eisenhardt , 1989 ) ."	231690009	no
Semi - synthetic Data : Following [ 5 ] , we generate semi - synthetic corpora from LDA model trained by MCMC , to ensure that the synthetic corpora retain the characteristics of real data . Gibbs sampling 5 http://qwone.com/Ëjason/20Newsgroups NonâCatchwords Catchwords Figure 1 : Plot of q i ( Î¶ , l ) for some random catchwords ( left ) and non - catchwords ( right ) . Each of three plots for catchword is for one topic ( l ) with two random catchwords ( i ) for each topic and each plot on right is for one non - catchword ( i ) with curves for multiple topics ( l ) .	15386282	yes
The fi eld distribution at the fundamental frequency is calculated by using a commercially available software tool , RSoft 's DiffractMOD . [ 44 ] The code implements a numerical method widely used in the analysis of optical properties of diffraction gratings , namely the rigorous coupled - wave analysis method . It consists in decomposing in Fourier modes the refl ected and transmitted fi elds as well as the distribution of the dielectric constant , the corresponding modal amplitudes being determined by integrating across the structure a system of ordinary differential equations defi ned by the boundary conditions at the input and output facets of the periodic structure . The Fourier modes consist of both propagating and evanescent waves , which allows one to rigorously determine the spatial profi le of the near - fi eld and the energy content of the diffracted far - fi eld . In our simulations , numerical convergence has been reached if 26 Fourier modes ( diffraction orders ) were used for each transverse dimension . Moreover , we assumed that the dielectric constant of gold is described by the Lorentz - Drude model , with the interband effects being described by a superposition of four Lorentzians . [ 45 ] Linear Optical Characterization : The UV - Vis measurements were carried out with a Perkin Elmer Lambda 900 UV / VIS / NIR Spectrometer . The CD - spectra were acquired with a Jasco J-810 Spectropolarimeter . The goniometer data are obtained with a home - built rig featuring an Ocean Optics Spectrometer ( QE65000 ) with detection range : 200 - 980 nm , the light source was an incandescent white light lamp with spectral range 200 - 2000 nm . The limiting factor for the wavelength range of the equipment was the wideband achromatic quarter waveplate 500 - 900 nm ( B. Halle ) . Light was focused on the sample to a spot of approximately 1 mm in diameter .	14188430	maybe
Mechanistic studies of catalytic reactions have become more common in academia and industry owing to their value for improving processes and also thanks to the availability of new technology to easily monitor the progress of ar eaction . Then ew reaction monitoring techniques can generate abundant , good - quality data during the entire course of areaction , but very few methods have been developed to exploit these features to extract mechanistic information . [ 1 ] Herein , as imple graphical analysis that uses all the reaction profile data to establish the order in catalyst is reported .	6582991	no
Confusion matrix for model recovery in the JG . Choices were simulated according to each model and then re - fit according to all six models . Darker colors indicate a lower probability that the fit model is the best model for the simulated data . Lighter colors represent cases with high probabilities .	236219670	no
Of the available models developed , LANCA Â® ( original model in Beck et al . , 2010 ) , as in the recent version released by Bos et al . ( 2016a ) , was selected as the recommended model for the impact evaluation in the Environmental Footprint ( EF ) framework ( Sala et al . , 2018 ) . This model was originally developed to assess the impact of different interventions involving land use on five soil functions , i.e. biotic production ( BP ) , groundwater recharge ( GR ) , erosion resistance ( ER ) , mechanical filtration ( MF ) and physiochemical filtration ( PF ) , based on site specific data . The reasons for selecting this model for the EF framework were that :	92988643	no
"We next assessed whether our observed phenomena in rodent models were relevant in human stroke 46 by reanalyzing invasive human ECoG ( ElectroCortiocoGraphy ) data collected from three human subjects undergoing invasive epilepsy monitoring to identify seizure foci 8,44 . Physiological data were recorded during a center - out reach task in which subjects were instructed to wait for a start cue and then reach as fast as possible to a target ( Fig 4a ) . Two of these patients had intact sensorimotor cortices ( hereafter Non - Stroke or NS1 / NS2 ) ; the third patient , however , had experienced an ischemic cortical stroke four years prior to the monitoring ( hereafter Stroke Subject or SS ) ( Fig 4b ) . The stroke subject had persistent motor deficits involving arm and hand movements ( Fugl - Meyer upper - limb score of 35 ) . He also showed impairments in speed of execution . Reaction time from "" Go "" to movement onset ( i.e. rise in mean EMG ) was slower for the affected versus unaffected arm ( reaction time of 635 Â± 40 and 423 Â± 72 ms , respectively , t(56 ) = -2.7 , p = 0.009 , two - tailed two - sample t - test ) . Similarly , the reach time from movement onset to target acquisition was longer for the affected arm ( reach time of 1266 Â± 58 ms vs. 914 Â± 51 ms , t(56 ) = -4.42 , p = 4.65e-5 , two - tailed two - sample t - test ) ."	49300729	no
Continuous measures collected at baseline and follow - up will be summarised at each time point separately , and as changes from baseline . Missing follow - up values may be carried forward from earlier visits for selected analyses ; in such instances , summary data will be presented both without , and with imputation .	255939865	maybe
With the ability of the DOF resolution being confirmed , this dispersive aplanatic metalens is highly expected to image microscopic biological specimens via tomography . Here , we placed a specimen of frog egg cells directly in front of the metalens with a certain object distance . Figure 4a shows a group of microscopic images obtained by the metalens with different wavelengths from 500 to 560 nm , the colors of which have been removed ; the sizes are normalized according to the zoom scaling to show the relatively realistic morphology and inner structures of the frog cells . The direct white - light image obtained by the metalens is given in Fig . 4b , showing a colorful picture due to the large dispersion . It is clear that the images of the cell membrane and nucleus evolve from blurry to clear and back to blurry again as the wavelength increases . Significantly , it is found that the cell nucleus changes from a large dark appearance to a small bright one , the change contrast of which is much stronger than that of the membrane images . This indeed indicates that the cell membrane and nucleus have different depths of field according to their different sizes . By a more careful comparison of these images , one may find that the clearest image of the cell membrane is at Î» = 520 nm , while that is at Î» = 530 nm for the nucleus , implying that there would be a small location distance between the layer centers of the membrane and nucleus . The derived imaging data of the layer position and imaging scaling with respect to the wavelengths are plotted in Fig . 4c , according to which the depth of the frog cell is roughly estimated to be 35 Î¼m , while that of the nucleus is 5 Î¼m .	207960716	no
blocks of X , R , the remaining optimization problem is a linear assignment problem on X with cost matrix âR , which can be solved using the Hungarian algorithm 3 . Note that if K m = K o or K i = K o , this implies that no matching problem needs to be solved -the first K o components of the minibatch posterior are matched directly , and the last K m are set as new components . In practical implementation of the framework , new clusters are typically discovered at a diminishing rate as more data are observed , so the number of matching problems that are solved likewise tapers off . The final optimal component mapping Ï is found by finding the nonzero elements of X :	16026830	no
Where m f represents the weight of the produced activated carbon ( g ) ; and m i is the weight of raw precursor , in this case being the biomass activated with ZnCl 2 . The software used for data treatment was Origin Pro 2019 .	244923290	no
"The collection , analysis and handling as well as the interpretation of data represents the central element in the field of digitalization in material research . However , these aspects have received the least attention so far . There are frequently reports on the utilization of artificial intelligence etc . , [ 1,38,43 ] but very little on the storage and ( automated ) interpretation of data leading to new knowledge and an accelerated materials discovery . However , they are the key elements , as shown , for example , by Amazon and others for their purposes , but not yet for materials science . The data are required to train software programs in the field of machine learning and artificial intelligence enabling automated routines to provide personalized solutions and suggestions . A first initiative that has recognized the potential in this field was the material genome project of the US government [ 44 ] and later the analog initiative in China . [ 45 ] In doing so , the competencies in the area of material research should be bundled and by a combined effort it should finally be possible to decrypt the "" material code "" [ 1 ] opening the field of material informatics , "" materialomics "" or "" polymeromics . "" [ 46 ] Currently , most of the research data is generated locally in academic and industrial laboratories and only there the primary data are accessible , stored in different formats at different storage location , which are partially offline . Furthermore , even in Figure 1 . A robotic mobile chemist at work filling vials and loading the gas chromatography equipment . Reproduced with permission . [ 33 ] Copyright 2020 , Springer Nature . the corresponding scientific publications only selected data are presented , typically only the data from successful experiments . [ 47 ] Thus , only very sparse , the really relevant data are shared within the scientific community . The quality of the provided data is sometimes questionable and the reliability is not given in every case . Another challenge in this context is the "" negative "" data , which are data obtained from experiments not resulting in the desired material . [ 48 ] These data are hardly published these days , [ 47 ] or even stored in a useful manner . Of course , this raises the question of how many experiments have already been carried out meaninglessly several times in the world , even though it has already been observed that the experiments are not promising ."	230820946	no
We present HYPE ( HUMAN EYE PERCEPTUAL EVALUATION ) to address these criteria in turn . HYPE : ( 1 ) measures the perceptual realism of generative model outputs via a grounded method inspired by psychophysics methods in perceptual psychology , ( 2 ) is a reliable and consistent estimator , ( 3 ) is statistically separable to enable a comparative ranking , and ( 4 ) ensures a cost and time efficient method through modern crowdsourcing techniques such as training and aggregation . We present two methods of evaluation . The first , called HYPE time , is inspired directly by the psychophysics literature [ 28,11 ] , and displays images using adaptive time constraints to determine the time - limited perceptual threshold a person needs to distinguish real from fake . The HYPE time score is understood as the minimum time , in milliseconds , that a person needs to see the model 's output before they can distinguish it as real or fake . For example , a score of 500ms on HYPE time indicates that humans can distinguish model outputs from real images at 500ms exposure times or longer , but not under 500ms . The second method , called HYPE â , is derived from the first to make it simpler , faster , and cheaper while maintaining reliability . It is interpretable as the rate at which people mistake fake images and real images , given unlimited time to make their decisions . A score of 50 % on HYPE â means that people differentiate generated results from real data at chance rate , while a score above 50 % represents hyper - realism in which generated images appear more real than real images .	165163969	maybe
Based on the logit predictions , we compute propensity scores , which proxy the probability of being sample constituents . In other words , the higher the propensity score , the higher the proximity to the characteristics of our sample firms . Following prior research , we apply a oneto - one nearest - neighbor matching with replacement ( Boyd et al . , 2019;Hendricks et al . , 2015 ) . We match each of our sample firms with the matching candidate in the same four - digit GICS industry that is closest based on its propensity score . Our results remain structurally consistent when using the second , third , fourth , or fifth nearest - neighbor for the control group composition . For each matching firm , we verified that it did not announce a COVID-19 response in the corresponding event window , following our initial data collection strategy ( see Section 3.1 ) . In case of a matched firm COVID-19 response announcement , we replaced the firm with the next nearest neighbor matched firm ( Boyd et al . , 2019 ) . Table A.3 presents the descriptive statistics for both our sample firms and the control group firms .	255571157	no
Furthermore , we performed whole - genome analysis and confirmed the existence of differences of multiple genes in the NOMAC treated RL95 - 2 cells compared with that of control cells . Surprisingly , no apoptosis - related genes , including caspases , TNF , Bcl-2 , p53 and etc . were found to change significantly . Interestingly , the genes of SUFU , Gli2 , Wnt7a , and PTCH2 closely related to tumor cell proliferation were significantly upregulated . Then , we detected the mRNA expression levels of these genes ( Wnt7a , Î² - catenin , SUFU , Gli2 , and PTCH2 ) by RT - qPCR to validate the microarray results after NOMAC ( 0 , 4 , 20 , and 100 Âµmol / L ) treatment for 3 , 6 , 12 , 24 and 48 h. Consistent with the microarray data , RT - qPCR analyses showed that SUFU and Wnt7a were expressed at significantly higher levels in NOMAC - treated RL95 - 2 cells than in control cells at 6 , 24 , and 48 h. To further confirm the expression of SUFU and Wnt7a in RL95 - 2 cells , we detect the protein expression levels by Western blotting . In consistent with our RT - qPCR results , NOMAC significantly increased the protein expression of SUFU and Wnt7a . This result suggests that inhibition of cell proliferation by NOMAC might be involved in SUFU and Wnt7a in the RL95 - 2 cell line . The effect of NOMAC on the expression of SUFU and Wnt7a were performed by RT - qPCR and Western blotting in KLE cells as well . However , the results showed that NOMAC could not alter the mRNA and protein expression levels of SUFU and Wnt7a in KLE cells . By using RT - qPCR and Western blotting analyses we found that SUFU and Wnt7a were upregulated in a dose - dependent manner in RL95 - 2 tumor xenograft tissues after NOMAC treatment , which is consistent with the results in vitro , Taken together , these results show that NOMAC inhibited the proliferation of type I endometrial cancer cell RL95 - 2 possibly associate with upregulating SUFU and Wnt7a in vivo and in vitro , but had no significant effect on the proliferation of type II cell line KLE and the expression of SUFU and Wnt7a .	4276238	no
Since the idea of RS appeared almost a decade ago , much work has been done in the phenomenology of warped extra dimensions . Much of this work relates to embedding the SM in the extra dimension , and the resultant implications for collider searches ( e.g. [ 2,3,4,5,6 ] ) . While allowing the SM fields to propagate in the bulk of the extra dimension alleviates problems with Flavor Changing Neutral Currents [ 7,8 ] and allows an understanding of the flavor hierarchy , other problems and constraints are introduced , most notably from the Peskin - Takeuchi parameters , S and T [ 9,10,11,12 ] , and from B factories [ 6,13 ] . With additional work ( usually involving the addition of other symmetries , such as custodial symmetry in the AdS bulk [ 14 ] , or an RS GIM mechanism [ 15 ] ) , the problems can be alleviated and constraints relaxed , making Kaluza - Klein ( KK ) gauge bosons with m KK 3 TeV consistent with current data , and within observational reach of the Large Hadron Collider ( LHC ) .	14797165	no
Air mass trajectories for 5 days backward analysis for Kuala Lumpur was simulated for before MCO and during MCO using the Hybrid Single - Particle Lagrangian Integrated Trajectory ( HYSPIT ) developed by the National Oceanic and Atmospheric Administration ( NOAA ) Air Resources Laboratory ( ARL ) . The longitude and latitude of the modelled backward trajectories was 3.1390 N , 101.6869 E with input meteorological data from Global Data Assimilation System ( GDAS ) 1.0 Ã 1.0 resolution global data .	231653879	maybe
"Contingently , the pandemic is also an unequalizer in terms of wealth ( Schrecker and Bambra , 2015 ) . The measures enacted to contain the spread of the disease include restrictions on movement and on a variety of business and non - business activities that have serious socioeconomic repercussions . The "" second pandemic "" disproportionately affects those who were already in precarious social , economic or working conditions , and reduces services for those who were already poor ( smaller businesses , unofficial forms of work , precarious contracts or economic conditions , poor housing , underserved areas ) . It has "" exposed , fed off and increased existing inequalities of wealth , gender and race "" by making the rich richer and the poor poorer ( Oxfam , 2021 ) . Country - specific as well as global data are clear in this respect , raising significant concerns that the world has emerged even more unequal through the COVID-19 pandemic ( Marmot et al . , 2020;Oxfam , 2021;Human Rights Council , 2020 ) ."	244902343	no
Numerical example . We consider 30 training points and 30 test points in R 2 , and we fit a logistic model with elastic - net regularization . This problem can be written using DPP , with x i as parameters ( see Appendix C for the code ) . We used our convex optimization layer to fit this model and obtain the gradient of the test loss with respect to the training data . Figure 1 visualizes the results . The orange ( ) and blue ( + ) points are training data , belonging to different classes . The red line ( dashed ) is the hyperplane learned by fitting the the model , while the blue line ( solid ) is the hyperplane that minimizes the test loss . The gradients are visualized as black lines , attached to the data points .	202786139	no
English . I was always present at the data collection site , and present in 4/42 interviews . Interviews 159 lasted between 35 and 60 minutes and took place in an aurally private location , often outside and 160 always within the perimeter of the immunisation clinic . 161	162169615	maybe
Perovskite Solar Cells just a few years of research , lead halide perovskite solar cells have reached certified efficiencies of 25.2 % , thereby already exceeding other well - established thin film solar cell technologies , such as CIGS or CdTe in small devices ( < 1 cm 2 ) . [ 1,2 ] Considering their nearly ideal optoelectronic properties for a solar cell semiconductor , that is , a high absorption coefficient , long carrier diffusion lengths , and highly luminescent nature , it is expected that perovskites will reach or even surpass the power conversion efficiency ( PCE ) of monolithic silicon solar cells ( 26.7 % ) . [ 3,4 ] Moreover , their comparatively wide bandgap and simple fabrication ( from solution or evaporation ) render them ideal candidates for applications in silicon - based tandem devices , where the perovskite solar cell is attached as add - on to , for example , industrially fabricated passivated emitter rear contact ( PERC ) or heterojunction with an intrinsic thin layer ( HIT ) silicon cells . [ 5][6][7 ] Today , silicon / perovskite tandem solar cells have the largest potential for a rapid industrial realization in the near future and silicon / perovskite tandem solar cells with 28.0 % PCE have already been demonstrated . [ 8 ] Importantly , tandem solar cells are not bound to the thermodynamic limitations of single - junction cells and efficiencies beyond 35 % [ 9 ] have been predicted for two - and four - terminal silicon / perovskite tandem cells . In order to unlock these potential PCEs for single - junction and tandem perovskite solar cells , it is essential to gain a more detailed understanding of the underlying recombination loss processes . It is well established that nonradiative recombination losses are the primary reason that perovskite solar cells have not yet achieved their full thermodynamic potential . [ 10,11 ] Nonradiative recombination losses limit not only the cells ' open - circuit voltage ( V OC ) but also the fill factor through an ideality factor larger than one . [ 10,12 ] The source of nonradiative recombination loses in perovskite cells remains a heavily debated topic . Historically , the main focus was reducing trap - assisted recombination at defects in the perovskite bulk or at grain boundaries . [ 10,13,14 ] Indeed , considerable improvements were achieved through advanced perovskite fabrication schemes to increase the grain size , enhance crystallinity , and the invention of multication and/or multihalide formulations . More recently , an increasing number of publications have been dedicated to addressing the issue of recombination at the perovskite surfaces [ 15][16][17][18 ] which differs from the bulk in terms of chemical composition and morphology . [ 14,16,19 ] For example , Beard and co - workers studied the charge carrier dynamics in single crystals and polycrystalline thin layers of methylammonium lead iodide / bromide ( MAPbI 3 /MAPbBr 3 ) using transient reflectance spectroscopy ( TRS ) . [ 20,21 ] In contrast to the often employed transient absorption spectroscopy ( TAS ) , this technique is very sensitive to the photoinduced carrier concentration in the surface - near region of the semiconductor . Experiments were performed with different excitation energies , thereby varying the penetration depth of the incident light . These investigations showed that surface recombination is more important than recombination within the crystalline grains and at internal grain boundaries . A detailed analysis of the data revealed a surface recombination velocity of less than 10 3 cm s â1 , orders of magnitude smaller than the recombination velocity of nonpassivated surfaces of traditional semiconductors which are of the order of 10 5 cm s â1 and above . Interestingly , the MAPI polycrystalline thin layer exhibited longer carrier lifetimes than the corresponding single crystal samples , which was attributed to unintentional trap passivation during thin film preparation . These findings put a strong emphasis on the understanding of the nature of surface traps and the suppression of surface recombination . This is particularly important when considering that advanced perovskites , which comprise multiple anions and/or anions of different chemical nature , are becoming increasingly used throughout the community . Molecular modifiers ( e.g. , tri - n - octylphosphine oxide , TOPO ) are often applied to passivate the surface traps . As shown in Figure 1 , Braly et al . [ 22 ] recently demonstrated that even the most simple methlyammonium lead iodide ( MAPI ) perovskite absorber ( with a bandgap of 1.6 eV ) can show an external photo luminescence quantum yield ( PLQY ) of â20 % , which would in principle allow a high open - circuit voltage of â1.28 V after passivating the top surface with TOPO . This value is very close to the absolute thermodynamic limit of 1.32 V , demonstrating that bulk defects are at least in this case of little importance . Moreover , high external PLQYs were also obtained in other perovskite absorbers ( e.g. , 66 % by Abdi - Jalebi et al . [ 23 ] ) .	204814249	maybe
purposes , Japan and South Korea ) by industry ( up to three digits for specific industries ) and by year for the period 1993 to 2018 ; the latter is the year used in our analysis . The IFR data are based on the ISIC revision 4 classification , and therefore can be easily matched with NACE revision 2 data from INAIL and EU KLEMS . In particular , we use employment data from EU KLEMS to construct a sectoral measure of robot use per 1000 workers that we adopt ( in logs ) as the main regressor of interest . 2 Finally , our analysis includes a set of controls for possible confounding variables that make it possible to take into account other industry - specific characteristics . In particular , we are interested in controlling for other factors related to the automation of the production process to ensure that we capture only how robotization , rather than other technology - related factors , affect the risk of workplace contagion . Accordingly , we use data from ISTAT based on the survey on information and communication technology ( ICT ) in enterprises . This survey covers the universe of active enterprises with 10 or more employees and offers different variables related to the use and purchases of ICT by firms for different years at an aggregate industry level ( up to two digits ) . Additionally , we include a control for capital intensity measured as the log of the capital - labor ratio at the two - digit sector level in 2017 and taken from EU KLEMS .	237473239	maybe
We observed that the models converged to a point where they performed similarly , occasionally getting stuck in bad local optima . No pre - processing was performed on the training data as our main aim here is to show the benefit of training GP models using larger amounts of data , rather than proving state - of - the - art performance .	1399138	no
Frozen MDA - MB-231 xenograft tumor slides were washed with ice - cold PBS . Cells were fixed , permeabilized , and incubated with Ki67 and Î³ - H2AX antibodies and fluorescentlabeled secondary antibodies . Immunostained cells were examined using Zeiss Axioplan 2 microscope ( Carl Zeiss , Thornwood , NY ) with a 20X objective . The AxioVison ( Carl Zeiss ) was used for data analysis .	3412678	no
A common , though perhaps naive expectation is that combining data from experiments that have been independently performed in different labs , with different experimental procedures , allows one to identify essential properties of the system that are invariant with respect to details of the experimental approach . In our case , in any given experiment , confounding effects may have led to some genes being spuriously identified as targets of AAGUGCU miRNAs ( false positives ) , and true targets of AAGUGCU miRNAs being missed ( false negatives ) . For example , because it is unclear whether the miRNA processing enzymes solely function in this pathway , it is important to analyze data from ESCs in which the miRNA biogenesis has been impaired at different levels ( Dicer in the studies of Sinkkonen et al . ( 17 ) and Hanina et al . ( 18 ) and Dgcr8 in the study of Melton et al . ( 19 ) ) . Furthermore , although ESCs expressing the full complement of miRNAs provide the most physiological reference point for the function of the miR-290 - 295 cluster miRNAs in normal , unstressed cells , the effect of these miRNAs in these cells is confounded by the effects of other co - expressed miRNAs . Similarly , if the profiled cell population was heterogeneous with respect to the pluripotency / differentiation status , the let-7 miRNAs may have masked the effect of miR-294 , because these miRNAs have antagonistic effects ( 19 ) .	7399731	no
First , the compilation of sectoral national greenhouse gas ( GHG ) inventories can be an interesting source of data to understand the carbon structure of an economy and its industry .	255847212	no
"where i â  j , as shown by the grey lines . Intuitively , the reward encourages the data classifier to agree with the crowds aggregator , while the punishment avoids them naively agreeing with each other , that is , both of them map everything to ( 1 , 0 , . . . , 0 ) . The measurement of "" agreement "" depends on the selection of f . See formal definition for M IG f in ( 1 ) ."	68205758	no
While disasters such as hurricanes can have a more predictable impact on demand for certain products , as presented in Morrice et al . ( 2016 ) , businesses need to find more reliable data sources that can support forecasting efforts to mitigate the impact of disruptions on supply chains ( Sharma et al . , 2020 ) . For example , Google Trends data can provide near - real - time information about consumer trends and perceived risks in different geographies , which have also been used for forecasting geo - spatial demand on certain products , e.g. , see Nikolopoulos et al . ( 2020);Fritzsch et al . ( 2020 ) ; Boone et al . ( 2018 ) . New data sources , such as Google Mobility , can also improve forecasting in the retail industry , as they also provide timely retail mobility data . However , there is a need to develop effective methodologies to accurately incorporate optimal lags in predictive variables , improving forecast accuracy in the retail industry .	255441206	no
While the discussion in previous sections focused on the non - parametric case , in practice we are limited to a finite amount of data , and the actual problem involves high dimensional continuous spaces . Thus , we resort to parametric representations for both the generator and the discriminator . In order to train the generator using standard back - propagation , we do not parametrize the generator distribution directly . Instead , we parametrize a directed generator network that transforms random noise z â¼ p z ( z ) to samples from a continuous data space R n . Consequently , we do n't have analytical access to the generator distribution , which is defined implicitly by the generator network 's noiseâdata mapping . However , the regularization term K(p gen ) in the training objective ( 1 ) requires the generator distribution . Faced with this problem , we focus on the max - entropy formulation , and exploit two different approximations of the regularization term K(p gen ) = âH(p gen ) .	13619197	no
The work of Case and Deaton 39 stimulated extensive media coverage . Stories typically featured white families - often in rust belt , Appalachian , or rural communities - struggling with opioid addiction . 24 - 26 41 - 43 This study suggests that the problem also affects non - white populations and has broader health implications ( beyond addiction ) than media coverage would suggest . While mortality rates among non - Hispanic whites experienced large increases during 1999 - 2016 , they also rose simultaneously ( and sometimes more substantively ) among non - Hispanic American Indians and Alaskan Natives . Moreover , our study refutes prior assertions that mortality rates have improved for non - Hispanic blacks and Hispanics . This was once true , but current data now reveal a reversal in progress for many conditions : mortality rates that had been decreasing among populations of color reached a nadir , giving way to increasing death rates , often accelerating faster among non - white Americans than among whites . This is especially troubling given the historically high baseline mortality rates that exist among populations of color , notably non - Hispanic blacks and non - Hispanic American Indians and Alaskan Natives . 2 Although mortality rates were higher among men than among women , the relative increase in fatal drug overdoses and suicides was greater among women , consistent with other reports of the worsening health disadvantage among women in the US . 21 22 38 44 45 Others have studied geographic patterns in US mortality trends . 4 9 21 46 - 49 Our study confirms reports 11 of higher mortality rates and larger relative increases in mortality in rural areas , but it also documents statistically significant increases within metropolitan areas . Non - Hispanic whites and Hispanics experienced the largest proportional increases in drug overdose deaths in suburban fringe areas , whereas the largest increases among non - Hispanic blacks occurred in small cities . Non - Hispanic American Indians and Alaskan Natives living in metropolitan areas experienced a larger relative increase in suicides than those in rural areas .	52008831	no
After the photovoltaic characterization , the 0.25 cm 2 perovskite PV devices ( abbreviated PVK ) were encapsulated by briefly melting a thin Field 's metal ( FM ) sheet on top of the silver con tact via a Peltier thermoelectric element and sealing the edges with epoxy resin . By maintaining the Field 's metal in a liquid state for only 20 - 40 s , a good adhesion to the underlying silver contact was ensured , while preventing a degradation of the perovskite layer through exfoliation of the Ag layer . Following the electroless Pt nanoparticle deposition , the performance of the resulting PVK|FM|Pt photocathodes was investigated for H 2 evolution . Typical examples of the results are depicted in Figure 5a , b , where the sign of the photocathode traces is reversed for convenience . Further data from all devices can be found in Figures S16 - S18 of the Supporting Information . In order to determine the reliability of the device fabrication procedures , performance statistics have been performed on an initial batch of eight 0.25 cm 2 PV devices ( V OC , b 1.00 Â± 0.06 V , J SC , b 18.9 Â± 0.8 mA cm â2 , FF b 72.3 Â± 3.8 % , PCE b 13.7 Â± 0.9 % ) , from which two were shorted . Due to the improved encapsu lation technique using thin Field 's metal foils and a Peltier thermoelectric element , all six remaining devices could be investigated for photoelectrochemical studies .	103057921	no
Growth was measured in three independent experiments in the ancestral ( G0 ) wild - type , dct-1 and pink-1 strains on control and treatment plates . About 300 age - synchronized L1s were plated on each 10 cm plate with the following conditions : control , 50 , 200 , 1000 M CdCl 2 , and 10 , 50 and 200 M AfB 1 . After 48 h , L4 C. elegans were washed off the treatment plates and transferred to unseeded plates . Images of each plate were then captured with a Keyence BZ - X700 using brightfield , and analyzed in ImageJ with the Fiji plug - in WormSizer ( 53 ) . Length data were normalized to the mean control length of each strain for each biological replicate . Box and whisker plots of length distributions were plotted in R and the means of biological replicates were used for statistical analysis ( 2 - way ANOVA , Tukey 's HSD post - hoc analysis ) . Total brood size was also determined in all three strains on control , 50 M CdCl 2 and 10 M AfB 1 plates ( N = 9 - 10 individuals per strain per treatment ) . On day 1 of adulthood , each individual worm was transferred to a new 6 cm plate with the respective treatment until reproduction ceased . Plates containing offspring were stored at 20 â¢ C for 2 days , and then counted .	251494986	maybe
The simplest form of the transcendental equation is obtained using the formulas for the tangent , but the other equations are needed to resolve some discrete ambiguities . All numerical simulations were performed with n = 2000 and N = 2000 for ensembles consisting of about 500 matrices ( without a restriction on the determinant ) . In the figures below , the solid lines correspond to the analytically derived boundaries , which are in very good agreement with numerical data . Figure 1 shows eigenvalue distributions in the z - and u - plane for t = 3 , t = 4 , and t = 5 . Numerical tests confirm that the topological transition of the domain of non - vanishing eigenvalue density occurs at t = 4 , when the domain becomes connected at z = â1 . This corresponds to the imaginary u - axis completely lying in the domain of eigenvalues . Note also that the eigenvalue density in the u - plane is indeed symmetric under reflections at the real and imaginary axis , which is related to inversion symmetry in z. Figure 2 shows eigenvalues for t = 12 and affirms that for large t the boundary approximately consists of two circles with center at z = 0 and radii exp(Â±t/2 ) .	16436669	no
The case definition adopted by the Chinese authorities initially was narrow ; it gradually broadened to allow detection of more cases as knowledge increased ( Tsang et al . , 2020 ) . However , to the best of our knowledge , the data we use reflect the same case definition throughout the observation period .	231706096	no
""" Moving forward , research might focus less on how to strengthen the average magnitude of these SSIs ' impacts and more on identifying subsets of ' best - responder ' adolescents , guiding tailored dissemination based on individual odds of benefit . "" 24 . P.16 - How generalizable are these findings ? The authors noted that participants were recruited via Instagram . Do the authors believe that this sample generalizes to community samples of adolescents , or might there be differences between those recruited via social media and those recruited via other means ? As an example , the authors note that 80 % of the sample identified as sexual minorities . I commend the authors for recruiting such a diverse and traditionally understudied group . At the same time , what is the nationwide percentage of US teens who identify as sexual minorities ? I am not an expert on this subject , but some survey data seem to suggest that the rate is around 10 % ( https://williamsinstitute.law.ucla.edu/wpcontent/uploads/LGBT-Youth-US-Pop-Sep-2020.pdf ) . Even if this an underestimate , it seems that the adolescents in this study identified as sexual minorities at a substantially higher rate than the national average . This , as well as other potential ways in which the recruitment method may have recruited a sample that differs from the US population , should be discussed further in the limitations section ."	242291039	no
No data reported on harms .	52883486	yes
Mateus Flores MontalvÃ£o : data collection . AbraÃ£o Tiago Batista GuimarÃ£es : data collection . Mohamed Ahmed Ibrahim Ahmed : analysis , and interpretation of results , and draft manuscript preparation .	246975333	no
Because we include conjugates in the average over all data points , the average of the imaginary part is zero . We perform the averaging only over a u , v range [ 1 , 10]GÎ» in order to remove any effects from large - scale structure , which may have a different net sense of polarization than the resolved emission ring .	233659565	no
where the complex frequenciesÏ s;as are common to all three fit functions , while the coefficients Î² are observable dependent . For scattering , we found that for a good fit , it is not necessary to determine the full - wave - vectordependent yet frequency - independent amplitude functions Î² S;s;as Ã°kÃ for each QNM . Instead , for just obtaining the complex frequencies , taking only two wave vectors in the radiation pattern with a distinct Fano spectrum suffices ( data plotted in Fig . 5e ) .	209310767	no
We selected 329 cities in mainland China as study settings because we could obtain data on both daily PM 2.5 concentrations from 2016 to 2020 and population sizes from 2016 to 2019 for the cities . We also collected data in 2015 as a reference before China 's 13 th Five - Year Plan . In particular , we focused on 80 cities in the key regions included in Table 1 General characteristics of population , mortality rate and PM 2.5 concentrations of 329 cities .   China 's latest TAPFAP .	237424987	maybe
Messenger RNA expression profiles of wild - type ( WT ) ( BY4742 ) , dot1Î ( NKI3002 ) , Dot1 - OE ( NKI8046 and NKI8047 ) and Dot1 - OE - G401V ( NKI8048 and NKI8049 , overexpressing catalytically inactive Dot1 in the absence of endogenous WT DOT1 ) were generated as part of a large and uniform collection of deletion and perturbation mutants ( 41,42 ) . Expression profiling and data analysis were performed as described previously ( 41,42 ) .	52184338	no
Zuschriften second - order rate constants for 3-(hydroxybenzyl)azolium adduct formation ( k 1 , m Ã1 s Ã1 ) and equilibrium constants ( K exp , m Ã1 ) t ob em easured ( Table 2 ) . [ 16 ] Formation of the 3-(hydroxybenzyl)azolium adduct involves two distinct steps : the initial deprotonation of precatalyst by base and the subsequent reaction of the NHC with aldehyde . A fter the formation of adduct oxyanion , the base can be regenerated upon protonation at oxygen resulting in an overall pseudo second - order process under these experimental conditions . This is confirmed by the excellent fitting of reaction data to ak inetic expression describing as econd - order reaction proceeding to ap osition of equilibrium . [ 12 ] Thep seudo firstorder rate constants for adduct dissociation ( k Ã1 , s Ã 1 ) c ould also be calculated as K exp = k 1 /k Ã1 .Additional estimates for k 1 and k Ã1 were obtained from reaction profile fitting , w ith the values used to calculate the corresponding equilibrium constants ( K fit ) . Pleasingly , t he fitted values obtained are in good agreement with those obtained from kinetic analysis , with the largest discrepancyo ccurring for the reaction using NHC precatalyst 36 where adduct dissociation is negligible ( Table 2 , entry 4 ) . [ 17 ] Next , the reverse decay towards equilibrium was studied . Analysis of the 1 HNMR reaction profiles for dissociation of the adducts of aldehyde 13 allowed rate and equilibrium constants of dissociation to be measured ( k d , s Ã 1 and K diss , m Ã1 ) and rate constants for association ( k a , m Ã1 s Ã1 ) t ob ec alculated ( Table 3 ) . [ 18 ] Although k a = k 1 and k d = k Ã1 adistinction has been made to differentiate between the two methods of measurement . Thed issociation analysis was not possible for the N-2,6-(MeO ) 2 C 6 H 3 adduct as the equilibrium lies so far towards the adduct that insufficient data could be obtained . Notably , the values for the equilibrium and rate constants measured from both the forward and reverse reactions at the same temperature are in good agreement with each other , showing that these methods can be used to give reliable measurements .	17974463	no
Since this is an entirely exploratory study where concrete theoretical framework is absent , this present investigation followed a systematic procedure to ensure authentication of the study regarding this qualitative investigation through interviews , filed observation , and literature review . For this method of study , justification of data source , collection method , and investigators ' reliability and validity have potential value and , thus , this study conducted the entire investigation maintaining the basic principles of triangulation methods ( Moon , 2019;Patton , 2002;Shareef et al . , 2020a ) . This qualitative study enabled data source triangulation by collecting information from several categories of stakeholders who have influence and interference in the social system of lockdown . Information was collected following different distinct and appropriate methods to validate method triangulation . Depending on the vulnerability , availability , and schedule , data was collected following several methods : a ) Face - to - face interviews ; b ) Telephone interviews ; c ) Video interviews ; d ) Discussion ; e ) Filed observation . To avoid investigator bias and preconceived inclination to any outcome , information was collected by four persons ( researchers and research assistants ) . In this way , personal bias was carefully avoided , and investigator triangulation was confirmed .	233073128	no
At the individual level , the different brain functional networks are attractive as their coherence , as manifested in their correlation structure , appears impacted by brain pathologies , such as schizophrenia [ 6 ] , neurodegenerative diseases -e.g . Alzheimer 's disease- [ 7,8 ] , or in the study of brain lesions [ 9 ] . From the clinical standpoint , there is a strong interest in spontaneous - activity data to study and diagnose brain pathologies because they can be recorded even on severely impaired subjects [ 10 ] .	1253631	no
"of biomedical literature at large , in which data sharing is almost non - existent 34 ( with few exceptions in some specific disciplines , such as genetics ) . 35 Moreover , our analyses focused on publications that were submitted directly after the implementation of new data sharing policies , which might be expected to have practical and cultural barriers to their full implementation . Indeed , our correspondence with the authors helped identify several practical difficulties connected to data sharing , including difficulties in contacting corresponding authors , and lack of time and financial resources on their behalf in preparing the datasets for us . In addition , we found a wide variety of data sharing practices between study groups ( ie , regarding the type of data that can be shared and the procedures that are necessary to follow to get the data ) . Data sharing practices could evolve in the future to deal with these barriers to data sharing ( table 3 ) . For all results that we were able to reanalyze , we reached similar conclusions ( despite occasional slight differences in the numerical estimations ) to those reported in the original publication , and this result that at least the available data shared do correspond closely to the reported results is reassuring . Of course , there is a large amount of diversity on what exactly "" raw data "" mean and they can involve various transformations ( from the case report forms to coded and analyzable data ) . 13 Here , we relied on late stage , coded , and cleaned data and therefore the potential for leading to a different conclusion was probably small . Data processing , coding , cleaning , and recategorization of events can have a substantial impact on the results in some trials . For example , SmithKline Beecham 's Study 329 was a well known study on paroxetine in adolescent depression , presenting the drug as safe and effective , 36 whereas a reanalysis starting from the case report forms found a lack of efficacy and some serious safety issues . 37 Strengths and weaknesses of this study Some leading general medical journals - New England Journal of Medicine , Lancet , JAMA , and JAMA Internal"	3285809	no
DISK AND NON - DETECTION OF LKCA 15 bcd Figure 1 shows the SCExAO / CHARIS near - IR images in broadband ( a median - combination of all channels ) and in K band ( top panels ) and Keck / NIRC2 L p images ( bottom panels ) . All data easily resolve the forwardscattering side of the crescent - shaped outer dust disk wall ( e.g. Thalmann et al . 2010Thalmann et al . , 2014 . However , no data set reveals direct evidence for LkCa 15 bcd . Instead , all data resolve another crescent - shaped extended structure interior to the outer disk wall , consistent with the wall of an inner dust disk previously only seen in polarized light ( Thalmann et al . 2015;Oh et al . 2016a ) .	152282903	no
We perform two experiments with synthetically generated tensor data . In the first experiment we fix the number of non - zero entries to be 10 6 and let I = J = K and vary the dimensions of the tensor . For the second experiment we fix the dimensions and let I = J = K and the number of non - zero entries is set to be 2I. The scaling behavior of the three algorithms on these two datasets is summarized in Tables 4 and 5 . Since we used a preferential attachment model to generate the datasets , the non - zero indices exhibit a power law behavior . Consequently , the number of columns with non - zero elements ( nnzc ( Â· ) ) for X 1 , X 2 and X 3 is very close to the total number of non - zero entries in the tensor . Therefore , as predicted by theory , DFacTo ( ALS , GD ) does not enjoy significant speedups when compared to GigaTensor , CPALS and CPOPT . However , it must be noted that DFacto ( ALS ) is faster than either GigaTensor or CPALS in all but one case and DFacTo ( GD ) is faster than CPOPT in all cases . We attribute this to better memory locality which arises as a consequence of reusing the memory for N as discussed in Section 3 .   	10013164	no
The protocol presented in this study summarizes the critical steps of the polysome profiling technique , and illustrates its successful application to a marine model . Using the protocol presented in this paper , we recently demonstrated that the mTOR signaling pathway controls fertilization - induced cyclin B mRNA translation in two different sea urchin species ( 13 ) . The number of new organisms studied is currently expanding , spanning all phyla of life , with large sets of associated genomic and transcriptomic data . Of the 31 animal phyla currently described , 12 are strictly marine phyla and represent emergent models in cellular and developmental biology ( 41,42 ) . Although mRNA transcription is widely studied as the cornerstone of gene expression , the mere presence of an mRNA is not a guarantee that the protein it encodes is translated . Polysome profiling has been proven to be a powerful tool for addressing the translational status of a given mRNA species , at a specific time , in response to biological changes , such as development or adaptation to environment . However , a prerequisite for these translational studies is to preserve the translational status of the cell and polysome integrity . Our protocol highlights the critical steps of polysome purification and provides suggestions for adapting it to other models . Our protocol will be useful for investigators interested in addressing the role of translational regulation in gene regulatory networks , as part of a comprehensive study of a model organism , both in terms of molecular mechanisms and comparative evolution .	15022309	no
Existing literature regarding the implementation of some of the above listed statistical approaches ( e.g. Stuart ( 2010 ) and Caliendo andKopeinig ( 2008 ) Jacob et al . ( 2012 ) ) rarely cover the specific challenges of economic evaluations , such as skewed and correlated cost and outcome data . Extensions of statistical approaches for the purposes of economic evaluation is a growing strand of methodological literature , for example , IV approaches have been extended to handle binary outcome data ( Terza et al . , 2008 ) as well as correlated cost and outcome data ( DiazOrdaz et al . , 2018 ) . Regression and matching methods can handle correlated data using a Bayesian framework ( Nixon and Thompson ( 2005 ) ; Manca and Austin ( 2008 ) ) , as well as the non - parametric bootstrap    ( Kreif et al . ( 2012 ) ; Kreif et al . ( 2013b ) ) . Furthermore , flexible parametric and semiparametric approaches have been proposed to handle skewed cost distributions ( Jones et al . , 2015 ) and outcomes , e.g. quality of life data ( Basu and Manca , 2012 ) . For complex interventions , beyond the correlated costs and outcomes , a further challenge is handling potentially correlated multiple outcomes ( Teixeira - Pinto and Normand , 2009 ) .	56178677	no
We used all studies that reported mortality to analyse the effect of hypothermia on mortality . This decision was based on our reasoning that the majority of deaths from perinatal hypoxic - ischaemic encephalopathy would occur in the neonatal period , thus mortality would be appropriately captured even when follow - up did not continue until 18 months of age . To analyse neurological outcomes , we selected completed randomised controlled trials that assessed neurological outcomes to at least 18 months of age . Composite neurological outcomes are reported for all infants randomly allocated to a study arm , with the number of infants not followed up included in the denominator when calculating the rates of the composite outcomes . Individual neurological outcomes are reported for survivors with available follow - up data .	27634567	no
The non - extensive framework was successfully applied to transverse momentum data for e + e â â hadrons in [ 17 ] . In the present work we present results concerning pp ( and pp ) reactions . The available data covered quite a wide range of particle interaction energies . We have started our analysis at p lab = 100 GeV / c [ 18 ] where the p â¥ distributions match quite nicely the exponential behaviour and then through [ 19 ] and ISR energies [ 20,21 ] , SPS [ 22 ] and [ 23 ] up to two Tevatron energies : â s = 630 and 1800 GeV [ 24,25 ] .	119366688	no
"While the distinctiveness of individual versus contextual social capital is well - recognized , research that incorporates both measures remain limited , making it empirically difficult to analyze their respective importance ( Mohnen et al . , 2015 ) . In this study , we treat social capital as properties of both actors and places by capturing individuals ' own reported level of social capital ( e.g. , their frequency of interaction with neighbors ) and the contextual - level of social capital in their wider area ( e.g. , aggregate frequency of neighbor - interaction in their area ) . We also explore alternative ways of capturing contextual social capital by drawing on two unique sources of data . In constructing "" community social capital , "" researchers largely average individual - responses across higher - level units ( e.g. , Hoogerbrugge and Burger , 2018;Nieuwenhuis , 2020;Yamaguchi et al . , 2019 ) . This methodological strategy , though widely practiced , has been questioned on grounds of accuracy ( Lagaert et al . , 2021 ) . Since high mobility may result in measures that are poor in internal consistency , some studies rely on key informants rather than the residents ( Fahmi et al . , 2019;Hardyns et al . , 2015 ) . Another , perhaps more critical , issue is endogeneity . When community social capital ( e.g. , "" neighborhood trust "" ) is constructed by averaging respondents ' reports of trust , models looking at its relationship with health outcomes can be biased to the extent that reverse causation exists between the two units of measurement . Drawing causal inference hence demands examining the effects of pre - existing social capital captured prior to measuring health outcomes , which is largely unmet in research ( Frankenburg et al . , 2012;Zhanow et al . , 2019 ) ."	237495162	no
The title compound was obtained after purification using flash column chromatography on silica gel using hexane ( R f = 0.48 ) in 71 % yield ( 63 mg ) as a colourless oil . 1 ( 14 ) , 120 ( 16 ) , 81 ( 5 ) , 69 ( 20 ) , 53 ( 6 ) . The data are in agreement with those previously reported in the literature . 8	3544731	maybe
"Moreover , satellite data is affected by factors such as satellite payload interference and space environment , which can cause occasional errors in continuous data . In our study , we use a "" sliding time window "" implementation combined with time series clustering techniques ( Petitjean et al . 2011 ) to take overlapping 5 - days windows in the time series ( separated by a 1 - day time lag ) features , which ensures that there is a coincidence between the formed series , but also avoids the error of continuous single - point data and has stable robustness ."	231847194	no
and , therefore , it decreases along the flow when G is positive definite . The mean curvature flow is an example of this kind , and , naturally , the branes deform by lowering their total volume towards minimal submanifolds . Of course , there can be other functionals which are also decreasing monotonically in time and serve as entropy of the deforming data .	115162856	no
Based on these data , we propose a model for the role of XAB2 in gene expression ( Figure 8) . At the deficiency of XAB2 , splicing of many genes including POLR2A goes wrong which leads to reduction of POLR2A. Loss of POLR2A triggers deregulation of overall gene expression and promotes senescent phenotype , so abundant XAB2 is critical in maintaining correct splicing of POLR2A to govern global gene expression and antagonize cell senescence .	195066276	no
We claim that the data / phenomena distinction makes sense not just within philosophy of science , but in all cases in which the technique of conceptual modelling is employed . The distinction allows one to discern some fine structure within the phenomenology step , which is not just a step of data collection . The actual work ( the empirical work in the lab , the historical work in the archive , the sociological work with questionnaires or interviews - but also armchair introspection ) indeed just leads to data : idiosyncratic local facts . However , from these , stable and reproducible phenomena have to be distilled in order to be put up against the theory at issue in the modelling cycle . 10 A phenomenology step that leaves out this move amounts to mere data collection - it is incomplete and can lead to a wrong assessment .	12017797	no
Contributors : KD and SRL drafted the manuscript . SRL , JCTC , and KD helped write the grant application for this project . All authors contributed to the manuscript 's critical review and approved the final version . KD is guarantor for the study and had full access to all of the study data and takes responsibility for their integrity and the accuracy of the data analysis .	73024878	maybe
To get some quantitative comparison , we can also try to fit a quadratic curve to our data . At larger Âµ/ÏT the behavior of our result is clearly something else than simple Âµ 2 , so we quite arbitrarily restrict the fitted region to Âµ/ÏT < 0.5 . Assuming that the first derivative vanishes , we look for the coefficients of Re(Ã 0 ) = c 1 + c 2 ( Âµ/ÏT ) 2 , which gives the derivatives as	7159793	no
CIF data are deposited with the CCDC , codes 1032195 - 9 .	12746149	yes
"We break up the training data into N by M rougly equal - sized blocks , where N is the number of parallel jobs , specified by the user ( typically 4 â¤ N â¤ 8) , and M â¥ 1 is the number of "" outer iterations per epoch "" , which is chosen to ensure that the number of samples processed per iteration is close to a userspecified value K ( e.g. K = 400 000 ) . The process of randomly distributing the data into N by M blocks , and ensuring that the order is randomized within each block , is done in parallel ; we wo n't give further details here , because the problem is straightforward and there is nothing particularly special about our method ."	15370378	no
Nevertheless it is clear that the two calculations are related . In particular , in Section 3.2 , we obtain the classical scattering data for the fermionic worldsheet fields in the soliton background by taking a limit of an appropriate finite gap solution . On the other hand , the scattering data for the bosonic worldsheet fields is obtained in Section 3.1 by explicit construction of soliton scattering solutions .	17016333	no
Of the 4886 deaths with available social class data between 1959 and 2000 , occupation was classified as manual in 2112 ( 43 % ) individuals , non - manual in 1391 ( 29 % ) , and unclassified in 1383 ( 28 % ) . Median age at death was higher in the non - manual group than in the manual group for most study years between 1959 and 2000 , and these differences were particularly apparent in the late 1980s and early 1990s ( fig 4 â ) . Odds ratios for death above median age at death were significantly lower in the manual group than in the non - manual group at all study time points ( table 2 â ) . After adjusting odds ratios for sex , we found that individuals in the highest socioeconomic class were also more likely to die above the median age of death than those in the lowest socioeconomic class (	19345532	no
Explicitly , in terms of the basis { e I = e i 1 â§ Â· Â· Â· â§ e i k } # I = k for â§ k C n , this map is given by the data	16502962	no
This section studies L2NNN 's generalization through a noisy - data experiment where we randomize some or all MNIST training labels . The setup is similar to , except that we added three scenarios where 25 % , 50 % and 75 % of training labels are scrambled . Table 5 shows the comparison between L2NNNs and ordinary networks . Dropout rate and weightdecay weight are tuned for each WD / DR run , and each WD+DR+ES run uses the combined hyperparameters from its row . In early - stopping runs , 5000 training images are withheld as validation set and training stops when loss on validation set stops decreasing . The L2NNNs do not use weight decay , dropout or early stopping . L2NNNs achieve the best accuracy in all three partially - scrambled   To illustrate why L2NNNs generalize better than ordinary networks from noisy data , we show in Table 6 trade - off points between accuracy and confidence gap on the 50%-scrambled training set . These trade - off points are achieved by changing hyperparameters Ï in ( 3 ) and v in ( 5 ) . In a noisy training set , there exist data points that are close to each other yet have different labels . For a pair of such points , if an L2NNN is to classify both points correctly , the two confidence gaps must be small . Therefore , in order to achieve large average confidence gap , an L2NNN must misclassify some of the training data . In Table 6 , as we adjust the loss function to favor larger average gap , the L2NNNs are forced to make more and more mistakes on the training set . The results suggest that loss is minimized when an L2NNN misclassifies some of the scrambled labels while fitting the 50 % original labels with large gaps , and parameter training discovers this trade - off automatically . Hence we see in Table 6 increasing accuracies and gaps on the test set . The above is a trade - off between memorization ( training - set accuracy ) and generalization ( training - set average gap ) , and we hypothesize that L2NNN 's trade - off between nominal accuracy and robustness , reported in Section 3.1 , is due to the same mechanism . To be fair , dropout and early stopping are also able to sacrifice accuracy on a noisy training set , however they do so through different mechanisms that tend to be brittle , and Table 5 suggests that L2NNN 's mechanism is superior . More discussions and the trade - off tables for 25 % and 75 % scenarios are in the appendix .	3695872	no
A field of view of 15 Ã 15 Â° with a sampling of 400 Ã 200 pixels was acquired for each measurement . For volume and OCTA data acquisition , three and five B - scans per position were acquired for averaging purposes and OCTA calculation , respectively .	230719129	no
Mega - events can be considered an integral component of much 20th century urban development ( MuÃ±oz , 2006 ) , with urban transformation and ' legacy benefits ' used to justify the expenditure ( Essex and Chalkley , 1998;Leopkey and Parent , 2011;Pound , 2003;Smith , 2012 ) . In many ways , the essence of a mega - event is scale . MÃ¼ller ( 2015 ) argues that there are four integral dimensions , along which scale should be considered : visitor attractiveness ; mediated reach ; cost ; and transformative impact . Hosting a mega - event has been described as ' one of the most fundamentally political acts of the modern age ' ( Horne and Whannel , 2012 : 204 ) which , necessarily , advantages some and disadvantages others . Indeed , securing and delivering a mega - event speaks to the power of the host city 's elite ( Liao and Pitts , 2006 ) . As MÃ¼ller 's framework demonstrates , the criteria that define a mega - event predominantly involve macro - scale interests . Reflecting this , evaluation data and impact assessments generally use aggregate monitoring data at city , regional or national levels eliding uneven development and differential community - level experiences ( Kasimati , 2003;Preuss , 2004;Owen 2005 ) . Furthermore , well - intentioned , elite attitudes towards the preferences of relatively disadvantaged groups may be based on assumptions rather than knowledge ( Ahlfeldt et al . , 2012 ) .	10489113	no
This study aims to build on this research which is suggestive of a positive relationship between fruit and vegetable consumption and well - being . We use a similar panel - data estimation approach to Mujcic and Oswald ( 2016 ) , with two main differences . First , we use data from a much larger representative longitudinal survey in the UK , namely the UK Household Longitudinal Survey ( UKHLS ) . Similarly to Mujcic and Oswald ( 2016 ) , the structure of this survey allows us to examine the relationship between daily variation in the consumption of fruit and vegetables and well - being , but we are also able to ascertain estimated effects for fruit and vegetable consumption separately when it comes to frequency of consumption , i.e. , how many days in a week an individual typically consumes fruits and vegetables . Second , as well as using a standard subjective life satisfaction measure ( similar to the one used by Mujcic and Oswald , 2016 ) , we also use a measure of ' mental wellbeing ' : the 12 - item General Health Questionnaire ( GHQ-12 ) . This measure , aside from being finer - grained , is also more relevant in capturing changes in mental health and thus perhaps better suited for informing public health policymakers . Finally , we also examine to what extent fruit and vegetable consumption in the UK varies along sociodemographic lines .	58651099	maybe
The computational nanoclassifier uses an HMM proteincoding gene model . The model consists of six exon states , six intron states , 5 0 and 3 0 flanking sequence states and one intergenic state to allow more than one protein gene per nanochromosome in the same or opposite orientation . A start state emits an ATG ( exactly ) , and a stop state emits a TGA codon ( exactly ) . For intron signals , hexamer nucleotide frequencies including exact GT or AGs are estimated from the training set . We included minimum length constraints on the intron state . The background ( null hypothesis ) model has the same HMM state - structure as the gene model , in order to match length distributions , but the emission statistics of all states are changed to background : 5th order Markov ( hexamer ) background statistics in the exon states ( estimated from the entire Stage 1 data set ) , and 0th order background nucleotide frequencies in all other states .	17701226	no
Cytochrome c 1 and the two core proteins 1 and 2 were the most resistant bc 1 subunits when some yeast mutant strains , lacking Qcr7p and/or Qcr8p , were analysed [ 53 ] . When the mitochondrial membranes isolated from these mutant yeast strains were analysed by BN - PAGE followed by SDS - PAGE and immunodecoration , a sub - complex of about 100 kDa was identified containing cytochrome c 1 bound to core protein 2 ( Figure 5a ) . This quite unexpected finding was also confirmed in a mutant yeast strain in which the gene encoding the core protein 1 had been deleted [ 8 ] . On the contrary , in another yeast mutant strain in which the gene encoding the core protein 2 had been deleted , the appearance of a new sub - complex of about 78 kDa and made up of cytochrome c 1 bound to core protein 1 was found ( Figure 5b ) [ 8 ] . Altogether , these data demonstrate the capability of these three proteins , cytochrome c 1 , core protein 1 and core protein 2 , to interact each other , thus increasing their stability in the absence of an assembled form of the bc 1 complex . Independent experiments , carried out in a yeast mutant strain in which the genes encoding both core proteins had been deleted ( âcor1/âcor2 ) and in which Cor2 - TAP was overexpressed , revealed the association of cytochrome c 1 with Cor2 - TAP [ 54 ] . This finding reinforced the previous results and suggested early and preferential binding of this catalytic subunit to the core protein 2 when the bc 1 complex assembly is blocked at the level of the early core . The interaction between cytochrome c 1 and the core proteins in an unassembled bc 1 complex is quite unexpected , but it is possible that the N - terminal pre - sequence of this catalytic subunit interacts with the core proteins during the import into mitochondria . In fact , the two core proteins are relatives of the Î± and Î² subunits of the MAS - encoded matrix processing peptidase present inside mitochondria [ 74 ] . However , differently from plants , the yeast core proteins do not show any protease activity . It is also noteworthy to observe that in the crystal structure of the mature bc 1 complex , cytochrome c 1 is in the vicinity of core protein 1 but not of core protein 2 ( Figure 5b vs. Figure 5a ) . However , the structural organization of the proteins can be different during the process of assembly of a multi - subunit complex in comparison to the mature form acquired after insertion into the inner mitochondrial membrane .	252261354	no
The requirement of NF - Y for repression of p53 family members is inferred from several findings . ( i ) The elimination of the CCAAT boxes leads to the abrogation of the negative effect of DNA - damaging agents , or p53 / p73 / p63 overexpression , on promoter function . ( ii ) In vivo ChIP experiments from our lab established that p53 is associated to G 2 /M promoters in NIH3T3 mouse fibroblasts , and it is activated through acetylation upon DNA - damage . Moreover , several control experiments strictly linked the presence of p53 to NF - Y bound promoters [ ( 20 ) and references therein ] . This picture is mirrored for p63 in the cells used here , HaCaT and primary keratinocytes , as representative of a tissue ( skin ) affected by p63 mutations in AEC patients and in knock - out mice . HaCaT cells harbour two DNA - binding mutant alleles of p53 . In these cells , the DNp63a is by far the most abundant , if not the sole isoform present [ ( 31 ) and Figure 1 ) . Our ChIP data identify DNp63a associated to cell - cycle regulatory genes and confirm that p53 is also bound ; importantly , this is observed both in immortalized and primary keratinocytes , indicating that this is not an epiphenomenon of immortalization . The PLK promoter , harbouring only one CCAAT , is devoid of DNp63 ( and p53 ) . Thus , CCAAT promoters are targeted not only by p53 , but also by p63 ; the presence of multiple CCAAT boxes is important for p63 association . It is possible that p73 , in the proper cellular context , behaves similarly , as evidenced by ChIP studies on the PDGF - b - R ( 43 ) . In none of these promoters are there recognizable p53 / p63 - binding sequences , and the most obvious hypothesis is that recruitment is obtained through direct protein - protein interactions with NF - Y. Indeed , endogenous NF - Y and p63 do interact ( Figure 4A ) . On the NF - Y side , the aC of the H2A - like NF - YC is required , a stretch clearly different from H2A , centered on the crucial , highly conserved Phenylalanine 111 ; a mutation of this residue abolishes binding to p63 , as well as to NF - YA ( 37 ) . The model resulting from the NF - YB - NF - YC crystal structure ( 37 ) suggests that multiple NF - Ys might predispose a peculiar , highly bent DNA structure for p63 association . This could reflect the tetrameric status of p63 , needing multiple NF - Y docking sites to associate , therefore being limited to promoters , and cellular conditions , in which multiple CCAAT boxes are bound .	10151339	no
The resulting trimmed primary and cultured virome datasets were analyzed using a pipeline created at the Alkek Center for Metagenomics and Microbiome Research at Baylor College of Medicine , employing a clustering algorithm ( VirMAP ) that reconstructs putative viral genomes using a mapping assembly strategy that leverages both nucleotide and translated nucleotide alignment information 11 . VirMAP uses a custom formatted version of gbvrl ( GenBank virus ) and gbphg ( GenBank Phage ) , however , to filter out false positives all other Genbank Organismal divisions were used as a master database . Viral taxonomies were assigned using a scoring system that incorporates nucleotide and translated nucleotide alignment results in a bits - per - base fashion and optimizes for the highest resolution taxonomic rank , generating a taxonomy ID aggregate bit score output . VirMAP testing and evaluation with in - house and public metagenomic viral datasets indicated the 300 aggregate bit - score threshold provides superior accuracy and sensitivity 11 . VirMAP has undergone extensive validation utilizing mock viral communities and publically available reference data sets that also report PCR analysis 11 .	208539479	maybe
Medical Center Groningen , the University of Groningen , Dutch Kidney Foundation and Dutch Diabetes Research Foundation . We thank Behrooz Alizadeh , Annemieke Boesjes , Marcel Bruinenberg , Noortje Festen , Pim van der Harst , Ilja Nolte , Lude Franke , Mitra Valimohammadi for their help in creating the GWAS database , and Rob Bieringa , Joost Keers , RenÃ© Oostergo , Rosalie Visser , Judith Vonk for their work related to data - collection and validation . The authors are grateful to the study participants , the staff from the LifeLines Cohort Study and the contributing research centers delivering data to LifeLines and the participating general practitioners and pharmacists .	235710711	no
Our assessment builds upon three sets of complementary observations . Traverse observations of air temperature and humidity , wind speed and solar radiation were performed using a collection of instruments placed on top of a car ( Sections 2.3 and 2.4 ) . The traverse measurements were complemented with observations at automatic weather stations ( AWS ) placed in the urban environment ( Section 2.5 ) . These measurements were used to determine temporal patterns and to correct the traverse observations for temporal trends . Finally , we collected data from official stations reporting to the World Meteorological Organization ( WMO ) in these three cities . The combination of micrometeorological measurements applied here allows evaluating spatial patterns of the most frequently used thermal indices ( Section 2.6 ) .	125082868	no
To estimate phenotypic variances explained by imputed data for some of the traits , we applied GREML - LDMS using GCTA ( v.1.93.2beta ; https://cnsgenomics . com / software / gcta/#Overview ) 57 . We created the GRM using all variants for BBJ mainland samples . We estimated LD scores using default parameters in GCTA , and stratified SNPs into LD score quartiles . Next , we divided the SNPs within each LD score quartile into six MAF groups ( MAF < 5 % , 5 % â¤ MAF < 10 % , 10 % â¤ MAF < 20 % , 20 % â¤ MAF < 30 % , 30 % â¤ MAF < 40 % , 40 % â¤ MAF ) and generated 24 GRMs . We calculated the phenotypic variance for each GRM and summed them to derive the total phenotypic variance ( Supplementary Table 7 ) . In the calculations , we randomly sampled 50,000 unrelated individuals ( GRM < 0.05 ) randomly downsampled from BBJ mainland individuals to avoid computational burden and used the same normalized values for quantitative traits and covariates for binary traits as used in the GWAS analysis .	252466144	maybe
This study proposes a prediction system , GasPhos , for predicting human protein phosphorylation sites and constructs prediction models for the six protein phosphorylation kinase families of CDK , CK2 , MAPK , PKA , PKC and Src . Because the number of other kinase families or subfamilies is relatively small , we constructed prediction models for predicting non - specific phosphorylation sites . The overall architecture is mainly to evaluate the performance of the classifier for different human kinase phosphorylation data . After selecting the best machine learning method , the Gas algorithm was used for feature selection to improve prediction performance . The results showed that our strategy of fusing the two algorithms can obtain better performance than other phosphorylation prediction tools that use a single strategy . The overall average Matthews correlation coefficient reached 0.739 , which was higher than those of the other tools . This shows that our system is more effective than other tools in predicting human phosphorylation sites , and the overall predictive capability has higher accuracy than other tools . We used human RAD9 protein , histone deacetylase 1 ( HDAC1 ) , HIV-1 viral protein U ( Vpu ) and IVA nucleoprotein ( NP ) as case studies to explore the applicability of this system . HDACs are very important to convert chromatin states and transition histones - protamines in human spermatozoa . GasPhos could be used to study the effects of heavy metals that lead to alterations in the reproductive health of marine organisms and humans [ 46][47][48 ] .	226044846	no
on validation split of ImageNet-1k using different lengths of queue ( K=128 , 512 , 1,024 , 4,096 , 8,192 , 16,384 , 65,536 ) in Figure . 7 . With the increasing of random data samples , the distillation boosts the accuracy of learned representations , however within a limited range : +1.5 when the queue size is  	231592453	no
The purpose of this study was to examine why blockchains split , identify the focal actors involved , and determine how their heterogeneity manifests itself . To answer our research question , we have conducted and presented a longitudinal case study of Bitcoin splits during 2015 - 2018 . We have analyzed data from online sources , technical documentation , netnographic engagement with the Bitcoin community , and in - depth interviews with Bitcoin experts . We employed ANT as a lens through which we interpret and analyze the data to identify the actors , the actor - networks , and their roles in the split process . In particular , we have considered the Bitcoin evolution according to relational ontology ( Latour , 1987(Latour , , 2005 and process view ( Langley et al . , 2013;Garud and Turunen , 2017 ) in order to better understand both the process and the outcomes of the blockchain evolution . In this way , we have increased the knowledge of the complexity of causal relationships ( Markus and Robey , 1988;Markus and Rowe , 2018 ) in information sciences and society . We have focused on the translation processes ( Callon & Latour , 1981 ) of two splits in Bitcoin history ( i.e. , BCH and Bitcoin Gold ) .	204451237	no
VirScan data comparisons between AFM cases and OND controls were made using the Mann - Whitney test with Bonferroni adjustment for multiple comparisons , n=42 AFM cases and n=58 OND controls . EV VP1 signal by ELISA was compared between n=26 AFM cases and n=50 OND controls using the Mann - Whitney test . When subsets were tested , exact n and statistical tests are provided in figure legends . All error bars are defined in figure legends .	204812289	no
Supplementary Fig . 7 . Anemia induced by tumorigenesis . Hematocrit ( HCT ) and hemoglobin ( HGB ) were measured in tumor - bearing mice at different time points ( n=4 or 5 ) after LLC or B16F10 inoculation , as indicated . Each point represents data from an individual mouse , and data are representative of at least three independent experiments . Two - tailed Student 's t - tests were used for all analyses . Error bars represent the means Â± SEM . Supplementary Fig . 8 . Listeria - specific CD8 + T cell responses remain intact in mice with acute anemia . a - b , Mice with established tumors ( 21 days after LLC inoculation , n=5 ) , acute anemia ( n=5 ) , or healthy control mice ( n=5 ) were infected with â³ actArLmOVA . Antigenspecific CD8 + T cells were measured by flow cytometric analysis of intracellular IFN - Î³ in spleen cells on day 7 post infection after stimulating splenocytes with OVA peptide in vitro . c - d , Mice with established tumors ( 21 days after LLC inoculation , n=5 ) , acute anemia ( n=5 ) or control healthy mice ( n=5 ) were intravenously injected with equal numbers of CD90.1 + CD8 + OT-1 cells . Six hours after OT-1 transfer , mice were infected with Lm . Splenocytes were harvested on day 7 post - infection and stimulated with OVA peptide in vitro . IFN - Î³ - producing CD90.1 + CD8 + OT-1 cells were quantified by flow cytometry . Data are representative of at least three independent experiments . Two - tailed Student 's t - tests were used for all analyses . Error bars represent the means Â± SEM . Supplementary Fig . 9 . Differential suppressive capacity of CD71 + TER119 + EPCs isolated from acutely anemic and neonatal mice . a - b , CD71 + TER119 + EPCs isolated from the spleens of anemic ( a ) and neonatal ( b ) mice were co - cultured at different CD8 + T cell : EPC ratios with CFSE - labeled CD8 + T cells that were stimulated with CD3 and CD28 antibodies(n=4 ) . Representative flow cytometry results and cumulative composite data show the proliferation of CFSE - labeled CD8 + T cells . Data are representative of at least three independent experiments . Two - tailed Student 's t - tests were used for all analyses . Error bars represent the means Â± SEM .	205572894	no
Statistical evaluation of the gaze time courses was based on a cluster - based permutation approach18 . This approach is ideally suited for evaluating physiological effects across multiple data points ( in our case , gaze position data across time ) . This approach effectively circumvents the multiple - comparisons problem by evaluating clusters in the observed grouplevel data against a single permutation distribution of the largest clusters that are found after random permutations ( or sign - flipping ) of the condition - specific , trial - average , data at the van   participant - level . We used 10.000 permutations and used Fieldtrip 's default cluster - settings . Specifically , we clustered adjacent time points whose univariate ( uncorrected ) t - statistic of interest was significant ( two - sided , alpha level of 0.05 ) , and calculated our cluster - statistic as the sum of all t - values in each cluster . After each permutation , the largest cluster was defined as the cluster with the largest summed t value . When the data before permutation contained more than one cluster , each observed cluster was evaluated under the same permutation distribution of the largest cluster .	71144269	no
The media uses familiar symbols to simplify the abstract risk of emerging infections , often by blaming the sick for putting others at risk for premodern diseases by not participating in modern , sanitary society ( Beck , 1999;Briggs & Mantini - Briggs , 2003;Farmer , 1992;Moeller , 1999 ) . Media coverage is therefore a good source of data for measuring the dominant stigmatizing discourses during an epidemic . Othering in media coverage is masked by the prominent position of scientists and by cultural reasoning , whereby anthropological terms are used to describe a population 's inferiority vis - a`-vis their culture ( Briggs & Mantini - Briggs , 2003 ) . Indeed , as Barde ( 2003 , p. 161 ) noted regarding epidemiological advances of the 19th century , discoveries of the causes of disease have '' changed only the language of the scapegoating , not the target . '' While many scholars agree on the role of the media in disseminating knowledge and risk discourses , the media 's effect on risk perceptions is much debated . Sensationalistic media coverage does not necessarily create heightened anxiety of being infected ( Bergeron & Sanchez , 2005;Joffe & Haarhoff , 2002 ) . Audiences may instead respond to the messages of reassurance ( Ungar , 1998 ) and locate the risk of infection among those othered by news coverage ( Joffe & Haarhoff , 2002 ) . Stigmatized populations may reject being labeled as at - risk by not complying with public health measures that would confirm their inferiority ( Nations & Monte , 1996 ) , while sanitary citizens may position themselves outside the defined risk category to create a sense of protection ( Briggs , 2004;Joffe , 1999 ) . Finally , variability exists within any group around how individuals respond to risk discourses ( Joffe , 1999 ) . This paper considers how risk discourses are produced and the responses of stigmatized populations in places without infection . I investigate the historical and political - economic dimensions shaping explanations of risk and blame during SARS , and the ways in which these ideas contributed to the production of local epidemic narratives in Chinatown , New York City .	28129795	no
"The performance of the device could be further enhanced with optimised structural parameters according to practical applications . For example , our control experiments prove that an appropriate silver layer is helpful for obtaining a high - quality colour hologram ( Supplementary section 9 ) . In addition , higher efficiency and less crosstalk can be achieved by utilising higher order peaks with thicker dielectric layers and suitable wavelengths ( Fig . S2e ) . The demonstrated 3D - integration concept is also extendable for achieving more complicated functions . For example , one can choose more types of colour filters to generate a fullcolour transmission image and smaller unit size to store more data because our algorithm can flexibly design the metasurface based on the distribution and size of the colour filters . Furthermore , the nanostructured hologram metasurface can introduce more complex structures , such as high - aspect - ratio and asymmetrical nanostructures , to achieve higher quality hologram images and polarisation Full - colour holography demonstration with 3D - integrated metasurfaces device . a Simulated "" four colour theorem "" painting consisting of five different colours ( including the boundary ) , which are red , green , yellow , blue , and navy blue , respectively . b Simulated "" Chinese painting of lotus "" hologram image , consisting of a pink lotus with yellow flower core , green lotus leaf , dark water , and a red dragonfly . c The greyscale images of the RGB components of the painting . d The fabricated colour filters containing five colours with 100 Ã 100 pixels . The scale bar is 100 Î¼m . e The hologram image projection in the experiment combining the RGB channels and f its corresponding RGB components multiplexed metasurfaces . For practical large - area and lowcost applications , the device can be mass - produced by the CMOS process , high - precision laser direct writing or nanoimprinting ."	202670825	no
To further verify the gene expression profiles obtained by RNA - Seq and the reliability of the important DEGs obtained from the assembled transcriptome , we selected eight key enzyme genes ( i.e. , CDS , ADH , ALDH , CHH MT , PYS , JMH , and GLIP ) involved in pyrethrin biosynthetic pathways to verify their differential expression by qRT - PCR . Three of these genes were in the anthocyanin synthesis pathway ( CHS , DFR , and ANS ) and bHLH TF ( Cluster-15496.37269 ) . The results ( Figure 6 ) show that the expression trends according to qRT - PCR were consistent with those indicated by the RNA - Seq data . Some differences may be due to the differences in the sensitivity , specificity , algorithms for qRT - PCR , or sequencing technique . The results obtained from the qRT - PCR analysis confirmed that the unigenes obtained from the assembled transcriptomes and the gene expression profiles from the RNA - Seq data were reliable . PCR , or sequencing technique . The results obtained from the qRT - PCR analysis confirmed that the unigenes obtained from the assembled transcriptomes and the gene expression profiles from the RNA - Seq data were reliable .	244820987	no
The G - BIRD - HSQMBC experiment was recorded with 8 K data points in F2 , 480 increments with 40 scans per increment , a delay time Ï/2 of 1/8J and optimised for 1 JC - H = 145 Hz . All data were zero filled to 1 K or 2 K in F1 for processing .	2318672	maybe
Daily urban air quality index ( AQI ) and six atmospheric pollutants ( i.e. , PM 10    IAC incidence of allergic conjunctivitis monitoring standards , calibration methods , and unified operation and maintenance management to ensure the accuracy of data in China . Based on the technical standard for automatic monitoring of air quality in China ( HJ 193 - 2016 ) , the real - time concentrations of NO 2 , SO 2 , O 3 , CO , and particulate matter ( i.e. , PM 10 and PM 2.5 ) were determined by the methods of chemiluminescence , ultraviolet fluorescence , ultraviolet photometry , gas filtering correlation infrared absorption , and Î² - ray , respectively . According to the Chinese Meteorological Observation Standard ( GB / T 33703 - 2017 ) , the indexes of air temperature , relative humidity , precipitation , air pressure , wind speed , and direction were monitored in real - time by automatic meteorological observation instruments . Visibility data was measured by an automatic visibility meter , which was composed of an optical transmitter , optical receiver , and microprocessor controller .	237551590	maybe
Safety evaluation committees . Patient safety was monitored throughout all parts of the study by an SEC established by the Sponsor . The SEC consisted of the principal investigators and Sponsor staff . The SEC monitored treatment - emergent data on an ongoing basis throughout study conduct for the purpose of ensuring the continued safety of patients enrolled in this study . During phase 1 ( dose escalation ) , the SEC were scheduled to meet after the first patient in each cohort completed 2 weeks ; after the third patient in each cohort completed the DLT evaluation period of 30 d Â±3 d after the last dose of AUTO3 in the case of split dosing ; in additional ad hoc meetings if safety stopping criteria were met ; and when clinically necessary based on emerging data .	238745241	no
which is smaller than the observed 1.7 delay . One needs to attribute the most delay time to t bo , which is consistent with the requirement of a significant ât jet . Meng et al . ( 2018 ) showed that the thermal radiation from a structured jet can account for the observed GRB spectrum . Within this scenario , one has to explain why ât jet is significantly longer than the dynamical time scale of the central engine ( â¼ millisecond ) . One possibility is to argue that this time scale is the the time scale of the hyper - massive NS , and the jet launching happened after the collapse of the NS . This hypermassive NS phase seems to be favored to interpret the kilonova data ( Margalit & Metzger 2017 ) . On the other hand , there is no obvious reason why a relativistic jet can not be launched during the hypermassive NS phase . Another issue of this interpretation is that the observed duration of the short GRB is much longer than Î´t R , which defines the typical duration of a shock breakout GRB through the angular spreading time scale . One needs an additional mechanism to interpret the duration .	102354750	no
It is well - established that informal caregiving is associated with increased physical strain ( Pinquart and Sorensen , 2003 ) and psychological distress ( Lacey et al . , 2019 ) among carers . However , establishing whether informal caregiving had a causal effect on mental health is challenging given potential endogeneity issues , including self - selection into caregiving ( Bom et al . , 2019 ) . To account for selection into caregiving , recent papers used different matching techniques . Bom and Stockel ( 2021 ) and Stockel and Bom ( 2021 ) employ propensity score matching to explore the health effects of informal caregiving using data from the UK and the Netherlands . They find negative mental health effects of caregiving , especially among caregivers who provide care for longer , and with higher intensity as measured by additional hours of caregiving . De Zwart et al . ( 2017 ) also employ matching to deal with selection issues when studying health outcomes of spousal informal caregivers . Analysing data from the Survey of Health Ageing and Retirement in Europe ( SHARE ) , they found that caregiving has a negative short - term effect on informal carers ' overall health . Previous evidence also appears to show that the negative effect of informal caregiving seems to be larger among specific groups of caregivers , such as older caregivers ( Bom et al . , 2019 ) ; women ( de Zwart et al . , 2017;Lacey et al . , 2019;Brenna , 2021 ) ; and people with more intense caregiving duties ( Bom and Stockel , 2021;Stockel and Bom , 2021 ) . However , an important limitation of these studies is that they appear to infer causality using matching as their main identification strategy and therefore rely on the conditional independence assumption ( effectively assuming that there are no unobservable confounders ) .	256194903	no
Figure S1 is given as an example to show the trend of residual variability of aluminium ( Al ) concentration in stormwater and the independent variables . As evident from Figure S1 , it is clear that no trend exists for the residuals variability and therefore , the model fitted the data well .    Figure S2 shows an example of the comparison of predicted concentration of Al ( vertical line ) 2 in stormwater from Rd1 when Rd1 was left out from the data set with the observed 3 concentrations of Al ( density plot ) at Rd1 . As evident from Figure S2 , the vertical line lies in 4 the area of high density of the observed data . This was also verified for the other study sites 5 and similar results were derived . This confirms that the model was valid for assessing the 6 concentration of Al in stormwater . Similar results were observed for all HMs and PAHs .	33477892	no
Contributors : SMAJT , HEdM , SJMH , FRMvdK , EAMS , MABvdS , and MJK contributed to the conception and design of the study . SMAJT and MJK acquired and interpreted the data . SMAJT and AGCB carried out the statistical analysis . SMAJT drafted the manuscript , which was critically revised for important intellectual content by all authors , who approved the final version . SMAJT and MJK are guarantors .	19841719	no
"In relations between economics and ecology , such incompatibilities over epistemic values of these fields are the subject of much contention ( Beder 2011 ) , and reflect a deeper entanglement of values with domain specific systems of practice of both fields . Armsworth et al . ( 2009 ) drawing on their experience in such collaborations , but also what they have "" witnessed â¦ . when serving as authors , reviewers , editors and grant panelists where a referee from one discipline criticized a researcher from the other for their poor use of statistics , "" ( p. 265 ) claim that ecologists and economists have different approaches to statistical regression which reflect deeper background assumptions about the aims of model - building or their basic "" philosophy of science . "" Economists are according to them more theory - driven , ecologists more data - driven . Economists use statistical regression to test theoretical models , whereas ecologists are much more interested in using the data to derive parsimonious causal relationships between variables . They are less interested in building and testing theories . They worry much more about the validity of their models , and testing for "" off - model "" relationships , rather than just picking out the most substantive relationships in the data . Hence economics and ecology can fall on either side of another difficult epistemic divide ; scientists who are suspicious of theory - laden approaches as distortive and biased , and those that think of data - mining or pattern recognition methods as unsubstantive , unprogressive and uninformed . These views can be tied to the general suspicions ecologists have about the justifiability of current economic theory . However , as a result , practices surrounding the use of statistical regression analysis can be very distinct ."	36385693	no
Using five different semiconductor alloy compositions and stochastically varying the microdisk diameter through nanofabrication enabled single - mode emission over a wide range in the tissue - penetrating NIR - II window , from 1170 to 1580 nm , with subnanometer linewidths ( Fig . 2a ) . Given 1 - nm bins within which LP emission is stable , this range provides more than 400 unique colors , with room for further expansion using different materials ( e.g. , InGaAsP and InAlGaAs for NIR - I and NIR - II , InGaN for visible ) . The use of the NIR range also preserves compatibility with conventional fluorescent probes in the visible wavelengths that can label different cellular features ( e.g. , nuclei , membrane ) . The availability of hundreds of spectrally distinct colors for multiplexed imaging enables longitudinal cell tracking even in dense , scattering tissues . In our study 25 , we used microdisk LPs to track thousands of individual cancer cells over several days in a 3D tumor spheroid invasion model . Our data enabled the classification of individual cells according to their motility and the identification of cells moving together in small packs within the spheroid by analyzing spatial correlations in velocities . Despite progress in the development of multiplexed imaging probes , the number of resolvable colors , or available barcodes , is still far fewer than desired for most applications ( ~10,000 cells per 1 mm 3 of tissue volume ) . To tag cells uniquely , the number of barcodes should exceed the number of cells . Spectral barcoding with LPs is a practical and scalable approach to break through this limitation . LPs with different emissions can be combined to readily achieve millions of unique barcodes ( Fig . 2b ) . One approach is the uptake of multiple LPs in each cell ( Fig . 2c ) , as long as LPs can be colocalized to specific cells by segmentation of cell boundaries . However , this approach would not be suitable for dividing cells since barcode fidelity would be lost upon LP segregation . A more tractable approach is using multiple LPs stacked together in a single particle to generate an emission composed of multiple laser lines 25 ( Fig . 2d ) . To associate spatial information with single - cell analyses , the emission spectra of LP tagged cells can be read during imaging to catalog the position and identity of cells within tissue and following tissue dissociation at an appropriate step before subsequent analyses ( Fig . 2e ) . For plate - based sequencing , LP emission can be measured during or after the sorting of single cells into individual microwells . LP cell tagging is also compatible with high - throughput methods , including microdroplet - based 26 and split - pool barcoding 27 , which introduce cell - specific DNA barcodes for highly parallel analysis as long as an association between the optical LP barcode and the DNA barcode is made .	201098479	no
Here we studied in detail how mouse small intestinal organoids interact with their matrix , and used the data to establish a well - defined hydrogel that supports the long - term expansion of organoids derived from different mouse and human epithelial tissues . We found that fibrin is a suitable scaffold that could   act as a physical substitute for BME . The mechanical as well as biochemical properties of the fibrin matrix are important parameters for organoid expansion , as increasing the stiffness of the gel or blocking the RGD domains in the scaffold inhibited growth . We further found that the transition from spherical organoids to budding organoids was associated with a shift of force distribution exerted on the matrix : while cystic organoids applied uniform pressure on the matrix , in differentiated organoids pushing forces became predominantly restricted to the crypt - like domains and the core domains counteracted the internal pressure with increased contractility . Finally , we identified laminin as the major biological signaling molecule in BME that is required for organoid growth .	52180970	no
In this paper , to speed up the learning of LVGGM , we proposed a sparsity constrained maximum likelihood estimator based on matrix factorization . We developed an efficient alternating gradient descent algorithm , and proved that the proposed algorithm is guaranteed to converge to the unknown sparse and low - rank matrices with a linear convergence rate up to the optimal statical error . Experiments on both synthetic and real world genomic data supported our theory .	3331779	no
Nearly 14 million units of whole blood or packed red blood cells were transfused in the United States in 2011 , the most recent year for which data are available . 1 Recent work showed that transfusion of four or more units of packed red blood cells was associated with 2.5 - fold increased odds of perioperative stroke or myocardial infarction . 2 Perioperative stroke and myocardial infarction , while rare , increase the risk of perioperative mortality by threefold to fourfold , and have far - reaching implications for postoperative function , quality of life , and hospital costs . [ 3][4][5 ] It is not known whether smaller volume transfusions - such as one to three units - are similarly associated with an increased risk for these outcomes , although there is a far greater population exposed to perioperative transfusion in the absence of hemorrhage per se .	14501396	no
In this paper we will explore the interaction between homogeneity and plane - wave limits . Section 2 is preparatory and reviews the basic technology of homogeneous manifolds , homogeneous structures , homogeneous geodesics as well as the classification of homogeneous plane waves by Blau and O'Loughlin [ 8 ] . Such plane waves come in two classes and are characterised by certain algebraic data , namely a real number and a symmetric and a skew - symmetric bilinear forms . In Section 3 we show how to compute these from the Lie algebraic data associated to a homogeneous spacetime and a homogeneous geodesic , in effect reducing the computation of the plane - wave limit to an algebraic calculation which can be easily implemented in the computer , for example . We present two derivations of this result : one using the covariant description [ 9 ] of the plane - wave limit and one involving a different limiting procedure equivalent , as we will show , to the plane - wave limit but without the need to find neither adapted frames nor adapted coordinates . We will also study the behaviour of the homogeneous structures under the plane - wave limit . Of course , the plane - wave limit depends on the geodesic and not just on the homogeneous structure , whence the results in this section are of necessity somewhat less comprehensive . Finally , in Section 4 we present some examples to illustrate our methods .	50633287	no
In total , I have had 69 semi - structured , informal interview exchanges ( 27 in - person interviews with 31 people that include subsequent audio and text messaging for purposes of clarifications and updates ) . In the interest of organizing the data , I grouped all of the audio exchanges with each interviewee into a single interview . This means I have a total of 39 interviews , which are numbered in the middle column of Appendix A ( interview details ) .	254384500	yes
QR is often done in terms of representation and correspondence ( Zyphur et al . 2016 ) . In this narrative , worldly phenomena are represented in research , including by theories , hypotheses , models , equations , samples , data , or parameter estimates . In turn , these can be true , valid , or unbiased by corresponding to their worldly counterparts , for example , when observed data correspond to what they are meant to measure or parameter estimates corresponding to correlations or causal effects in a population . This narrative helps constitute multiple epistemologies in core disciplines of business ethics research , including psychology , sociology , economics , statistics , and analytic philosophy ( e.g. , Gabbay et al . 2011;Pedhazur and Schmelkin 2013;Shadish et al . 2002;Wasserman 2013;Wooldridge 2010 ) . The narrative does help to organize QR , but it causes two problems that we now describe : an ethic of probabilistic inference ; and a simplistic understanding of QR .	254380504	no
[ 33 ] . Each example in these datasets consists of a premise sentence and a hypothesis sentence , gathered from various online news sources . The task is to predict if the premise entails the hypothesis . It has 2,769 instances with 90 % training and 10 % validation data .	3284367	maybe
Indeed , under the preferential attachment mechanism , a positive feedback would arise by which the more frequently a research subject were studied , the more likely it would be studied again . As a result , an old subject would receive more attention than the recent one . Therefore , the probability of reusing a topic tuple ( Î  ) would decrease with the rank of this tuple 's first usage [ 32 ] . This , however , directly contradicts the recency feature observed in the data ( Fig . 2e ) , demonstrating the inherent inability of preferential attachment based models to capture research interest change . The second class of models treats the individual interest change as a Markov process on the knowledge network [ 4,8,49 ] . This approach provides a comprehensive picture of the geometry of knowledge network that gives rise to subject proximity . However , the heterogeneity feature leading to the power - law distributed topic tuple usage can not be generated by a Markov process with fixed transition probabilities . Moreover , the knowledge network characterized by individuals ' move between research subjects is not static but dynamic [ 39 ] , which can not be accounted for without introduc- The methodology introduced here implies some limitations and potential for future work . When composing topic vector , we assume papers on which an author 's name appears are equally representative of his / her research interests . This assumption is justified by the difference between the interest in the problem addressed by this paper and the contribution to the paper or recognition of each author [ 3,58 ] : every author has to be interested in the problem to engage in co - authoring the paper . In the future work , it would be interesting to systematically quantify the difference of each co - author 's interest in a single paper on which they collaborate . The macroscopic patterns emphasized in this study are not significantly affected by potential errors in name disambiguation	6911864	no
The title compound was obtained after purification using flash column chromatography on silica gel using 5 % ethyl acetate in hexane ( R f = 0.11 ) in 94 % yield ( 79 mg ) as a pale yellow oil . 1 ( 23 ) , 115 ( 4 ) , 91 ( 7 ) . The data are in agreement with those previously reported in the literature . [ 31 ]	51940399	maybe
When Empathy is high , it delivers employee outcomes directly and contributes to those effects indirectly through a halo effect on Courage . Whilst this is interesting from a theoretical perspective , it is likely to matter little in the examination of individual organizations since employee attributions are broad approximations . However , it can become relevant in comparisons of organizations which differ markedly on Empathy . In this case , data collection could be preceded by pre - survey experiments that target the employee 's organization and a proximate competitor , since observations of the competitor are less likely to be subject to preference bias ( Fiske et al . 2002;Judd et al . 2005 ) . Finally , the results of Hypothesis 9 suggest that CSR practices have important strategic implications for the firm 's relationship with employees , highlighting the importance of managing CSR internal communications in line with the desired organizational image ( Vlachos et al . 2014;Pfeffer and Salancik 1978 ) .	234120882	no
Total lipids were extracted from BAL using the method described by Bligh and Dyer ( 1 ) . Lipid extracts were separated and analyzed by 2D - HPTLC ( 2 ) . Total lipids ( 60 nmol ) were applied onto and the plates were first developed with a solvent system consisting of chloroform : methanol : 28 % ammonium hydroxide ( 65:25:5 v / v ) . After the plates were dried with a forced N 2 blower to remove the solvent , they were developed in the second dimension with a solvent system consisting of chloroform : acetone : methanol : glacial acetic acid : water ( 50:20:10:10:5 v / v ) . The phospholipids were visualized by exposure to iodine vapors and identified by comparison with authentic phospholipid standards . Lipid phosphorus was determined by a micro - method ( 3 ) . LC / ESI - MS was performed using a Dionex Ultimate TM 3000 HPLC coupled on - line to ESI and a linear ion trap mass spectrometer ( LXQ Thermo - Fisher ) . The lipids were separated on a normal phase column ( Luna 3 m Silica 100A , 150x2 mm , ( Phenomenex , Torrance CA ) ) with flow rate 0.2 mL / min using gradient solvents A and B. Solvent A was chloroform / methanol/28 % ammonium hydroxide , 80:19.5:0.5 ( v / v ) . Solvent B was chloroform / methanol / water/28 % ammonium hydroxide , 60:34:5:0.5 ( v / v ) . The column was eluted during the first 3 min isocratic at 0 % solvent B , 3 - 20 min with a linear gradient from 0 % solvent B to 100 % solvent B , and then 20 - 23 min isocratic at 100 % solvent B , 23 - 35 min linear gradient to 0 % solvent B , 35 - 40 min isocratic at 0 % solvent B for equilibrium column ( 4 ) . The spectra of CL were acquired in negative mode and the scan data type was set to centroid .    ( 180 nmol	2582916	no
Before evaluating dissolution rates of metals during oxidation and reduction processes , w ee stablish ad ataset of parameters that can influence dissolution . Figure 1p resents thermodynamic data on A ) the first oxide transition ( E 0 ) , [ 6,15 ] B ) oxygen adsorption energy at aq uarter monolayer coverage ( DH O , ads ) , [ 14b ] and C ) cohesive energy ( E coh ) [ 14a ] of each studied metal . Note there is adirect correlation between E coh and E M - M .S imilar to most element - specific descriptors , t here are apparent trends to be observed within the periodic table . First , with increased d - band filling , the first oxidation potential ( Figure 1A)o r , in other words , t he metal nobility increases . The nobility increases gradually from 3to5d - shells . Like nobility , t he affinity to form an oxide ( Figure 1B ) increases with increased d - shell filling but drops slightly with an increased number of d - shells . T he bond strength between metal atoms ( Figure 1C ) , on the other hand , decreases with   To correlate these thermodynamic data to experimentally determined transient dissolution rates during oxidation and reduction of the metals and their electrochemically formed oxides , weoxidized all metals at aconstant overpotential ( h = 200 mV ) to E 0 .J ust before starting the measurements , a ll electrodes underwent at horough polishing procedure which is required to minimize the amount of native oxides formed in the air [ 16 ] ( please refer to the experimental part for more information ) . Equal overpotentials impede consistent oxidative stress in each metal . Therefore , t he recorded dissolution appears to be ag ood measure of stability comparable between metals and directly correlated to acommon descriptor . Figure 2s how s the results for nine of the investigated metals in an alkaline electrolyte ( while some other transition metals , f or example , M oa nd Ag were also studied , data are not shown here as the dissolution was very fast and impossible to quantify ) . Here , all the investigated metals are expected to form the corresponding thermodynamically stable oxides . W e also repeated the same experiment for all metals in the acidic environment . However , only data for PGM metals are presented in Figure S1 since none of the investigated 3d metals form astable oxide in acidic pH. Indeed , the outcome of such an oxidation experiment on 3d metals in acid using ICP - MS to track the dissolution rate is shown in Figure S2 . One can observe an exponential increase of active dissolution with potential . During oxide formation at h = 200 mV in alkaline media , all the investigated metals undergo transient dissolution marked by the colored brackets in Figure 2 . The extent of transient dissolution increases within each d - shell .	232161001	maybe
Direct comparisons between corresponding data products delivered by separate pipelines allow us to quantify the degree of confidence that we may have in their properties and their dependence on specific choices in calibration procedure . Figure 21 ( top ) shows the distribution of visibility amplitude differences betwen the reduction pipelines , in units of their thermal uncertainty . Thermal errors represent aï particular scale of interest ; however , visibilities reduced by separate pipelines are not independent variables and share the same thermal noise realization . Another useful quantity is the relative absolute amplitude difference . As indicated in Table 8 , the median relative difference between the most consistent pair of pipelines , HOPS - CASA , is 3.8 % , well within the budget of aï priori flux density calibration ( Section 6 ) . While for 3C 279 all three pairs represent aï similar level of consistency , for M87 the HOPS - CASA pair is by far the most consistent one , as indicated in Table 8 . This result is consistent with known difficulties in the processing of low S / N data with the AIPS pipeline , originating from the lack of S / N to constrain a fringe solution in the two - second intervals used for fringe fitting ( Section 5.3 ) . Distributions of differences between amplitude data products are unbiased ; however , significant tails are present , with 10 % of the M87 visibility amplitude data inconsistent by more than 22.8 % for the most consistent pair , HOPS - CASA .	115150503	no
Reaction phase diagram . In addition to the observed phase transitions , t he gradual shift in the Bragg peaks to lower q during the BzMA polymerization indicates progressively larger domain spacings . M ore detailed analysis of the SAXS patterns enables the varying dimensions of these ordered phases to be assessed . In the early stages of the polymerization , the system comprised ad isordered array of micelles which most likely possess ap seudo - spherical morphology . T he mean distance between nearest neighbor micelles ( D DIS ) c an be estimated from the structure factor peak maximum ( q * ) using the simple relationship D DIS Â¼ 2p/ q * . SAXS patterns recorded in situ during the polymerization indicate the presence of aBCC phase between 60 and 74 min , with the unit cell size increasing from 24.1 to 26.6 nm during this interval . From these dimensions , t he nearest neighbor center - to - center distance ( D BCC ) c an be calculated from the   Figure 3B ) . B ) Additional peaks ( black squares ) that are observed in coexistencewith the BCC ( upper pattern , gray diamonds ) and hexagonal ( lower pattern , gray triangles ) phases can be assigned to Miller indices originating from the HCP sphere phase ( see black squares ) . SAXS patterns are offset by an arbitrary multiplication factor to avoid overlap of the data . C ) Correlation between the theoretical q values for Bragg peaks corresponding to an HCP phase and the experimental data determined from ( A ) . The HCP phase comprises the unit cell shown in the inset , in which spheres are arranged within an HCP lattice with characteristic unit cell dimensions ( a HCP and c HCP ) . unit cell size using the equation D BCC Â¼ ffiffi 3 p a BCC 2 . [ 57 ] Similar structural parameters can be calculated for the HEX phase , which becomes the dominant phase within 80 min . Themean center - to - center distance for nearest neighbor cylinders ( D HEX ) can be calculated using a HEX Â¼ D HEX Â¼ 2d 10 ffiffi 3 p . [ 57 ] Finally , within the coexisting HCP phase , t he center - to - center distance ( D HCP ) f or neighboring spherical micelles is simply the unit cell parameter a HCP , i.e. , D HCP Â¼ a HCP . [ 57 ] Mean inter - micelle distances increase from 20.9 to 23.1 nm between 60 and 74 min . This greater inter - separation distance between neighboring micelles is the result of the mean micelle core radius increasing by approximately 1.1 nm as the core - forming PBzMA block grows longer . There is also am odest increase in the mean inter - cylinder separation distance , f rom 22.2 nm after 80 min to 23.2 nm at the end of the BzMA polymerization .	232262823	no
In this paper , we have explained how new types of symmetries are hidden in the algebra of local observables in gauge theories . The general idea is to reconstruct the gauge - variant data from the gauge invariant observables by studying the gauge invariant set of equations that the gauge - variant quantities must satisfy . The solution of this problem is governed by a Galois symmetry group , which may be a strict subgroup of the gauge group . Remarkably , this provides a perfectly well - defined notion of gauge symmetry breaking at the quantum level .	15116130	no
In   2017 ) ] in a unique framework . By doing so , we embrace a more principled approach to align covariance representations ( as to tackle Problem 1 ) , while , at the same time , solving Problem 2 with a novel unsupervised and data - driven cross - validation technique .	3522489	no
Comparing population - level waste shedding over time , rates varied by variant - specific stages , and changes in shedding rates were potentially influenced by associated disease expression and variant - driven viral loads . However , the relationship between disease severity of clinical cases and waste shedding could not be directly measured in the absence of explicit patient data . Additionally , waste shedding rates were determined based on community - level analyses and should not be interpreted as representative at an individual level .	252669606	no
In summary , these data demonstrate that peripheral , hematopoietic cell - specific Th deficiency does not affect energy expenditure , and that macrophages lack the capacity to produce sufficient catecholamines to promote thermogenic effects in iWAT or BAT .	4033199	no
A consortium of industry leaders with vested interests in databases ( Teradata ) , statistical software ( SPSS ) , data consulting ( IBM ) , and transaction software ( NCR ) formulated a research agenda . The other participants ( Daimler AG and OHRA ) represented data - intensive industries , e.g. , the automotive and insurance industry . Funding for the consortium was approved as part of the ESPRIT programme , with the aim of producing an open standard for data mining . Although CRISP - DM is the most commonly endorsed data mining process , it is not the only process available . The framework is nominated by many industrial participants as the most commonly used data mining process ( KDnuggets , 2014 ) . Another alternative is SEMMA , which stands for Sample , Explore , Modify , Model and Assess , developed by the SAS Corporation ( SAS , 2019 ) . SEMMA is not intended as a general purpose framework for analysis , although it has been adopted as such by some . The CRISP - DM model has even been expanded in steps and methodology by still newer authors . Azevedo and Santos ( 2008 ) offer a critical comparison of the The ability and capacity to analyse data into useful information Alignment between supply of data and demand of information alternatives . Substantial changes have occurred in business , society and technology in the nearly twenty years since the CRISP - DM framework was launched . In turn this has required proponents of the field to develop new conceptions of knowledge where the ideal data science practitioner mixes computer science , business knowledge and acumen , and statistical knowledge all in one person . Likewise the functional relationship between data mining team members and other professionals inside public and private analysis bureaus is increasingly being reconsidered . These concepts have in large part helped to define data science as a new domain of knowledge and a new kind of professional expertise . See for instance the discussion by Hicks and Irizarry of the needs of this new field of education ( Hicks and Irizarry , 2017 ) .	239658990	no
Information about germline mutation in FPC is essential for developing surveillance and treatment strategies , and there have been several studies along these lines ( Table 2 ) . According to a germline mutation analysis of four genes ( BRCA1 , BRCA2 , PALB2 and CDKN2A ) in 727 affected cases including 521 FPC , the percentage of cases harboring the above gene mutations was higher in FPC probands than in non - FPC probands ( 8.0 % vs. 3.5 % ) ( odds ratio : 2.4 , 95 % CI : 1.1 - 5.4 ) [ 63 ] . In this study , the mutation prevalence in the FPC cohort was 3.7 % for BRCA2 , 2.5 % for CDKN2A , 1.2 % for BRCA1 , and 0.6 % for PALB2 . Grant et al . conducted targeted sequencing of 13 genes associated with hereditary cancer syndromes or FPC for 290 PC probands , and showed the mutation prevalence was 2.6 % ( 95 % CI : 0 - 6.0 ) in cases with a history of PC in FDR and 4.0 % ( 95 % CI : 2.1 - 5.9 ) in those without any history [ 64 ] . Petersen et al . also conducted germline analysis of 25 cancer susceptibility genes for 303 PC patients including an FPC cohort in the Mayo Clinic Familial Pancreatic Cancer Registry , and reported that 12.9 % of 186 FPC cases and 9.4 % of 117 non - FPC cases harbored some mutations [ 65 ] . From a Japanese cohort of 1,197 PC patients , Takai et al . identified 88 ( 7.3 % ) FPC cases , and conducted germline sequencing of hereditary cancer susceptibility genes [ 66 ] . In this study , deleterious mutations were detected in 8 of 54 ( 14.5 % ) cases , including 3 ( 5.6 % ) BRCA2 mutation , 2 ( 3.7 % ) PALB2 mutation , 2 ( 3.7 % ) ATM mutation and 1 ( 1.9 % ) MLH1 mutation . These data indicate genomic heterogeneity in FPC , although inconsistencies in mutation prevalence among studies might be influenced by the number of target genes , limited sample size or subjects ' backgrounds , including ethnicity . Importantly , previous studies found no susceptibility gene mutations in more than 80 % of FPC cases , suggesting that further investigations to identify novel susceptibility genes should be fruitful . Germline mutations in cancer susceptibility genes are also found in cases without definite family history or association with hereditary syndromes . Hu et al . conducted germline analysis of 22 cancer susceptibility genes for 96 PC cases without preselection based on family history , and detected deleterious mutations in 13.5 % of the cases , including 9.4 % for four genes ( BRCA1 , BRCA2 , ATM , and MSH6 ) [ 67 ] . Yurgelun et al . conducted targeted sequencing of 24 hereditary cancer susceptibility genes in a series of 289 resected PC , and detected mutations in 9.7 % of the cases including 7.3 % for HRR genes and 1.0 % for MMR genes [ 68 ] . Targeted sequencing of 32 genes in an unselected PC series of 854 cases revealed deleterious mutations in 3.9 % of the cases , including 3.5 % for 7 FPC - related genes [ 69 ] . Hu et al . recently compared genomic data of 3,030 affected cases and a normal cohort , and found that 5.5 % of the affected cases harbored mutation in 6 genes associated with increased PC risk ( CDKN2A , TP53 , MLH1 , BRCA1 , BRCA2 , and ATM ) [ 70 ] . In the latest germline analysis of 298 unselected PC patients , 23 ( 7.7 % ) patients harbored deleterious mutations in PC susceptibility genes [ 71 ] . In this study , 6 of 23 ( 26.1 % ) mutated cases actually did not fulfill prescribed genetic testing criteria for hereditary cancer syndrome or FPC , and 12 of the 23 ( 52.2 % ) mutated cases would not have been checked according to the criteria . These results indicate that the disparity in germline mutation prevalence between FPC and sporadic PC is not dramatic , and that current screening strategies chiefly based on family history can not completely extract susceptibility gene carriers . On the other hand , exhaustive genomic analysis seems not to be cost - effective , since mutation is not so frequent . Here , software risk assessment tools based on family and past history of PC , such as PancPRO , might deserve further consideration [ 72 ] .	67858936	no
Most general purpose matrix libraries for JavaScript represent a multi - dimensional matrix with a nested JavaScript array . In contrast , Sushi2 represents a matrix with TypedArray , which is used for transferring numeric data between the CPU and GPGPU . TypedArray is a one - dimensional numeric array with fixed size and bit width at construction , as in arrays of C language . The array accommodates efficient storing and manipulation of large data . TypedArray which stores 32 - bit floating point numbers is named Float32Array and the one that stores 8 - bit unsigned integer is named Uint8Array . The numeric type of JavaScript is a 64 - bit floating point number , but some WebCL environments do not support it . Therefore , the basic numeric type of matrix is a 32 - bit floating point number . However , the precision of a 32 - bit floating number is only 23 - bit , so it can not be used as an index of a large matrix ( which have more than 2 23 elements ) . This is a problem for functions such as argmax , so a 32 - bit signed integer matrix is also implemented . Moreover , an 8 - bit unsigned integer matrix for raw image data and a logical matrix for Boolean operations are implemented .	1915088	no
TMAs offer high - throughput immunohistochemical analysis of clinical samples and provide for study of tissue and cell - type specific networks underlying pathophenotypes ( 4,21 ) . TMA Navigator is a unique interactive platform for TMA data processing and analysis that has been successfully tested on multiple web browsers ( Internet Explorer , Firefox , Chrome , Opera , Safari ) . Key features include batch correction ( 17 ) , unsupervised stratification by marker scores , survival analysis and network inference . An extensive user guide and demonstration datasets are available . We very much appreciate feedback on any issues relating to TMA Navigator , ideally sent via the form at www . tmanavigator.org/contact , and welcome requests for new functionality . . Spearman correlation network for trastuzumab - treated breast cancers . All marker pairs were scored using Spearman correlation and significant edges ( FDR P 0.05 ) are shown . Colour of network nodes ( markers ) ranges from blue to orange , indicating low to high degree ( number of significant connections ) . Positive and negative edges are respectively shown in grey and red . The network can be explored interactively , for example to alter layout and set significance threshold . Clicking on a marker summarizes neighbours , clicking on an edge displays the Spearman correlation and P - value . The above network recapitulates several expected interactions including a cluster of proteins that promote EMT ( Snail , Slug , Vimentin , ZEB1 ) and an adhesion cluster ( E - cadherin , b - catenin , Claudin-7 ) ( 30 ) . Networks may also be exported as GraphML for use with external software or as a PNG or SVG image .	4226862	no
My overall approach was naturalistic enquiry and specifically ethnography , the key feature of which is lengthy and repeated engagement with field sites and research participants ( Messac et al . , 2013 p. 184 ) . My research took place in an economically depressed small town in a rural , formerly coal - mining area of the North East of England and a contrasting second site : a deprived urban neighbourhood three miles from the centre of a North West city . Increasing spatial segregation by income ( Fahmy et al . , 2011;Quillian , 2012 ) means that the social gradient in smoking is reflected in place - based inequalities ( Glenn et al . , 2017;Pearce et al . , 2012;Thompson et al . , 2007 ) so that by selecting areas of high deprivation for this study , I was also choosing areas with high rates of smoking . I made fifty visits during 2017 and 2018 to venues including community centres , shops , libraries and working men 's clubs ; however most of my time was spent at a community project in each field site serving mainly unemployed people and over half the interviewees were service users and staff from these two venues ( n = 36/59 ) . Ethical approval for the research was obtained from the Economics , Law , Management , Politics and Sociology ( ELMPS ) Ethics Committee at the University of York . I talked research participants through an information sheet which explained the purpose of my study , the identity of the funders , anticipated use of data and other issues before obtaining written consent ( ASA , 2011 ) . Research locations have been obscured and names and other details of participants changed in the text to protect anonymity .	201749444	maybe
The goodness of fit of the proposed research model was calculated for the two - factor measurement model that included employees ' unethical behavior and ethical behavior of organization . The fit statistics Ï 2 ( N = 2024 , df = 894 = 30,894.27 , p < 0.001 ; CFI = 0.910 ; IFI = 0.911 ; RMSEA = 0.035 ; PCLOSE ( 1.000 ) indicated a good fit between the hypothesized model and data ( Byrne , 2010 ) .	237409895	no
Baseline 25.50 Fine - tune from C10 14.32 Fine - tune from C100 14.38 Ours ( C100 ) 12.35 Ours ( C10 , C100 ) 11.09 model using weights pretrained on CIFAR-10 and CIFAR-100 reduce test errors by more than 10 % . Compared with fine - tuning , student model training in our framework further reduces the test error by 3 % . Note that we only train on the labeled data while other approaches use this data for testing of semi - supervised approaches . Hence our results are obtained using fewer data and may not be directly comparable . We still list their results in Table 6 for reference . In Fig . 5 we illustrate the accuracy over the epochs of training .	69629714	no
For the interrupted time series analysis we will have at least 48 data points ( monthly initiation and cessation proportion estimates ) , with 10 data points after our exposure time period ( using the July 2015 CPRD build ) and each data point will have at least 336 outcome events . Using a power calculation for the comparison of Poisson counts across two groups , we will have 90 % power at a 95 % confidence level to detect a rate ratio of at least 1.07 when comparing the rate of either initiation or cessation before and after the exposure time period	437614	maybe
CalcGrad ( ) ; foreach parameters : In the communication part , the pairs of the quantized values and the parameter indexes in each node are broadcast to all nodes . The i - th node 's input data size n i ( i = 1 , ... , p ) may be different among nodes , where p denotes the number of nodes . An MPI function called allgatherv realizes such an operation . Because recent successful image recognition neural network models like VGG ( Simonyan & Zisserman , 2015 ) or ResNet ( He et al . , 2016 ) have a large number of parameters , the latency term in communication cost can be ignored even if we achieve very high compression ratio such as c > 1 , 000 . In such cases , a type of collective communication algorithms called the ring algorithm is efficient ( Thakur et al . , 2005 ) . Its bandwidth term is relatively small even though its latency term is proportional to p. Although the naive ring allgatherv algorithm costs unacceptable O(max i n i Â· p ) time , TrÃ¤ff et al . ( 2008 ) proposed a method to mitigate it by dividing large input data , which is called pipelined ring algorithm . For example , an allgatherv implementation in MVAPICH adopts a pipelined ring algorithm for large input data .	3402524	no
The exact procedure that we use to check for unification of gauge couplings for data in Fig . 1 is as follows . First , we fix the SUSY scale M SU SY = 1 TeV. We further set Î· = Î» = Î± = Î± = 1 and then vary x and g GU T , where g GU T is the gauge coupling at the GUT scale . Once all these parameters are given we numerically determine the masses of the superheavy fields , including the gauge ones , in arbitrary units of m. Then we define the following coefficients	17807230	no
Overall these data suggest that mitochondria of IR - NT3 rats possess higher protein quality control and greater defensive capacity to face IR injury .	727347	no
Modeling waste disposal rates using separate time series requires more work , however it appears a better modeling approach , at least using waste disposal data in the current study . Comparing to the baseline , approaches 3 ( truncated total ) and 4 ( truncated fraction ) better captured the total waste disposal behaviors during the COVID-19 period ( Fig . 2c , d ) , probably due to the periodicity of the weeklong data set . Both approaches 3 and 4 accurately predicted total waste disposal rates in the full range . Substantial improvements in model performance were observed below 50 t / day . Approach 4 appears slightly better , with more points located directly on the 45 - degree line ( Fig . 2d ) . Fig . 3 presents model performance indicators for the four approaches . It is obvious that the use of waste fractions helps to reduce the modeling errors and increase R value . Compared to the baseline approach , the MAE of approach 2 decreased from 145.45 to 114.53 , and the MAPE decreased from 625.92 % to 391.54 % ( Fig . 3a ) . The MSE was reduced by 26.2 % from 31,709 to 23,390 and R value increased from 0.63 to 0.79 ( Fig . 3b ) . The results highlight the potential benefits of modeling total disposal rate using different waste fractions .	235336704	no
contain sparse bag - of - words feature vectors for each document and a list of citation links between documents . Documents and citation links are regarded as nodes and edges while constructing the graph . 20 instances are sampled for each class as labeled data , 1000 instances as test data , and the rest are used as unlabeled data . The goal is to classify each document into one of the predefined classes . We use the same data split as in [ 47 ] and [ 18 ] . We use an additional validation set of 500 labeled nodes for tuning hyperparameters as in [ 18 ] .	3290366	maybe
Dark Delay in Imaging Experiments : Any excitation wavelength for imaging Fluo-4 intensities will cause at least a partial change of E / Z ratios . Dark periods were therefore included to allow Ca 2 + signals in TRPC5 - expressing cells to develop for some time towards their plateau without such interference that would depress peak signals ( there is a much slower response of the Ca 2 + -imaging agent , on a seconds scale , than electrophysiology readouts that are on the millisecond scale ) . The data points used to construct the action spectrum were collected from 24 the very first images after the dark phase , reflecting the Ca 2 + influx induced by the applied onswitching wavelength during a defined dark time interval .	246403838	maybe
Measuring A L would be quite interesting , but what A L receives is of course one single combination of contributions from all the anomalous parameters . We are performing a model - independent analysis of possible new - physics effects , but once we get actual experimental data , our results are going to be applied for a realistic model building . If A L does not depend on some parameters so much , it will be hard to test any models in which those parameters play a significant role . Therefore it must be important to see how A L depends on each parameter .	14696846	no
One approach would be to build individual models for each county , using historical data from previous elections . Immediately we encounter several practical challenges : 1 ) By building independent models for each county , we fail to share information between related counties , resulting in a loss of statistical power , 2 ) Since elections are relatively infrequent , the amount of data on each county is limited , resulting in a further loss of power , and 3 ) To ensure that the models are able to explain the preferences of an electorate , we will be forced to use simple models ( e.g. logistic regression or decision trees ) , which will likely have limited predictive power compared to more complex models . This simultaneous loss of power and predictive accuracy is characteristic of modeling large , heterogeneous datasets arising from aggregating multiple subpopulations . Crucially , in this example the total number of samples may be quite large ( e.g. there are more than 3,000 US counties and there have been 58 US presidential elections ) , but the number of samples per subpopulaton is small . Furthermore , these challenges are in no way unique to this example : similar problems arise for examples in financial , biological , and marketing applications .	202772010	no
I start this paper in Sect . 2 by providing some theoretical and empirical backing for why Weinberg et al . ( 2001 ) found the hypothesis about SES and Gettier judgments plausible . In Sect . 3 I introduce the Great British Class Survey . Sections 4 - 6 describe the experiments , and report the results . Section 7 concludes . The Appendix contains the texts of all vignettes as well as table work . Supplementary Materials contain information on the construction of the SES variables and other relevant matters , and will be made available online , together with the data .	237505077	yes
"Biosensors promise direct , sensitive , and rapid analysis of complex samples , such as medical samples , which are currently subjected to time - and material - intensive techniques ( e.g. ELISA ) . Thus , biosensors could revolutionize the analysis of complex samples in healthcare , medicine , and the life sciences . [ 41 ] Various approaches , including methods based on nanowires , surface plasmon resonance , and microcantilevers , have shown promising results in this regard . [ 42,43 ] The research groups of Whitesides [ 44 ] and Niemeyer [ 45 ] independently described fabrication routes towards affordable , disposable biosensor platforms . Lieber and co - workers demonstrated the use of nanowire - based field - effect transistors for the electrical detection of distinct disease - marker proteins in clinically relevant serum samples . This approach could eventually facilitate pattern analysis of existing and emerging biomarkers for diagnosis . [ 41,46 ] Matrices with immobilized morphogenic proteins are usually used in tissue engineering as a structural support for cells in bone , [ 47,48 ] skin , [ 49,50 ] articular cartilage , [ 51 ] and vascular tissue , [ 52 ] and are also used in neural - stem - cell expansion . [ 53 ] Iwata and co - workers developed enhanced cell - culture substrates for the selective growth of neural stem cells ( NSCs ) that displayed artificial dimers of epidermal growth factor , a strong activator of NSC proliferation . With their approach , they could significantly enhance cell - growth rates relative to those observed in usual methods . [ 54 ] Radisic and co - workers successfully assembled endothelial cells in a three - dimensional collagen scaffold by functionalizing it with vascular endothelial growth factor ( VEGF ) and thus demonstrated that vascularization in large three - dimensional tissue constructs , which would be required to ensure oxygen supply , might be possible with immobilized VEGF . [ 55 ] Despite the large number of successful examples of the application of protein biochips in biomedical and biotechnological research , numerous challenges remain to be tackled . Most protein biochips are currently prepared by traditional strategies , which lead to random protein orientation on the chip surface . This random arrangement can negatively influence protein activity or ligand binding as a result of steric hindrance , and can thus lead to a decrease in assay efficiency or even the falsification of assay results . [ 34 ] The problem might be solved by the implementation of moreadvanced methods for the preparation of protein biochips . Many such methods have been developed over the last few years . [ 4 ] The expression and purification of thousands of proteins with retention of their intrinsic activity is far from trivial . [ 34 ] However , a growing number of approaches for the fast production of high - quality proteome - scale protein biochips are being developed for several organisms . One example is the "" full - length expression - ready gene collection "" ( FLEXgene ) , which consists of complete - ORF plasmid collections from various species for the simple cloning and expression of whole proteomes . [ 56 ] The introduction of label - free detection methods , such as mass spectrometry or surface plasmon resonance ( SPR ) , will simplify microarray analysis , since interaction partners no longer need to be labeled . This feature is particularly important for large - scale analysis based on protein biochips . Evans - Nguyen et al . incubated a superhydrophobic , selfassembled - monolayer - modified , porous gold surface displaying immobilized antibodies with plasma spiked with an antigen peptide , and after matrix application detected bound peptides directly by using MALDI . [ 57 ] Campbell and Kim reviewed the promising application of SPR for the label - free readout of protein - protein interactions on protein microarrays . [ 58 ] The standardization of microarray production , application , and data analysis would improve and ensure the quality of data obtained with protein microarrays . This standardization would include subsequent confirmatory studies with independent methods to verify the findings of protein - microarray screens ."	35417338	no
The systematic literature review method is always better than a traditional review because it helps to identify the gaps in studies and provides information on areas where the majority have been undertaken . However , these COVID-19 cases and associated incidents are very new and at the time of the first submission , it was only 6 months happened after COVID-19 . Thus , most of the information was covered including either government documents , quick submission or the different published research article . It was not either very clear at that time how and for how long the global impact will remain active . However , after the first revision and during the time of the second submission , it was clear that the impact of COVID-19 remained drastic and aligned with the previous work . For the discussion section , a wider review has been included which has an immense influence on building energy has been included . In our study , we did not investigate more on details of COVID-19 virus . Fig . 1 illustrates the mechanism of performing this review work . At the first step keywords such as COVID-19 - energy , COVID-19 -social , COVID-19 - environment , COVID-19 - transport , COVID-19 -economy , COVID-19 sustainable were employed to obtain published work . Details of the COVID-19 virus and its genetic structure and comparative relation between the genetic structures of other SARS viruses were excluded . This information was added only in the introduction section to start the topic . For the 2nd steps publication period between 2020 and 2021 was included . In this process , we excluded the work , which was based on perspective and added only which included real time data analysis . However , to make a clear and positive discussion more relevant work in the building sides were included and for them , publication ranged varied between 2015 and 2021 however priority was given to the most recent updates for each specific topic .	236247702	no
Interestingly , let us finally emphasize that our results hold using only the ( 1D ) output s of f ( Â· ; Î¸ f ) as input to the adversary . We could similarly enforce an intermediate representation of the data to be pivotal , e.g. as in ( Ganin and Lempitsky , 2014 ) , but this is not necessary .	12519545	no
Another important effect on the dark high - frequency capacitance is that of applied voltage , which critically depends on the bias range and device charge density . At reverse bias , the capacitance often saturates toward C g , as illustrated in Figure 16 , meaning full depletion of the space charge zone . However , care must be taken when interpreting the capacitance in the Mott - Schottky plot representation at forward bias because at least two different capacitances compete below and around V bi . Like in the experimental data in Figure 16a , some devices actually present a nearly constant charge density profile Ï(x ) = qN eff ( negative , if N eff â N A ) , x being the distance from the junction . Hence , the Mott - Schottky analysis is meaningful and the fitting of the linear region of low forward bias gives N eff and V bi . However , in most cases , the quasi - intrinsic character of the perovskite and variable doping by vacancy displacement prevents the use of this technique , which is the situation of Figure 16b . For such samples , the fitting of the nearly linear region around equilibrium ( Figure 16b dashed red line ) would deliver a meaningless V bi value , and the fitting of the apparently linear abrupt step around the expected V bi ( Figure 16b , solid red line ) is that the transition to a dominant exponential capacitance that appears as flat - band potential is approached and exceeded ( see Figure 16 , right axes ) . Consequently , Mott - Schottky analysis is not useful here . Actually , for some devices , the shape of the charge density can be approximated to a power law Ï(x ) = qÎ·x Î³ ( Î· is a constant with units of cm â(Î³ +3 ) and Î³ is an integer ) . Thus , by integrating the Poisson equation ( analogously to Section S1.1 in the Supporting Information ) along a depletion layer of width w , it is easy to obtain after some calculations [ 97,106 ] ( ) dl ( 2 ) bi	103419711	no
"â¢ Enforcement of decisions on standards is based on availability of resources ( e.g. , funding , training , etc . ) to support resource - scarce stakeholders , but these are sometimes not available ( Oosterveer et al . 2014;Brandi et al . 2015 ) â¢ Land conflicts seem to only be solved if powerful players ( e.g. , international NGOs ) help rural communities strengthen their bargaining position visÃ  - vis companies ( KÃ¶hne 2014 ) . Yet , out of 600 palm oil related land conflicts in Indonesia , only few affected communities were able to resort to the support of external actors ( KÃ¶hne 2014 ) â¢ Companies used the RSPO pre - certificate assessment as a legitimacy proof in land conflicts with communities ( KÃ¶hne 2014 ) â¢ Report "" Who watches the watchman ? "" ( EIA 2015 ) found that auditing firms sometimes collude with companies to hide standard violations ( e.g. , labor abuses , land conflicts with local communities ) . There were 52 complaints of certification violations in the RSPO system ( EIA 2015 ) thus pushing the conflict outside the RSPO ( harnessing value conflict through deliberation , Table 4 ) . Furthermore , the RSPO has overall consulted a heterogeneous , yet limited group of stakeholders to better understand the debated issues and develop appropriate assessment tools . Participation and influence was limited to those sources that were considered as technical and objective ( harnessing knowledge uncertainty through deliberation , Table 5 ) . For example , given the knowledge uncertainty and value conflicts between the proponent of GHG emissions targets and palm oil producers , the RSPO commissioned a first working group ( WG1 ) in 2008 to review all stages of the palm oil supply chain and create support for voluntary actions to reduce emissions . As no consensus for â¢ Data collection and analysis on GHG emissions is implemented exclusively by one stakeholder group ( companies ) , which are asked to self - assess their performance ( Bessou et al . 2014 ) . Moreover , pilot tests suffered of limited data availability at company level in 2012 and 2013 ( Bessou et al . 2014 ) â¢ The GHG calculator was developed from a knowledge approach chosen by environmental consultancy firms and energy companies ( Bessou et al . 2014 ) , so little input from other stakeholders was used in the assessment â¢ Land titling was needed to receive RSPO certification , but this enforcement system was contested because it implies an acceptance of market - based mechanisms for a monetary evaluation of land ( Johnson 2014 ) . Thus , the perspective of stakeholders providing a sociocultural value to the land was ignored at a monitoring level ( Johnson 2014 ) decision - making could be reached , another working group ( WG2 ) was established in 2009 , comprising both members of the Executive Board as well as 20 non - RSPO members , with representation from each of the RSPO 's constituting groups . WG2 was tasked with developing a framework for verifiable reductions in GHG emissions . To reduce further value conflict , processes of deliberation within WG2 were focused on getting a better scientific understanding of the problem and developing technical measurement tools ( Bessou et al . 2014 ) . This was supposed to lay the foundation for a legitimate decision - making process surrounding the revised P&C."	254380182	no
Finally , to validate our approach beyond our simulator by using real language , we collected data via Amazon Mechanical Turk . Due to the cost of data collection , we focused on real language versions of Tasks 4 ( Knowledge Verification ) and 8 ( Missing Triple ) , see Secs . 3.2 and 3.3 for the simulator versions . That is , we collect dialoguess and use them in an offline supervised learning setup similar to Section 4.1.1 . This setup allows easily reproducibile experiments .	14741151	maybe
Metabolites of rapidly dissected WT and Vldlr â/â retinas ( flash frozen less then a minute from euthanasia ; 15 - 16 biological replicates ) were homogenized in 80 % methanol ( 8 ÂµL / mg of tissue ) containing the internal standards inosine-15 N 4 , thymine - d 4 , and glycocholate - d 4 ( Cambridge Isotope Laboratories ) using a TissueLyser II ( Qiagen ) bead mill for 4 minutes at 20 Hz . Samples were centrifuged ( 9,000 g , 10 min , 4 Â° C ) to pellet debris and supernatants were analyzed using two liquid chromatography tandem mass spectrometry ( LC - MS ) methods to measure polar metabolites as described previously . 45 , 46 Briefly , negative ionization mode multiple reaction mode ( MRM ) data were acquired using an ACQUITY UPLC ( Waters ) coupled to a 5500 QTRAP triple quadrupole mass spectrometer ( AB SCIEX . The column was eluted isocratically at a flow rate of 250 ÂµL / min with 5 % mobile phase A ( 10 mM ammonium formate and 0.1 % formic acid in water ) for 1 minute followed by a linear gradient to 40 % mobile phase B ( acetonitrile with 0.1 % formic acid ) over 10 minutes . The ion spray voltage was 4.5 kV and the source temperature was 450 Â° C . Raw data were processed using MultiQuant 2.1 ( AB SCIEX ) for automated peak integration and metabolite peaks were manually reviewed for quality of integration and compared against known standards to confirm identity .	8165361	no
Supplementary data to this article can be found online at https://doi . org/10.1016 / j.scitotenv.2022.160163 .	251656040	yes
Modelling the electron density distribution in each crystal structure using the experimental X - ray diffraction data was performed using the multipole refinement model advocated by Hansen and Coppens [ S13 ] . The electron density is described using the formula shown in Equation 1 , where Ïc(r ) and Ïv(r ) are the spherical core and valence electron densities , the summation in the third term accounts for the valence electron deformations and the dlmÂ± are density - normalised real spherical harmonics expressed in polar coordinates . The isolated atom valence density and the Slater type radial functions R1 are modified by the scaling factors ( Îº and Îº ' ) to account for the radial expansion or contraction of the valence shell .	237371566	no
Finally , our approach projects data to 2 K dimensions which could be a concern if the original feature dimension itself is less than 2K. However , since we are only concerned with data that has underlying independent subspace assumption , notice that the feature dimension must be at least K. This is because each class must lie on at least 1 dimension which is linearly independent of others . However , this is too strict an assumption and it is straight forward to see that if we relax this assumption to 2 dimensions for each class , the feature dimensions are already at 2K.	14179068	no
However , there is no consistent pattern that describes the evolution of SARS - CoV-2 across all chronic infections . Whereas some cases display considerable evolution in the spike ( S ) protein , in other chronic infections , relatively limited evolution is observed . In this study , we set out to consolidate the evolutionary patterns found across chronic infections by re - analyzing previous reports and by sequencing a cohort of six patients with chronic SARS - CoV-2 infection from the Tel Aviv Sourasky Medical Center ( TASMC ) 14,15 . We explore the shared and unique mutational patterns that emerge in different chronically infected patients and compare them to those observed in global data reflecting transmission chains in acutely infected individuals . We focus on correlates of adaptive evolution and the potential for the creation of new VOCs .	247155371	no
We have obtained high - S / N HST spectra of the Î»9348 , Î»9365 , Î»9428 and Î»9577 C + 60 bands along seven heavily reddened interstellar lines of sight . The strong Î»9577 band and weaker Î»9365 band are clearly identified in all sightlines , with wavelengths and equivalent width ratios closely matching the latest laboratory data . A weak Î»9428 band can also be seen in the early B - type sightlines where contamination from stellar features is less severe . The Î»9428 wavelength and profile appear to differ from those expected based on the laboratory measurements of Campbell et al . ( 2018 ) , and its measured equivalent width is â¼ 50 % less than expected , but residual stellar / interstellar contamination can not be ruled out as a possible explanation for these small discrepancies . The Î»9348 band could not be detected due to its intrinsic weakness and overlapping stellar lines . In summary , we confirm the presence of all three expected C + 60 bands in the diffuse interstellar medium , with strength ratios consistent with those measured in the laboratory for C + 60 -He at very low temperature . We consider this the first robust detection of the Î»9428 interstellar band . Combined with prior , ground - based observations of the Î»9365 , Î»9577 and Î»9632 bands ( e.g. Walker et al . 2015Walker et al . , 2016Galazutdinov et al . 2017b;Lallement et al . 2018 ) our HST spectra place the detection of interstellar C + 60 beyond reasonable doubt .	121292704	no
Refer to Web version on PubMed Central for supplementary material . Summary of the analysis pipeline . The fMRI time - series data from a pre - defined region - ofinterest ( ROI ) are rearranged into a time - by - voxels matrix A , as are the time - series from all vertices / voxels outside the ROI ( matrix B ) . For reasons of computational tractability , the dimensionality of B is losslessly reduced using singular value decomposition ( SVD ) , yielding B. For every voxel within the ROI , its connectivity fingerprint is computed as the Pearson correlation between the voxel - wise time - series and the SVD - transformed data , yielding matrix C. Then similarity between voxels is computed using the Î· 2 coefficient . Manifold learning using Laplacian eigenmaps is then applied to this matrix , yielding a set of connection topographies , which can remapped to other regions by taking the maximum correlation . Then , trend surface modelling is applied to summarize these connection topographies by fitting a set of trend coefficients ( Î² ) that optimally combine a set of spatial polynomial basis functions . Finally , canonical correlation analysis ( CCA ) is used to find associations with these behavioural measures . See Methods for further details Panel a : The striatal connection topography estimated here from resting state fMRI in humans ( Left ) shows an excellent correspondence with the theoretical pattern of connectivity between reward - related brain areas and the striatum based on invasive tracing studies in animals ( Right , reproduced from 5 ) . Panel b : The pattern of connectivity between the connection topography in the striatum ( centre ) and the cerebral cortex . Arrows indicate examples of cortical regions for which topographic connectivity with the striatum is preserved . The inset shows the theoretical connectivity pattern derived from invasive tracing Relative importance of different variables in driving the multivariate correspondence between the topography from the left striatum and the behavioural battery ( derived from all 466 subjects used in the analysis ) . Panel a : Importance of connectivity gradients in predicting the behavioural scores . The top left panel ( G1 ) shows structure coefficients corresponding to the principal predictive gradient estimated by CCA . These are rescaled such that the maximum in the image is equal to one and can therefore be considered to be in arbitrary units ( a.u . ) . The remaining panels show differences between the rescaled principal CCA gradient and each successive rescaled predictive gradient ( a.u . delta ) . For example , G2 - G1 is the difference between the second gradient and the first . This helps to highlight the differences between the predictive gradients . Panel b : Predictive pattern of measures contributing to the CCA predictions . These are the structure coefficients aggregated across behavioural domains ( see Methods ) and are also rescaled such that the maximum behavioural domain has a value of 1 , here represented by a point on the outermost circle .	13913896	maybe
The study uses a two - step methodology . First , confirmatory factor analysis ( CFA ) was conducted to assess the steps ' reliability and validity . Second , a structural model and path analysis were developed to test the hypotheses . The use of SEM as a data processing tool is justified because the research investigates hypotheses based on a solid theoretical context . The collected data often satisfy the multivariate criteria for an analysis to support SEM 's suitability , which means that the collected data are usually normally distributed and do not have multicollinearity problems . Common method bias ( CMB ) may be a problem , owing to the self - reported quality of results . This was checked using a Harman onefactor test .	237669349	no
Dizziness NA Outcome data reported in review meta - analysis .	52883486	maybe
The high - level controller senses inputs from proprioceptive data and , for visual tasks , an egocentric camera mounted at the root of the body ( Fig . 4 ) . A noteworthy challenge arises due to the movement of the camera itself during locomotion . The proprioceptive inputs are encoded by a single linear layer , and the image is encoded by a ResNet ( see Appendix A ) . The separate inputs streams are then flattened , concatenated , and passed to an LSTM , enabling temporally integrated decisions , with a stochastic policy and a value function head . The high - level controller receives inputs at each time step even though it may only act when the previous behavior ( gait cycle or control fragment ) has terminated .	53792719	no
In conclusion , our data reveal that P2X7 can form functional complexes with TMEM16 channels in HEK293 T cells . Interestingly , a very recent work has also reported similar modulation of P2X7 activity with another channel , TMEM163 [ 50 ] , suggesting that P2X7 may functionally associate with different kinds of ion channel families . We propose that the functional complexes formed between P2X7 and TMEM16 channels act as a regulating hub , which , upon P2X7 activation and dependent on the surrounding membrane cholesterol level , orchestrates a hive of activity , eliciting not only channel gating ( e.g. , efflux of K + and Ca 2 + signaling ) , but also other cell - specific signaling , including membrane blebbing , interleukin release and phospholipid scrambling [ 9 ] . Given the critical roles of P2X7 and TMEM16 channels in many diseases , this platform may be involved in important pathophysiological processes that lead , for example , to inflammation [ 51 ] and mechanical allodynia [ 52,53 ] , and may therefore be therapeutically important . Future work is needed to unravel its broader implications in disease .	235652719	no
Even if the event 1 - OGC 151030 is not a true GW - GRB observation , the prospects for detecting such signals in the near future in data from the second or third LIGO observing run seem compatible with more optimistic scenariosï  ( Howell et al . 2018 ) . In the years to come , the combination of information from different astronomical observations will be of increasing importance and will likely include not just GW and gamma - ray observations , but also other parts of the electromagnetic spectrum , neutrinos , and cosmic raysï  ( Branchesi 2016 ) . In particular , surveys of kilonova candidates with the Large Synoptic Survey Telescope may provide another population which could be further correlated with GW candidates and increase the reach of multi - messenger searchesï  ( Andreoni et al . 2018;Setzer et al . 2019 ) .	119088820	no
Specifically , the aim of this paper is to analyse the effect that a greater presence of women in management teams has on business behaviour in relation to labour and human rights , and the mediating role that a greater performance in regard to these issues has on corporate transparency . The results from a sample of 1243 international firms for the period 2013 - 2017 ( corresponding to an unbalanced data panel of 5693 observations ) show that gender diversity in management teams is positively associated with performance in relation to labour and human rights , and that such a performance acts as a mediating factor by fostering a higher disclosure of information regarding these issues .	238721332	maybe
That is , we strived to test if the medians of the two samples are statistically the same . Compared to other tests for repeatability , for example , the student t - test , the Î¼ - test requires fewer assumptions and is more robust 27 . We thus used a Matlab built - in function , ranksum , to perform the Î¼ - test and the hypothesis results and prominent P - values are summarized in Supplementary Table S2 . As shown in this table , the null hypothesis H = 0 is valid for all the 2 Ã 4 sets of measurement data ( from devices A and B at four different locations ) , showing the strong inter - device repeatability of our c - Air platform .	4666001	no
"The healthcare industry is no exception . In the digital age , many hospitals and care providers have actively pursued innovations for contactless services and operational processes for improved productivity and organizational agility ( Lee and Lee , 2020b ) . Through applications of advanced information and communication technologies ( ICTs ) , such as artificial intelligence ( AI ) , Internet of Things ( IoT ) , big data , 3D printing , virtual and augmented reality ( VR / AR ) , smart sensors and robots , drones , etc . , various contactless services have been implemented . Telemedicine , which has been widely practiced since 1990s , well before the COVID-19 pandemic period , is of course part of contactless healthcare service . However , contactless healthcare services in the digital age encompass far beyond the traditional scope of telemedicine ( Marin , 2020 ) . Dr. Bart Demaerschalk , director of the Synchronous Services Center for Connected Care of Mayo Clinic , states that "" the COVID-19 pandemic has essentially accelerated U.S. digital health by about 10 years "" ( Marin , 2020 ) . Accordingly , digital technology enabled contactless healthcare services have also made a big stride in their developments during the pandemic ."	232055750	no
3.1 . 1018 ) . All data points were collected from a web - based research panel operated by Norstat . The third survey was sent only to those who responded to the second survey , but the second , fourth , and fifth surveys were sent to all original respondents . The response rate was 28.3 % at ( T1 ) and was good for all follow - up time points compared to the first one ( T2 : 72.54 % ; T4 : 63.40 % ; T5 : 56.03 % ) or in the case of T3 , compared to the previous T2 ( T3 : 82.02 % ) . For this study , we formed a five - timepoint longitudinal data set comprised of respondents ( n = 840 ) who had participated in each round of surveys , that is , 46.23 % of the original survey respondents .	245335854	maybe
We extend the method first applied to M1206 in Sereno et al . ( 2017 ) to the 16 X - ray regular CLASH clusters with high quality , ground - based data for WL ( Table 1 ) . We do not consider the five lensing selected clusters , which are mostly merging or irregular systems . In fact , our modelling requires that matter and gas follow an ellipsoidal geometry and that gas and matter are aligned and co - centered . Modeling of complex distributions could require using finite mixture models as collections of ellipsoids that fit individual subclusters ( Kuhn et al . 2014 ) .	54596003	no
As the data analysis showed , this study was able to provide a hybrid mathematical model that converts infectious waste into energy , as well as offset the total costs associated with waste generated during the COVID-19 pandemic . The proposed model also minimizes the risk of virus contagion during the collection and transportation of infectious waste . The solution results of this model lead to useful managerial insights : ( i ) To prevent the spread of the COVID-19 virus through infectious waste , managers can generate energy from infectious waste and offset a part of the costs imposed during the COVID-19 epidemic . ( ii ) On the other hand , the results showed that the proposed model is able to consider the risk of virus contagion through infectious waste . Managers can follow the proposed model to control the risk of virus contagion through infectious waste despite the higher prevalence of the virus in different scenarios . ( iii ) Defining mathematical models and data as certain in applied problems reduces the flexibility of the model in uncertain conditions ( in real - world ) , and was affected in the quality of the model . The result showed that the proposed model was feasible in uncertainty . Therefore , in the proposed model , considering the severity of the outbreak by various scenarios and uncertain demand for waste collection indefinitely can greatly help in solving this problem . ( iv ) The use of a Bi - level model assists the managers in managing the huge amount of waste generated during the outbreak of COVID-19 by taking into consideration the concern of the government ( total costs ) and the concern of the contractor ( risk of virus contagion ) . Finally , based on the results obtained , it can be stated that in the case of energy production from waste during the COVID-19 pandemic , 34 % of the total cost of waste collection and transportation can be compensated .	237659056	no
In this section , we describe the dependent and independent variables used in our econometric models . These models aim to determine the factors that significantly impact consumer mobility activities as a consequence of the COVID-19 pandemic . We combine four main sources of data : 1 ) Google Trends data , 2 ) Google Mobility data , 3 ) Data on mortality and number of infections due to COVID-19 , and 4 ) Twitter data ( tweets ) relating to the COVID-19 pandemic .	255441206	maybe
margin between the correct top - k predictions and the incorrect ones . Our empirical results show that traditional top - k loss functions do not perform well in combination with deep neural networks . We believe that the reason for this is the lack of smoothness and the sparsity of the derivatives that are used in backpropagation . In order to overcome this difficulty , we smooth the loss with a temperature parameter . The evaluation of the smooth function and its gradient is challenging , as smoothing increases the naÃ¯ve time complexity from O(n ) to O ( n k ) . With a connection to polynomial algebra and a divide - and - conquer method , we present an algorithm with O(kn ) time complexity and training time comparable to cross - entropy in practice . We provide insights for numerical stability of the forward pass . To deal with instabilities of the backward pass , we derive a novel approximation . Our investigation reveals that our top - k loss outperforms cross - entropy in the presence of noisy labels or in the absence of large amounts of data . We further confirm that the difference of performance reduces with large correctly labeled data , which is consistent with known theoretical results .	3384895	no
We circumvent these limitations here by employing high degrees of sample deuteration , which strongly reduces the dipolar - dephasing contribution to 15 N R 11 rates . [ 8 ] In highly deuterated samples , that is , samples that are fully deuterated at non - exchangeable sites , and in which the exchangeable ( amide ) sites are ( partly ) reprotonated , the proton dipolar coupling network is strongly diluted , allowing for highresolution highly sensitive proton - detected ssNMR spectra , and long 15 N coherence life times . [ 8,9 ] Figure 2 a shows representative examples of residue - wise R 11 RD profiles obtained on a sample of deuterated microcrystalline ubiquitin that has been reprotonated at exchangeable sites to 50 % . 15 N R 11 data have been measured at a MAS frequency of 39.5 kHz , and spin - lock rf field strengths of 2 - 15 kHz , that is , far from the n = 1 rotary resonance condition ( which is at 39.5 kHz ) . The reported rate constants are on - resonance R 11 , that is , the R 1 contribution in the tilted rotating frame has been eliminated ( using standard formulae , [ 1a ] see the Supporting Information ) .	6603953	no
Plasma membrane proteins were retrieved from two datasets : ( i ) UniProt ( 23 ) , querying reviewed Homo sapiens proteins with the GO term ' plasma membrane ' ( GO:0005886 ) annotated by ' any manual assertion ' method ( 4602 proteins ) and ( ii ) plasma membrane proteins experimentally detected by HPA version 18 ( 31 ) , querying for the subcellular locations ' plasma membrane ' and ' cell junctions ' ( 1734 genes mapped to 1776 UniProt ACs using the UniProt ID mapping tool ) . Note that both datasets include proteins that are integral to the plasma membrane ( e.g. receptors ) as well as peripheral membrane proteins that may attach to integral membrane proteins or penetrate the peripheral regions of the membrane ( e.g. receptor - interacting proteins ) . Information on the presence or absence of signal peptide , lipidation sites , and transmembrane domains was obtained from UniProt on January 2019 ( 23 ) . The set of 7025 nascent proteins liable to form 3 UTR - protein complexes ( i.e. having protein - protein and protein - RNA interactions , as well as present in HPA ) , even though not enriched in plasma membrane proteins , contain a higher proportion of proteins localized in plasma membrane without a signal peptide or transmembrane domains than the proteome ( 52.4 % versus 31.4 % , using UniProt data ) . Thus , to avoid potential biases , statistical comparisons were done against this set of proteins instead of the proteome in plasma membrane - related analysis .	219174148	maybe
"A key marker of non - profits ' operations in journalism is their tendency to establish regional and global networks and their partnerships with NGOs , humanitarian organizations , and international foundations through which they gain funding , visibility , and influence ( cf . Wright 2018 ; Cottle and Nolan 2007;Fenton 2010;Powers 2018;Rosenstiel et al . 2016;Waisbord 2011;Tietaah et al . 2018 ) . Civic technologists form what Reese ( 2015 ) describes as a transnational advocacy network that adapts "" a global project to diverse local contexts "" ( 2263 ) . This means that transnational advocacy networks champion "" problem - solving "" approaches that promote "" global norms and conversation "" ( Reese 2015(Reese , 2263 ) about issues such as human rights , civil liberties , digital or data literacy , constructive journalism , or open source . Baack ( 2018b ) and Cheruiyot and Ferrer - Conill ( 2018 ) found that data - driven non - profit civic tech organizations are embedded in a transnational advocacy network bound together by overlapping actor - constellations , transnational networking organizations ( like "" Code for All "" ) , and continuous exchange . This involves shared data practices , definitions , and identities in the sector ( cf . Donohue 2016 ) ; an overlap in personnel across countries through fellowships , trainings and regular international conferences ; and a high degree of communicative connectivity between organizations ( Hepp 2015 ) through continuous online discourse , regular participation in international events , and cross - national collaborations ."	159434250	no
We now propose an alternative approach to sequentially train deep neural networks without referring to past data . In our deep generative replay framework , the model retains previously acquired knowledge by the concurrent replay of generated pseudo - data . In particular , we train a deep generative model in the generative adversarial networks ( GANs ) framework [ 10 ] to mimic past data . Generated data are then paired with corresponding response from a copy of the past task solver to represent old tasks . Called the scholar model , the generator - solver pair can produce fake data and desired target pairs as much as needed , and when presented with a new task , these produced pairs are interleaved with new data to update the generator and solver networks . Thus , a scholar model can both learn the new task without forgetting its own knowledge and teach other models with generated input - target pairs , even when the network configuration is different .	1888776	no
Fermi motion is of primary importance in another inclusive B decay , namely the radiative decay b â sÎ³ . A dedicated OPE approach accounting for the relation to the nonperturbative B - meson parameters extracted from B â X c âÎ½ was developed and applied to the description of the photon energy moments with cuts in Ref . [ 7 ] . It proved quite successful in describing the available B â X s + Î³ data . The results of [ 7 ] underline the importance of including subleading effects , going beyond the leading - twist description of Fermi - motion . Another advantage of the approach proposed in [ 7 ] is that it implements the Wilsonian version of the OPE with a ' hard ' cutoff that separates the perturbative and non - perturbative effects [ 8 ] and reduces the significance of perturbative corrections . In this approach , sometimes referred to as the kinetic scheme , the non - perturbative parameters are also well - defined and perturbatively stable . The contributions of soft gluons are absorbed into the definition of the heavy quark parameters and of the distribution function .	11117005	no
In this paper , the key assumptions are explained in more detail and the most relevant sources are displayed . In order to encourage other researchers , companies and LCA experts to reproduce , update or adjust our findings , the supplementary documentation ( SD ) provides detailed information on other assumptions ( mainly about the chosen inventory data ) , data sources , process schemes and the used inventory processes ( mostly from the Ecoinvent database ) .	222117836	yes
Recent advances of next generation sequencing technologies ( 1,2 ) allow the identification of both balanced ( inversions , translocations ) and unbalanced ( deletions , duplications ) structural variations ( SVs ) in the genome . The identification and characterization of such variations is of high importance in current genomic research , as it has been shown that many of them play a significant role in various disorders such as cancer ( 3 ) . Currently , there are several possible ways to identify and discover SVs in the genome using different types of genomic data ( 4 ) . First , read - depth or depth - of - coverage can be used to infer the relative copy number of genomic regions when compared with a reference sample . Second , the relative mapped position of readpair members , known as paired - end mapping , can be used to find deletions , tandem duplications , inversions and intra - chromosomal signatures . Finally , reads that span a DNA breakpoint in the sample appear as split reads when mapped to the reference genome . Several variant callers based on read - depth , pair - end or their combination already exist and are extensively reviewed by Alkan and colleagues ( 5 ) . Such callers store the results along with the genomic information in flat files that are difficult to process and interpret . Because such genomic data sets range in scale from thousands to millions of data points covering multiple gigabases of sequence , visualization approaches need to cope with such a high complexity and play a key role in revealing patterns of variation and relationships between experimental data sets .	16011222	no
The true mechanisms behind the ineffectiveness of therapy or related hyperprogression are not yet clear . PD - L1 expression is more often associated with the predominance of the Th1 - type immune response , but these data are still ambiguous . Since the point of the application of drugs is the immune response in the tumor , it is very important to determine its direction . It is well - known that the immune response in a tumor can both inhibit and support its growth and progression . In this regard , the efficacy of immunotherapy is likely to be related to the type of immunoinflammatory response occurring in the tumor rather than to the presence of the immune response itself . Difficulties in finding efficacy markers may be related to the marked heterogeneity of the tumor microenvironment , even within one tumor tissue [ 6 ] .	255913813	no
Finally , the articles identified as relevant were classified based on different definitions , theoretical concepts , and application methods regarding the importance of mass data collection processes . Following Moher et al . ( 2009 ) , Brocke et al . ( 2015 , and Stieglitz et al . ( 2018 ) , the articles with inadequate terms and inconclusive results , no relation to the research topic , as well as without quality evaluation or description and specification of terms were excluded .	233029680	no
The novel coronavirus ( COVID-19 ) is a global pandemic with public health importance , hence , has characteristics of global common shock and transboundary effects . Failure to account for such characteristics across countries , cities or continents render the model estimation spurious . The outlined data characteristics can be accounted for in a technique that controls for cross - section dependence . Despite the global common shock and transboundary effects , the cross - sectional time series may suffer from heterogeneity -- due to differences in the onset of COVID-19 , intervention and treatment across countries . Thus , both cross - section dependence and heterogeneity alter the consistency and robustness of COVID-19 estimation and modeling across countries . Due to the dynamics of COVID-19 spread , previous studies highlighted the importance of accounting for unobserved common factors and individual - specific effects ( Owusu and Asumadu , 2020 ) . The unequal distribution of data on COVID-19 cases , underlying health conditions , climatic factors , socioeconomic and demographic factors across countries pose another challenge in the selection of an estimation technique that controls for unevenly spaced data , cross - section dependence and heterogeneity . Here , we utilized the panel standard error corrected estimation technique that accounts for city - level heteroskedastic errors . In addition , the crosssectional time series approach adopted solves for contemporaneous correlation across cities . For brevity , the generic estimation procedure can be expressed as :	232200170	no
Many studies have focused on whether perceivers ' judgments conform to the expectations of the experimenter or actor rather than their reliability across perceivers . This is a top - down , confirmatory approach to measuring the recognition of expressive signals . We intentionally depart from this approach , as others have more recently 10 . Instead , we measure interrater agreement levels in emotion recognition judgments - a bottom - up , data - driven metric .	73728390	no
For the purpose of analysing the data , it was decided to compare the same period of the year in 2019 and 2020 ; that is : 27th March 2019 - 31st May 2019 ( Spring 2019 ) , and 27th March 2020 - 31st May 2020 ( Spring 2020 ) , the latter capturing the start and development of the UK lockdown period . This resulted in 43,186 complaints being analysed . Only for the analysis of the temporal variations in noise complaints , the periods considered range from 1st January to 31st May , both in 2019 and 2020 , because of the need to detect potentially sudden changes ( i.e. , transitioning from a non - lockdown to a lockdown scenario ) .	234831025	no
Given two large matrices A and B we study the problem of finding a low rank approximation of their product A T B , using only one pass over the matrix elements . This problem has many applications in machine learning and statistics . For example , if A = B , then this general problem reduces to Principal Component Analysis ( PCA ) . Another example is a low rank approximation of a co - occurrence matrix from large logs , e.g. , A may be a user - by - query matrix and B may be a user - by - ad matrix , so A T B computes the joint counts for each query - ad pair . The matrices A and B can also be two large bag - of - word matrices . For this case , each entry of A T B is the number of times a pair of words co - occurred together . As a fourth example , A T B can be a cross - covariance matrix between two sets of variables , e.g. , A and B may be genotype and phenotype data collected on the same set of observations . A low rank approximation of the product matrix is useful for Canonical Correlation Analysis ( CCA ) [ 8 ] . For all these examples , A T B captures pairwise variable interactions and a low rank approximation is a way to efficiently represent the significant pairwise interactions in sub - quadratic space .	9508796	no
The conventional method to analyze the performance of a zeolite sample , as well as most newly developed adsorbent materials , as a potential CCS material is to acquire gas isotherms at a set of relevant temperatures and pressures for the gases present in the mixture from which CO 2 is to be removed . However , as has been suggested , relevant temperatures and pressures for different systems can vary widely . For example , conditions for post - combustion capture , where the major separation is between CO 2 and N 2 , are signifi cantly different from that for pre - combustion capture , where CO 2 is to be separated out from H 2 or CH 4 . Indeed even among post - combustion capture systems at different power stations there can be subtle differences , such as the CO 2 concentration in fl ue gas from a gasfi red station to that from a coal - fi red station as discussed earlier . These issues coupled with the advanced synthesis methods to rapidly generate a variety of cation exchanged species ( e.g. , K + and Na + ) of many different zeolites mean that a large quantity of gas adsorption isotherm data need to be collected for a comprehensive analysis on one single type of materials . [ 25 ] Therefore a signifi ca nt bottle - neck for CO 2 adsorption studies using new zeolite - based adsorbent materials is the availability of access to effi cient gas adsorption instrumentation . As a result instrument manufacturers are attempting to develop automated high throughput gas adsorption analyzing units . One notable example of which is a volumetric technique that can analyze 28 samples in parallel recently developed by Wildcat Discovery Technology Inc. [ 28 ] This apparatus has recently been demonstrated in a high throughput study of cation exchanged forms of zeolites Na - A ( LTA ) and Na - X ( FAU ) for use in CCS , with the results acquired from the high throughput analyzer validated against data acquired from a conventional Micromeritics ASAP 2020 gas adsorption analyzer . [ 29 ] Zeolites have already been widely used in many industrial processes . However , their application in CO 2 capture from power plant fl ue gas has not been as successful . This is likely because zeolites can be deactivated by moisture , leading to a signifi ca nt reduction in CO 2 adsorption capacity . One possible explanation for this phenomenon is that water can reduce the strength of the local electric fi eld on the cation sites . [ 30 ] Since water is an inevitable product from combustion , cation exchanged zeolites are considered to be ineffective unless the moisture content is removed prior to CO 2 adsorption , or prevented from entering the zeolite by some other means . There are , for example , several reported attempts at forming a waterproof coating for zeolites , which have had a highly hydrophobic surface layer chemically bound to the zeolite crystallites in a post - synthetic process . [ 31 ]	54778784	no
Whole - genome sequencing ( WGS ) and a Genomizer analysis ( v 10.1.0 ) were used to conduct a comprehensive and unbiased ranking of other potential genetic risk modifiers , including those associated with a lower risk of Alzheimer 's dementia , helping to exclude other potentially protective genetic factors 10 . For processing the WGS data , the same dragen pipeline described above was used . The data was aligned to the GRCh37 decoy genome ( hs37d5 ) . Variants that were called at a depth of < 10X were filtered out and then were annotated using Ensembl 's Variant Effect Predictor ( VEP ) tool . The version of VEP using was v93 . The filtered and annotated set of variants was then compiled for Genomizer analysis . Further information can be found in the Life Sciences Reporting Summary .	207898971	no
End - to - End Learning Task - specific architectures for end - to - end deep learning require large datasets and work very well when such data is available , as in the case of neural machine translation ( Bahdanau et al . , 2014 ) . General purpose end - to - end architectures , suitable for multiple tasks , include the Neural Turing Machine ( Graves et al . , 2014 ) and its successor , the Differential Neural Computer . Other architectures , such as the Neural Programmer architecture ( Neelakantan et al . , 2016 ) allow end - to - end training while constraining parts of the network to execute predefined operations by re - implementing specific operations as static differentiable components . This approach has two drawbacks : it requires re - implementation of the black - box function in a differentiable way , which may be difficult , and it lacks the accuracy and possibly also scalability of an exisiting black - box function . Similarly Trask et al . ( 2018 ) present a Neural Arithmetic Logic Unit ( NALU ) which uses gated base functions to allow better generalization to arithmetic functionality .	58004637	no
3 - General procedure for the synthesis of amino alkynes 2a , 2b , and 2c [ 6 ] Scheme S4 : Synthesis of Fmoc protected amino alkynes 2 . 3a : Boc - L - Ala ( 1.5 g , 7.9 mmol ) in DMF ( 16 mL ; 10 mL ) was treated according to the abovementioned procedure . Purification over silica gel ( 30 % EtOAc/70 % CH 2 Cl 2 ) afforded compound 3a as white solid ( 1.3 g , 72 % ) . The NMR spectroscopic data were in agreement with those described in the literature . [ 7 ] 3b : Boc - L - Ile ( 1 g , 4.3 mmol ) in DMF ( 8.5 mL ; 5.5 mL ) was treated according to the above mentioned procedure . Purification over silica gel ( 15 % EtOAc/85 % CH 2 Cl 2 ) afforded compound 3b as colourless oil ( 964 mg , 81 % ) . The NMR spectroscopic data were in agreement with those described in the literature . [ 7 ] 3c : Boc - L - Val ( 1 g , 4.6 mmol ) in DMF ( 9 mL ; 6 mL ) was treated according to the abovementioned procedure . Purification over silica gel ( 20 % EtOAc/80 % CH 2 Cl 2 ) afforded compound 3c as colourless oil ( 919 mg , 77 % ) . The NMR spectroscopic data were in agreement with those described in the literature . [ 7 ] 4a - c : To a solution of the Weinreb amides 3a - c ( 1 eq . ) in anhydrous THF at 0 Â° C , afforded compound 4a as white solid ( 69 mg , 75 % ) . The NMR spectroscopic data were in agreement with those described in the literature . [ 7 ] 4b : Weinreb amide 3b ( 116 mg , 0.5 mmol ) in THF ( 1.5 mL ) was treated according to the abovementioned procedure . Purification over silica gel ( 5 % EtOAc/95 % CH 2 Cl 2 ) afforded compound 4b as colourless oil ( 66 mg , 69 % ) . The NMR spectroscopic data were in agreement with those described in the literature . [ 7 ] 4c : Weinreb amide 3c ( 121 mg , 0.5 mmol ) in THF ( 1.5 mL ) was treated according to the abovementioned procedure . Purification over silica gel ( 5 % EtOAc/95 % CH 2 Cl 2 ) afforded compound 4c as colourless oil ( 60 mg , 64 % ) . The NMR spectroscopic data were in agreement with those described in the literature . [ 7 ] 5a - c : To a solution of the aldehyde 4a - c ( 1 eq . ) and K 2 CO 3 ( 2 eq . ) in anhydrous MeOH , the Bestmann - Ohira reagent ( dimethyl ( 1 - diazo-2 - oxopropyl)phosphonate ;	11227657	maybe
Our recent theoretical study of the young Sun 's twin , k 1 Ceti , suggests that over the course of 11 months its global corona underwent a drastic transition from nearly a dipole to a complex magnetic topology strong dipole quadrupole and octopole components and the formation of a low - latitude coronal hole . We used the stellar magnetograms reconstructed for two epochs , 2012.9 and 2013.8 , using high - resolution spectropolarimetric data in Stokes I and V obtained with dedicated instrumentation including the NARVAL spectropolarimeter at the Telescope Bernard Lyot ( France ) and HARPSpol@ESO ( Chile ) ( RosÃ©n et al . 2016 ) . We use the low - resolution reconstructed large - scale magnetic field ( lmax = 10 ) of the star to determine the harmonic coefficients and construct a Potential Field Source Surface model of the background magnetic field at the source - surface height of 2.2 Rsun ( RosÃ©n et al . 2016 ) . As discussed in Airapetian et al . ( 2019b ) , the global magnetic field of k 1 Ceti at 2012.9 is mostly dipolar with 9 0 tilt with respect to the rotation axis and resembles the current Sun 's global field at solar minimum . However , the magnetic field shows the signatures of large - scale restructuring to 45 0 tilted dipolar component with 2/3 of the contribution from quadrupolar and octopolar components , which is typical for the declining of the declining phase of solar maximum . To determine the background solar wind density , we use the Guhathakurta et al . ( 2006 ) model that empirically scales the value based on the distance from the ACS and the radial distance . By assuming constant mass flux , we can then calculate the radial solar wind speed . In our empirical models for the background solar wind we use the same coefficients as previously used for solar ForeCAT simulations .	207847842	no
Constructed PPI graphs from the different network analysis tools using filtered gene expression data from EMBL - EBI Expression Atlas as input are illustrated in Figure S1 for BioGrid - based networks and in Figure S2 for String - DB constructed networks . Networks were then filtered to unique nodes by subtracting the merged intersection of all three disease type - specific networks , illustrated in Figure 1 in case of BioGrid - constructed networks and in Figure 2 based on StringDB . The resulting numbers of nodes and edges as well as calculated parameters from network analysis , including network diameter , clustering coefficient and connected components for each disease - and database - specific network , are summarized in Table 1 .	210709562	maybe
All participants were registered with the NHS at recruitment and their NHS number is a unique personal identifier used in all NHS health records , including the NHS breast cancer screening programme and admissions to NHS hospitals . Study participants were followed by record linkage using their unique NHS number and other personal details for deaths , 5 cancer registrations , 5 emigration , 5 and hospital admissions , 6 7 thus providing close to complete follow - up for all these events . The hospital admission data include details of all NHS funded hospital admissions , including day surgery , dating from 1981 in Scotland 6 and from 1997 in England . 7 For every hospital record the primary reason for admission and up to 13 additional clinical diagnoses are coded using the International Classification of Diseases 10th revision ( ICD-10 ) 8 ; as well , up to 12 procedures are coded using the Office of Population Censuses and Surveys Classification of Surgical Operations and Procedures , fourth revision ( OPCS 4 ) . 9 For these analyses the main outcome , gallbladder disease , is defined as the first hospital admission after recruitment to the study with a primary diagnosis of cholelithiasis or cholecystitis ( K80 and K81 , ICD-10 ) or a cholecystectomy ( codes J181 - J189 , OPCS 4 ) . Analyses were also done using as an outcome the first admission for cholecystectomy alone ( codes J181 - J189 ) .	27496106	maybe
The neutrino parameters fit the atmospheric neutrino data and the small mixing angle ( SMA ) MSW solution of the solar neutrino problem [ 18 ] .	14116427	no
Model compression . While it is known that the problems of data and model compression are very closely related , COIN explicitly casts the problem of data compression into a problem of model compression . There exists a rich body of literature on model compression , [ 35,21,13,36,18,15 ] , which could likely be used to improve COIN 's performance .	232110691	no
with its neighbor until all gradient g is accumulated into a single GPU . The communication complexity for i GPUs is log2i . The GPU with accumulated gradient then sends the accumulated gradient to CPU for further processing . Note for each communication ( either GPU - to - GPU or GPU - to - CPU ) , the communication data size is the same , i.e. , |g| . Assume that within a machine , the communication bandwidth between GPUs is C gwd 3 and the communication bandwidth between CPU and GPU is C cwd , then the communication overhead within a machine can be computed as |g| C gwd * log2i + |g| C cwd . We successfully used NCCL benchmark to validate our model . For communication between machines , we also assume all - reduce communication model , so the communication time between machines are : ( Cncost + |g| C nwd ) * log2j , where Cncost is the network latency and C nwd is the network bandwidth . So the total communication time is Tcomm(i , j , K , |g| ) = |g| C gwd * log2i + |g| C cwd + ( Cncost + |g| C nwd ) * log2j . We successfully used OSU Allreduce benchmark to validate this model .	3747520	no
As shown in Figure S3 , no hydrogen under potential deposition ( H - UPD ) is realized at the nanoparticles during cyclic voltammetry , although this could be expected for Pt electrodes . This may be attributable to the strong specific adsorption of citrate anions on the PtNPs as has been reported by Attard et al . 27 Therefore , H - UPD can not interfere with the capacitance measurements . In order to figure out the origin of the capacitive spikes being either charging of the impacting nanoparticle or perturbatio n of the electrode double - layer by the nanoparticle , step potential chronoamperometry was run using different ultramicroelectrodes ( carbon , Pt , Au ) as the working electrode ( Figure S4 ) . During these experiments changes of the transferred charge were investigated as a function of the applied potential . Spikes from â0.30 V to +0.05 V vs. Ag / AgCl ( +0.10 V to +0.45 V vs. RHE ) were included in data analysis to avoid any parallel faradaic reaction and to be able to precisely resolve spikes from background noise . Observed background currents are in the typical range for microelectrodes and may originate from oxygen reduction caused by very small amounts of oxygen entering the deoxygenated electrolyte upon NP injection into the measurement cell , although the NP suspension was deoxygenated by Ar purging prior to injection , as well . The current associated to this is at least 100 times smaller than expected for air saturated solution and can , hence , be concluded not to significantly alter the capacitance measurements .	244449648	no
We present descriptive statistics as mean and standard deviation for normally distributed data or median and interquartile range when distributions were skewed . We used the Ï 2 test to compare groups for categorical variables . We evaluated differences between independent samples by using Student 's t test if variables were normally distributed or Mann - Whitney U test for skewed data .	14753775	no
Interfacial intermixing plays an important role in the field of semiconductor NCs . Held et al . [ 40 ] recently examined the radial elemental composition of core - shell nanostructures by fitting an error function model to STEM - EDX maps and applied the method to single - shell Ge / Si NCs synthesized by plasma deposition as well as to double - shell CdSe / CdS/ ZnS NCs synthesized by the controlled hot - injection method ( similar to the method used for single - and multishell upconverting NCs ) . The parameters used to extract the radial distributions of the core and shell materials were the radius of the core ( r core ) , the thickness of the interface ( Ï i ) , the outer radius of the shell ( r shell ) , the roughness of the outer surface of the shell ( Ï s ) , and finally a parameter ( p ) that describes the fraction of the residual core material in the shell , thus taking into account intermixing . The radial distributions of each element within individual NCs are reproduced here in Figure 12 . These results suggest that , also in the case of semiconductor NCs , an intermixed region is formed with the core material moving out into the shell . It may be of interest to extend such modeling to allow a fraction of the shell material to also be present in the core and see whether this improves the fit to the experimental data . In any case , further EDXS experimental work and modeling is of general interest to understanding the internal chemical makeup of core - shell NCs .	205290073	no
The algorithm underlying our GTSC framework recursively partitions the tensor data . We stop the process when the partitioning metric is bad , which lets us cluster the data without specifying the number of clusters ahead of time . This provides an advantage over existing tensor decomposition methods such as PARAFAC that require the number of clusters as an input to the algorithms . Finally , we show that our method asymptotically scales linearly ( up to logarithmic factors ) in the size of data . In Section 4.2 , we perform numerical scaling experiments to demonstrate the scalability of our method .	3258518	no
Median follow - up was 56 months ( 25 - 75 percentiles , 53 - 60 months ) 24 - hour K urinary excretion was estimated from a fasting morning urine samples Models are unadjusted Models did not adjust for BP Low risk Participants from other trials from 733 centres from 40 countries with established CVD or high - risk diabetes mellitus who provided a baseline urine sample ; two cohorts were combined because both trials recruited participants from the same sites , time period , using the same eligibility criteria , and used the same methods to capture baseline clinical data and outcome measures	20664522	no
Comparison with other studies The decision to implant a ventricular assist device is based on several indices , including deterioration in haemodynamic variables or the unsuitability of a candidate for transplantation . Initial studies by the Cardiac Transplant Group and Registry of the International Society for Heart and Lung Transplantation showed that previous mechanical assistance had a significantly negative effect on survival . 11 This area remains controversial given recent studies from several groups that showed comparable survival . In the absence of device related complications , optimal perfusion of end organs by adequate unloading of the heart and maximal circulatory support can be achieved . This provides an improved overall clinical status of recipients and smoother transition during transplantation and early recovery . Such patients can experience a considerable improvement in quality of life , with return to activities of daily living . One research team carried out a prospective , multicentre , non - randomised , controlled study to evaluate the left ventricular assist device as a bridge to transplantation . 12 A total of 280 candidates at 24 centres were treated with Heartmate and compared with a historical control group of 48 patients not supported with a left ventricular assist device . Outcome measures were defined as laboratory data ( haemodynamic , haematological , and biochemical ) , New York Heart Association functional class , and survival . The mean duration of support was 112 days , with 54 patients supported for more than 180 days . A total of 188 patients ( 67 % ) were bridged to transplantation , and 10 ( 4 % ) elected to have the device removed . Of the patients with the device , 82 ( 29 % ) died before transplantation , compared with 32 ( 67 % ) of the 48 control patients . Complications included bleeding , infection , neurological dysfunction , and thromboembolic events . Survival one year after transplantation was significantly higher in patients in the device group than in those in the control group : 158 ( 84 % ) v 10 ( 63 % ) .	21434986	no
Inaccuracy is measured by the Brier score throughout . Now , you can ask whether these results are enough to tell so strongly in favour of explanationism , but that is n't my concern here . Rather , I want to focus on a more fundamental problem : Douven and Wenmackers ' argument does n't really compare Bayes ' Rule with explanationism . Instead , it compares Bayesian - rule - for - worldly - data - plus - Averaging - for - social - data with Explanationist - rule - for - worldly - data - plus - Averagingfor - social - data . So their simulation results do n't really impugn Bayesianism , because the average inaccuracies that they attribute to the Bayesian updating rule do n't arise from it . They arise from using Bayesianism in step ( ii ) , but something quite different in step ( iv ) . Douven and Wenmackers ask the Bayesian to respond to the social evidence they receive using a non - Bayesian rule , namely , Averaging . And Averaging lies far from the Bayesian rule . 19 Why , then , do Douven and Wenmackers use Averaging rather than Bayes ' Rule for step ( iv ) ? Here is their motivation :	237364643	no
We pooled and cut the freshly resected terminal ilea from 3 - 4 neonatal mice into 2 - to 5 - mm pieces and incubated ( 37 Â° C , 15 min ) them in extraction buffer ( HBSS , 15 mM HEPES and 1 mM EDTA ) to remove the epithelial cells . We then incubated ( 37 Â° C , 30 min ) the cut tissues with shaking ( 150 rpm ) in digestion buffer ( RPMI 1640 with 10 % FBS , 15 mM HEPES , 1 % penicillin / streptomycin ( wt / vol ) , and 300 U ml â1 collagenase VIII ) . We isolated the lamina propria lymphocytes from the resultant single cell suspension by discontinuous Percoll ( GE Healthcare ) gradient at 40 - 80 % interface and incubated ( 37 Â° C , 5 h , 5%CO 2 ) the cells ( 4 Ã 10 7 ) in culture medium containing RPMI 1640 with 10 % FCS , 1X nonessential amino acids , 10 mM HEPES , 2 mM L - glutamine ( all from Invitrogen ) and 1 % penicillin/ streptomycin with 1:1000 Golgi Stop ( 554724 , BD Biosciences ) , 10 ng / ml phorbol 12myristate 13 - acteate ( PMA ) and 500 ng / ml calcium ionophore A23187 ( both from Sigma - Aldrich ) . We washed and incubated ( 4 Â° C , 10 min ) the cells ( 10 7 ) with anti - mouse CD16/ CD32 ( eBiosciences ) and then reincubated ( 4 Â° C , 30 min ) with FITC - conjugated anti - mouse TCRÎ² antibody ( Clone KJ16 - 133.18 , eBiosciences ) , PE / Cy7 - conjugated anti - mouse TCRÎ³Î´ antibody ( Clone GL3 , Biolegend ) , APC - conjugated anti - mouse CD4 antibody ( Clone RM4 - 5 , Biolegend ) and BV - conjugated anti - mouse NKp46 antibody ( Clone lone 29A1.4 , eBiosciences ) . For intracellular staining for IL-17 , we washed and fixed ( 4 Â° C , 60 min ) the surface - stained cells in 1X Cytofix / Cytoperm buffer ( BD Biosciences ) and permeabilized them ( 4 Â° C , overnight ) using 1X Permeabilization Buffer ( BD Biosciences ) according to manufacturer instructions . We stained the cells intracellularly with PE - conjugated antimouse IL-17 antibody ( Clone TC11 - 18H10.1 , Biolegend ) or PerCP - conjugated anti - mouse RORÎ³ antibody ( Clone B2D , eBiosciences ) then washed ( 2x ) and resuspended them in flow cytometry buffer . We collected the data with LSRII ( BD Biosciences ) and analyzed the data with Flowjo ( Treestar ) .	8410272	maybe
We performed power calculations before data was collected using the G*power program ( Faul et al . , 2007 ) to determine sample size . For a moderate effect size ( f = 0.25 ) with Î± = 0.01 in a 2 Ã 2 design ( 4 groups , numerator df = 1 ) and power of 0.95 , we would require a total sample size of 289 participants . All participants were screened with the same attention check procedure as in Studies 1 and 2 leaving a final sample of 253 participants from MTurk ( 60 % females ; M age = 35.17 , SD age = 11.59 ) . A sensitivity power analysis revealed that the study was powered to detect a medium effect size ( f = 0.267 ; â Î· p 2 = 0.066 ) assuming an alpha level of 0.01 and 95 % power .	244772733	no
To address this issue , we initially adopt a stylized approach constructing ' virtual workplaces ' which rely on the 2011 UK Census commuting origin - destination tables at the MSOA level for individuals with a fixed workplace . The UKTUS data includes a Standard Industry Classification ( SIC ) code for everyone in the dataset . Matching data from the UKTUS to SPENSER baseline data via the PSM process and the UKTUS we were able to assign to each of our synthetic resident workers an employer industry among the 21 divisions from the Standard Industry Classification ( SIC ) 2007 . We assume that all workers have an equal exante probability to commute to all destinations independently from the SIC to which they belong . We build the set of possible destinations by multiplying the number of MSOAs in the study area , M = 107 , to that of the SIC divisions , S = 21 , obtaining 2,247 options . We then populate these virtual workplaces with synthetic workers based on their reference SIC and their Census relative probability to commute from M i to any M j , with j = 1 â¦ i â¦ J , thus including the MSOA in which the worker resides .	239011333	maybe
"Risk awareness among the public is critically important to prevent the spread of infectious diseases ( Guo et al . , 2015 ) . It is possible to significantly reduce the spread of infectious diseases by pre - emptively disseminating knowledge about how widely infectious diseases are spreading and how severe the outbreaks will be and educating the public on precautionary measures ( Funk et al . , 2009;Wang et al . , 2019 ) . In addition , to effectively respond to the spread of infectious diseases , it is important for people to recognize the general symptoms of infection , so that they may determine whether or not they are infected by comparing their own symptoms with those of people around them , and then take appropriate measures accordingly ( Zang , 2018 ) . In the past , people mostly relied on mass media and word of mouth to obtain information about an infectious disease and how to prevent it and respond to it ( Wu et al . , 2012 ) . However , with the availability of the internet and the widespread use of search engines , people began to seek information more actively , and this effort is reflected in the data of their search activity . There have been many studies of behavioral analysis or forecasting using RSV in various fields , not only regarding infectious diseases , and in many such studies , RSV was understood through the lens of the human behavior processes described in theories such as the five stages of the consumer buying process or the innovation adoption model ( Kotler et al . , 2014;Rogers , 2003 ) . According to these theories , problem awareness leads to information searching and the seeking of alternatives for problem solving ( Jun et al . , 2014 ) . In the same vein , RSV regarding infectious diseases has been found to be useful for quantifying the level of people 's awareness of infectious diseases ( Boehm et al . , 2019 ) . Through specific keyword analysis , it is possible to distinguish , for example , whether people want to know "" what "" infectious disease is spreading is and "" what "" kinds of symptoms indicate infection , or whether are seeking information on "" how "" to prevent and treat it ( Cairo , 2020 ) . Because Google has a dominant share ( 92 % ) of the global search engine market ( Statcounter , 2020 ) , the RSV of Google searches has been recognized to be an especially effective means of gauging people 's perception of infectious diseases ( Do et al . , 2015;Hu et al . , 2020 ) ."	232282755	no
In the next experiment , we trained , DCN , VaDE , DEPICT ( using agglomerative clustering initialization ) and IMSAT ( using adversarial perturbations for data augmentation ) on the 2D datasets of Figure 1 . The experiments were performed using the code published by the authors of each paper .	3278749	yes
â¢ For each attribution method , the task similar trees obtained on the three probe datasets are highly similar . It again verifies that our method is insensitive to the choice of the probe data .	202788309	no
VarAFT is a multiplatform freely available software that allows the simultaneous annotation , filtration , and breadth and depth of coverage analysis of WES , WGS and targeted sequencing experiments from any sequencing platform . Its graphical user interface , various modules and unique features , such as pathogenicity predictions from UMD - Predictor and HSF , allow untrained users to rapidly highlight disease - causing mutations in multiple genetic scenarios . In addition , VarAFT allows visualization of data quality ( breadth and depth of coverage ) through direct access to BAM files . The nucleotides and genotypes can also be easily accessed through IGV .	44149555	no
Considering data on the persistence of SARS - CoV-2 and other enveloped viruses in raw wastewater , the residence times in sewage systems ( in the range of hours ) , and in the WWTP ( varying between 24 and 48 h depending on the WWTP treatment line ) , SARS - CoV-2 detected in secondary - treated wastewater should already be mostly non - infectious , a premise supported by the results from our study , either by using cell culture or viability RT - qPCR .	245704937	no
There are various ways to correct for detector afterpulsing . The most straightforward method is cropping the FCS auto - correlation curve , thereby removing the spurious data points at short lag times . This strategy is justified in many biological applications , as the diffusion in biological samples is often relatively slow . However , when short lag time information is required , a different approach is needed . One method consists in characterizing the after - pulse component , e.g. by calculating the auto - correlation function ( ACF ) of the detector signal under constant white light illumination and fitting the data with a power law , as shown in Figure S2 ( c ) . The same power law factor can then be added to the FCS fit model 5 . A second method is calculating FCS cross - correlations between the signal coming from different pixels . In this case , the afterpulsing effect can be completely filtered out , as the afterpulsing signals do not correlate , see Figure S2	231811388	no
XAS and XMCD experiments were performed at the X - Treme beamline [ 44 ] of the Swiss Light Source at the Paul Scherrer Institute . The measurements were performed in the total electron yield mode , with the magnetic field being aligned antiparallel to the incoming X - ray beam and forming an angle Î¸ with the surface normal of the sample . Special care had been taken in order to center the beam by rechecking the sample position and signal every multiple of 10 Â° . At Î¸ = 80 Â° , the projected beam spot width on the surface is 2.8 mm , being still considerably smaller than the sample width of 4 mm . The measurements were performed using a defocused X - ray beam in order to minimize the photon flux . Accordingly , no significant beam damage could be observed in the spectra throughout the measurements . For magnetization curves no data points were collected within B = Â±0.2 T at a magnetic field sweep rate of 2 T min â1 due to polarization reversal of the coil current , which also implied a waiting interval of around 20 s at zero field . XMCD relaxation measurements were performed by continuously alternating between both polarizations Ï + and Ï â . The resulting curve was then calculated by interpolation and subtraction of both curves , XMCD(t ) = Ï + ( t ) â Ï â ( t ) . In order to minimize the photon flux the beam shutter was only opened for t acqu = 0.5 s with a waiting time of t reversal = 22.3 s in between each point due to polarization reversal . The flux for the relaxation measurements thus had been corrected using Ï Ï = + t t t cw acqu acqu reversal , [ 4 ] with Î¦ cw being the respective continuous flux value depending on the beam spot size . [ 44,45 ]	237095368	no
In examining the response of DLBCL cells to Hsp90 inhibitors we discovered that Bcl6 , the most commonly involved oncoprotein in DLBCL , is an Hsp90 client protein . The relationship between Hsp90 and Bcl6 occurs at multiple levels and has implications for understanding the biology of normal germinal center B - cells and DLBCL pathogenesis . Approximately 70 % of DLBCLs are Bcl6 positive , yet only about half of these cases contain translocations or point mutations that could drive constitutive Bcl6 expression14 . Yet DLBCLs lacking these genetic lesions can still be biologically dependent on this oncogene17,18,21 . The physical and functional interaction of Hsp90 and Bcl6 may at least in part explain this phenomenon , by virtue of directly stabilizing both the Bcl6 mRNA and protein . Although the proportional contribution of Hsp90 to Bcl6 mRNA versus Bcl6 protein stability can not be precisely asserted , our data indicates that both effects contribute to maintain Bcl6 levels . Upregulation of Bcl6 is required for normal B - cells to form germinal centers , within which B - cells undergo affinity maturation . The fact that Hsp90 localizes to the nucleus of normal centroblasts raises the possibility it could contribute to B - cell differentiation by allowing Bcl6 to accumulate in germinal center B - cells . These data suggest that BCL6 might in fact function as a stress response gene that forms part of a larger , post - transcriptionally regulated program governed by Hsp90 .	5917522	no
"The first world - directed approach to smell is the feature - based view . Those that endorse this approach concede that olfaction is world - directed , but claim that what we olfactorily perceive are not objects but only properties or features ( see Matthen 's brief discussion of olfaction in 2005 , pp . 284 - 285 for such an account ) . We do n't smell the fruitiness , smokiness and maltiness of a coffee as bound together , but instead simply perceive these properties , free of any particular object . Matthen says that smells , "" have , at best , a primitive - that is , an undifferentiating - feature - location structure - every smell of which I am aware is simply here "" ( p. 284 ) . He adds that olfactory content "" does not come in object - attribute form "" ( ibid . ) . This sort of feature - based approach has also traditionally been dominant within olfactory science , where the primary goal has been to understand olfaction by identifying how different features of a chemical stimulus are represented in olfactory experience . 3 However , the tides are turning in the olfactory sciences and an object - based approach to olfaction , advocated by Stevenson ( 2006 , 2007 ) , has recently gained in popularity . Wilson and Stevenson ( 2006 ) argue that an object - based approach can make sense of a growing body of data from neurobiology and psychology . In particular , they think an object - based approach better accounts for the behavioural evidence and for the need to perceive biologically salient groups of odorants amid changing olfactory stimulation ( p. 1892 ) ."	46983730	no
"The striking observation that our Universe is accelerating is providing cosmologists and particle theorists with one of the most intricate and puzzling problems in modern physics . Over the past decade , experimental evidence supporting a non - zero cosmological energy density which appears to be non - clustered and homogeneously and isotropically distributed across the Universe , has grown to almost certainty [ 1,2,3 ] ( see also [ 4,9 ] for more up - to - date references ) . Although there persists room for different explanations [ 5,6,7,8 ] , and the observational data may not be fully solid and should be taken with some precautions [ 9 ] , the so called "" Concordance Model "" ( or ÎCDM for Cold Dark Matter ) , despite its disquieting implication that we do not know what the great majority of the Universe is made of , is nowadays widely accepted ."	119189844	no
Encouraging D to use its capacity in a constructive way is non - trivial . One theoretically sound potential approach to regularize D is to use a Bayesian neural net , whose model capacity away from data is not degenerate . However , computationally scalable deep Bayesian neural networks are still an active area of research ( HernÃ¡ndez - Lobato & Adams , 2015;Hasenclever et al . , 2017 ) and are not easy to use . Alternatively , we can use auxiliary tasks to regularize D 's capacity usage . If given labelled data , semi - supervised learning as an auxiliary task for D , as shown in Salimans et al . ( 2016 ) , improves GAN training stability and the resulting generative model . We hypothesize that if the data domain has other structures that can be exploited as supervised learning signal , Exploiting these structures could as well potentially improve the GAN training stability like in Salimans et al . ( 2016 ) .	13669032	no
Absolute coordinate prediction For absolute coordinate prediction , the global features y and local features c ( i , j ) are sampled by 1 ) feeding an image from the data distribution through the feature encoder , and 2 ) sampling a random spatial location ( i , j ) from which to take the local features c ( i , j ) . Given y and c ( i , j ) , we treat the coordinates i and j as independent categorical variables and measure the required log probability using a sum of categorical cross - entropies . In practice , we implement the prediction function p Î¸ as an MLP with two hidden layers , each with 512 units , ReLU activations , and batchnorm . We marginalize this objective over all local features associated with a given global feature when computing gradients .	52055130	no
Electrochemical sensors degrade in vivo due to biofouling , which requires replacement every 3 - 4 d. [ 86 ] These electrochemical sensors , typically used for the management of diabetes , are intrinsically prone to drift in vivo ; hence they require frequent calibration with finger prick blood tests . The measurement of glucose concentration in interstitial fluid is associated with a lag time as compared to blood glucose . Limitations of these wearable glucose sensors apply to all types of electrochemical sensors and include ( i ) frequent calibration of the sensor , ( ii ) sensor readout drift due to biofouling , ( iii ) biweekly sensor replacement , and ( iv ) relatively high cost . Other well - known sensors in wearables include heart rate monitors , thermometers , and accelerometers . These types of sensors have been fully characterized and work seamlessly ; however , the amount of signal processing and data processing required to for healthcare applications is large and requires continuous operation and energy supply .	48355667	no
In order to understand this apparent difference , we have to investigate the 3D nature of the optically induced crystallization and its consequences for the MS resonance tuning . The highly nonlinear relation between temperature and crystallization speed in PCMs combined with the short time scales of the optical switching leads to the process being dominated by spatially inhomogeneous and nonequilibrium temperature distributions . This results in crystallization depths that strongly depend on the temperature gradient in the PCM layer , which can only accurately be determined using self - consistent multiphysics simulations . In a first approximation for this complicated multiphysics problem , we performed simulations where we varied the crystallization depth of the C - spots by approximating them as elliptical cylinders with a height d ( corresponding to the crystallization depth ) smaller than the whole GST - film thickness t ( Figure 3a ) . The resulting resonance shifts ÎÎ½ res ( d , a ) for each crystallization depth d ( color - coded ) against the spot size a are shown in Figure 3b Figure 1a ) . Each antenna in the array is switched with centered C - spots of size a ( color - coded ) . All curves show a clear resonance , which shifts from Î½ res = 2028 cm â1 ( vertical blue line ) in the amorphous case to 1692 cm â1 ( vertical yellow line ) in the fully crystalline case . The inset shows the resonance shift ÎÎ½ res ( a ) = Î½ res ( a ) -Î½ res ( 0 Âµm ) with respect to the amorphous state . Its slope is largest for a â l ( dashed gray line ) because of the strong local fields at the antenna tips in resonance . b ) Normalized FTIR reflectance spectra of ( 6 Ã 6 ) antenna arrays covered and switched according to A. The resonance frequency positions are marked by colored ticks on the top , an arrow indicating the resonance shift ÎÎ½ res , while ÎÎ½ res ( a ) is shown as inset . The largest increase in resonance shift is measured for a â l ( dashed gray line ) . c ) Optical microscope images of the antenna arrays corresponding to three different spectra for a = 0 , 1.73 , 3.19 Âµm ( colored frame according to legend in panel b ) . The scale bars equal 1 Âµm . crystallization depth d leads to a larger resonance shift for the same C - spot size a. The experimentally obtained resonance shifts for different spot sizes a are plotted as cross marks . These crosses do not follow any one of the simulated curves for a fixed d. Rather , the data points seem to lie on different curves of increasing crystallization depth d for increasing spot size a. This indicates that C - spots of different lateral size also have different crystallization depth , which explains the trend of the resonance shift observed in the experimental data .	167209872	no
The COVID-19 pandemic has continuously evolved over time . As such , it was necessary to truncate data collection efforts and proceed with our analysis . Here , we explain the time frame and locations selected for inclusion in this study and discuss the investigated Google Trends search terms .	255441206	maybe
Let L(p gen ) = xâX p gen ( x ) â p data ( x ) c * ( x ; p gen ) , substituting the results from equation ( 20 ) into ( 21 ) , the L(p gen ) * can be written as	13619197	no
R 50 version 3.2.1 was utilized for data analyses . Specific R packages and other tools/ software used for analyses are noted in the respective sections below .	13938356	no
The measures T KS and T DS introduced in subsection 2.4 provide a statistical goodness - of - fit measures of the model to single neuron count statistics , and is evaluated per neuron . The predictive count distribution of the model is the reference distribution for evaluating Z - scores ( Equation 7 ) , and thus allows one to quantify dispersion T DS ( Equation 11 ) and goodness - of - fit T KS ( Equation 10 ) of the data with respect to our predictive model . By using a full predictive model , the Kolmogorov - Smirnov framework is applicable to data beyond repeatable trial structure in the inputs , such as continual recordings of freely moving animals .	235690076	no
Mini - batch parallel SGD addresses this issue by increasing compute before communication . Each worker now computes a mini - batch of size b before communication . This scheme is implemented in state - of - the - art distributed deep learning frameworks [ 1,17,23 ] . Recent work in [ 7,30 ] explores the current limitations of this approach , as in general it is reported that performance degrades for too large mini - batch sizes [ 9 ] . As a remedy , [ 13,35 ] propose to parallelize SGD in a different way : instead of keeping the sequences on different machines in sync , let them evolve locally on each machine , independent from each other , and only average the solutions a the end . Zhang and coauthors [ 33 ] show statistical convergence ( see also [ 6 ] ) , but the analysis restricts the algorithm to at most one pass over the data , which is in general not enough for the training error to converge . Current work explores the benefits of more frequent averaging of the parallel sequences [ 4,32 ] , but thus far the question of how often communication rounds need to be initiated has eluded a concise theoretical answer . Indeed , the lack in the theoretical understanding of local SGD is astounding : the literature does not even resolve the question whether averaging helps , i.e. concretely , whether running local SGD on K workers is K times better than running just a single instance of SGD on one worker . 1 We fill this gap in the literature and provide a concise convergence analysis of local SGD . We show that averaging helps , i.e. by frequently synchronizing K local sequences , the convergence rate increases by a factor of K , i.e. a linear speed - up can be attained . This shows that local SGD is as efficient as parallel mini - batch SGD , but the communication cost can be drastically reduced .	43964415	no
This procedure resulted in a set of 450 out of the initial 802 announcements of firm responses to the COVID-19 crisis . In a third step , ensuring that the stock market reaction is attributable to an announcement , we further eliminated announcements with confounding events on the announcement date ( Faramarzi & Bhattacharya , 2021;McWilliams & Siegel , 1997 ) . We also excluded announcements of firms with insufficient financial data available in the Thomson Reuters database . Our final sample consists of 376 COVID-19 response announcements from 191 unique firms . From these 191 firms , 87 firms made two or more distinct announcements during our data collection period . As investors may perceive subsequent announcements from the same firm differently , we consider only the first response announcement from each firm as a robustness check . Our empirical results remain consistent . Table 1 presents the distribution of our sample across industries , based on the two - digit Global Industry Classification Standard ( GICS ) . Notably , the majority of COVID-19 response announcements is from Health Care firms ( 110 ; 29 % ) , followed by firms from Consumer Discretionary ( 59 ; 16 % ) and Industrials ( 55 ; 15 % ) . Fig . 2 further illustrates the S&P 500 index performance and the distribution of our sample announcements over time . The majority of COVID-19 responses was announced during and shortly after the sharp S&P 500 performance drop in mid - March 2020 , supporting our sampling assumption that our announcements are indeed reactive responses to the COVID-19 crisis .	255571157	no
Compared with previous reports , the new RAS system presents several advances . First , the new design employed thin AODs in a compact configuration ( Figure 1 ) . The entire assembly of the four AODs that make up a spherical acousto - optic lens was contained in a 20 Ã 20 Ã 30 cm 3 box , which can be inserted as an add - on module to existing TPM systems . Second , the usage of elliptically polarized light and the field - programmable gate array - based AOD control system provides better signal uniformity across a large scanning angle . Third , the synchronized high - speed data acquisition allows rapid line scanning in 3D , especially in the planes that are far away from the natural focal plane of the objective lens . These features provide great flexibility and convenience to the calcium imaging measurement . One can carry out ( 1 ) high - speed continuous volumetric imaging , ( 2 ) full- frame multi - plane imaging , ( 3 ) random - access sub - volume imaging , ( 4 ) random - access patch imaging and ( 5 ) random - access point imaging .	52132280	no
"To develop the methodology , we followed Stieglitz et al . ( 2018 ) and Saura ( 2020 ) and divided the SLR into the following three steps . The first step was based on the analysis and definition of the main theoretical concepts . In the present study , this included the classification of the main massive data collection techniques used in the literature . To this end , we followed Bem ( 1995 ) and Webster and Watson ( 2002 ) who argued that "" a coherent review is born only from a conceptual coherent structuring of the topic itself "" ."	233029680	no
Thorough mutational analyses of the A730 loop domain were previously carried out and revealed the importance of this loop for catalysis ( 16,18 ) . In agreement with our structure of the A730 loop , the reversal of the four Watson - Crick base pairs within this domain ( U753 - G732 , G754 - C731 , C758 - G729 and A759 - U728 ) did not significantly affect cleavage activity , but mutations of loop residues had more important effects ( 16 ) . Although all base substitutions at G757 ( G9 ) and A730 ( A20 ) led to reduced activity , replacing the G9 - A20 combination by a G - C , a G - U or an A - A was less detrimental than other substitutions ( 16,18 ) . Thus , these mutational data indicate the importance of a purine at position 757 and of cis - WC/ WC base pairing ( 75 ) between residues 757 and 730 . This is in agreement with the role of the G9 - A20 base pair in stabilizing the S - turn motif . Mutation of A756 ( A8 ) by U , C or G caused the largest reduction in cleavage activity [ $ 400 - 800 - fold ; ( 16,18 ) ] , which is consistent with its proposed mechanistic role as a general acid ( 21,23,25 ) . Functional group modifications of A756 revealed that the Watson - Crick edge of A756 is particularly important for cleavage ( 17 ) . In the structure of SLVI , the Watson - Crick edge of A8 is exposed in the minor groove and accessible for docking with the cleavage site internal loop and performing its catalytic role .	15730385	no
Firms are subject to multiple crises over time . From a scope perspective , most crises only relate to the affected firm itself or to a specific region ( Wenzel et al . , 2020 ) . For example , the global ridehailing firm Uber experienced a data breach in 2018 , exposing private data related to 600,000 Uber drivers ( Al - Muslim , 2018 ) . The resulting crisis negatively affected financial performance and reputation , leading to a rework of Uber 's data privacy and internal data access policies . Analogously restricted to the scope of single firms , Raithel and Hock ( 2021 ) , for instance , investigate the match between product crises and product recall responses .	255571157	no
Eurostat data have been used in this paper to estimate the carbon impacts of the COVID-19 outbreak for the 23 European countries for which consistent data are available . GDP data at industry level breakdown have been used to calculate the production variations that have taken place in the first semester of 2020 compared to the same period of the previous year . The carbon intensities provided by Eurostat for the year 2018 , and reported in Table A1 of Appendix A , have been used to estimate the CO 2 emissions change ( Eurostat Air Emission database ) . In Table 1 , the industry breakdown considered in this paper is reported together with the related NACE Rev. 2 activity classification . 1 Following the approach proposed by Han et al . ( 2021 ) , where carbon factors and GDP variations are used to estimate the CO 2 emission change , the carbon dioxide emissions drops are here estimated according to Eqs . ( 1 ) and ( 2 ) , where the carbon intensities of the NACE Rev.2 activities are assumed to remain unchanged from the year 2018 .	231677611	yes
Imaginary number unit Shape learning involves the learning of a mapping from input geometrical signals to desired output quantities . The representation of geometrical signals is key to the learning process , since on the one hand the representation determines the learning architectures , and , on the other hand , the richness of information preserved by the representation acts as a bottleneck to the downstream learning process . While data representation has not been an open issue for 2D image learning , it is far from being agreed upon in the existing literature for 3D shape learning . The varied shape representations used in 3D machine learning are generally classified as multiview images ( Su et al . , 2015a;Shi et al . , 2015;Kar et al . , 2017 ) , volumetric voxels ( Wu et al . , 2015;Maturana & Scherer , 2015;Wu et al . , 2016;Brock et al . , 2016 ) , point clouds ( Qi et al . , 2017a;b;Wang et al . , 2018b ) , polygonal meshes ( Kato et al . , 2018;Wang et al . , 2018a;Monti et al . , 2017;Maron et al . , 2017 ) , shape primitives ( Zou et al . , 2017;Li et al . , 2017 ) , and hybrid representations ( Dai & NieÃner , 2018 ) .	57721298	no
The top panel in Fig . 2 shows all objects with I 814 < 26.5 in the plane of V 606 â I 814 color vs. I 814 magnitude . The 11 spectroscopically - identified clusters have a remarkably small range in color : we find V 606 â I 814 = 0.36 with an observed rms scatter of Ï V âI = 0.039 . This is not a result of selection ; we obtained spectra of nearly all compact objects in the vicinity of NGC1052 - DF2 irrespective of their color . The bottom panel of Fig . 2 shows the relation between the SExtractor FWHM and I 814 magnitude for all objects that have colors in the range V 606 â I 814 Â± 2Ï V âI . We note that the results are not sensitive to the precise limits that are used here . As expected , the spectroscopically - identified GCs are small . The dashed line corresponds to FWHM < FWHM + 2.5Ï FWHM = 4.7 pixels . We find that the spectroscopic completeness is 100 % for I 814 < 23 objects that satisfy the color and size criteria . We find 16 candidate GCs with 23 < I 814 < 25.5 , but as we show below most are probably compact background galaxies . The grey scale panel of Fig . 2 shows the I 814 data after masking all objects that do not satisfy these criteria . The masked image was smoothed with a Gaussian of FWHM = 0 . 9 .	55273849	no
The shortfall in achievement of quality indicators reported here has serious implications . Taking coronary heart disease as an example , Gemmell and colleagues have estimated that if 90 % of those with coronary heart disease received recommended drug therapy , including Î² blockers , 3067 coronary events would be prevented annually in England . 31 This calculation was based on 61 % of those eligible receiving Î² blockers , which is comparable to the 65 % who received Î² blockers in the English longitudinal study of ageing ( see web extra table A ) . If those at high risk of coronary heart disease received better advice on lifestyle , Gemmell and colleagues estimated that 4410 events might be prevented . 31 Quality for geriatric conditions was relatively poor in this study and no geriatric conditions were included in the general practice contract . It is possible that inclusion of geriatric conditions in future payment for performance schemes would improve quality . It was not possible , however , to determine from this observational study whether the contract had a causal relation with improving quality of care . Care for diabetes and ischaemic heart disease but not all other conditions has been improving for several years . 9 12 The general medical conditions included stroke , hypertension , diabetes , and ischaemic heart disease , all of which have been subject to major national guidelines such as national service frameworks , and have been the focus of quality improvement activities in primary care trusts . 32 Arguably barriers to implementing evidence based practice for geriatric conditions are greater , despite the national service framework for older people , 33 than for the high mortality conditions that are the focus of much medical practice , 34 35 and the clinical skills required for these conditions may be less well taught to doctors . 4 Further research is needed to compare these results with quality measurements from directly observed clinical care and from medical records . Longitudinal follow - up will allow analysis of links between the quality of care received by participants and later health outcomes . These data are purely descriptive and further analysis of the data is required to describe participant characteristics , such as socioeconomic status and region of residence , associated with good quality care . 36	12800514	no
The screening identifies 311 hits ( 1.5 % overall hit rate ) . The work goes , however , beyond reporting these screening results . We delineate a procedure to combine computational methods to validate binding site prediction from FTMap and PDBsum with the experimentally detected binding ligands . This procedure relies on the prediction of chemical sub - moieties essential for binding and the similarity of these substructures in the set of experimental binders . The thus identified and prioritized binding sites allow application of focused docking protocols and further , the experimental cross - validation by protein - based NMR experiments . From these protein - based NMR experiments , we show that dissociation constants of these fragments with proteins range from 80 ÂµM to several millimolar . The determination of binding affinities can be used to prioritize medicinal chemistry campaigns . Using bioinformatics , identification of fragment binders also serves as starting point for database searches of known binders , using chemical similarity scores between fragments and known inhibitors as selection criterion . Thus , the herein developed workflow allows for holistic screening of the majority of the viral proteome . It provides highly valuable data for the day - to - day support of medicinal chemistry campaigns aiming at developing novel drugs applying fragmentbased drug discovery . These data will also serve development of artificial intelligence ( AI ) based algorithms to inform hit - to - lead campaigns .	252356101	maybe
However , these questions are only part of a broader issue of legitimacy . Data science is becoming more contested because of issues of accountability , fairness , and legitimacy . On a more positive note , the contestation of data science can be seen as a maturation of the field . Obviously , any practice or method has its strengths and weaknesses , and for more mature practices , these strengths and weaknesses are better known . If we consider this , combining the strengths of data science with the wisdoms of the work floor to gain knowledge is full of promises .	239658990	no
The dependence of the strength of the negative ET ( represented by the HOM integral ) on the average output power below the TMI threshold is shown in Fig . 6a . The strength of the negative ET depends nonlinearly on the average power . For 190 W and above , the strength of the negative ET is underestimated because the calculated HOM integral decreases due to a strong back transfer from the HOM into the FM , which manifests itself as dips in the HOM content . The reason for this phenomenon is that the phase shift between the RIG and the MIP becomes larger than Ï at various locations along the fiber , which corresponds to a positive phase shift that enables an energy coupling from the HOM to the FM . Additionally , we have investigated the evolution of the strength of the maximum negative ET , i.e. , the HOM content at the time at which the strongest negative ET occurs , as a function of the average power , which is represented by the blue dots in Fig . 6b . The maximum possible energy coupling , which corresponds to a full ET from the FM into the HOMs , is reached at~150 W average output power , where the curve saturates . Derived from coupled - mode theory and according to ref . 33 , the maximum coupling strength , which is denoted as Î max , for transmission gratings is expressed as where Îº is the coupling coefficient and L is the length of the grating . This behavior should also be observable for the RIG in our fiber , even though it is non - uniform over the whole fiber length due to the anisotropy that is induced by the power extraction under counter - pumping conditions . However , it is possible to define an equivalent uniform RIG that will result in the same maximum possible energy coupling 33 . Thus , we have fitted the experimental data of Fig . 6b up to the saturation level of 150 W , which is the region where Eq . ( 1 ) is valid , with the following function :	75137626	no
The experimental kinetic data was fit to the pseudo - first - order ( Eq . ( 4 ) ) , pseudo - second - order ( Eq . ( 5 ) ) as well as the Weber and Morris intra - particle diffusion ( Eq . ( 6 ) ) kinetic model equations , the parameters and linear regression coefficients ( R 2 ) of which are presented in Table 2 . Based on the correlation coefficient , the pseudo - second - order was the best fit for all the experimental data . This has been noted for several other similar studies for Mg - Al LDHs ( GonzÃ¡lez et al . , 2015;Huang et al . , 2015;Ma et al . , 2014;Yang et al . , 2016 ) , but has not previously been noted for Cu 2 + uptake kinetics of Ca - Al type LDHs . Additionally , the q e values obtained via the pseudo - second - order model were similar to those obtained experimentally . This suggests that the pseudo - second - order model will work well for this LDH for the whole - time range . Thus , the second order sorption mechanism appears to be dominant , and the overall rate of metal uptake was controlled by a chemisorption process ( Ho , 2006 ) . The fit of the experimental data to the intra - particle diffusion model Eq . ( 6 ) provides an insight into the overall rate of sorption ( Table 2 ) . The intercept value ( C ) provides an indicator of the boundary layer thickness , with higher values representing a greater boundary layer effect . Table 2 shows that the intercept values obtained are much higher than those obtained in other studies ( GonzÃ¡lez et al . , 2015 ) , suggesting that intra - particle diffusion plays a strong role in the sorption process . Additionally , the high k ip values indicate that there are many active sites on the surface of the Ca 2 Al - EDTA LDH for Cu 2 + ions to attach to , thus enhancing the diffusion rate .	58624850	no
"When machine learning models are employed "" in the wild "" , the distribution of the data of interest(target distribution ) can be significantly shifted compared to the distribution of the data on which the model was trained ( source distribution ) . In many cases , the publicly available large - scale datasets with which the models are trained do not represent and reflect the statistics of a particular dataset of interest . This is for example relevant in managed services on cloud providers used by clients in different domains and regions , or medical diagnostic tools trained on data collected in a small number of hospitals and deployed on previously unobserved populations and time frames ."	68220930	no
Theorem 4 is proved in App . F of the supplementary material . Note that this expected regret is over both the i.i.d . choice of data samples and the i.i.d . choice of ( b(t ) , c(t ) ) pairs .	108296106	no
The core of M87 was frequently monitored over the entire year of 2017 at 22 GHz with the VLBI Exploration of Radio Astrometry ( VERA ; Kobayashi et al . 2003 ) , as part of a regular monitoring program of a sample of Î³ - ray bright AGNs ( Nagai et al . 2013 ) . A total of 17 epochs were obtained in 2017 ( see Figure 2 and Table A1 in Appendix A ) . During each session , M87 was observed for 10 - 30 minutes with an allocated bandwidth of 16 MHz , sufficient to detect the bright core and create its light curves . All the data were analyzed in the standard VERA data reduction procedures ( see Nagai et al . 2013;Hada et al . 2014 , for more details ) . Note that VERA can recover only part of the extended jet emission due to the lack of short baselines , so the total fluxes of VERA listed in Table A1 in Appendix A significantly underestimate the actual total jet fluxes .	233231412	maybe
Generally , this work focused on the two following research questions . One is how to systematically , comprehensively and accurately assess the health effects of decreasing PM 2.5 levels during the 13 th FYP period and the other is how to identify the impact of the COVID-19 outbreak on the changes in PM 2.5 concentrations and the implementation of China 's long - term air pollution control policies ? In this study , we selected 329 cities in mainland China as study settings to comprehensively estimate the chronic health effects of air pollution control of PM 2.5 from 2015 to 2020 . By comparing empirical data with the predicted results , we also analyzed whether COVID-19 has had a large influence on China 's long - term air pollution control effectiveness . Since China is the largest developing country in the world today and is facing severe problems of particulate pollution , analyzing the effects of China 's air pollution control policies will not only assist the Chinese government in adjusting and implementing 14 th FYP pollution prevention and control policies , but also inspire countries around the world facing serious pollution by PM 2.5 , particularly those in development . Moreover , as China 's policy implements and control effectiveness in response to COVID-19 are unique in the world , there is a particular need to eliminate the impact of the sudden epidemic on changes in PM 2.5 concentrations .	237424987	no
Mortality data were retrieved from the national cause of death registry until 1 September 2007 . Participants who did not die during follow - up were censored at that time or at time of emigration .	2391023	maybe
Google Mobility Data : Google mobility data is generated by aggregating information from users ( who have agreed to share their location information ) in conjunction with Google Maps . 2 Further , the mobility information is grouped into six broad categories that have comparable features from a social distancing guidance perspective . The six categories are : ( i ) retail & recreation , ( ii ) grocery & pharmacy , ( iii ) parks , ( iv ) transit .	255441206	maybe
For deviations around the preferred geodesic Î³ , the solutions can be written in terms of the initial data at some point u â² on Î³ by introducing matrix functions A(u , u â² ) and B(u , u â² ) as follows :	10182446	no
The data obtained from the upstream point Pieve di Santo Stefano in the first sampling campaign ( autumn 2013 ) were excluded from data analysis due to unexpected microbial and chemical contamination ( see paragraph 3.6 ) . The values b LOQ were set as half of the LOQ for average calculation ( according to Directive 2009/90 / EC ) . Statistical analyses were performed using the software PAST , version 3.11 ( Hammer et al . , 2001 ) . All analyzed parameters were grouped for data analysis as described in Table 2 Analysis of variance was performed with log transformed data considering sampling campaigns , sampling points and seasons as variance factors . The correlation between microbiological parameters and grouped chemical compounds was assessed by the Spearman 's non - parametric rank - order correlation coefficient by including all five samplings and evaluating sites separately . The Bonferroni correction for multiple testing was incorporated by setting the significance cut - off by dividing the P value for the number of tests to be conducted . The Principal Components Analysis ( PCA ) between sampling points was performed on a correlation matrix , implying standardization of variables , calculated using normalized data values from Table 1 List of the rRNA - targeted probes used for Fluorescence in Situ Hybridization ( FISH ) analysis , corresponding microbial taxa identified , oligonucleotide sequence and rRNA position . Further information is available at http://www.microbial-ecology.net/probebase ( Greuter et al . , 2016 ) .	113407555	maybe
( 1 ) Are the risk severity perception indicators ( i.e. , Google Trends search data ) affected by risk susceptibility measure ( i.e. , pandemic health impact metric ) ? ( 2 ) How is consumer mobility affected by the two distinct dimensions of risk perceptions : susceptibility and severity ? ( 3 ) Given the correlated nature of Google Trends search data , how do we construct a parsimonious model to predict retail mobility ? ( 4 ) How do the risk perception dimensions differentially impact the various mobility activities in different metro areas ?	255441206	no
The data are found to be consistent with the Standard Model predictions . Assuming directË1 pair production with both top squarks decaying in either the two - body channelË1 âË0 1 , the three - body channel the minimumË1 andË0 1 masses up to about 1 TeV and 500 GeV respectively . The results improve on the previous ATLAS limits obtained in a two - lepton final state and provide unique sensitivity among the ATLAS searches in the mass region where the decayË1 âË0 1 becomes kinematically allowed . For the dark - matter model , assuming spin-0 mediator production in association with a pair of top quarks and decay with 100 % branching ratio into a pair of dark - matter particles , scalar ( pseudoscalar ) mediator masses up to about 250 ( 300 ) GeV are excluded at 95 % confidence level for mediator couplings = = 1 to Standard Model and dark - matter particles .	231749472	no
This downsampling procedure was repeated 10,000 times , with the results shown in Figure 3 . The full observations of MS0735 are shown in the left panel , while a single , characteristic downsampled image is shown in the middle panel . The fulldepth image shows the obvious presence of cavities in the raw data , outlined by the dashed green ellipsoidal regions , which are still recovered a large fraction of the time ( at an average significance of 0.9Ï and 0.7Ï ) in the significantly shallower downsampled images . In comparison , the southern and northern cavities in SPT0528 are even more convincing , at 1.8Ï and 1.4Ï below their expected surface brightness , respectively . The bootstrapping procedure above demonstrates that cavities as large as those in MS0735 , the most energetic outburst we know of , could be detected with Chandra at the same observing depth and redshift of SPT0528 at the same level , inspiring more confidence that those in SPT0528 are real .	208512986	no
We have previously reported on a non - randomized , open - label , phase I / II clinical study ( based on a lentiviral gene therapy vector ) involving seven pediatric patients with severe WAS . Details of the gene therapy study design and procedures have been reported previously 20 . The patients were treated at Necker - Enfants Malades Hospital ( Paris , France ; ClinicalTrials.gov identifier NCT01347346 ) and at Great Ormond Street Hospital ( London , UK ; ClinicalTrials.gov identifier NCT01347242 ) . Patients were enrolled in the Long Term Safety Follow up of Haematopoietic Stem Cell Gene Therapy for the Wiskott - Aldrich Syndrome ( WASFUP ) study ( ClinicalTrials.gov identifier NCT02333760 ) , which was designed to follow patients for an additional 13 years after the initial gene therapy study . The WASFUP study protocol was approved by the UK and French drug regulatory agencies and the appropriate investigational review boards , such as the Gene Therapy Advisory Committee in the United Kingdom and the ComitÃ© de Protection des Personnes in France . A CONSORT flow diagram detailing enrollment of the patients is available in the Supplementary Information . Data were collected manually and transferred to the Altizem Society for data management through Clintrial software .	246277226	yes
Trophoblast cells highly express the HSPE1 protein [ 13 ] . The main annotated role of HSPE1 is the chaperonin mediated protein folding together with Hsp60 [ 14 ] . It has also been suggested that HSPE1 may be critical in the suppression of T cell activation [ 15 ] . In myocytes , it has been also described that HSPE1 inhibits the proapoptotic activity of cells and shifts the cell fate balance toward survival [ 16 ] . It has also been proposed that HSPE1 is selectively released from proliferating cells and is an active player of cell signalling network [ 15 ] . Recombinant HSPE1 selectively binds to human CD4 + T cells in vitro [ 17 ] and can induce T reg differentiation in mouse animal model [ 18 ] . Besides proteins , miRNAs are the most important molecular cargo of EVs [ 19 ] . miRNAs dynamically regulate the expression of gene networks ( 1 ) and contribute to the function of cell differentiation at the posttranscriptional level [ 20 ] . EV - associated miRNome is regarded as one of the most promising clinical biomarker for diagnosis , prognosis , and therapeutic options [ 21 ] . On the basis of these data , we hypothesized that trophoblast - derived EV - associated HSPE1 and miRNA cargo specify the generation and heterogeneity of T reg cells at the feto - maternal interface .	198192189	no
We chose to explore whether this new approach could correct the SPIM artifacts seen in Fig . 1 . Fig . 1b shows a surface rendering of the sample , which gives an idea of the relative positions of the eyes and neuronal structures . Because it provides an overview of the entire head , the attenuation artifacts caused by the eye pigmentation are not readily apparent . In Fig . 3a , we have therefore rendered a sub - volume of the fluorescent structures of the ( see figure on previous page ) Fig . 1 Absorption artifacts in light sheet imaging . a Attenuation artifacts in simple vs. complex structures . Green : fluorescent regions ; gray : attenuating regions ; cyan arrows : illumination directions ( for simplicity , the effects of attenuation on the emitted fluorescence are not shown ) ; dark green : non / poorly illuminated regions . Left : When the attenuating region is relatively simple ( geometrically ) , the artifacts can be corrected by multiview reconstruction ( in the case shown , two views are sufficient ) . Right : For more complex attenuating structures , there are generally regions in the sample that are not clearly illuminated by any view and thus are not properly corrected by standard multi - view reconstructions . b Surface rendering of a cleared embryonic stage E12.5 mouse head , immunolabeled for Tuj1 ( class III Î² - tubulin , a neuronal marker ) . The sample was imaged using both LSFM ( Tuj1 , white surface ) and tOPT ( eye pigments , cyan surface ) . The retina contains pigmented cells that significantly absorb light and , therefore , create contrast to visualize the eyeball . Although absorption artifacts are present in the LSFM image , if they are not recognized for what they are , they may be misinterpreted as an intrinsically weaker signal . c A 130-Âµm - thick slice through the fluorescence image at the level of the red dashed line in b. The light - absorbing retina casts two shadows : the horizontal shadow on the right indicates where illumination ( from the left ) was considerably reduced , and the vertical shadow ( below the eye ) indicates the regions obscured from the view of the objective lens used for detection , which is above ( ill = illumination , det = detection ) . d , e show the reconstruction of the eye pigmentation from a tOPT scan in the region indicated by the red box in ( c ) and the overlay of the pigmentation and the fluorescence signal imaged in the SPIM mode , respectively . The shadow artifacts in the fluorescence data are well aligned with the eye pigmentation . Scale bars : 500 Âµm head in Fig . 1b , where the shadow artifacts are now visible , both to the right of the eye ( where the fluorophores are only weakly excited because the eye pigments block the illuminating light sheet ) and behind the eye with respect to the detection direction ( where the emitted fluorescence is blocked from reaching the detection optics by the pigmentation ) . Fig . 1d , e show the reconstruction of the eye pigmentation from a tOPT scan in the region indicated by the red box in Fig . 1c and the overlay of the pigmentation and the fluorescence signal imaged in SPIM mode , respectively . The shadow artifacts in the fluorescence data are well aligned with the eye pigmentation .	52941474	no
Using Poisson sampling , we encode each 28 Ã 28 image into a 2D 784 Ã L binary matrix , where L = 400 represents the duration of each spike sequence in ms , and a 1 in the matrix represents a spike . The simulation time step is set to be 1ms . No other preprocessing or data augmentation is applied . Table 4 shows that ST - RSBP outperforms all other SNN and non - spiking BP methods .	201070480	no
The cross validation procedure is described as follows . The data is divided randomly into M folds of equal size m = n / M . For fold j , let the testing set D te ( j ) be itself , the cross validation set D cv ( j ) be any other fold , and the training set D tr ( j ) be the remaining . The size of the three are m , m , ( M â 2)m respectively . For fold j , suppose at most L decision rules are calculated based on the training set , namely t j1 , Â· Â· Â· , t jL . Evaluated on the cross validation set , let l * -th rule be the rule with most discoveries among rules that satisfies 1 ) its mirroring estimate F DP ( t jl ) â¤ Î± ; 2 ) D(t jl ) /m > c 0 , for some small constant c 0 > 0 . Then , t jl * is selected to apply on the testing set ( fold j ) . Finally , discoveries from all folds are combined .	36049331	no
Lipidomic analysis was performed as described previously with slight modifications ( 35 ) . Briefly , total cellular lipids were extracted with methyl tert - butyl ether ( MTBE ) ( Sigma Aldrich ) from fresh cell pellets and dried in a SpeedVac concentrator ( Thermo Scientific ) . Lipid samples were resuspended in 50 % isopropanol , 50 % methanol and analyzed by liquid chromatography tandem mass spectrometry ( LC - MS / MS ) . Twenty microliters of lipid solution were loaded onto a 15 cm Accucore Vanquish C18 column ( 1.5 m particle size , 2.1 mm diameter ) and separated using an Ultimate 3000 XRS ultraperformance LC system ( Thermo Scientific ) . The mobile phase consisted of 60 % acetonitrile , 10 mM ammonium formate , and 0.1 % formic acid ( phase A ) and 90 % isopropanol , 10 % acetonitrile , 10 mM ammonium formate , and 0.1 % formic acid ( phase B ) . LC gradient was 35 - 60 % B for 4 min , 60 - 85 % B for 8 min , 85 - 100 % for 9 min , 100 % B for 3 min , 100 - 35 % B for 0.1 min , and 35 % B for 4 min at a flow rate of 0.3 ml / min . Mass spectra were acquired by an Orbitrap Fusion Lumos Tribrid mass spectrometer ( Thermo Scientific ) operated in a data - dependent manner . Parameter settings for FTMS1 included orbitrap resolution ( 120 000 ) , scan range ( m / z 250 - 1200 ) , AGC ( 2 Ã 10 5 ) , maximum injection time ( 50 ms ) , RF lens ( 50 % ) , data type ( profile ) , dynamic exclusion for 8s using a mass tolerance of 25 ppm , and cycle time ( 2 s ) ; FTMS2 included orbitrap resolution ( 30,000 ) , isolation window ( 1.2 m / z ) , activation type ( HCD ) , collision energy ( 30Â±3 % ) , maximum injection time ( 70 ms ) , AGC ( 5 Ã 10 4 ) , and data type ( profile ) . Acquired raw files were analyzed using LipidSearch ( v1.4 ) ( Thermo Scientific ) for sample alignment , MS2 identification and MS1 peak area calculation . Statistical analyses were conducted using the Perseus ( v1.6.6.0 ) software ( 36 ) , wherein the P values were calculated by two - tailed Student 's t - test and corrected for multiple hypothesis testing via the Benjaminin - Hochberg method . Volcano plots were generated using the ggplot2 in the R environment ( R Development Core Team ; https://www.r-project.org/ ) ( v3.5.0 ) .	213671700	no
The dataset used in this paper consists of three different groups of data . First , the daily log returns of the three largest cryptocurrencies , Bitcoin ( BTC ) , Ethereum ( ETH ) and Ripple ( XRP ) , as ranked by market capitalization during the sample period ( from January 1 , 2020 , to December 31 , 2020 ) , are included . These top three cryptocurrencies represent 82.1 % of the cryptocurrency market , and Bitcoin alone has a 69.2 % share in this market at the end of December 2020 . Second , the exchange rates of the three major fiat currencies , the euro , GBP and Chinese yuan , against the US dollar are included . Third , the RavenPack Coronavirus Media Coverage Index ( MCI ) was used to measure the level of media coverage with this issue . 2 This coronavirus index ( MCI ) is the 2 See the https://www.ravenpack.com/ website , which provides insights generated automatically from real - time news from over 22,000 news and social media sources .	236449955	maybe
MyoGrip is a very sensitive myometer that evaluates hand grip strength [ 35][36][37 ] MyoGrip data were collected for each participant using a three - trial maximal effort grip strength protocol . Raw data , collected in kg , were then analyzed using the percentage predicted 38 .	256032596	maybe
Dashed lines indicate the data fits with the model ( Equation ( 4 ) ) . e ) Ammonia removed over time when isolating each step by incrementalling increasing NH 3 pressure from 0.25 to 0.85 bar to 1.75 bar with 50 wt% MnCl 2 /SiO 2 at 350 Â° C . Dashed lines indicate the prediction of each term in the model ( Equation ( 4 ) ) .	233828232	no
In K19 we introduced a new set of simulations that were the first of their kind to model the full population of stars ( younger than 5 Gyr ) that comprise a Milky Waylike disk galaxy . All stars are born in clusters with a range of initial conditions informed by observations and detailed simulations . The dynamical evolution of 4 billion stars was performed with orbit integration of test particles coupled to a realistic time - varying galactic potential , which includes a disk , halo , bulge , bar , spiral arms , and GMCs ( as perturbers ) . These simulations predict a rich structure in the combined phase and chemical space that should inform our understanding of the nature of clustered star formation . . Normalized fraction of co - moving pairs as a function of the separation ( left panel ) and velocity difference ( right panel ) -data is the black line , Poisson errors for the data in grey ( too small to be seen ) , fiducial simulation is the dashed blue line , axisymmetric simulation is the dashed green line , and NCSF is the dashed red line . All three simulations underestimate clustering at the smallest separations ( âr < 5 pc ) . The disagreement may arise from contamination from disrupting wide binaries , or due to lack of complexity in our prescription for star formation . The differences in the fraction of pairs for the velocity difference in the simulations and the data indicates that the count of pairs at small velocities is sensitive to both clustered star formation and the non - axisymmetries in the potential of the Milky Way . The fiducial simulation , which has both , agrees better with the data than the other models .	102353914	no
The measured time traces of the Brillouin signal of the OCC - BOTDA system are shown in Fig . 4a . The data clearly show a BGS with a main peak and a ghost peak that is found to occur every 20 ns ( corresponding to a spatial resolution of 2 m ) , which agrees well with the simulation results , as plotted in Fig . 2 . Compared with the BGS ( black line ) for a strain change of ÎÎµ = 0.0 Î¼Îµ , the BGS ( magenta line within the blue wireframe ) for a strain change ÎÎµ = 700 Î¼Îµ is time - shifted . Subsequently , a zoom - in view for the blue wireframe is shown in Fig . 4b as the strain changes from ÎÎµ = 0.0 Î¼Îµ to ÎÎµ = 700 Î¼Îµ , with the horizontal axis label converted from a time value to a frequency value . It is clearly shown that the central frequency of the main peak initially shifts by~42 MHz with respect to the local BFS at 10.705 GHz at room temperature . The time ( or frequency ) of the main peak is evidently up - shifted as the strain change is increased .	52136642	no
We emphasize that although Scheme 1 allows a satisfactory kinetic fit of the data it contains speculative elements and at present should be considered as a working model .	18799888	no
Each experimental proximity measurement ( z e ) was then used as an input for the distance of water between the transducer and the PS object in simulation , producing the traces in Fig . 3c . Experimental ( z e ) and simulated ( z m ) proximity measurements from Fig . 3b , d are then collated in Fig . 3e as a function of step number and experimental averaging bin size . Each point on the red curve represents the average measurement and standard deviation of 100 bins each containing one measurement , whereas the blue curve averages the data into two bins each containing 50 measurements . Overall there is strong agreement between experiment and simulation , with the only notable deviation occurring at the first measurement ( z - step 1 ) , which is likely due to the boundary occurring within the blind zone of the wavelet transform .	233416742	no
In the following we want to discuss the fitting of the coevaporated sample series , representing an example of samples with a higher degree of non - radiative recombination . A SRH bulk lifetime of about Ïn + Ïp = 750 ns best describes the experimental TPL data of coevaporated bulk passivated with TOPO in the glass / perovskite / TOPO stack ( grey ) . This SRH bulk lifetime would allow much higher opencircuit voltages than 1.05 V. Combined with an effective radiative recombination coefficient krad = 2Ã10 -10 cm 3 s -1 , a Voc of about 1.23 V would still be possible for the coevaporated bulk if no additional recombination losses would occur in the stack . The simulations suggest that for the coevaporated cell , these additional recombination losses are caused by misaligned energy levels and increased recombination at both interfaces ( see Figure 6 ) . Interface recombination at the PTAA / MAPI interface ( coevaporated sample ) leads to slightly shorter decay times TPL , HLI ï´ at small Fermi - level splitting ( green ) as opposed to the samples without charge - extracting layers attached ( grey ) . Note that these two decay time curves nicely overlap at high âEF , where radiative and Auger recombination dominate the ÏTPL , HLI .	231942588	no
Phenotype curation . BBJ collected baseline clinical information and dietary and activity habits information through interviews and reviews of medical records using a standardized questionnaire . We selected 81 traits ( 57 anthropometric traits and biomarkers , 11 dietary habits , six behavioural traits , six diseases and one dummy ; Supplementary Tables 2 - 4 ) . We used these data from participants above the age of 18 , and drinking and smoking traits from those above the age of 20 . We normalized each anthropometric trait and biomarker traits by applying rank - based inverse normal transformation as previously reported ( Supplementary Table   8) [ 51][52][53 ] . For each dietary habit , the participants were asked to clarify the frequency of consumption on a four - point scale , and we assigned the corresponding values to their responses as previously described 26 , where almost every day = 7 , 3 - 4 days per week = 3.5 , 1 - 2 days per week = 1.5 and rarely = 0 . Behavioural traits included ever versus never drinking and ever versus never smoking 54 as binary traits , and the frequency of four PAs ( light - PA , gymnastics , walking and sports ) . For each PA , participants were also asked for the frequency and the length of time per week on a seven - point scale , and we quantified the activity by converting the responses to total minutes of activity time per week ( min week -1 ) , where â¥30 ( 15 ) min day -1 = 210 ( 105 ) , < 30 ( 15 ) min day -1 = 140 ( 70 ) , three to four times a week for â¥30 ( 15 ) min = 105 ( 52.5 ) , three to four times a week for < 30 ( 15 ) min = 70 ( 35 ) , one to two times a week for â¥30 ( 15 ) min = 45 ( 22.5 ) , one to two times a week for < 30 ( 15 ) min = 30 ( 15 ) and rarely = 0 ( the number in parentheses indicates gymnastics time ) .	252466144	maybe
As the human retina in the foveal region does not usually exceed a thickness of 300 Âµm 31 , the retinal image ( see figure on previous page ) Fig . 2 Characterization measurements of the two 256 - channel AWGs . Measured spectral characteristics of a AWG 1 and b AWG 2 for every eighth channel : the minimum , maximum , mean , and standard deviation of the peak powers are provided in the two figures . The thin black line is a polynomial second - order fit to the peaks . This fit shows the AWGs typical spectral envelope , which is different for the two designs . The deviation of the individual peaks from this envelope fit ( peak power minus power of the envelope at the peak wavelength ) is shown in the two figures below ( red lines with blue crosses ) . The deviation of~Â±0.5dB can be explained by the inaccuracy of the fiber alignment with respect to the chip . For the OCT measurements , where no fiber at the output was used , these variations are not present . Sensitivity roll - off measurements of c AWG 1 and d AWG 2 with the respective axial resolution measurements as insets : 14.5 Âµm in air and 10.7 Âµm in soft tissue ( AWG 1 ) and 8.8 Âµm in air and 6.5 Âµm in soft tissue ( AWG 2 ) . e Scheme of the SD - OCT on - chip setup : a Superlum SLD fed broadband light to a fiber coupler , and 830Î¼W ( AWG 1 , a booster amplifier and a 90/10 coupler were used ) and 480Î¼W ( AWG 2 , no booster amplifier and a 50/50 coupler were used ) light on the eye interfered with the reference light and was coupled into the on - chip AWG . Projection optics were used to project the light from the PIC end facet onto a CCD camera . FC fiber coupler , PC polarization controller , L lens , C collimator , M mirror , AWG arrayed waveguide grating , AD achromatic doublet c Unaveraged and d five times averaged fovea acquired with AWG 1 at 34kHz . e Unaveraged and f five times averaged fovea acquired with AWG 2 at 20kHz . In areas perpendicular to the scanning beam , strong reflection induces visible side lobes . g 3D representation of the retina in the foveal region acquired with AWG 1 at 67kHz , and h corresponding OCTA image calculated from the volume using five B - scan repetitions . The black area on the right side of the angiogram corresponds to missing data due to motion correction in the lateral direction of the subject could be aligned to be within the 6 - dB rolloff region to achieve the best possible contrast . However , it is not only the macular region that is of clinical relevance . The optic nerve excavation towards the brain well exceeds the thickness of the retina itself , and therefore , deeper imaging is required to visualize it . Cup - to - disc ratios of the optic nerve head are used to monitor glaucoma patients 32 , which requires the full optic nerve cup to be visible in the tomograms . Good signal quality at deeper depths is also required for patient imaging . If the patient can not fixate very well , then higher axial movements are expected , which results in imaging further away from the zero delays . To investigate the impact of the strong signal roll - off in the AWG systems on the contrast of tomograms , the subject 's optic nerve cup was imaged . Figure 4 shows a summary of the acquired volumes and selected B - scans in the area of the optic nerve head . Each tomogram is an average of three registered B - scans ; the 200 B - scans in the 3D volumes are also an average of three B - scans each . A B - scan consists of 400 A - scans . Figure 4c , f , i shows 3D volumes of the optic nerve depression obtained with AWG 1 at 67 kHz , AWG 1 at 34 kHz , and AWG 2 at 20 kHz , respectively . From these volumes , we selected two types of B - scans : Fig . 4a , d , g displays to nerve head to determine whether the optic nerve cup can be visualized . AWG 1 , having a slightly better roll - off than AWG 2 , shows the entire cup in Fig . 4a , d , which could be used for glaucoma monitoring . AWG 2 , as shown in Fig . 4 g , fails to visualize the cup fully due to the high signal roll - off , though the thickened retinal nerve fiber layer shown in Fig . 4h is resolved with good contrast using AWG 2 . Tomograms in this area acquired with AWG 1 , however , still show better signal with depth ( Fig . 4b , e ) , as the choroid layer is visible , whereas it is almost not visible when imaged with AWG 2 ( Fig . 4h ) .	230719129	no
The bed bugs ' unusual reproductive strategy of traumatic insemination [ 58 ] causes copulatory wounding in females and increases their risk of microbial infections . As females typically are mated after a blood meal , they have developed reproductive immune anticipation triggered by feeding cues [ 71 ] to deal with any microbes that are injected with sperm or that otherwise invade their bodies . In response to feeding cues and preceding traumatic insemination , females pre - emptively express AMPs and upregulate lysozyme - like activity [ 17,58,[71][72][73 ] . As previously reported , blood - fed female bed bugs have stronger overall antimicrobial activity than blood - fed male bed bugs [ 67 ] . Here we studied whether the mode of immune challenge affects the upregulation of defensins in a sex - specific manner . After ingestion and injection of bacteria - laced blood , males had the highest defensin expression in their midgut and RoB , respectively . Defensin expression by females , however , did not follow this pattern and ingestion of Gr+ bacteria caused a higher response in the RoB. Regardless , our data show that the mode of immune challenge affects sex - specific defensin expression in bed bugs .	252665524	no
"Functional testing confirmed that there was no effect of ETX001 on ENaC - mediated sodium absorption or CFTR - mediated secretory currents that may have influenced downstream assays of mucosal hydration . Furthermore , as intracellular calcium levels were not buffered in the CF - HBE assays , it was important to test whether ETX001 could influence calcium signalling to correctly interpret the primary cell work . This was especially important as it has been proposed that TMEM16A plays a central role in the regulation of intracellular calcium signalling [ 79,80 ] . Using a combination of knockdown experiments as well as TMEM16A blockers , it has been reported that TMEM16A is required for GPCR - mediated calcium release from the ER and is therefore central to a host of calcium - mediated biological activities . ETX001 did not directly influence calcium levels and failed to modulate GPCR - mediated increases in intracellular calcium , further supporting a direct TMEM16A - potentiator mode - of - action in the primary cell assays and challenging the proposed role for TMEM16A in calcium regulation . mechanism , ETX001 and related compounds showed no activity on TMEM16A when intracellular calcium was clamped to zero . ETX001 treatment of CF - HBE enhanced short - circuit current responses to calcium - mobilising agents , including UTP and the SERCA pump inhibitor , cyclopiazonic acid ( Figure 3B ) . As mentioned above , the good correlation between recombinant patch - clamp assay data and native TMEM16A - expressing CF - HBE further supported the identity of TMEM16A as the native airway CaCC . ( 1 ÂµM ) . The change in ASL height from baseline was measured following a 1 h treatment with ETX001 or vehicle under "" static conditions "" , i.e. , no shear stress , and also after 3 h of continual shear - stress . Reprinted from [ 39 ] with permission of the American Thoracic Society . Copyright Â© 2020 American Thoracic Society . The American Journal of Respiratory and Critical Care Medicine is an official journal of the American Thoracic Society ."	214771763	no
The AD and CVD CNTs are purchased from n - Tec ( Norway ) and Bayer Material Science ( Germany ) , respectively . The FCVD CNTs are functionalized mainly with the carboxylic groups following the protocol described in the supporting information and Ref . [ 16 ] . All CNTs are deposited on an acetone cleaned silicon substrate for friction measurements performed with a Veeco Nanoscope IV Multimode AFM at room temperature and in ambient environment . Details about Raman measurements , sample preparation and TEM data regarding CNT structure , size and number of walls are reported in the supporting information . A cantilever ( PPP - LFMR , Nano and More ) with a typical spring constant k N = 0.2 N m â1 is used . The spring constant of cantilever is calibrated with the Sader 's method [ 31 ] . The lateral sensitivity is calibrated by the wedge method [ 32 ] . The R N T and average R T ip = 50 nm are inferred directly from the AFM images of CNTs . The friction forces are measured usually beginning with F N â 3 nN and decreased stepwise until the tip is out of contact with the sample . The tip velocity is kept at 1 Âµm s â1 for all measurements . All measurements discussed in Fig . 1 , 2 , and 3 are performed at R.H. of about 40 % . In Table II , we repeat the measurements on two FCVD CNTs at controlled R.H. of 20 % and 36 % . The fluctuation of R.H. is less than 1 % during the entire experiment .	8685330	no
We further explored the role of copper in the complex formation by UV / Vis spectroscopy ( Figure 3 ) . Upon binding to the amino acids , the absorption maximum of the dienophile ( 326 nm ) displayed ared - shift ( 375 nm ) , while the amino acid absorbance at 275 nm exhibited afine structure and increased in value ( Figure 3a , b ) . Notably , t itration of CB [ 8]Â·dÂ·Cu 2 + or CB [ 8]Â·eÂ·Cu 2 + into the substrate resulted in alarge dienophile absorbance at 375 nm , while the absorbance at 326 nm was drastically decreased ( Figure 3c , d ) . Moreover , the amino acid absorbance was also red - shifted and the entire spectra generally broadened . These data indicated that the presence of CB [ 8 ] dramatically increases the extent of Cu 2 + bound to Based on the qualitative data obtained through spectroscopic techniques , w ef urther evaluated the interaction of CB [ 8]Â·dÂ·Cu 2 + and CB [ 8]Â·eÂ·Cu 2 + with 1a through ITC.T he titration of am ixture of amino acid and Cu 2 + into the dienophile solution resulted in al ow - affinity interaction ( Supporting Information , Figures S15 aa nd S16 a ) , while the titration of CB [ 8]Â·dÂ·Cu 2 + and CB [ 8]Â·eÂ·Cu 2 + into 1a showed as trong binding event for both systems ( Supporting Information , Figure S17 ) . Although the K eq values obtained from the ITC analyses were one order of magnitude higher than those measured by UV / Vis ( Table 2 ) , the trend was exactly the same ( Supporting Information , Figures S15 , S16 ) .	14527477	no
Encouraging collaboration and team science . Studies of statistical power persistently find it to be below ( sometimes well below ) 50 % , across both time and the different disciplines studied 2,35,36 . Low statistical power increases the likelihood of obtaining both false - positive and false - negative results 2 , meaning that it offers no advantage if the purpose is to accumulate knowledge . Despite this , low - powered research persists because of dysfunctional incentives , poor understanding of the consequences of low power , and lack of resources to improve power . Team science is a solution to the latter problem -instead of relying on the limited resources of single investigators , distributed collaboration across many study sites facilitates high - powered designs and greater potential for testing generalizability across the settings and populations sampled . This also brings greater scope for multiple theoretical and disciplinary perspectives , and a diverse range of research cultures and experiences , to be incorporated into a research project .   Various potential threats to this model exist ( indicated in red ) , including lack of replication 5 , hypothesizing after the results are known ( HARKing ) 7 , poor study design , low statistical power 2 , analytical flexibility 51 , P - hacking 4 , publication bias 3 and lack of data sharing 6 . Together these will serve to undermine the robustness of published research , and may also impact on the ability of science to self - correct .	6326747	no
While thus far , the data presented in this paper have been derived from interviews with people living with Types II and III SMA , for some families living with Type I SMA , and particularly those who had experienced the premature death of a family member , the expressive capacity of genetic technologies to prevent the recurrence of SMA , while acknowledged , was presented as less significant in the context of reproduction . Fraser is in his fifties and experienced the deaths of his first two children , Ciaran and Eve , to SMA Type I before their first birthdays . He described his feelings about the use of prenatal testing and selective termination to ensure that his third child did not have SMA by contrasting it with the decisions facing families affected by Type II SMA : I think that if you 've got Type II then there 's a big dilemma in the family . If you 've got a Type II that 's ten years old and you 're expecting again , you know I 've heard Type IIs say ' would you have gotten rid of me then if you 'd had the chance ? ' , you know ? It 's different when it 's Type II in the family because.they live . They can lead perfectly full , happy lives.which was just not going to be the case for my children . Ciaran and Eve both suffered and died .. I do n't think anyone could see a dilemma for wanting to stop that . No one could say to me that if I did [ prenatal testing and selective termination ] that I did n't love and want my children to live because they had SMA . No , of course I did .. but the fact is that they were n't going to live , so yes , although I wanted Ciaran and Eve , I also wanted rid of the.horror of what happened to them.and not go through that again . I do n't see that anyone could take issue with that . not even a Type II .	23107370	no
In contrast to results on the circular DNA , ClpXP did not inhibit the cleavage reaction on the linear DNA ( in fact , there was a slight increase in cleavage rate ) and did not de- EcoKI was monitored as a function of time ( 0 , 5 , 10 , 20 , 40 , 60 and 120 min ) in the absence or presence of ClpXP . Samples were separated by either agarose gel electrophoresis ( upper gel ) or by SDS gel electrophoresis followed by western blotting using an HsdR antibody . Graphs to the right of each gel show quantified data : standard deviation error bars from at least two repeat experiments . ( C ) Proteolysis of HsdR was monitored following 120 - min EcoKI reactions in the absence or presence of ClpXP on the DNA shown . For the linear DNA with res binding sites , Tn21 resolvase was also added where indicated . Each res site has three binding sites for three resolvase dimers . Samples were separated as in ( B ) . grade the HsdR within error ( Figure 5B ) . As noted above , the long - lived interaction between HsdR and the cleaved DNA does not result in HsdR degradation , suggesting a different post - cleavage conformational state that is not recognized by ClpXP . The rate of linear DNA cleavage under the PD buffer conditions was actually slower than the rate of circular DNA cleavage . Therefore , the time it takes to cleave the DNA does not appear to be directly relevant to whether or not ClpXP can interact with HsdR. Instead it is more likely that the important factor is the total time in the translocation state ( rather than dissociated or cleaved states ) , which is elevated on circular DNA ( 53 ) .	17245828	no
The global distribution of bats at each of the two time periods was then determined by combining the relevant vegetation map with two types of species - specific data available for all known bats : extents of occurrence and habitat requirements ( IUCN , 2020 ) . Extents of occurrence represent the outermost geographic limits of a species ' observed or projected occurrence ( Gaston and Fuller , 2009 ) ; these spatial envelopes do not account for the distribution of vegetation within that area and therefore generally extend substantially beyond a species ' actual distribution ( Gaston , 2013 ) . Habitat requirements include one or more vegetation categories in which a species can occur . Extents of occurrence were rasterised from their spatial polygon format to a 0.5 Â° grid , and subsequently refined by retaining only those grid cells where the previously estimated natural vegetation type , at the relevant time , was included in the species ' list of habitat requirements . In this way , the geographical range of each individual bat species was estimated for the early 20th century and for the present . Finally , the total bat species richness in each grid cell was obtained as the number of species whose estimated geographic range included the grid cell at the relevant time period .	231713620	no
The low temperature data presented in support of this expectation were taken from Monte Carlo simulations on a particular system , namely a ( 2 + 1)-dimensional Z 4 gauge model , which is the simplest exhibiting more than just the fundamental string .	17987625	maybe
How exactly is the evidence from the studies of cancer in experimental animals supposed to help establish the appropriate correlation in humans ? The proposal here is that the established correlation between benzo[a]pyrene and cancer in experimental animals may be carried over to humans by means of extrapolation . An influential suggestion is the mechanism - based approach to extrapolation : ' the mechanisms approach to extrapolation suggests that knowledge of mechanisms and factors capable of interfering with them can provide a basis for extrapolation ' ( Steel 2008 , p. 85 ) . According to this approach , a claim about an experimental animal model may be extrapolated to humans only if there is some knowledge that the mechanisms which support the causal relation of interest in the animal models are sufficiently similar to those in humans , where the mechanisms are sufficiently similar only if there are no differences in the mechanisms that would result in a difference in the outcome of interest produced by the mechanisms . Notice that this means that the requirements for mechanistic similarity are more stringent the more specific the outcome that is being extrapolated ( Steel 2008 , pp . 93 , 94 ) . In other words , extrapolating a precise quantitative claim about the extent to which an exposure increases the risk of cancer requires closer mechanistic similarity than extrapolating the qualitative claim that the exposure is a cancer hazard . Leuridan and Weber ( 2011 , p. 97 ) claim that ' it is clear that the IARC procedures do take into account the role that information about mechanisms can play in extrapolating results from animal experiments to humans ' . Indeed , this claim seems to be supported by the explanation of the role of mechanistic data that is provided by IARC :	46965433	no
"This initial coding produced several major themes , one of which was the "" link between disciplines and sense of personal responsibility "" theme discussed in this article . The first - order concepts pertaining to that theme were then re - analyzed as a separate body of data , producing secondorder themes , which were then abstracted into three aggregate dimensions that describe the research phenomenon ( cf . Gioia et al . 2013 ) , here the implications of students ' rationalizations about disciplinary specializations for their sense of personal responsibility . These three dimensions are : ( i ) mental models , that is , students ' cognitive representations of disciplines ; ( ii ) disciplinary culture , expressed as in - and out - group - based prototypes and responsibility attributions ; and ( iii ) moral autonomy , expressing a belief in individual moral sovereignty and simultaneously others ' ( but not one 's own ) moral fallibility . Given that the coding process can be intuitive and hard to explain ( Schreier 2012 ) , a model is provided in Fig . 1 following Gioia et al . ( 2013 ) , offering a "" chain of evidence "" showing how these three themes were derived from the data ( Brinkmann 2013 , p. 113;Elo et al . 2014 ) ."	254386200	no
The simulation data presented in this study clarify that the relative permeabilities of SV channels / TPC1s calculated with the GHK equation are not very informative and do not say anything about the real permeability through these channels . Instead , they can be largely misleading by implying a high Ca 2 + conductance from a relative permeability ratio of P Ca :P K â 5:1 . Under physiological conditions with~100 mM K + in the cytosol , 10 - 200 mM in the vacuole , submicromolar concentrations of Ca 2 + in the cytosol and up to 1 mM in the vacuole , however , Ca 2 + can not be released by SV channels from the vacuole in significant amounts [ 45 ] . Our combined simulation data now provide further insights that can explain the apparent contradictions in the literature .	238743505	no
The performance of the reviewers can also lead to variation in reported adverse event rates . Selection and training of reviewers was standardised within budget and logistic constraints . The country leaders were trained by the international faculty who also oversaw some of the data collection in most countries . The country leaders would then train reviewers in the individual countries with standardised manuals and data collection tools . The time for training was about four days for the country leaders and in most countries at least two days for the reviewers , who then had further supervision from the country leaders during the record review period .	2416506	no
Compared to a linear fit of the recorded data , the SOC precision shows a median deviation of 0.024 % with a standard deviation of 0.43 % . Furthermore , comparing both the OCV and the IR methods , we found the median difference of the SOC E estimates to be around 1 % with a standard deviation of 1.88 % ( see Figure 6b ; and Figure S9 , Supporting Information ) . Thus , it can be concluded that in situ IR spectroscopy is a precise and accurate tool comparable to OCV cells to monitor the SOC E of a RFB .	236259860	no
We defined serious infections as admission to hospital for 24 or more hours with one of the following infections : pneumonia ( infiltrate noted on chest radiograph ) , sepsis ( bacterial pathogen isolated from blood culture ) , viral or bacterial meningitis ( pleocytosis in cerebrospinal fluid and identification of bacteria or viruses ) , pyelonephritis ( â¥10 5 /ml pathogens of a single species , white blood cells in urine , and an increase in serum C reactive protein levels ) , cellulitis ( acute , suppurative inflammation of the subcutaneous tissues ) , osteomyelitis ( bacterial pathogen identified from bone aspirate ) , and bacterial gastroenteritis ( bacterial pathogens in stool ) . A consensus panel blinded to the results of the index tests adjudicated outcomes on the basis of information collected from 10 regional hospitals and follow - up information provided by the clinicians . Definitions of the terms used in this study and the methodology for recruitment and data collection are published elsewhere . 15 A simple observational analysis was undertaken to characterise the diagnostic value of gut feeling . In case of an empty cell in a 2Ã2 table , we applied a correction by adding 0.5 to each cell . We carried out a multivariable logistic regression analysis using backwards selection at a significance level of 0.05 to explore the clinical features associated with gut feeling in the subset of children for whom the clinician did not have a clinical impression of serious illness . Supplementary table 2 lists the clinical features used to build the regression models . We restricted the first regression model to features that are not part of the formal clinical examination , such as a change in crying or concern of the parents . A second model was then built using all variables , including those elicited from clinical examination , such as meningeal irritation . We compared both models using the Akaike information criterion . 16 This criterion balances both the goodness of fit and the number of variables used by imposing a penalty for an increasing number of variables . We selected as the optimum model that with the lowest Akaike information criterion value . Linearity of continuous features was checked with the lincheck module . All analyses were done with Stata v.11 .	5916840	no
Our HM-3 - Fc fusion protein was designed for extension of in vivo half - life of HM-3 . The fusion protein was created by fusing the Fc - domain of modified human IgG4 and HM-3 with a 15 - amino - acid GS as a linker . HM-3 - Fc significantly prolonged the half - life of HM-3 without losing HM-3 bio - activity . In order to evaluate the anti - RA activity of HM-3 - Fc in vivo , we used a CIA model mice and we found that subcutaneous injections of 25 mg / kg HM-3 - Fc once every 7 days showed the same anti - RA activity as administration of the same dose once every 5 days and the key indicators were better than the positive control drug Adalimumab ( Figure 7 , Supplementary Figure S6 , Table 1 , Supplementary   Table S1 ) . If the frequency of administration was systematically optimized and increased to 7 days , the half - life in the human body may be further extended to 15 days . Meanwhile pharmacokinetic studies in plasma of cynomolgus showed that after a single dose treatment , the HM-3 - Fc group exhibited a dramatically longer half - life , higher Cmax and larger AUC0â240 h than the HM-3 group . The half - life of HM-3 - Fc in cynomolgus was extended to 15 h , which was almost 700 times than that of HM-3 polypeptides . According to the experimental data , we supposed the frequency of HM-3 - Fc administration could be extended to once every 15 days . Compared with HM-3 that need an administration of twice daily , HM-3 - Fc can significantly improve life quality and compliance of RA patients .	52184973	no
During the 13 - month monitoring period , SARS - CoV-2 RNA was detected in nearly all samples , and recovery - adjusted concentrations ranged from a minimum of 4.3 log 10 gc / L for Facility 1 at the onset of the pandemic to a maximum of 8.7 log 10 gc / L for Facility 7 during the winter 2020/2021 surge ( Table S2 ) . Fig . 2 summarizes the site - specific average BCoV recoveries and also illustrates the relationship between wastewater SARS - CoV-2 concentrations and confirmed COVID-19 case data reported at the zip code level by the Southern Nevada Health District . With the exception of   . The shedding trajectory was then revised for the current study ( upper dashed line ) based on the seroprevalence calibration approach . The solid black line illustrates an alternative constant - shedding assumption that achieves the same total viral load over the infection period . After integrating the fecal shedding curves over the duration of an infection ( assumed to be 25 days ) , the models resulted in total SARS - CoV-2 loads of 1.21 Ã 10 11 gc / infection ( original assumption ) or 2.42 Ã 10 11 gc / infection ( final assumption ) .	248325387	no
Anion and cation concentrations are summarised in Tables 2 and 3 , respectively . Generally , Pond 2 had higher concentrations of anions in comparison to the other ponds , whereas Pond 16 had higher concentrations of cations . Sources of nitrogen ( e.g. ammonium and nitrate ) were either undetectable or low ( < 1 Î¼mol / l ) in Ponds 1 and 9 indicating they may be severely nutrient limited , which will impact microbial growth . No anion or cation concentration exceeded the maximum permissible concentration Table 2 Anion concentrations ( Î¼mol / l ; means Â± SE ; n = 3 ) of water collected from ponds used by Kenyan rural smallholder farmers . Values of concentration that share the same letter ( a , b , c ) are not significantly different between ponds ( P < 0.05 ; Kruskal - Wallis test ) . * indicates concentration below the limit of detection . Anions include :   ( Ayers and Westcot , 1994 ) . All ponds exceeded the MPC for chloride ( 0.28 Î¼mol / l ) , based on local guidelines ( National Environment Management Authority , 2006 ) for irrigation water quality . However , this value is much lower than the internationally accepted standard ( 9872.23 Î¼mol / l ) , which no ponds exceed . A Shapiro - Wilk test determined that the chemical data was not normally distributed . With the exception of ammonium , formate and lithium ( lithium concentrations below the limit of detection ) there were significant differences in ion concentration between ponds ( Kruskal - Wallis test , P < 0.05 ) . However , no significant differences between ponds were detected for acetate and phosphate after a post - hoc Dunn 's test with Bonferroni adjustment for multiple comparisons . Pond 2 had the highest concentration of chloride ( 600.35 Â± 35.99 Î¼mol / l ) , nitrate ( 422.59 Â± 24.94 Î¼mol / l ) , sodium ( 1678.17 Â± 85.04 Î¼mol / l ) and sulphate ( 86.49 Â± 3.48 Î¼mol / l ) . Nitrate concentration had the most variability ( coefficient of variation = 385 % ) driven by the higher concentrations found in Pond 2 , which was at least 111 - fold greater than any other pond . Pond 8 had the highest concentration of carbonate ( 429.57 Â± 3.95 Î¼mol / l ) . Pond 16 had the highest concentration of calcium ( 834.40 Â± 30.00 Î¼mol / l ) , fluoride ( 60.33 Â± 6.84 Î¼mol / l ) , magnesium ( 218.82 Â± 4.79 Î¼mol / l ) and potassium ( 331.28 Â± 6.20 Î¼mol / l ) . Manganese concentration was very low ( < 1.13 Î¼mol / l ) and was only detected in ponds 1 , 10 , 11 . Lithium was not detected in any of the ponds tested .	245874241	maybe
While apparently very natural , we do not think that the latter step is legitimate . This is because several ordinary folk appraisals allegedly supporting a normative connection between knowledge and action can be straightforwardly explained by principles such as KAP , but can not receive any adequate explanation in terms of a KBDT . On the contrary , the latter theory seems to deliver the wrong verdicts about such cases . In what follows , we will focus in particular on three sets of intuitive data discussed in the contemporary literature : lotteries , negligence and blame , and attributions of responsibility and culpability . 36	232292483	no
[ I]n science , we rarely just happen across useful data . Typically , we must actively search for data , in the many areas of science that rely on experimentation even produce our data . Because our time is limited , as is our funding , we constantly have to make decisions as to which instruments ( telescopes , microscopes , etc . ) to construct , which expeditions to undertake , which experiments to run , and so on . Such decisions will be informed by which hypotheses we deem most promising . Had we deemed hypothesis H promising , and had we wanted to compare that with the hypothesis currently dominant in our field , we might have run a different set of experiments than we actually did , given that in fact we deemed H more promising than H and were mainly interested in comparing H with the received doctrine . Which hypothesis or hypotheses we deem most promising , and most worthy of spending our limited resources on , will at least in part depend on how probable they appear to us , compared to their most direct rivals . If ( say ) a Bayesian update makes H more probable than H , while the opposite will be the case if we update via some non - Bayesian update rule , then our decision to use one of these rules may put us on a very different research path with very different downstream consequences than if we had decided to use the other rule . Which of these paths will eventually lead us to have the more accurate representation of the world will have nothing to do with which of the rules minimizes expected inaccuracy of the piece of evidence now lying before us . ( Douven 2021 , p. 107 ) Douven is right , of course . What credences our update rule bestows on us will determine not just how we 'll choose when faced with practical decisions , such as whether or not to publicly announce a new medical treatment , but also how we 'll choose when faced with an intellectual decision , such as which experiment to run next , which hypothesis to pursue , and so on . So , even if we focus only on our purely epistemic goal of accuracy , we 'll want credences that lead us to choose how to gather evidence in a way that maximises the accuracy we obtain after we choose them , perform them , and update on the results . But of course we have a ready - made answer to that challenge . The expected pragmatic argument for Bayes ' Rule applies just as well when the options between which you 'll choose after updating are whether to pursue one hypothesis or another , or whether to conduct this experiment or that one , and when the utilities that attach to those hypotheses at the different possible worlds are given by the accuracy of the credence functions you 'll end up with if you do pursue that intellectual trajectory .	237364643	no
Controlling for covariates . By matching , we reduced the differences in covariates between treated and control groups , although we failed to remove them altogether ( Supplementary Fig . 1 ) . Following recommendations in ref . 51 , we regressed the outcomes not only on a treatment but also on the covariates that we matched on to further Negative binomial regression . Because the numbers of cases are nonnegative integers ( Supplementary Fig . 2 ) , some studies rely on negative binomial regression 21,22,41 . Therefore , we also applied negative binomial regression to our matched data 52 , using the log of the population size as an offset variable so that various sized municipalities are comparable . Unfortunately , the estimation procedures only converged for the treatment variables as of 6 , 10 and 16 April , and only if we did not include any covariates . The coefficient estimates of the treatment variables sometimes implied that school closures even significantly increased the number of cases , while they rarely ( significantly ) decreased the number of cases ( Extended Data Fig .   3 ) . The findings remain the same : there is no evidence that school closures reduce the number of COVID-19 cases .	240073269	no
In our previous works , we checked the cytotoxic effect of Tpc and the TDP1 inhibitors - monoterpene 3 - carene - derived compounds [ 48,49 ] and UA combined with monoterpenoids [ 49 ] , measured separately and jointly with Tpc - using a panel of HEK293FT and HEK293A Tdp1 knockout isogenic clones . We showed that Tdp1 knockout cells were more sensitive to Tpc compared to WT cells . The data on the HEK293FT mutants were of low reproducibility [ 48 ] , which is why we decided to change the basic cell line to HEK293A [ 49 ] . In this work , we created new PARP1-/-HEK293A cells using the CRISPR - Cas9 approach ( Figure S27 ) . The sensitivity of the PARP1-/-cell line to Tpc was lower than WT HEK293A cells ( CC50 50 Â± 5 nM and 27 Â± 4 nM respectively , Figure   S28 ) . We checked the intrinsic cytotoxicity of the leader compound ( 10a ) on the HEK293 wild type and TDP1-/-and PARP1-/-cell lines using a colorimetric test ( Figure 6 ) . The cytotoxicity of 10a was nearly the same for all the cell lines , with a CC50 of 15 - 20 Î¼M   Table 1 . DMSO , for the red curve on the cells treated with 1 ÂµM topotecan and 1 % DMSO , and for the blue curve on the cells treated with 2 ÂµM topotecan and 1 % DMSO , in order to exclude the effect of topotecan itself and see the effect of the drug combination . Right panel : cells treated with 1 % DMSO ( black line ) or 5 ÂµM 10a ( red line ) were taken as 100 % in order to evaluate the effect of the combination rather than the individual substance 10a .	239506328	no
To analyze factors of campaign creation , we used a negative binomial model to predict the number of campaigns created in each county , with an exposure offset to adjust for county population size . Negative binomial models were used because data was overdispersed for Poisson models . We predicted that campaign prevalence would be correlated with indices of both need and capabilities -that is , both the complex economic and health needs arising from the COVID-19 pandemic ; and the resources that give campaigners the capability to launch a campaign and expect it to be relatively successful . Independent variables included the number of confirmed coronavirus cases per capita in each for the last date in our dataset , July 31 , 2020 along with county level median income , population , race and education estimates .	235472679	no
These data prompted us to examine the specificity of the anti - immunoadhesin responses . As shown in Fig . 5b , antibodies from each animal had a distinct specificity . Serum from 05C004 ( 5L7 recipient ) reacted with purified 5L7 and 4L6 , but not N4 , suggesting that these antibodies were raised against the framework sequence in the scFv domain of 5L7 and 4L6 . Serum from 05C053 ( 5L7 recipient ) reacted with all three immunoadhesins , suggesting that these antibodies were raised against the Fc fragment that each chimeric protein had in common . Finally , serum from 05D043 ( N4 recipient ) reacted only with N4 , demonstrating specificity for the CD4 moiety that was unique to N4 .	15266579	no
If cyanogen is really an abundant species in interstellar clouds , it is conceivable that larger members of the series of dicyanopolyynes are present as well . The next member is dicyanoacetylene ( NC 4 N ) , which , as NCCN , is non polar and thus indirect strategies to probe it are necessary . Dicyanoacetylene can be efficiently formed through the reactions CN + HC 3 N or C 3 N + HCN / HNC , which are barrierless according to calculations by Petrie et al . ( 2004 ) . An astronomical search for the protonated form of NC 4 N is not yet feasible as there is little spectroscopic information on this ion . However , the metastable isomer NC 3 NC , which lies 1.12 eV above NC 4 N has a moderate calculated dipole moment of 1.04 - 1.096 D ( Horn et al . 1994;Lee 1998 ) , and its rotational spectrum has been measured in the laboratory ( Huckauf et al . 1999 ) . It is not present in our Î» 3 mm data of L483 and TMC-1 , although this is probably not the best wavelength range to search for such a heavy molecule in cold sources . A search at longer wavelengths may probe more fruitful . There are other two metastable isomers , but one ( CNC 2 NC ) is non polar while for the other ( NCNC 3 ) , which lies 2.60 eV above NC 4 N ( Jiang et al . 2004 ) , spectroscopic data is lacking .	52160607	no
Taken together , our data show that Rad9 interacts with Aft1 transcription factor and that Aft1 is quantitatively required for Rad9 recruitment to promoter and coding regions of specific Aft1 - regulated gene targets .	2292338	no
In this study , the spatial - temporal patterns of Sentinel-5P TROPOMIderived air pollutants , namely , NO 2 and SO 2 , and MODIS - derived AOD are monitored and investigated between January 2019 and September 2020 including first wave lockdown period of COVID-19 outbreak over Turkey . The GEE platform is used for the retrieval and processing of satellite imagery , and data analysis .	238664729	no
In this network visualization , nodes are unique game vectors that have been realized by a published game . Two nodes are connected by an edge if the Hamming distance of the two vectors is equal to one . Our measures of innovation can be interpreted using the network : a game type is distinct if its vector of mechanism 's node is far from the center of the network , away from the other nodes . A game type is novel if it introduces a new node to the network -and moreso if that node is disconnected from the other nodes . Finally , a game type is resonant if subsequently published games are close to it in the network . In this framework , games that implement a new type and are then frequently imitated are the major innovation success stories . We plot the evolution of the overall board game industry in this network landscape of types in Figure 2 . To draw the network we use a physics - inspired force layout algorithm [ 29 ] . The algorithm simulates the network as a physical system : nodes repel one another as though they were charged particles , while edges act as springs pulling connected nodes together . We run this layout algorithm for the data at the end of 2017 , fixing the nodes in previous years to their position . To improve visibility we also filter for game vectors implemented by more than five games in our entire database , and do not plot nodes disconnected from the main component of the network in 2017 . Within each snapshot , nodes are larger if there are more games with that vector published by that time . We highlight those nodes for which crowdfunding is particularly common in red . Nodes are colored orange if they were crowdfunding hotspots in previous snapshots , but now tend to be implemented by traditionally funded games .	230799516	no
The change of synoptic map sources may lead to some differences in the PFSS results . We also calculate the results with the filled version of WSO maps , in which the missing data are filled by interpolation from adjacent CRs . Figures from the WSO results showing the same information as that of Figures 2 and 3 are presented in the support material . It can be seen that although the WSO results tend to give larger fraction of coronal hole area in the mid - latitude , the main findings from the GONG results , including the evolution of coronal hole distributions , the dominance of low / mid / high latitude coronal holes in footpoints of the near - ecliptic field lines , and the evolution of the HCS structures , are still valid . Figure 4 presents the time series of the daily mean solar wind speed and the wavelet power spectrum of the solar wind speed . During minimum 22/23 , the solar wind exhibits periodicity of solar rotation ( 27 days ) at the very beginning and the second half of the study interval . During minimum 23/24 , relatively structured fast solar wind streams persist through 2008 , with most of their maximum speed above 600 km / s. Periodicities at both solar rotation ( 27 days ) and its subharmonic periods ( 13.5 , 9 days ) are observed for continuously long patches with high spectral intensities . The periodicity at solar rotation indicates that the fast streams recur in each rotation , implying that the low - latitude coronal holes generating these streams persist for many rotations in this interval . The subharmonic periods implying two or three major low - latitude coronal hole regions are longitudinally separated , resulting in a pattern of two - three peaks in the speed profiles ( Luhmann et al . 2009;Tulasi Ram et al . 2010;Li & Feng 2018 ) . In 2009 , the solar wind speed starts to decay and the strong periodicities disappear . This change may be explained by what can be observed from Figure 2 ( b ) and ( e ) . The distributions of the low - and mid - latitude coronal holes are fickle in 2009 , and the low - latitude coronal holes gradually diminish . For the recent solar minimum 24/25 , strong fast solar wind streams with maximum speed higher than 600 km / s are observed between yr 2019.5 and 2019.9 , when the band of isolated low - latitude coronal hole in Figure 2 ( c ) is seen . Significant periodicity at solar rotation is continuously observable during the occurrence of the fast streams , being similar to what has been seen in 2008 . However , the subharmonic solar rotational periodicity is not evident , implying there may be only one major fast stream in each rotation . Between 2020.0 and 2020.5 , as the solar corona evolves into the dipolar state , the slow solar wind becomes dominant , and no periodicity pattern can be seen in the wavelet spectrum . A similar situation can be found in minimum 22/23 around the mid of 1996 . In the second half of 2020 , the fast streams are observed again , with apparent one - rotation periodicity and observable half - rotation periodicity , indicating that a two - peak structure recurs in each rotation . Figure 5 compares the distributions and averages of solar wind parameters in the three minima . The shapes of the distributions of speed for minima 22 and 24 look similar , but the occurrence of high - speed solar wind above 500 km / s in minimum 24/25 is the lowest among the three minima . The distribution of minimum 23/24 is characterized by the high - speed tail above 600 km / s , but such high - speed tail is absent in minima 22/23 and 24/25 . As can be seen in Figure 4 ( a ) , ( c ) and ( e ) , the 27 - day average speed represented by the green line fluctuates around 400 km / s in minima 22/23 and 24/25 . In contrast , it decreases gradually from about 500 km / s to about 350 km / s in minimum 23/24 , following the decaying of the low - latitude coronal hole seen in Figure 2(e ) . The average solar wind speed of minimum 24/25 is lower than that of the two previous minima , and even lower than that of minima 20/21 and 21/22 ( Jian et al . 2011 ) . The average IMF strength during minimum 24/25 is weaker than that of minimum 22/23 , but stronger than that of minimum 23/24 . The strengthen of IMF from minimum 23/24 to 24/25 ends the trend of IMF weakening from minimum 21/22 to 23/24 ( Jian et al . 2011 ) , and may also be in connection with the increase of the solar polar field . The distribution of mass flux density and number density of minimum 24/25 have occurrence of large value higher than that of minimum 23/24 , and the occurrence of small value higher than that of minimum 22/23 . The average number density and mass flux density of minimum 24/25 lie between those of minima 22/23 and 23/24 .	235795106	no
A good mobile - app - driven business method focuses on a more creative and competitive strategic business ideology that can support and direct SME businesses in an innovative , profitable , and sustainable manner ( Gomeseria , 2019 ) . Users ' intention to use mobile apps for market purposes is affected by their understanding of data control and information ( Libaque - SÃ¡enz , Wong , Chang , & Bravo , 2020 ) . ( Price et al . , 2020 ) assess the viability and efficacy of a new , constructive - theoretical mobile app designed to encourage self - control and healthy eating . Two pilot programs were launched to test the smartphone - app - aided RANAS solution 's potential to change recycling behavior ( Shan , Ang , & Yang , 2020 ) . Because of the advancement of emerging technology ( Islam , 2017;McGuire & Islam , 2015 ) , mobile applications in SME businesses could strengthen these systems . After evaluating things such as timely , economical , faster , and global reach , they discovered that these metrics are positively associated with mobile app use and affect SMEs ' sustainability performance . Accordingly , we proposed the following hypothesis :	237669349	no
Prior review papers on the LCA of lithium - ion batteries ( LIBs ) can be categorized into three main groups dependent on their goals : identifying and reducing sources or uncertainty/ variability ; [ 7][8][9 ] synthesizing results and determining key drivers to inform further research ; [ 10,11 ] and critical review of literature to improve LCA practices . [ 12 ] Sullivan and Gaines [ 9 ] reviewed life - cycle inventory estimates for lead - acid , nickel - cadmium , nickel - metal hydride , sodium - sulfur , and Li - ion batteries and calculated their own estimates for comparison ; the conclusions focused on the need to fill key data gaps . Ellingsen et al . [ 7 ] Rechargeable batteries are necessary for the decarbonization of the energy systems , but life - cycle environmental impact assessments have not achieved consensus on the environmental impacts of producing these batteries . Nonetheless , life cycle assessment ( LCA ) is a powerful tool to inform the development of better - performing batteries with reduced environmental burden . This review explores common practices in lithium - ion battery LCAs and makes recommendations for how future studies can be more interpretable , representative , and impactful . First , LCAs should focus analyses of resource depletion on long - term trends toward more energy and resourceintensive material extraction and processing rather than treating known reserves as a fixed quantity being depleted . Second , future studies should account for extraction and processing operations that deviate from industry best - practices and may be responsible for an outsized share of sectorwide impacts , such as artisanal cobalt mining . Third , LCAs should explore at least 2 - 3 battery manufacturing facility scales to capture size - and throughput - dependent impacts such as dry room conditioning and solvent recovery . Finally , future LCAs must transition away from kg of battery mass as a functional unit and instead make use of kWh of storage capacity and kWh of lifetime energy throughput .	237792009	no
SO 2 is one of the tropospheric trace gases that is mostly produced by volcanoes and industrial activities . Due to the presence of sulfur compounds in oil and coal , their combustion leads to the production of SO 2 . We analyzed the spatio - temporal variations of the monthly average SO 2 column density over Turkey as in Fig . 5 . No - data pixels are available from January to April in both 2019 and 2020 data sets . The main reasons are cloud fraction condition , the algorithm limitations for producing the data and quality assurance contrast . Due to noise on the SO 2 values , negative vertical column concentrations are perceived as low SO 2 emissions . According to the Sentinel-5P product readme file ( https://se ntinel.esa.int/web/sentinel/technical-guides/sentinel-5p/products-al gorithms ) , it is recommended to filter outliers as concentration values lower than â 0.001 mol / m 2 .	238664729	no
The associations of NO 2 with daily total , cardiovascular , and respiratory mortality were assessed using the same analytical protocol in all locations , based on extension of a two stage design widely used in previous multilocation time series studies . 13 14 In the first stage , we estimated the city specific associations using a time series quasiPoisson generalised linear regression model featuring a natural cubic spline function of time with seven degrees of freedom ( df ) per year to control for unmeasured temporal trends and indicators for day of the week . Temperature was adjusted using a natural spline function with 6 df . Relative humidity was adjusted with the same spline function with 3 df in cities where such data were available . For the potential lag effect of NO 2 and temperature , we a priori selected the moving average of lag 03 days to control temperature according to modelling choices of many previous studies . 14 15 We modelled the association between NO 2 and mortality using a distributed lag model with a linear lag response function , inspecting the lag structure on a single lag day of 0 to 3 , and moving average of the present and previous day ( lag 01 ) to identify the optimal lag choices .	232341383	no
The OSCAR server and web application is an open system for cluster analysis of microarray data , with an automated procedure to incorporate and manage all clustering algorithms . It provides a comprehensive and friendly environment to both users and algorithm developers . A database system is developed to manage all the algorithms , including their documentation , their parameters , each parameter 's description , type , bounds and default value . When a user accesses the OSCAR website , the server will automatically list all the algorithms currently available , together with a URL to the documentation for each of the algorithms listed . When a user chooses a particular algorithm , all information about the parameters and input files of the algorithm is retrieved from the algorithm database and automatically displayed to the user . Users can use the interactive web forms to adjust the parameters , upload input data and execute the computation on the server . Algorithm ' developers ' can use the interactive web forms to incorporate their own algorithms to OSCAR without revealing their source codes . The submitted algorithm will be managed by OSCAR 's database , sharing the same output format and be accessible to all users ( Supplementary Figure S1 ) .	52828088	yes
This example shows that even when we have not included twists or RR data that involve the blow - up modes of T 6 /(Z 2 Ã Z 2 ) , the blow - up moduli can nevertheless be stabilized due to the interplay of orbifold twisted sector and untwisted sector in the intersection form .	119468677	no
Besides being robust against adversarial noises , L2NNNs have other desirable properties . They generalize better from noisy training labels than ordinary networks : for example , when 75 % of MNIST training labels are randomized , an L2NNN still achieves 93.1 % accuracy on the test set , in contrast to 75.2 % from the best ordinary network . The problem of exploding gradients , which is common in training ordinary networks , is avoided because the gradient of any output with respect to any internal signal is bounded between -1 and 1 . Unlike ordinary networks , the confidence gap of an L2NNN classifier is a quantitatively meaningful indication of confidence on individual data points , and the average gap is an indication of generalization .	3695872	no
As one might expect , the data are noisy , so to improve the specificity of these results we combined data from all three microarray experiments . We tested to see if there was a statistically significant correlation ( P < 0.01 ) between Hamming distance and co - expression using Kendall 's tau , a rank - based measure of correlation . We find that out of a total of 33 motifs for which there is sufficient data available , 7 have statistically significant negative correlations in all three microarray experiments . In other words , for these motifs , similar k - mers have similar expression patterns and clusters of k - mers in the motif graph correlate with clusters of gene expression . The seven motifs are YDR026c , DAL82 , BAS1 , SPT23 , HAP4 , ADR1 and MBP1 . No motifs were foundto have statistically significant positive correlations in all three experiments . The most obvious example of clustering affecting gene expression is ADR1 ( Figure 1b ) , which has two unconnected clusters .	11811651	no
While running the queries in March 2020 , we filtered the results to include only documents published on the platforms in the period 2015 - 2020 ( in the case of Google Scholar , the documents outside the range were filtered out automatically , whereas in the case of other platforms they were filtered out manually ) . For the majority of platforms , all retrieved documents were used with the exception of Google Scholar for which a particularly large number of documents were retrieved ( see Table   1 ) . To keep the analysis feasible , we added an additional limitation to the data collection for Google Scholar and examined the first 100 results suggested by the platform to be most relevant for the respective queries .	239186570	maybe
Projects aimed at large - scale screening for genetic interactions have identified several sources of experimental error , which led to the development of analysis methods that are tailored to the resulting large data sets . For example , we have successfully applied Synthetic Genetic Array ( SGA ) ( 14 ) analysis to ascertain the effects of $ 5 million double gene deletions in yeast ( 1 ) . A number of the best practices emerging from analysis of these data can not be implemented directly for smaller screens , as they rely on a large assembly of controls and estimating biases from hundreds of different experiments to correct for systematic experimental errors . Moreover , other available methods are shared as code only ( 15)(16)(17 ) , which may rely on obtaining expensive software licenses , a somewhat steep learning curve to compile and use the published code , or do not include all the analysis steps in a single web - based interface , making them less accessible . Consequently , laboratories that are interested in performing and analyzing a relatively small number of customized screens , such as those designed for detailed analysis of specific pathways , are lacking user - friendly data analysis solutions . Here , we present SGAtools , a simple complete solution for analyzing static image - based screens of ordered arrays of microbial cultures . SGAtools is an easy - to - use website that implements state - of - the - art normalization and quantification methods and includes some basic tools useful for visualizing the data .	9520440	no
"The hospital morbidity data system contained information on encrypted patient identification and episode number ; age , sex , indigenous status , and postcode ; date of admission and date of separation ( that is , transfer , discharge , or inpatient death ) ; international classification of diseases ( ICD ) codes for the main diagnosis and up to 19 additional diagnoses for up to four external causes ( E codes ) , and for the main procedure and up to 10 additional procedures ; type of hospital attended ( public , private , other ) , admission type ( emergency or elective ) , and payment classification . We used ICD-9 for 1980 - 7 , 18 ICD-9 - CM for 1988 - June 1999 , 19 and ICD-10 - AM from July 1999 onwards . 20 Data from the death records included encrypted patient identification , age , sex , indigenous status , primary cause of death , date of death , and postcode . We extracted linked hospital and death records for all patients aged â¥60 with an admission for ADR in 1980 - 2003 in Western Australia . In an assessment of the technical performance of the linkage system in finding true matches between records , both the proportion of invalid links ( false positives ) and of missed links ( false negatives ) was estimated to be 0.11 % . 17 Definition of ADR and identification of patients We included all ADRs that resulted in hospital admission or that occurred while patients were in hospital and extended the length of hospital stay . An ADR event was defined as any hospital separation with an ICD E code indicating that either the admission or extended hospital stay was because of the adverse effects of drugs , medicines , and biological substances in therapeutic use : E930 - E949 ( ICD-9 and ICD-9 - CM ) or Y40 - Y59 ( ICD-10 - AM ) . The codes included any adverse effect caused by correct use of drugs , medicines , or biological substances properly administered in therapeutic or prophylactic doses , excluding errors in the technique of administration of drugs , intentional and unintentional overdose , and abuse of a drug . Thus , our definition of ADRs was consistent with the more recent and clearer version : "" An appreciably harmful or unpleasant reaction , resulting from an intervention related to the use of a medicinal product , which predicts hazard from future administration and warrants prevention or specific treatment , or alteration of the dosage regimen , or withdrawal of the product . "" 21 ADR = adverse drug reaction ; ICD = International Classification of Diseases ; ENT = ear , nose , throat . * Excludes antineoplastic antibiotics ( E930.7 ) from ICD-9 / ICD-9 - CM ( were added to primarily systemic agents , which include antineoplastics ) . â Excludes benzodiazepines ( E939.4 ) from ICD-9 / ICD-9 - CM ( were added to group sedatives , hypnotics , antianxiety drugs , which includes benzodiazepines in ICD-10 ) . â¡Excludes sympatholytics ( E941.3 ) from ICD-9 / ICD-9 - CM ( were added to agents primarily affecting cardiovascular system , which include these in ICD-10 ) . Â§ Excludes theophylline ( E944.1 ) from ICD-9 / ICD-9 - CM ( was added to agents affecting muscles / respiratory system , which includes antiasthmatics ) ."	7801013	maybe
"The latent variable "" business expectations "" includes three indicators from the "" Business Tendency and Consumer Opinion Surveys "" carried out by the OECD . The chosen items that cover the opinion of the economic sectors are manufacturing , construction , and services . This survey asks entrepreneurs : "" How do you expect your business activity ( sales ) to change over the next 3 months ? "" The data from this survey are published monthly . In our analysis , we calculate the average of the last three months available ( August , September , and October ) , and these months also coincide with the second outbreak of the COVID pandemic ."	238220795	maybe
One exception to the generally good afterglow fits is the most recent 3 GHz non - detection by VLASS , which requires a â¼ 50 % drop in flux over a baseline of just two years from the prior detection . Such a rapid change is challenging to explain in afterglow models ; even large discontinuities in the ISM density produce at most order - unity changes in flux ( Mimica & Giannios 2011 ) , but only over timescales comparable to the source age , which in this case is 23 years . Alternatively , this flux drop may be a sign of scintillation - induced fluctuation . Reanalysis of VLASS data or new observations are needed to confirm the flux drop .	119092270	no
XRD patterns were taken using an X'Pert - Pro MPD diffractometer ( Netherlands PANalytical ) with a Cu KÎ± X - ray source ( Î» = 1.540598 Ã ) . TEM images and TEM - EDS mapping were taken with an FEI Tecnai G2 F20 S - TWIN TMP microscope ( 200 kV ) . SEM image and SEM - EDS mapping were taken with a Zeiss scanning electron microscope ( Zeiss Supra55 ) . We note that three different regions with a size of~5 Î¼m Ã 5 Î¼m for the samples were used for the EDS measurement ; the O / F ratio was obtained by averaging these data , and determined to be ( 12.3 Â± 2.0)% . XPS was performed on a Rigaku XPS-7000 spectrometer . The carbon peak at 284.6 eV was used as a reference to correct the charging effect .	53721407	no
Many farmland birds have a high proportion of agricultural seeds and plant material in their diet ( Holland et al . , 2006 ) , and so have potential for exposure to NNs applied as seed treatments through ingestion of either treated seed or seedlings ( Mineau and Palmer , 2013 ) . The presence of pesticide active substances on potential food items highlights the need for quantitative risk assessment as part of the authorisation process , but the complexity of undertaking this assessment where direct and substantive exposure can be expected is widely acknowledged . The risk from dietary exposure is assessed within regulatory procedures by combining information on toxicity of the respective compound and estimates for levels of exposure that wild birds may be subject to via seed treatments ( European Food Safety Authority , 2010 ) . Lower tiers of assessment will normally indicate potential risk for seed treatments , so ' higher tier ' assessment , such as the use of radio - tracking data and focal species dietary data , is required to estimate the level of exposure in farmland bird species more accurately ( European Food Safety Authority , 2006 ) . Product application instructions also play an important part in safeguarding wildlife from pesticide use . With regards to NN seed treatments specifically , product labels state that seeds should be buried at a minimum depth of 4 cm , and that no seed should be left on the soil surface after drilling ( Bayer Crop Science UK , 2019 ) . Nevertheless , it is recognised that absolute compliance with this requirement is impossible to achieve ( European Food Safety Authority , 2010 ) . The availability of seed on the soil surface is known to be a function of crop type , season of sowing , soil condition , sowing equipment , and location within the field ; for example , in the Netherlands , average surface seed densities were greatest for winter wheat with standard sowing equipment ( 20 and 31 seeds / m 2 measured in successive seasons ) and on average there was 3.5 times more seed present on the soil surface at the headlands compared to the field centre ( de Snoo and Luttik , 2004 ) .	214731247	no
The increasing use of electronic medical records ( EMR ) , driven mainly by efforts to improve the quality of patient care , have also launched a discipline of research using EMR data . In the past decade , methods and tools specifically used to conduct EMR research have allowed for sophisticated analyses including pharmacovigilance , 1 genetic association , 2 and pharmacogenetic studies . 3 Phenotype algorithms using EMR data to classify patients with specific diseases and outcomes is a foundation of EMR research . Diagnoses or billing codes are typically used in these algorithms , and are examples of structured EMR data . These data are readily available and searchable ( fig 1 ) , but vary in accuracy . Recent work has focused on incorporating other informative EMR data to develop robust phenotype algorithms . Beyond billing and diagnoses codes , advanced EMRs contain a variety of structured data such as electronic prescriptions and laboratory values . A substantial portion of clinical data is also embedded in unstructured data in the form of narrative text notes , either typed or dictated by physicians ( fig 1 ) . Extracting accurate infor - mation from narrative notes is a well known challenge to clinical researchers and is typically obtained through laborious medical record review . Natural language processing ( NLP ) , 4 a specialty of computer science and informatics , has greatly helped researchers extract clinical data from narrative notes in a high throughput manner . While cutting edge NLP technologies have been successfully applied to internet search engines and automatic speech recognition , they are only now being adapted with new methods for biomedical research .	2590062	no
To investigate spatial diffusion of psychiatric hospitals in France from the 19th century to the present day , the initial task involved building an original historical database of psychiatric hospitals , their location and date of establishment , indicating the points at which , in different parts of France , asylum facilities were first adopted as innovative care institutions for the mentally ill . This was achieved using a number of different data sources . These data were then analysed and interpreted in the light of the conceptual frameworks and the historical context discussed above .	12739152	maybe
The values of the fit parameters and the results for r 0 , f K and f K /f Ï are collected in Tables 3 and 4 , respectively . The extrapolation to the physical up / down quark mass and the interpolation to the physical strange mass has been performed by inserting in eqs . ( 5 ) and ( 6 )   K are the experimental pion and kaon masses . In both Tables , we show the results of our fits when we take the data at Î² = 3.8 into account and when we leave them out . As can be seen , the values of the fit parameters , as well as those of the decay constants , are found to be well consistent in the two cases . In the following , therefore , we will consider for f K and f K /f Ï only the predictions obtained by including the Î² = 3.8 data . From the results given in Tables 3 and 4 , one can also derive our prediction for the pion decay constant in the chiral limit , f , and the LECl 4 = b/2 + 2 ln(4Ïf /m Ï + ) . We obtain the values f = 121.7(1)MeV andl 4 = 4.66 ( 6 ) , which are in good agreement with the results of the scaling analysis performed by our Collaboration in [ 10 ] , f = 121.66(7)(26)MeV and l 4 = 4.59(4 ) ( 13 ) . The quality of the fit for the combined chiral and continuum extrapolation of the pion and kaon decay constant is illustrated in fig . 2 .	2547827	maybe
Natural image patches We tested the scalability of the DDC - HM by applying it to a natural image data set ( van Hateren and van der Schaaf , 1998 ) . We trained the same generative model as before on image patches with dimensionality D x = 16 Ã 16 and varying sizes of latent layers . The recognition model had a hidden layer of size 500 , K 1 = 500 , K 2 = 100 encoding functions for z 1 and z 2 , respectively , and used 1000 samples during the sleep phase . We compared the performance of our model with the IWAE ( k=50 ) using the relative ( three sample ) MMD test ( Bounliphone et al . , 2015 ) with a exponentiated quadratic kernel ( width chosen by the median heuristic ) . The test establishes whether the MMD distance between distributions P x and P y is significantly smaller than the distance between P x and P z . We used the image data set as our reference distribution and the IWAE being closer to the data as null hypothesis . Table 1 summarises the results obtained on models with different latent dimensionality , all of them strongly preferring the DDC - HM . Sigmoid Belief Network trained on MNIST Finally , we have evaluated the capacity of our model to learn hierarchical generative models with discrete latent variables by training a sigmoid belief network ( SBN ) . We used the binarised MNIST dataset of 28x28 images of handwritten images ( Salakhutdinov and Murray , 2008 ) . The generative model had three layers of binary latent variables , with dimensionality of 200 in each layer . The recognition model had a sigmoidal hidden layer of size 300 and DDC representations of size 200 for each latent layer . As a comparison , we have also trained an SBN with the same architecture using the VIMCO algorithm ( as described in ( Mnih and Rezende , 2016 ) ) with 50 samples from the proposal distribution 2 . To quantify the fits , we have performed the relative MMD test using the test set ( N = 10000 ) as a reference distribution and two sets of samples of the same size generated from the SBN trained by the VIMCO and DDC HM algorithms . Again , we used an exponentiated quadratic kernel with width chosen by the median heuristic . The test strongly favored the DDC HM over VIMCO with p < 10 â20 ( with MMD values of 6 Ã 10 â4 and 2 Ã 10 â3 , respectively ) .	44086783	yes
Over the past few decades , global network traffic has grown explosively due to the demands for higher bandwidth and faster connections of various multimedia and data services ( e.g. big data , cloud computing , streaming video , Internet of Things , machine - to - machine communication , and remote surgery ) 1,2 . Conventional cable - based transmission approaches can not meet the enormous data transmission requirements . With the advantages of low loss , large bandwidth , and anti - electromagnetic interference , optical fibres have replaced cables and have been widely used as the transmission medium in fibre to the home ( FTTH ) networks , metropolitan area networks ( MANs ) , backbone networks , and transoceanic communications 3,4 . Due to the wide application of fibre - optic networks , optical fibres exist anywhere in modern society , and the fibre can be exploited for more functions than data transmission . In addition to acting as the transmission medium in fibreoptic networks , optical fibre can also act as the sensing medium in optical fibre sensors [ 5][6][7 ] . Among the numerous optical fibre sensors , distributed optical fibre sensing ( DOFS ) interrogates a large number of points in a single sensing fibre , thus providing an overwhelming advantage over conventional node - type sensors in longdistance measurement [ 6][7][8 ] . In particular , DOFS techniques functionalities for fibre - optic network 25,33,34,[38][39][40][41 ] . Initially , Î¦ - OTDR only utilized dedicated or idle undersea fibre cables as the sensing medium to detect seismic waves 20,33,34 . In recent years , Î¦ - OTDR has been integrated into coherent optical communication networks by wavelength - division multiplexing ( WDM ) and frequencydivision multiplexing ( FDM ) to enable both data transmission and distributed vibration detection [ 38][39][40][41 ] . With these integrations , traffic monitoring and road roughness detection have already been explored in the existing fibreoptic networks . It is foreseeable that more potential functions such as urban structure imaging , safety monitoring of the city gas pipeline , and ocean detection are also likely to be developed . However , the demonstrated schemes just share fibres in DOFS and fibre - optic networks , and there are still two individual systems . Due to reserving channels for DOFS ( fibre or spectrum resources ) , the current solutions reduce the transmission efficiency . For integrated schemes using individual spectrum channels in communication and DOFS , the transmission performance may be degraded as the strong probe used in DOFS easily excites non - linear effects . Moreover , coherent optical communication is commonly used for long range transmission and seems poorly match to conventional DOFS ( which works efficiently in tens of kilometres ) . Since data transmission is the primary function of fibre - optic networks , an efficient integrated solution should maintain or even improve the transmission performance . Theoretically , it is possible to improve the transmission performance by suppressing or utilizing the non - linear effects 42 . Therefore , the current solutions might not be good choices for implementing integrated sensing and communication in optical fibres , especially for the short / middle range application scenarios .	255967705	no
We also used the patch - clamp technique to characterize functional P2X3 receptors in chromaffin cells in tissue slices from the adrenal gland . Current responses to P2X3 receptor agonists ( Î± , Î² - meATP and Ap 4 A ) locally applied to the cell under investigation were compared between Control and CCI preparations . Î± , Î² - meATP ( 10 ÂµM , 3 s ) induced inwardly - directed currents in 37 % ( 28 out of 76 cells ) of cells tested from Control animals ( n = 5 rats ) . Interestingly , current responses differed in their inactivation kinetics ; 89 % of responding cells ( 25 out of 28 ) showed fast inactivating responses , whereas the other 11 % displayed sustained , non - inactivating currents . Moreover , sustained currents could be reproducibly elicited by Î± , Î² - meATP , applied at 2 min intervals , while the fast - inactivating ones could not ( Figure 5A ) . Ap 4 A ( 10 ÂµM , 3 s ) also activated currents in 36 % of cells tested ( 5 out of 14 cells ; n = 2 rats ) , all which were fast declining ( data not shown ) . Due to the low occurrence of non - desensitizing currents and our interest in homomeric P2X3 receptors , we focused our efforts on the characterization of transient currents . Importantly , the semisynthetic dinucleotide Ip 5 I ( 10 ÂµM ) markedly reduced fast - inactivating currents evoked by Î± , Î² - meATP ( 80 % reduction , n = 8 cells ; 2 rats ) ( Figure 5B , D ) and Ap 4 A ( 60 % reduction , n = 3 cells ; 1 rat ) ( data not shown ) .	58538295	no
The data selection and pre - processing procedure closely resembles that of Naul et al . ( 2018 ) . To minimize confusion , we selected sources based on information from the ASAS - SN variable star catalog . Classifications in the catalog , generated using their RF classifier , are treated as the true labels of the sources . We note that these labels may not be completely genuine . Only variables with classification probabilities above 90 % and at least 200 epochs were used . Light curves with Su - perSmoother residuals greater than 0.7 were omitted to ensure only true periodic sources were included . Following Jayasinghe et al . ( 2018 ) , we further filtered out saturated and faint sources with V < 11 and V > 17 .	155090960	maybe
In this study , fuzzy - set QCA ( fsQCA ) was carried out , as it allows a more fine - grained understanding and a more conservative test of sufficiency than does crisp - set QCA ( csQCA ) ( Schneider and Wagemann , 2012 ) . For this reason , the raw data of both outcome and condition measurements needed to be calibrated to fuzzy - set scores that represent the set - membership values of the cases .	226323969	no
General procedure for photocatalytic hydroxylation of aryl boronic acids to aryl phenols with diverse catalysts . Arylboronic acid ( 0.50 mmol ) , triethylamine ( TEA ) ( 1.50 mmol ) , photocatalyst ( 3.0 mg ) , and acetonitrile ( CH3CN ) ( 3.0 mL ) were added to a 10 mL glass tube with a stirring bar . The mixture was stirred for certain time at room temperature under visible light irradiation with white LED lamp ( 0.07 W / cm 2 ) and the presence of oxygen ( 1 atm ) . Subsequently , the COF or CMP catalyst was isolated by centrifugation and washed with DCM for several times . The organic phases were combined , and dried under vacuum to yield the crude product , which was further purified by silica gel column chromatography to determine the isolated yields as listed in Tables 1 and 2 . NMR data are as follows . General procedure for photocatalytic reductive dehalogenation of Î± - bromoacetophenone and photoredoxborylation of diazonium salt to boronic ester . Î± - Bromoacetophenone ( 0.50 mmol ) , N , N - diisopropylethylamine ( DIEA ) ( 0.55 mmol ) , DBOV - COF as photocatalyst ( 3.0 mg ) , Hantzsch ester ( 1.0 mmol ) , and CH3CN ( 3.0 mL ) were added to a 10 - mL glass tube with a stirring bar . The mixture was stirred for 12 h at room temperature under N2 and visible light irradiation with white LED lamp ( 0.07 W / cm 2 ) . Subsequently , the DBOV - COF catalyst was isolated by centrifugation and washed with DCM for several times . The organic phases were combined , and dried under vacuum to yield the crude product , which was further purified by silica gel column chromatography to determine the isolated yield as shown in Scheme S3 . Scheme S3 . Photocatalytic reductive dehalogenation of Î± - bromoacetophenone with DBOV - COF as photocatalyst .	244932348	maybe
Magnetic resonance imaging ( MRI ) was performed on a 3 Tesla Tim Trio ( Siemens ) and included a magnetization - prepared rapid gradient - echo ( MPRAGE ) processed with Freesurfer ( FS ) to identify grey white and pial surfaces to permit regions of interest ( ROI ) parcellation as follows : cerebellar grey , hippocampus , and the following Braak Stage related cortices : entorhinal , parahippocampal , inferior temporal , fusiform , posterior cingulate , as described previously [ 23][24][25][26 ] . 18 F - Flortaucipir ( FTP ) for positron emission tomography ( PET ) was prepared at MGH with a radiochemical yield of 14Â±3 % and specific activity of 216Â±60 GBq / Î¼mol at the end of synthesis ( 60 min ) , and validated for human use 27 . 18 F - FTP PET was acquired from 80 - 100 minutes after a 9.0 to 11.0 mCi bolus injection in 4 Ã 5 - minute frames . 11 C - Pittsburgh Compound B ( 11 C PiB ) PET images were prepared and images acquired as previously described 23 using a Siemens / CTI ( Knoxville , TN ) ECAT HR+ scanner ( 3D mode ; 63 image planes ; 15.2 cm axial field of view ; 5.6 mm transaxial resolution and 2.4 mm slice interval . 11 C PiB PET was acquired with a 8.5 to 15 mCi bolus injection followed immediately by a 60 - minute dynamic acquisition in 69 frames ( 12Ã15 seconds , 57Ã60 seconds ) . PET images were reconstructed and attenuation - corrected , and each frame was evaluated to verify adequate count statistics and absence of head motion . 18 F FTP specific binding was expressed in FS ROIs as the standardized uptake value ratio ( SUVR ) to cerebellum , similar to a previous report 26 , using the FS cerebellar grey ROI as reference . For voxelwise analyses , each subject 's MPRAGE was registered to the template MR in SPM8 ( SPM ) , and the spatially transformed SUVR PET data was smoothed with a 8 mm Gaussian kernel to account for individual anatomic differences 28 . To account for possible 18 F FTP off - target binding in choroid plexus , which may confound hippocampal signal , we used a linear regression to regress the choroid plexus , as previously reported 29 . 11 C PiB PET data were expressed as the distribution volume ratio ( DVR ) with cerebellar grey as reference tissue ; regional time - activity curves were used to compute regional DVRs for each ROI using the Logan graphical method applied to data from 40 to 60 minutes after injection 23,30 . 11 C PiB retention was assessed using a large cortical ROI aggregate that included frontal , lateral temporal and retrosplenial cortices ( FLR ) as described previously 31,32 . 18 F - fludeoxyglucose PET was performed on a 64 - section PET / computed tomography imaging system ( Biograph mCT ; Siemens ) using intravenous administration of 5 mCi ( 185 million Bq ) of 18 F - fludeoxyglucose after a 30 - minute radiotracer uptake period when resting in a darkened room , followed by a 30 - minute dynamic emission scan ( six 5 - minute frames ) . Images were reconstructed with computed tomographic attenuation correction .	207898971	maybe
The primary role of Ag nanoparticles on a semiconductor is believed to be the promotion of charge separation , as demonstrated by studies of the Ag / mpg - C 3 N 4 system ( see the previous Section 2.4.3 ) . [ 84 ] Further investigation on the promotional effect of Ag in Z - scheme systems was made by means of time - resolved emission spectroscopy using a semiconductor and Ru(PS ) , as a model RuRuâ² complex . As discussed earlier , Ru(II ) tris - diimine complexes such as Ru(PS ) exhibit emission centered at â640 nm , due to transitions from the lowest 3 MLCT excited state . [ 135,136 ] Emission decays were measured using several semiconductors known to effectively promote Z - scheme CO 2 reduction in conjunction with Ru(PS ) , so as to observe deactivation of the 3 MLCT exited state of Ru(PS ) . Figure 14 shows typical emission - decay data obtained using CaTaO 2 N and Al 2 O 3 . [ 98 ] The emission from Ru(PS ) on Al 2 O 3 ( an insulator ) evidently decayed over time ( Figure 14A ) , and this behavior remained unchanged even in the presence of TEOA , indicating that reductive quenching of the excited state of Ru(PS ) by TEOA was negligible .	147706686	no
â¢ Interpretability . Our method determines important connections with a mini - batch of data at single - shot . By varying this mini - batch used for pruning , our method enables us to verify that the retained connections are indeed essential for the given task .	52920837	no
In a forthcoming work , following research in cognitive neuroscience and its philosophy ( e.g. Raftopoulos , 2015 ) , I suggest organising the above functions ' outputs as five linked stages of the observation process : sensation ; perception ; observation ; data ; phenomena . Sensation regards light intensity computation and the production of the retinal image ; perception regards the individuation of the scene into unidentified objects ; observation regards ascription of meaning to the surveyed scene . Data are organised , temporally successive observations ; phenomena are causal descriptions of data . A strong advantage of this model , I claim , is that it systematizes the theoryladenness literature , with most of its theses expressible as token cases of the general form function . Examples :	238651842	no
"We found that PSDs of many studied crystals become constants in the low frequency range ( Figure S5.1 , Supporting Information ) and thus can be well approximated by Equation ( 1 ) . The other crystals demonstrate deviations of different extent in their PSDs from constant levels in the low frequency region ( Figure S5.2 , Supporting Information ) . We need to stress that the longer the correlation times probed , the smaller the number of data points become . This results in a large statistical uncertainty of the estimated PSD in the low frequency region . To understand if the observed deviations from constant levels have any significance , one needs to compare them with the statistical deviations in the PSDs of TLSs where spectrum must be constant at low frequency . For this purpose , we generated intensity traces of TLSs using Monte Carlo simulations with the same bin time , trace length , and characteristic time as in our experiments and then calculated their PSDs using the same algorithm as for the experimental data ( Figure 2 and Notes S6 and S7 , Supporting Information ) . We found that PSDs of TLSs , similarly to the experimentally observed PSDs for our crystals , also often show some "" wavy saturation "" shape in the low frequency range instead of a constant . However , these deviations are as large as expected from the confidence intervals calculated by our algorithm ( Figure 2c , d ) . Thus , considering the error bars , we can classify most of the recorded PSDs ( 75 % ) as possessing saturation and hence exhibiting well - defined maximum fluctuation correlation times in the range from 0.5 to 10 s ( Note S7 , Supporting Information ) . Thus , only 25 % of the studied crystals possess even slower fluctuation dynamics with times in the range of 100 s or longer ( Figure 2e , f ) ."	244605114	no
We next wondered if SPARCS promote positive feedback signal amplification . We detected high levels of dsRNA preferentially produced from MLT1C49 , MLT1J and MLT1A in 10 min IFNÎ³ pulsed H69AR cells , even after 24 h ( Fig . 2h ) . TAG - aided sense / antisense transcript detection ( TASA - TD ) PCR 17 confirmed that dsRNA resulted from bidirectional transcription of MLT1C49 , MLT1J , and MLT1A ( Supplementary Fig . 8a ) . IFNÎ³ pulse treatment activated and sustained pTBK1 and pIRF3 in addition to pSTAT1 in H69AR but not H69 cells ( Fig . 2i ) , which further amplified SPARCS expression , pTBK1 , and its effector cytokines over time ( Fig . 2j and Supplementary Fig . 8b , c ) . Transfection of the dsRNA mimic Poly(I : C ) induced type I / II IFNs in H69AR cells ( Supplementary Fig . 8d ) and direct IFNÎ± / Î² exposure or Poly(I : C ) itself induced SPARCS ( Supplementary Fig . 8d , e ) , consistent with positive feedback induced by dsRNA and type I IFN . Furthermore , exposure of untreated H69AR cells to IFNÎ³ primed conditioned medium activated TBK1 and STAT1 and induced CXCL10 , IFNÎ² and ERV expression ( Supplementary Fig . 9a - d ) . These data confirmed feedforward signaling downstream of SPARCS activation ( Supplementary Fig .   9e ) . As expected , treatment with the JAK1/2 inhibitor Ruxolitinib disrupted this circuit , whereas TBK1 / IKKÎµ inhibition with MRT67307 , partially inhibited downstream CXCL10 expression ( Supplementary Fig 9f - h ) . Finally , MAVS deletion also downregulated multiple cytokines / chemokines following Poly(I : C ) or low dose IFNÎ³ pulse treatment , especially when co - deleted with STING ( Fig . 2k - m , Supplementary Fig . 9i , j ) , and impaired tumorigenicity in nude mice ( Fig . 2n ) .	49908711	maybe
In this trial , the rate of patient enrolment was not high . This may reflect the absence of previous data in this setting and the difficulty of obtaining patient consent to participate in the trial , this was also reflected by the high number of withdrawals at six months .	52910025	no
In company E in e - commerce industry , the primary goal of its transformations is to quickly scale up the operations to keep up with the surge in demand . Three transformations have been adopted : WFH , ML in operations , and predictive analytics in sales forecasting . First , the company has developed many tools to ease the transition to WFH . The main goal of these tools is to facilitate decentralized collaborations between different departments and teams since such collaborations are of critical importance in dealing with a large amount of urgent operational issues that happen at the same time . Second , the company has used ML to identify potential operational issues , such as shortages of resources , which could result from decentralized decision making . Third , the company has adapted its sales forecasting models , e.g. , by incorporating social media data , to predict abnormal demand patterns in the pandemic period .	245617006	no
To assess if the reduced steady state level of BC200 upon CSDE1 knock - down was a consequence of a change in the rate of BC200 decay , we knocked down CSDE1 for 72 h and then inhibited global transcription by treatment of the cells with 5 g / ml Actinomycin D ( 48 ) . An equal number of cells were harvested at each of the indicated timepoints and BC200 levels were quantified by RT - qPCR ( Figure 7A ) . Decay rates under control and CSDE1 knock - down conditions were calculated by fitting the data to an equation modeling one - phase decay . The half - lives determined demonstrated a 40 % reduction in the half - life of BC200 under CSDE1 knock - down . While a significant change was observed for BC200 , global RNA decay was unchanged as was observed by plotting the relative change in total RNA purified at each timepoint ( Figure 7B ) . A second CSDE1 siRNA exhibited a similar impact on BC200 decay and CSDE1 knockdown did not significantly impact decay of the 7SL RNA ( Supplementary Figure S8C , D ) . Half - life measurements in MCF-7 cells are in good agreement with a previously published study ( 52 ) .	52336782	no
In comparison to the estimation of the cointegrating relationships , some studies have explored the causal relationships between economic growth , energy consumption , and CO 2 emissions through a multivariate framework using the Granger - causality time series or panel data approaches . The results of the empirical findings are , however , inconsistent . The existing literature addressing the casual relationships mainly falls into three categories . The first category of studies found evidences supporting unidirectional or bidirectional causality . Taking India as an example , Ghosh and Kanjilal ( 2014 ) demonstrated a unidirectional causality running from energy consumption to economic activity . Al - mulali et al . ( 2013 ) found that while 60 % of Latin American and Caribbean countries maintained a positive bidirectional long - run relationship between energy consumption , CO 2 emissions , and economic growth , the remaining 40 % yield mixed results . Using error - correction - based Granger causality models , Acaravci and Ozturk ( 2010 ) found a one - way causal relationship to exist between economic growth and energy consumption . The same result was arrived at by Jalil and Mahmud ( 2009 ) in their study of China . Results of the study taken by Pao and Tsai ( 2010 ) indicated bidirectional strong causality between energy consumption - emissions , and bidirectional long - run causality between energy consumption - output , along with unidirectional causalities between emissions - output and energy consumptionoutput ( both strong and short - run , respectively . ) . Further , Sari and Soytas ( 2009 ) found a long - run relationship between income , energy consumption , and CO 2 emissions in Saudi Arabia , but not in Indonesia , Algeria , Nigeria , and Venezuela . However , Narayan and Popp ( 2012 ) revealed a negative causal relationship to exist between energy consumption and economic growth in the G6 countries . The second category comprises of research that has found no causality existing between the variables . Soytas et al . ( 2009 ) found that income does not maintain a relation of Granger - causality with carbon emissions in the United States in the long run ( although energy use does ) . Soytas and Sari ( 2003 ) did not locate a causal relationship between the variables - energy conservation can , in their analysis , help reduce CO 2 emissions without affecting a country 's economic growth . Apergis et al . ( 2010 ) found that in the short - run renewable energy consumption does not contribute to reductions in emissions . In addition , Hossain ( 2011 ) found that there was no evidence of long - run causal relationship from economic growth to CO 2 emissions and from economic growth to energy consumption for the panel of newly industrialized countries from 1971 to 2007 . The third category studies have found that the direction of causality is methods or periods dependent . For instance , using panel smooth transition regression , Heidari et al . ( 2015 ) found that the casual relationship between economic growth , energy consumption and CO 2 emissions is time instability dependent . CO 2 emissions increased with GDP growth in the first stage ( per capita income below 4686 USD ) while the direction was reversed in the second stage ( per capita income above 4686 USD ) . The study on Malaysia taken by Begum et al . ( 2015 ) showed that over the period of 1970 - 1980 , CO 2 emissions decreased with economic growth ; however from 1980 to 2009 , CO 2 emissions increased sharply with a further increase of GDP . Similar results were also found by Cleveland et al . ( 2000 ) . Taking China as an example , Wang et al . ( 2011 ) demonstrated the existence of short - run and long - run causality running from energy consumption to economic growth using a multivariate causality test . Similar studies were taken in Russia by Zhang ( 2011 ) , in Switzerland by Baranzini et al . ( 2013 ) , and in Turkey by Yalta ( 2011 ) . In addition , Burke et al . ( 2015 ) explored the short - run effects of GDP growth on CO 2 emissions for 189 nations taking 1961 - 2010 into consideration . They found evidence of delayed effects between energy - economy causality dialogs : specifically , emissions tend to growth quicker after booms and slower after recessions . Using a meta - analysis of the existing large literature , Kalimeris et al . ( 2014 ) did not find a genuine causal effect between energy and GDP in the literature as a whole . Similar results were also found by Bruns et al . ( 2014 ) using the same method .	45215519	no
As previously mentioned , we use SR plant capacity concepts to assess the efficient use of existing hospital capacity in Hubei province and test their correlation with mortality . Then we use LR plant capacity concepts to assess the build - up of new hospital capacity . We now turn to a discussion of available data to implement these different plant capacity models .	231706096	no
Assuming the data are independent and identically distributed ( i.i.d . ) , the logarithm of the likelihood can be calculated as	6019003	no
This section presents the main results from the study as follows : subsection 4.1 describes the empirical data collected from multiple company cases in the manufacturing industry . The findings from the empirical data analysis brought the model to its final version as presented in subsection 4.2 . Subsection 4.3 goes on to provide an account of how the model was converted into a tool which was tested in an industrial application . Finally , additional noteworthy results emerging from the model development and tool testing are presented in subsection 4.4 , some of which are further discussed in section 5 .	229426053	no
"Detection , control and elimination of ( both existing and emerging ) contaminants to reduce their impact on ecosystems and human health is a nonstop process . [ 242 ] In this ambitious , but essential task , disposable sensors will continue to play a central role . Next milestones for disposable sensing devices in environmental analysis include : i ) the development of easy - to - use sensors that can be quickly repurposed for the detection of "" new "" emerging contaminants . ii ) Although a number of multianalyte [ 86,87,136,217,221,226,243 ] and multimodal [ 86,87 ] disposable sensors already exist , to generate detailed models of the effects of environmental contaminants ( which require large datasets ) , highly multiplexed platforms that provide extensive , "" more complete "" analysis of contaminants need to be implemented . iii ) Internet - connected , transient disposable sensors that collect data , share and biodegrade without an environmental footprint . These systems may be able to create pollution maps autonomously with minimal user interaction . iv ) Development of new classes of disposable sensors that can measure analytes currently limited to centralized laboratories ."	155102091	no
The dataset consists of two latent components , one is a Gaussian distribution and the other follows a Gamma distribution with shape parameter Î± = 1.2 . One million data point are generated from this mixture distribution . Figures 3 shows the learned conditional distributions for each component . We can see DSGD - KSVD achieves almost perfect recovery , while Fourier and Nystrom random feature methods either confuse high density areas or incorrectly estimate the spread of conditional distributions .	9814012	maybe
The oldest survey to track the Ca II H&K line emission was the Mount Wilson Observatory HK Project that examined bright nearby stars for photospheric and chromospheric variability for decades ( Wilson 1968;Vaughan et al . 1978;Baliunas et al . 1995 ) . With the extensive data available through this survey , the search for MGM candidates followed ; this search has now spanned decades , using data from some of the most extensive surveys . The biggest challenge , however , has been to set down the criteria for a good MGM candidate based on observations of magnetic activity levels , metallicity , age , stellar type , gravity , and the relation between these properties ( e.g. , Baliunas & Jastrow ( 1990 ) , Henry et al . ( 1996 ) , Saar & Testa ( 2012 ) ) .	119358595	no
"The data in the contingency table are clearly not independent by the Fisher exact test ( P < 0.004 with or without the unevaluable class ) . There is a good correlation ( trend ) between scan score and clinical outcome , with a P < 0.01 for the Cochran - Armitage trend test when the clinical outcome is collapsed into "" Good "" and "" Poor "" outcomes ."	3397862	no
The pseudospins in Sr 2 IrO 4 , entangling both spin and orbital momenta due to the strong SOC at Ir - site , are aligned into an AFM lattice below the NÃ©el temperature T N ~ 240 K [ 13,24,25,28 ] , as illustrated in Figure 2 . The absence of anomaly at T N in the electrical transport data is in agreement with the scenario of J eff = 1/2 Mott state . All the pseudospins lie in the ab - plane , and show uniform deviation of ~13 Â° from the a - axis . The canting is within the ab - plane , and there is no canting along the c - axis . Various techniques , including neutron scattering and resonant X - ray scattering ( RXS ) , demonstrated that the pseudospin canting rigidly tracks the rotation of IrO 6 octahedra , resulting in the well - known locking relation : ï¡ ~ ï¦ [ 37,39,41 ] . This locking effect between the pseudospin canting and lattice distortion was reproduced theoretically by Jackeli et al . [ 42 ] . Because of the canting , net magnetic moments appear alternatively in each IrO 2 planes , and are coupled antiferromagnetically along the c - axis . In this sense , Sr 2 IrO 4 is fully compensated at the ground state without showing macroscopic magnetization . A magnetic field H larger than the critical value H flop can cause a flop transition , and the net moments of IrO 2 layers are then ferromagnetically aligned along the c - axis , resulting in a weak ferromagnetic ( FM ) phase [ 43,44 ] , as sketched in Fig   Benefiting from recent technological advances in resonant X - ray scattering , direct probing of the Ir pseudospins is allowed , noting that Ir has large neutron absorption ratio , which challenges related characterizations using neutron scattering technique [ 37 ] . Extensive efforts in the last several years revealed that the AFM order is mainly stabilized by the strong nearest - neighbor ( NN ) intralayer AFM interaction of ~ 0.1 eV [ 45][46][47 ] . Regarding the interlayer coupling , it was found to be as small as ~ 1.0 ï­eV , 10 5 times weaker than the intra - plane AFM coupling [ 47 ] . Such a large 10 magnetic anisotropy allows the so - called flop transition , also known as the AFM to weak FM ( AFM - wFM ) transition , as demonstrated with RXS [ 43 ] . The AFM order of Sr 2 IrO 4 looks fairly robust and the AFM fluctuation with long - rang in - plane correlation was found to persist at even ~ 20 K above T N , which can be described by the two - dimensional S = 1/2 quantum Heisenberg model [ 47 ] . Another work addressing on critical behavior of Sr 2 IrO 4 revealed that the critical scattering can be followed out to a much higher temperature ( T N +73 K ) , and XY anisotropy is important for accounting for the pseudospin interactions [ 48 ] . High magnetic field experiments revealed that the AFM order does n't show any trace of breakdown up to H ~ 60 T [ 25 ] . The weak FM phase was found to be quenched at hydrostatic pressure P ~ 20 GPa , which is probably due to the reorientation of pseudospins from the ab - plane to the c - axis rather than the AFM order collapse [ 49 ] .	204967964	no
"Besides transparency , practitioners also related trust to privacy , with some data scientists noting that users have to know that the media organization deals with their data in a responsible way and respects their privacy . By contrast , project owners and journalists argued that trust depends primarily on news content , with one project owner noting that , "" You can write in an objective , and impartial , and credible manner , and with this you build trust . "" Similarly , an FD journalist stated that users will trust the media if recommended articles fulfil certain values , "" And then I do not mind if a human or a robot has done that [ recommended the article ] . "" Consequently , trust can be treated as "" kind of a checkpoint "" that determines if the organization or brand is performing well in general ; that is , as a factor that relates first of all to the organization or brand , and only by extension to the way it uses ANRsa conclusion supported by our earlier findings about user attitudes towards ANRs and the fact that trust in them is guided largely by trust in a brand ( Monzer et al . 2020 ) ."	237282779	no
Some of these data are also included in Fig . 1 of the main article . No simulation of the data was undertaken for [ Fe(bpp NH2,H [ PF 6 ] 2 are of lower accuracy than the others , for similar reasons , and the errors on the quoted T Â½ values for those compounds are correspondingly larger . The derived T Â½ values for those compounds are in good agreement with predictions based on the ï³ P and ï³ P + Hammett parameters , however ( Fig . 3 , main article ) .	43007051	maybe
, wheret i is the bin coordinate and y i the number of data points in it . This model reaches posterior consistency in the limit of bin width going to zero [ 34 ] . Thus it is expected that the accuracy improves with tighter binning .	53670030	no
The COVID-19 pandemic is impacting multidimensional poverty both directly and through associated policy responses in countries across the globe . These policy responses include school closures , strict lock downs , restrictions to human mobility , as well as restrictions to local and international trade . In this section we implement microsimulations to ascertain the potential impact on the global MPI of increases in two indicators : nutrition and school attendance . We focus on these particular indicators because of their relatively larger weight in the global MPI , the availability of relevant data to inform scenarios , and the plausibility of short - term impacts .	238478212	no
Using this method , we can estimate the maximum capacity of all bases , liquids or solids . Therefore , ammonium hydroxide solution ( â30 % w / w ) will have a maximum CO 2 adsorption capacity of 8.8 mmol g â1 , while that of BeO solid can be as high as 37.0 mmol g â1 , which is probably the material available with the highest theoretical CO 2 adsorption capacity via neutralization . Unfortunately , this estimation assumes a 100 % stoichiometric reaction and it is unlikely to happen , particularly for solid , non - porous adsorbents such as CaO , due to the accessibility of sites . Therefore , the experimental data are usually much lower than these values . For amine adsorbents , normally it is assumed that two amine groups will react with one CO 2 molecule to form the more stable carbonate species ( see Figure 1 ) . Therefore , the N / CO 2 ratio provides a certain degree of indication on how effi cient an amine - based adsorbent is . On the other hand , the effi ciency of CO 2 adsorption for an adsorbent can be derived from the experimental and theoretical maximum adsorption capacity as follows : Mesoporous silica 1.0 - 2.0 chemisorptions onto basic groups ( e.g. , amines ) 1 - 5 g [ 13 ] Carbons ( CNT , mesoporous carbon ) 0.5 - 3.0 Physisorption ( except amine - functioanlized CNT ) < 1 g [ 13 ] Organic cage framework ( OCFs ) 1.0 - 5.0 Physisorption and chemisorption < 1 g [ 15 ] This value indicates how many basic sites , such as the number of amine groups on an adsorbent , are engaging with CO 2 molecules .	54778784	no
Holography is capable to reconstruct both the intensity and phase information of an object , which has been widely applied in optical display 16,17 , data storage 18,19 , information security 20 , and microscopy 21 . In recent years , the concept of holography has been extended to nonlinear optics , leading to new domains in nonlinear holography [ 22][23][24][25][26][27][28][29][30 ] . Since the encoded information is reconstructed in the newlygenerated wavelength , nonlinear holography has been viewed as a promising technique for high - density optical storage and high - security optical encryption . 2D NPC is the popular platform to realize nonlinear holography 24,30,31 . However , it can only provide 2D modulation of nonlinear interacting waves , which severely limits the performance of nonlinear holography . For example , the general configuration in previous works is typically based on nonlinear Raman - Nath diffraction 32 , in which the phase - matching condition is partially satisfied ( i.e. , there still exists a certain residual phase mismatch ) . Therefore , the typical conversion efficiency of the reported nonlinear holography is 10 -6 or less 33 . Another key issue in demonstrating nonlinear holography is its ineffective multiplexing / demultiplexing capability . Only a few schemes have been reported that can achieve nonlinear multiplexing holography with limited channel numbers 15,22,23,34 . For example , in a specially designed metasurface , spin angular momentum is introduced to encode two different patterns at the secondharmonic ( SH ) wave 22 . However , the multiplexing capacity , as well as the conversion efficiency , need to be significantly enhanced for practical applications .	235917402	no
We add all the words that appear more than 50 times in the Pinterest40 M dataset into the dictionary . The final vocabulary size is 335,323 . Because the vocabulary size is very huge , we adopt the sampled SoftMax loss [ 8 ] to accelerate the training . For each training step , we sample 1024 negative words according to their log frequency in the training data and calculate the sampled SoftMax loss for the positive word . This sampled SoftMax loss function of the RNN part is adopted with Model A , B and C. Minimizing this loss function can be considered as approximately maximizing the probability of the sentences in the training set .	9461243	maybe
The uptake of SARS - CoV-2 and several other viruses from wastewater indicate passive samplers , especially electronegative membranes , may be capable of producing time - weighted average or semi - quantitative data . Despite the promising qualitative and kinetic results , studies considering the ability of passive samplers to produce accurate SARS - CoV-2 RNA quantitative data from wastewater are limited . Schang et al . ( 2021 ) found that SARS - CoV-2 RNA concentrations on passive samplers demonstrated a statistically significant correlation with concentrations in wastewater and suggested that passive samplers could yield semi - quantitative data , but replication is needed .	248267379	no
We next evaluated the consequence of eliminating Î² - Klotho from the nervous system on metabolic parameters . Neither the Klb tm1(Camk2a ) or Klb tm1(Phox2b ) mice had changes in body weight or other metabolic parameters under ad libitum chow - fed conditions ( Fig 4a ; Supplementary Table 1 ) . As expected 16,21 , Klb tm1 â·Tg(Fgf21 ) mice had significantly lower body weight , tibia length and plasma insulin and cholesterol concentrations than control Klb tm1 mice but no change in percent lean mass or fat mass ( Fig . 4a ; Supplementary Fig . 6a ; Supplementary Table 1 ) . Notably , the changes in body weight , tibia length and plasma insulin and cholesterol concentrations observed in Klb tm1 â·Tg(Fgf21 ) mice were reversed in Klb tm1(Camk2a ) â·Tg(Fgf21 ) mice ( Fig . 4a ; Supplementary Fig . 6a ; Supplementary Table 1 ) . These changes were not reversed in Klb tm1(Phox2b ) â·Tg(Fgf21 ) mice with the exception of cholesterol concentrations ( Fig . 4a ; Supplementary Table 1 ) . These data indicate that FGF21 action on the SCN mediates the effects of FGF21 on body weight and insulin levels .	17593591	maybe
To understand the structural characteristics of the NaMnO 2 that allow for the sodium deintercalation and reinsertion , the structure of the NaMnO 2 was analyzed by powder X - ray diffraction , and solid - state NMR . The X - ray diffraction ( XRD ) pattern of the as - prepared monoclinic NaMnO 2 is shown in Figure 2 . Through utilizing a Reitveld refinement of the crystalline structure , the lattice parameters are defined as , a = 5.649 Ã , b = 2.829 Ã , c = 5.769 Ã , Î² = 112.8 Â° . These values are closely related to those found in literature ( a = 5.63 Ã , b = 2.86 Ã , c = 5.77 Ã , Î² = 112.9 Â° ) . [ 24,25 ] Given this and the crystalline structure of NaMnO 2 , the MnîO bond lengths in the MnO 6 octahedron are 2.30 Ã ( 2Ã ) and 1.84 Ã ( 4Ã ) respectively . This analyses confirms the activity of the NaMnO 2 according to the Jahn - Teller effect . [ 23 ] Further to this , the DCP data , assuming that the prepared materials are completely phase pure , the chemical formula is determined to be NaMnO 2.09 .	104467195	no
www.advmat.de www.advancedsciencenews.com as reduced porosity , complex synthetic procedures , or the need for advanced instrumentation . An alternative route for creating highly hydrophobic exterior surfaces without hampering the material 's internal porosity is the creation of rough surfaces , so - called corrugation , on the nano - to micrometer length scale . In 2014 , Kitagawa and coworkers reported superhydrophobic MOF materials by using external surface corrugation originating from aromatic surface groups . [ 48,69 ] The authors reported a porous coordination polymer with external surface design ( PESD ) , [ Zn 4 ( Âµ 3 -OH ) 2 ( BTMB ) 2 ( DMF ) 3 ( MeOH ) ] using the organic linker BTMB 3â (= 1,3,5 - tris(3 - carboxyphenyl)benzene ) , which possesses an aromatic hydrocarbon - terminated surface ( Figure 16a ) . The material 's surface area is 295 m 2 g â1 and powder XRD measurements of flake - shaped single crystals of PESD-1 reveal that the ( 010 ) surface is the material 's dominant surface ( Figure 16c ) . Calculations based on single - crystal data confirm a nanometerscale corrugation along this surface with a periodicity of 1.2 Ã 1.1 nm 2 , caused by the surface termination by the aromatic hydrocarbons of the organic linker . Atomic force microscopy ( AFM ) characterization suggests that the ( 010 ) surface is relatively flat in larger length scales ( Figure 16b , d ) . To examine the material 's hydrophobic properties , contact angle measurements were performed on as - synthesized and activated powder , single crystals , and pellets , all of which yielded markedly different results ( see discussion in section 3.5 about challenges in characterization ) . The authors additionally performed solvent adsorption at 298 K for water , benzene , cyclohexane , and toluene . In the water adsorption experiments , for hydrophobic materials rather untypical behavior is observed on PESD-1 . Two significant steps at 0.27 and 2.3 kPa are observed on the adsorption isotherm . This indicates that while the exterior surface is repellent toward liquid water , the interior pore space is actually hydrophilic and accessible to water vapor ( like a lotus leaf ) . The adsorption isotherm of hydrophobic organic solvents such as toluene and benzene shows a gate - opening adsorption isotherm , although cyclohexane was not adsorbed . These results indicate that PESD-1 has framework flexibility along with size - selective pores toward guest molecules . The same group recently reported a de novo synthetic method for preparing other MOF with nanosurface corrugation , including PESD-2 and PESD-3 [ Zn 2 M 2 ( Âµ 3 -OH ) 2 ( BTMB ) 2 ] ( M = Co and Ni ) , with Co 2 + or Ni 2 + occupying the octahedrally coordinated Zn 2 + positions . [ 205 ] It should be noted that the reported bimetallic MOFs exhibit outstanding superhydrophobic behavior even at elevated temperatures . PESD-2(Co ) exhibits a particularly large surface area and good uptake of solvents such as benzene , toluene , and cyclohexane .	173994028	no
Based on the evidence of cellular senescence , intensive investigations have been carried out to address the role of DDR proteins in aging . DNA repair - deficient nematodes have a significantly shorter life span while several long - living mutants show increased repair activity , suggesting DNA repair capacity influences the aging process and affects longevity in nematodes [ 62 ] . Results of genetically modified mice studies also support a preventive function of DDR proteins on aging . Wong et al . demonstrated that telomere dysfunction and Atm deficiency accelerates the aging process in mice [ 63 ] . Similarly , the absence of breast cancer 1 ( Brca1 ) full - length isoform causes senescence in embryos and aging in adult mice [ 64 ] . Deletion of Atr in adult mice also leads to age - related phenotypes and stem cell loss [ 65 ] . In addition to protein kinases , knockout of Ku80 , a non - homologous end joining protein involved in DSB repair , showed early aging in mice [ 66 ] . These data suggested that deficiency in DNA repair promotes aging in vivo .	5321228	no
To determine the relationship between COVID-19 and the degree of competitiveness of the regions and the state of their health systems , their value in 2019 , the latest year available , has been considered for the latter . This temporal difference favours the explanation of causal relationships between the variables . Complete data have been obtained for all variables for a total of 28 countries of the European Union , including the United Kingdom .	233550712	no
To acknowledge the multi - actor setting of data science for risk - based inspection , we added three activities to the CRISP DM model . Two prior activities are focused on respectively enlarging knowledge and sharing knowledge between professionals and data analysts . Another extra feature is a focus on valorisation after the knowledge creation phase . The framework was used in practice by developing a risk model for the Dutch Food and Safety Authority ( NVWA ) . Three key dilemmas were found .	239658990	no
We study the problem of constructing a hypothesis test for an unknown data - generating function h : R p â R , when h is estimated with a black - box algorithm ( specifically , Gaussian Process regression ) from n observations { y i , x i } n i=1 . Specifically , we are interested in testing for the hypothesis :	8775835	no
We carried out EBSD measurements in an electron micro scope that was equipped with a solidstate detector initially designed as a position sensitive , single photon counting detector , from which other applications such as ion and electron detection have evolved ( Figure 1a ) . [ 28,29 ] The sensor is equipped with an electronic noise free circuit , and therefore provides high sensitivity and fast readout , which enable us to acquire clear EBSD maps of halide perovskite films on glass quickly before damaging the samples . We used an optimized beam current of 100 pA at an accelerating voltage of 30 kV , with a pixel dwell time of 100 ms . The electron dose needed for acquiring EBSD maps here is 6000 times lower than what was previously neces sary for single crystal samples using the traditional phosphor screen and camera ( 6 nA for 10 s ) . [ 22 ] Backscattered electrons escape from the tilted sample and are projected onto the detector in a pattern of spherical bands that reflect the Bragg angles of the local crystal lattice ( Kikuchi lines ) . [ 30 ] By scanning the beam across the sample , we collected a pattern from each pixel and indexed it to the cubic CH 3 NH 3 PbBr 3 lattice to con struct a map of the film 's local crystallographic orientations . Figure 1b - e shows EBSD maps of the CH 3 NH 3 PbBr 3 per ovskite prepared with different spinning times . The grain size becomes larger with reduced spinning time ( at a given spin speed ) , which is consistent with trends inferred from SEM ( top panel Figure 1b - e ) . Most crystal grains are oriented in the [ 001 ] direction and the surface orientation propagates throughout the whole film ( Figure S10 , Supporting Information ) . On sam ples with larger than average grain size , however , the popula tion becomes more dispersed to higher index orientations of [ 101 ] and [ 111 ] because of many smaller crystal grains trapped among adjacent larger grains ( bottom panel Figure 1b - e ) . The mean of the distribution of apparent grain sizes obtained from optical images differs from the mean of the distribution obtained using EBSD ( Figure 1 g , the method in Figure S5 in the Supporting Information ) . Typically the difference is less than 40 % , but in one particular case ( orange trace ) , the optical images indicate an average grain size of more than a factor of 1.9 larger than the actual grain size . Figure 1f shows the ori gins of this discrepancy between an SEM image and its corre sponding EBSD map . Some pixels of the map show no Kikuchi pattern , for instance , area 4 ; this indicates a disordered region , which could contain amorphous ( not fully crystallized ) mate rial , [ 31 ] nanocrystalline perovskite with grains much smaller than our interaction volume ( â250 nm based on Monte Carlo simulation ; Figure S6 , Supporting Information ) or a com posite of the two . From EBSD data alone , we also can not rule out the influence of surface roughness ( Figure S9 , Supporting Information ) . The observation of disordered regions occurs primarily in the sample with an average grain size of 32 Âµm . In the optical image , such regions would be incorrectly classi fied as part of their neighboring grains . Furthermore , the iden tical Kikuchi patterns between domains 1 and 2 in Figure 1f ( across the dashed line ) indicate that they are one grain , while their morphology ( based on the SEM ) suggests there is a grain boundary . In another area ( solid line in Figure 1f ) , the SEM suggests there is no grain boundary but the EBSD map shows that one is present .	53096529	no
In this study , we defined that the mobility change by MTR use to be the percentage difference in average daily subway - use at time t , compared to the average of that in a non - pandemic week ( January 6 to 12 ) . Some studies that used mobile phone data to evaluate human movement , defined the mobility change to be the percentage difference in average daily distance travelled in an area at time t , compared to the average of that on the same weekday before the COVID-19 pandemic ( Engle et al . , 2020 ) .	231880553	no
The appointed unit coordinator entered data collected from each unit on the study database . During data entry , the software automatically performed plausibility and completeness checks . Each variable was defined in detail before the start of data collection , and the definitions were available in both paper and electronic form . To facilitate plausibility checking , each variable was assigned a range of probable values and a range of possible values ( storage range ) .	17421582	no
where B and B CM B = 3.25(1 + z ) 2 are the source and the equivalent Cosmic Microwave Background magnetic fields , respectively ( ÂµG ) , and Î is the injection index . We checked that this method , while approximate ( it assumes Î½ Î½ b , where Î½ b is the break frequency of the synchrotron spectrum , which is a reasonable assumption ) provides consistent results with those of spectral modeling ( see also Bruno et al . 2019 ) . We used the minimum energy loss field B = B CM B / â 3 = 3.4ÂµG ( see de Gasperin et al . 2017 ) , that maximizes the radiative lifetime of the emitting particles ( we also verified that assuming equipartition returns consistent results ) . The injection index Î was set to 0.7 ( typical values can range from 0.5 to 0.9 , see Biava et al . 2021 and refer - ences therein ) . Since , with the available uv - sampling at 4.8 GHz , we recover flux from the extended lobes only at the â¼2Ï level , our results suffer from relatively large uncertainties ( up to a factor of 2 ) . As a note of caution , we observe that using B = 3.4ÂµG and neglecting adiabatic expansion losses of the relativistic electrons results in possibly overestimated radiative ages ; adopting steeper values of Î would result in even lower ages . On the other hand , the spectrum of the integrated flux from the cavity regions could also be described with a continuous injection model ( Pacholczyk 1970 ) , which would result in higher radiative ages than those predicted using Eq . 5 . These arguments are particularly important for the Nf cavity : assuming Î â¼ 0.8 - 0.9 ( close to the observed spectral index ) would result in its radiative age being close to zero . However , a detailed comparison between different models and injection indices goes beyond the accuracy that can be reached with the available radio data , which only provide approximate radiative ages . Fig . 3 shows a sampling of the spectral indices with beam - sized ellipses ( 1.6 Ã 1.1 ) in the E - W ( blue ellipses in panel a ) and N - S ( red ellipses ) directions . The spectral index profiles ( panel c ) show no strong steepening towards the outer regions : the innermost region has a spectral index of â¼1 ( consistent with Gitti et al . 2006 ) , which is steeper than typical core emission ; however , this may be explained by the relatively large beam ( 1.6 Ã 1.1 ) , which does not resolve the core - jet components . The t rad profiles show that from the center to the outer regions the E - W radiative ages range between 15 - 35 Myr , while the N - S ones range between 15 - 25 Myr . Additionally , we computed the integrated flux from the cavity regions to obtain the radiative ages within each feature ( last column in Tab . 1 ) . The E - W ages are consistent with both buoyancy , sound speed and refill times . For the N - S cavities , we only have upper limits ; the Nf cavity has t rad â14 Myr , which is lower than the timescales suggested by buoyancy and refill ages , and is closer to the sound speed age .	243847290	no
In Figure 3 , we present the median radial profiles of the stellar population properties of the three types of galaxies including stellar ages , metallicities and Mgb/ Fe . Figure 3 ( a)-(c ) are for the main samples of galaxies . As shown in Figure 3 ( a ) , red spirals and elliptical galaxies show similar shallow age profiles out to 1.5 R e , although red spirals are slightly younger than ellipticals . As labeled in the y - axis of the figure , red spirals formed their bulge and disk components within â¼ 1.5 Gyr before redshift â¼ 1.2 â 1.3 , and ellipticals formed within â¼ 1 Gyr before redshift â¼ 1.5 . In contrast , the central region ( < 0.3 R e ) of blue spirals shows a steep mass - weighted age gradient with similar ages to red spirals and ellipticals at the very center , while their disk components show flat age gradients but are much younger than red spirals and ellipticals . The above results suggest that red spirals most likely harbor star formation histories that resemble ellipticals instead of blue spirals . Blue spirals started to form their bulges at a similar time to red spirals but have an extended star formation history in the outer parts , which is consistent with a prolonged inside - out formation scenario . Figure 3 ( b ) presents the median radial profiles of the stellar metallicities . Red spirals show a rather flat metallicity profile from the center out to 1.5 R e . Blue spiral galaxies and ellipticals show similarly steeper metallicity gradients than red spirals , with blue spirals being more metal - poor than ellipticals . Compared to red spirals , blue spirals are more metal - poor over the entire probed radius , and the metallicity difference varies from â¼ 0.03 dex to â¼ 0.1 dex . On the other hand , elliptical galaxies are more metal - rich in the inner region ( 0.5 â 0.6R e ) but more metal - poor in the outer region ( 0.5 â 0.6R e ) than red spirals . Figure 3 ( c ) shows the median radial profiles of Mgb/ Fe . Mgb is used to probe the Î± elements ( e.g. , Worthey et al . 1992;Zheng et al . 2019 ) that are produced by type II supernova , while Fe is synthesized in type Ia supernova . The Î± / Fe ratio traces the relative importance of the intense starburst and the subsequent long - term quiescent star formation ( Matteucci & Greggio 1986;Worthey et al . 1992 ; Thomas et al . 2005 ) Figure 2 . The median radial profiles of V star /Ï star for red spiral galaxies ( red ) , blue spiral galaxies ( blue ) and red elliptical galaxies ( black ) in the main samples ( a ) and in the subsamples ( b ) , with a radial bin of 0.15 R e . The error bar represents the error of the mean . The downward arrows indicate the median effective radius of the bulge component for red spirals ( red ) and blue spirals ( blue ) .   Figure 3 . The median radial profiles of stellar mass - weighted age ( a ) , stellar mass - weighted metallicity ( b ) , and log(Mgb/ Fe ) ( c ) for red spiral galaxies ( red ) , blue spiral galaxies ( blue ) and red elliptical galaxies ( black ) in the main samples . The same properties for the subsamples are shown in ( d)-(f ) . The data points connected by dotted lines show the profiles along the ellipse with position angle and ellipticity from NASA - Sloan Atlas ( Abazajian et al . 2009;Blanton et al . 2011 ) . The bin sizes are 0.15 R e . The error bar represents the error of the mean . The downward arrows indicate the median effective radius of the bulge component for red spirals ( red ) and blue spirals ( blue ) .	202558966	no
The rGGGC(CAG ) 5 GUCC , referred to r(CAG ) 5 oligomer , was purchased from Integrated DNA Technologies , Inc. The r(CAG ) 5 oligomer was dissolved in diethylpyrocarbonate ( DEPC)-treated water to the final concentration of 1.2 mM. Prior to crystallization , the oligomer was heated at 75 â¢ C for 10 min and cooled slowly to room temperature within 3 h. Crystals were obtained from the condition of 100 mM HEPES ( pH 7.5 ) , 1.6 M ( NH 4 ) 2 SO 4 and 10 % PEG 400 at 16 â¢ C using vapor diffusion method . X - ray diffraction data were collected on the beamline TPS 05 at National Synchrotron Radiation Research Center ( NSRRC ) in Taiwan . The HKL2000 program ( 41 ) was applied for data processing . The RNA structure was solved by molecular replacement using the Phaser program embedded in the PHENIX suite ( 42 ) , manually revised using Coot ( 43 ) , and further refined using PHENIX ( 42 ) . The truncated rUUGGGC(CAG ) 3 GUCC structure ( PDB code : 4YN6 ) ( 40 ) was used as a search model . The 3DNA program ( 44,45 ) was used to calculate the helical parameters of the RNA structure . Data collection and refinement statistics are summarized in Table 1 . All structural figures were drawn by the software PyMOL . The coordinate was deposited in the Protein Data Bank ( PDB ) with an accession code of 7VFT .	250175714	yes
In addition to sO 2 prediction , a major important feature of our data - driven DSL method is to quantify the uncertainty for each prediction . To do so , we specifically design the loss function for training the network to properly capture the underlying statistics of the data . The commonly used loss function , that is , the mean squared error ( MSE ) , assumes a homogeneous Gaussian distribution of the errors in the predictions . This assumption severely limits its ability to adapt different types of spectral data variations ( e.g. , spectral signal outliers , non - uniform noise , and unevenly sampled data ) that are inevitably inhomogeneous . To account for this , we design a customized loss function derived from a heterogeneous Gaussian distribution model . Using the training data set ( I i , [ spO 2 ] i ) , i = 1 , 2 , â¦ , N , where I i and [ spO 2 ] i are the ith vis - OCT spectral measurement and the ground truth pulse oximeter spO 2 , respectively , our loss function L G ( w ) is	181990850	no
For scatter plots of flow speed versus vessel diameter for individual vessel segments ( Fig .    5a ) , diameter estimations were performed at the same vessel locations within one - photon video sequences as flow speed determinations . To examine the diameter of a blood vessel at a chosen pixel , we examined one - dimensional intensity profiles of the vessel along lines that cut through the chosen pixel at various angles . These line profiles were computed at two - degree angular intervals and extended from the pixel of maximum intensity ( the center of the vessel ) to the nearest local minima ( the vascular boundary ) . These profiles were fit to Gaussian functions , and the blood vessel diameter was defined as the 1 / e 2 width of the narrowest Gaussian fit that met minimum goodness of fit and minimum amplitude criteria . We also confirmed that mean blood vessel diameters as determined from the one - photon data sets matched those from the twophoton data sets .	14912406	no
In this paper we have considered the possibility that DAMA is a true discovery of dark matter , and investigated the properties a theory of dark matter needs to have in order to account for the data . We have shown that inelastic dark matter is consistent with the findings of DAMA as well as other direct detection experiments and seems to provide a better account for the sum of this data than other proposed explanations such as light elastic dark matter or dark matter scattering off detector electrons . Extending the study of Ref . [ 14 ] , we find that heavier inelastic dark matter can give a reasonable fit to the data , particularly for lower values of the galactic DM escape velocity .	16521526	no
"The comparison between available data and the order s 4 - avor and order 2 s 3 - avor calculations discussed kinematic regions and to the physical quantities they are suitable for . With more abundant and more precise experimental data on charm production , the composite generalized MS formalism , which encompasses both , will be needed to make reliable comparisons . With this in mind we are now ready to extend the 4 - avor calculation to include the necessary O ( 2 s ) terms , along with the O ( 2 s ) matching conditions . Such a calculation would include all the advantages the current calculation has in addition to the advantages of the current 3 - avor NLO calculation . Finally , the generalized MS formalism provides a framework to extract information on the gluon and the charm distributions of the nucleon { to the same accuracy as the overall NLO global QCD analysis based on total DIS structure functions and other hard processes . Having established that our calculation does a reasonable job in describing the existing HERA data , we are now in a position to explore the question of whether the proton contains a non - perturbative charm component 35 ] . Certainly , it must at some level , so the real question is how small is it ? The handle on the charm distribution is unique to the generalized formalism , since the xed 3 - avor scheme does not allow the charm parton as an independent degree of freedom . m We note that there have been recent phenomenological studies of \intrinsic charm "" which take the theoretical cross - section to be the simple sum of the 3 - avor FFN scheme formulas and an intrinsic charm contribution by the heavy - quark excitation mechanism 36,37,38 ] . This approach can not be internally consistent , because the 3 - avor calculation assumes parton evolution with no charm quark distribution , while \intrinsic charm "" explicitly requires one . The intimate interplay between the hard matrix elements and parton evolution is consistently incorporated only in the generalized MS scheme . Although there has been a recent e ort to examine this problem incorporating some of the ideas of the general scheme 39 ] , a fully consistent study , preferably based on more extensive data , still awaits to be done . n m The CTEQ5HQ parton distributions used in our calculations here contains charm partons , but does not use an independent non - perturbative charm component as input . This feature is not inherent to the formalism . n Because all active partons are coupled , the inclusion of a non - perturbative charm component of the nucleon will a ect all parton distributions . Hence , it will in uence the global tting of all available data sets , including the extensive DIS sets . If a reliable conclusion is to be drawn , it will not su ce to combine a subset of existing parton distributions ( in a conventional scheme ) with modi ed charm and gluon distributions ( in the new scheme ) , as is done in 39 ] using GRV and MRST distributions . Phenomenologically , such a combination can upset the original good global t to existing data , particularly the precision DIS data . Among theoretical problems , the NLO evolution equation and the momentum sum rule will not be observed , due to the mixing of these hybrid parton distributions . the universal form given in the process - independent functionsf b a ( x ; mc ; 1 ; s ( ) ) , so that they can be factorized out in the manner of Eq . ( 4 ) , ! a ( Q ; x ; m c ; 1 ; s ( ) ) = X bf b a ( x ; m c ; 1 ; s ( ) ) b ! b ( Q ; x ; m c ; s ( ) ) ; ( 17 ) with b ! a being fully infra - red safe in the sense that it is free of all 1 dependence . In the 4 - avor scheme de ned below , the functionsf b a ( x ; mc ; 1 ; s ( ) ) will also contain the same large logarithmic terms as ! a ( Q ; x ; mc ; 1 ; s ( ) ) , so that these too factorize in Eq . ( 17 ) with the result that b ! a is free of all ( s ln ( mc ) ) n terms , and it is well - behaved as m c ! 0 :"	15351369	no
where E U is the Urbach energy , Î± the absorption coefficient , E g the bandgap , hÎ½ the photon energy and Î± 0 a constant . [ 7 ] The Urbach fit was applied to the absorption front in the log - linear absorption plots ( Figure    S5a and S5b ) . A comparison of the fitted Urbach models to the absorbance data is given in Figure S5a - c , showing that there is a good fit . If we compare the Urbach models themselves to observe the absorption only due to the tail of sub - bandgap states , we can see that as the conduction band was raised , the energy required for sub - bandgap absorption also increased ( Figure S5d ) . This is in agreement with the photoluminescence spectra data in Figure 3b and suggests that the available electron acceptor levels due to any sub - bandgap states below the Zn 1 - x Mg x O conduction band were shifted to higher energies as the conduction band was shifted upwards by Mg doping .	12138755	no
Several isolated rDNA clones also contained palindromic structures , and fiber - FISH analyses of the uncloned chromosome 21 DNA ( from which the clones were derived ) showed similar non - canonical structures ( Supplementary Figure S6 ) . It is plausible that such structures could arise from recombination between IGS repeats ( Supplementary Figure S9 ) . However , palindromic sequences were not confidently recovered from long - read WGS data , and so their prevalence in uncloned DNA may not be as high as previously suggested ( 62 ) .	46894431	no
"Once that implicit contents are brought to the foreground two related questions arise : ( a ) what is the nature of the implicit information conveyed by extensionally equivalent frames sharing the same explicit contents ? And ( b ) how is the implicit information conveyed by the frames ? Drawing on some empirical data presented below , my answer to the first question is that the ( choice - relevant ) implicit information conveyed by the frame is about the most likely context of use of a frame , that is , the typical background conditions corresponding to such context . This information is not part of what is asserted in the frame , but rather part of what is assumed about context whenever a certain frame is employed . The resulting assumption concerns neither the intentions of any particular speaker , nor any other particular contextual aspect surrounding the framed utterance , since surveys are usually non - conversational contexts where both the "" speaker "" ( pollster ) and the framed issue are absent . In implicitly conveying information typically associated with a frame , valence framing induces an addition of a proposition to that literally expressed by an utterance , which bring us to the second question . The propositional addition induced by framing seems to occur through the activation of a default mechanism resulting from a process of standardization , i.e. by way of a regular pattern of use or choice of a frame whenever certain contextual conditions are assumed to be the case . As we will see , this is also suggested by recent empirical data on frame choice ."	237769565	no
The type of data storage . The data can be stored on a server or be part of the software that users use to access services on the Internet , such as cookies or the cache of browsers and applications . The user must be informed if these data should be deleted by him / herself or by companies within the indicated time frame . Technology Technology used to access and collect user data . Depending on the sophistication of the given technology , the speed of data collection and the amount may be truncated .	233029680	maybe
These are findings from the particular regulatory and business settings we studied in China . We can not directly generalize beyond these cases . What we can do though is ponder to what extent these findings are particular to these cases by exploring what core mechanisms were at play and contemplate whether these mechanisms may also be at play elsewhere . Here of course the cases we studied in Chine exist in an authoritarian and developing legal context , where regulators have limited autonomy , and where there have been structural instances of capture and corruption . All of these may well play a role in explaining our results , although we did not find direct evidence that they did . Another important particularity of the cases studied in China is the role of legal counsel . As explained in the methods section , legal counsel in China has until recently not been involved directly with everyday compliance processes , and nor did we find any trace of such involvement in the cases we studied . Thus , it may well be that in jurisdictions where there has been a more developed compliance function in an internal legal department or as a separate department run by lawyers that transmission of legal rules would have been more successful . Work by Edelman and Talesh has shown how in - house counsel play a role in the reception and transmission of legal norms into corporations , and by doing so adapt what the law is to the context of the corporation , thus changing its original meaning and function ( Edelman 1992;Edelman et al . 1991;Edelman and Talesh 2011b ) . Such work , however has not traced the transmission of the law deeper into the company . So , at the moment there is no data to compare our findings to from jurisdictions with a more developed legal compliance function , and our findings , together with those of Edelman and Talesh may serve as starting points for future research replicating our study design in settings with a more developed legal compliance function .	234050691	no
"The QSPR study of these aliphatic organic compounds was performed with the selection of the data set , generation of molecular descriptors , simple linear regression statistical analysis and model validation techniques . The model applicability was further examined by plotting predicted data against experimental data for all of the compounds . All regression analysis was carried out using the Origin [ 27 ] and TSAR programs [ 28 ] . The statistical parameters used to test the prediction efficiency of the models obtained were the correlation coefficient ( r ) , standard deviation ( s ) , coefficient of determination ( r 2 ) and null hypothesis test ( F - test ) . The validity of the model was tested with the cross - validation coefficient ( r cv 2 ) using "" leave - one - out "" in the software program TSAR 3.3 for windows [ 28 ] . A group of seven compounds , not included in the original QSPR models , was employed for the external validation ."	11920298	no
"Data infrastructures created by EHRs and mandated reporting are commonly framed as offering new opportunity to address fundamental causes and reduce health disparities , linking EHR data sources to broader objectives of reducing inequality ( Institute of Medicine , 2014;Adler and Stead , 2015;Douglas et al . , 2015 ) . As health systems face growing pressure to quantify health outcomes , costs , and equity goals via performance metrics from EHR data sources , standardized data is expected to expand public visibility of clinical encounters , inform state programs of disparity reduction , and induce providers and staff to redress social problems through clinical care ( Institute of Medicine , 2013 ; Anderson et al . , 2018;DeMeester et al . , 2017;Cantor and Thorpe , 2018 ) . The stakes of quantification are therefore quite high : without measuring "" the social , "" advocates and experts warn , biomedicine will continue to elide social factors driving health outcomes , thereby reproducing health Cruz   inequalities ( Cahill and Makadon , 2013;Douglas et al . , 2015;Penman - Aguilar et al . , 2016;Zhang et al . , 2017;Wasserman et al . , 2019 ) . At the same time , public anxieties over the rise of "" data - driven care "" suggest potential structural limitations with data - centered approaches , including deeper concern over what data standardization captures and what it obscures ( Cruz , 2020;Thompson , 2020 ) ."	237292347	no
3 . RESULTS Figure 1 shows the angular power spectrum of the arrival directions of the simulated UHECR up to order l max = 64 for particles reaching the Earth with energies E > 8 EeV , E > 10 EeV , or E > 15 EeV. Remarkably , for all three energy ranges our results show a statistically significant ( s > 5Ï ) dipolar anisotropy , whereas on smaller solid angle scales the distribution of the arrival directions is always compatible with an isotropic directional distribution . The significant dipolar anisotropy with no higher - order anisotropies for arrival energies E > 8 EeV ( see Fig . 1a ) is in excellent agreement with the latest data of the Pierre Auger Observatory . In a recent study , the Pierre Auger Collaboration reported a significant ( s > 5Ï ) dipolar anisotropy ( Aab et al . 2017c ) , whereas an earlier study found isotropy for the higher - order multipole moments ( Aab et al . 2017b ) . Similarly , our results for arrival energies E > 10 EeV ( see Fig . 1b ) are well in line with O. Deligny for the Pierre Auger Collaboration and Telescope Array Collaboration ( 2015 ) , which mentions indications of a dipolar anisotropy for the same energy range . This finding , however , is not statistically significant with reference to a significance level of 5Ï , but based on our simulation results we can expect that the dipolar anisotropy in the experimental data will become significant as soon as enough data are available . O. Deligny for the Pierre Auger Collaboration and Telescope Array Collaboration ( 2015 ) also considers higher - order contributions to the angular power spectrum up to order l = 20 and finds that they are compatible with isotropy . This is again consistent with our simulations and we predict that one will find no significant anisotropy also for even larger l when they are addressed in experiments in the near future . Our results for arrival energies E > 15 EeV ( see Fig . 1c ) are predictions that we expect to get confirmed by future experimental studies . We are not aware of any relevant studies considering the angular power spectrum of the arrival directions of UHECR in this energy range . For E > 8 EeV , E > 10 EeV , and E > 15 EeV the values of C 1 ( E ) are 3.74 Â· 10 â3 , 6.28 Â· 10 â3 , and 1.34 Â· 10 â2 , respectively .	59471904	no
Further linguistic data which appears to support the claim that expressives contribute to both descriptive and expressive content can be found in languages that utilise a honorific system . One such example present in Japanese is discussed by McCready ( 2010 ):	238686546	no
To achieve highly sensitive detection of viral RNA in wastewater , the processes for viral concentration , RNA extraction and RT - preamplification - qPCR were improved . Specifically , we found that PAC - based flocculation and enzymatic proteolysis processes enabled efficient recovery and extraction of viral nucleic acids from wastewater , respectively ( data not shown ) , and thus these processes were included in the established protocol of the COPMAN ( Fig . 1 ) . However , proteolysis of the solids would inevitably promote the release of PCR inhibitors into the liquid phase , reducing the efficiency of the downstream molecular processes . To overcome this issue , we compared multiple RT - PCR enzymes using RNA from various wastewater samples in Japan , and successfully identified a set of inhibitor - resistant enzymes for the RTpreamp - qPCR step ( i.e. , the Reliance Select cDNA synthesis kit , the Biotaq HS , and the TaqMan Environmental Master Mix 2.0 for RT , preamplification , and qPCR , respectively ) that enables efficient and sensitive detection of SARS - CoV-2 RNA in wastewater . As a result , the COPMAN achieved high detection sensitivity of viral RNA even in wastewater samples containing a significant amount of PCR inhibitors ( data not shown ) .	251328452	maybe
Our data add to the growing evidence that migraine is associated with increased risk of vascular events 6 8 11 12 and that the risk of specific cardiovascular disease outcomes might depend on the presence or absence of vascular risk factors . 5 8 Our results are of interest for general practitioners as a history of migraine in combination with information on vascular risk status , as measured by the Framingham risk score , could indicate future cardiovascular disease events . This is analogous to recent work indicating that a history of pre - eclampsia is a risk factor for cardiovascular disease in later life . 23 Our data imply that among patients with migraine , cardiovascular risk factors should be more carefully sought and controlled .	1375620	no
Convolutional neural networks are used for extracting information from images by interpreting ( classifying ) different features inside a photo . [ 441 ] For sensory data in medicine , a common application of CNNs is to diagnose patients from an EEG , EMG , or ECG recording . During classification , CNNs extract quantifiable information from these images ( which are represented by a matrix of numbers ) by first downsizing or sectioning off key areas of the photo into smaller matrices , [ 441 ] where each color pixel is represented by three integer RGB values ranging from 0 to 255 . Down - sampling is achieved by convolving ( sliding ) different matrix filters across the photo and remapping the data into a new array that can be used to identify different features inside the image . [ 441 ] As a simple example , the convolution of a vertical edge detection filter is shown below :	245168336	no
We initially explored fits with absorbed single - component models , including a multi - color disk ( diskbb , Mitsuda et al . 1984 ) and power - law functions . The line - of - sight absorption was characterized in terms of an equivalent neutral hydrogen column density via the tbabs model ( Wilms , Allen , & Mc - Cray 2000 ) . These models are rejected by the data ( powerlaw : Ï 2 /Î½ = 17.0 , disk blackbody : Ï 2 /Î½ = 10.8 , where Î½ is the number of degrees of freedom ) . A significantly improved fit is obtained when these components are combined ( Ï 2 /Î½ = 3.1 ) ; the residuals are consistent with calibration uncertainties below E â¤ 3 keV and broad Fe K emission , signaling reflection from the inner disk ( see Figure 1 ) . In these fits , there is evidence of an edge feature at E â 9 keV. It is not fully consistent with the K - shell edges of Fe XXV or Fe XXVI ( 8.83 keV and 9.28 keV , respectively ) , nor with Au L - shell edges ( 9.63 keV and 9.71 keV ) that could be instrumental . The feature is weak and does not affect the measurements of black hole spin made below .	119199756	no
Code availability - The code to analyze data are available from the corresponding author upon request .	3494925	yes
Concretely , the Min - Max data normalisation technique has been adopted for feature ranking , which aims to ensure each data attribute is compared in an equitable manner . To improve the performance of classification and ensure the degree of membership in the TSK+ is calculable , the selected features in U are further normalised using a total number of eight normalisation techniques [ 34 ] in this work , including Min - Max ( MM ) normalisation , 1 - normalisation , 2 - normalisation , Power Normalisation ( PN ) , and its variants ( i. e. 1PN , 2PN , PN 1 , and PN 2 ) .	231573178	no
The phase has been shifted by the same constant offset for each segment for clarity . The bottom row shows the first overtone mode obtained after subtracting the fundamental mode , its next four harmonics , and the combined frequencies . The phase for these have been shifted by the same constant offset for each segment for clarity as well , although with a different offset than the fundamental mode . The fundamental mode lightcurve grows in amplitude going from left to right , which is what is seen in the Fourier analysis presented above . Also , the first segment of data ( top left plot of Figure 4 ) has a pronounced bump at a phase of â¼ 0.8 . As the amplitude grows , this bump decreases . The presence of the bump is what causes the first harmonic peak of the fundamental mode to be large in the first segment , and as the bump disappears , the growing amplitude of the fundamental mode pulsation balances out this peak in the Fourier analysis . The folded lightcurves for the first overtone mode have very slight changes in comparison , again matching what is seen above . There is a small decrease in the amplitude , and there appears to be a small phase shift of the peak .	235790448	no
Domain generalization is traditionally addressed by learning representations that encompass information from all the training domains . Muandet et al . ( 2013 ) learn a kernel - based representation that minimizes domain dissimilarity and retains the functional relationship with the label . Gan et al . ( 2016 ) extends Muandet et al . ( 2013 ) by exploiting attribute annotations of examples to learn new feature representations for the task of attribute detection . In Ghifary et al . ( 2015 ) , features that are shared across several domains are estimated by jointly learning multiple data - reconstruction tasks .	13754527	no
In temperate lakes with clear water and low primary productivity , the range of Î´ 13 C observed in consumer trophic levels often reflects the relative importance of benthic ( generally more 13 C - enriched ) and pelagic ( 13 C - depleted ) carbon sources ( Hecky and Hesslein , 1995 ) . However , at the sites included in the current study , phytoplankton biomass is high and transparency is low ; and benthic primary productivity is likely to be strongly limited by the low - light conditions ( Vadeboncoeur et al . , 2003 ) . Based on light attenuation coefficients and site depths as reported by Poste et al . ( 2013 ) , the mean percentage of light reaching the bottom at our study sites never exceeded ( and was often much lower than ) 1 % of surface irradiance . As such , pelagic carbon sources should dominate the Table 3 Summary of results of stable isotope and mercury analyses ( ranges in Î´ 13 C , Î´ 15 N , TL , and THg ) for fish included in regressions , log(THg)~Î´ 15 N regression results ( r 2 adj and P values ) , and calculated TMFs . Species - level results for Î´ 15 N , Î´ 13 C and THg analyses are found in Table S1 . Regressions for all sites were carried out using only fish data , except for Lake Nkuruba , where zooplankton were included due to the lack of primary consumer fish in this lake . Addition of zooplankton to the Lake Nkuruba regression analysis had a substantial effect on the regression results ( regression equation for fish only regression : â0.13 Â± 0.21 + ( 0.13 Â± 0.03)Î´ 15 N ) . Superscript letters next to log(THg)~TL regression equations describe the results of an ANCOVA followed by a post hoc multiple comparison test ; sites labeled with a common letter had no significant difference in regression slope ( P b 0.1 ) .	35982195	no
We finally quantified the crosstalk among gut microbiome , clinical phenotypes , liver transcriptome , urine and plasma metabolomes by estimating the proportion of shared variation amongst the different tables through Rv coefficients ( Fig . 6 , see Methods ) . A high proportion of information ( 79 - 97 % ) was shared between matching datasets ( Fig . 6a ,   Supplementary Table 11 ) , suggesting a strong similarity between metagenomic and phenomic data ; the weakest ( 79.44 % ) being between urinary metabolome and clinical parameters . The metagenomic data shared 92 - 93 % similarity with clinical parameters , liver transcriptome and plasma metabolome , while they only shared 74.68 % with the urinary metabolome . This statistical crosstalk analysis suggests that , although metagenomic and phenomic data have strong similarity , there is still information attached to each original dataset which , if pooled together , could result in a robust signature .	49411975	no
The data on confirmed cases , deaths , and test recipients were also collected daily . As shown in Table 1 , such data was collected by the ECDPC from 37 OECD countries . However , collection of data was omitted on some dates , in some countries . For comparison of all these variables across countries , the data on both new cases and deaths were standardized to represent incidence per 1 million people . The number tested was standardized to be expressed as the rate of tests per 1000 individuals . 5 In the determinant factor analysis , due to the weak normality of the distribution , we converted the data to the square root values , as explained above . 6 Table 2 shows the changes in the RSV , the key variable of this study , from just before the event week to the mid - point , in the 37 OECD countries we analyzed . In addition , Table 2 shows the dates when the peaks of new cases and deaths existed during the analysis period . In Table 2 , we see that RSV showed rapid changes in many countries around March 11 and March 12 . 17 out of 37 countries ( 45.9 % ) also exhibited their peak immediately following the declaration ( within 2 days ) and 28 out of 37 countries ( 75.7 % ) reached their peak of RSV within a week . These results confirm the likelihood that the WHO 's pandemic declaration had a significant effect on the changes in RSV , while also indicating that there were differences among countries . Table 2 also presents the duration of the analyzed RSV . Duration is defined as the period ( in days ) until the RSV was restored to that of March 10 , a date just preceding the event week . Table 2 also shows significant differences by country : it is notable that Italy , Japan , and Korea , where a large number of confirmed cases had already been reported , experienced a very short duration . The durations presented in Table 2 had a very high correlation with the RSV increase rate in the event week ( Pearson correlation coefficient 0.808 , p - value < 0.000 ) , and this can be confirmed by referring to Fig . 3 . We thus confirmed that the greater the increase in RSV , the longer the duration , and in consideration of multicollinearity , we did not add RSV duration as a variable in our analysis .	232282755	maybe
We used different configurations of cells with homeotropic ( perpendicular ) and planar BCs for the LC far - field director N 0 . In the former case , polyimide SE1211 ( Nissan Chemical Industries , Ltd. ) was spin - coated onto the glass plates with transparent indium tin oxide ( ITO ) electrodes at 3000 rpm for 60 s and baked at 180 Â° C for 60 min . In the latter case , a thin layer of 1 wt% aqueous polyvinyl alcohol ( PVA , Sigma - Aldrich ) was spin - coated and kept in an oven at 100 Â° C for 1h and then unidirectionally rubbed . The cells were assembled using 30 Î¼m silica spacers and glued at their edges with UV - curable NOA-63 glue ( Norland Products , Inc. ) ; the cell gap thickness was confirmed by using an optical interference method . We used an Olympus BX-51 polarizing optical microscope ( POM ) equipped with 10 Ã , 20 Ã , and 50 Ã objectives with numerical aperture 0.3â0.9 along with a CCD camera ( GS3 - U3 - 28S5C , from Point Grey Research ) . The light source was a tungsten - halogen lamp . Extinction and transmittance spectra were recorded using a microscope - mounted spectrometer USB2000 - FLG ( Ocean Optics ) with a broadband ( 400 - 1200 nm ) polarizer inserted into the optical path after the sample . Electric switching properties , including the threshold voltage and response time , were measured utilizing a photodiode and data acquisition card SCC-68 ( National Instruments Co. ) controlled by a homemade software [ 6 ] written in LabVIEW and a Si amplified photodetector PDA100A ( Thorlabs Inc. ) . The response times , including both the rise time upon applying the voltage and the decay time after removing the voltage , were measured as in our previous studies and are described elsewhere [ 6][7][8][9][10 ] . Wavelengthselective studies of switching of dye and GNR orientations utilized optical interference filters such as 700 nm long pass filter ( Semrock Inc. ) and an infrared filter ( Olympus ) . TEM images were obtained using a FEI Tecnai T12 Spirit .	255415059	no
The exclusive processes we consider in this paper are DVCS and J / Î¨ production . Light meson production was studied in our previous paper [ 17 ] where we found that the dipole model predictions generally agree well with the data modulo a rather strong dependence upon the meson wavefunction . For an alternative investigation of the link which exists between low x DIS and exclusive processes at high energies we refer to [ 18 ] .	10207446	no
The electrokinetic analysis of a Na / NiCr 2 S 4 cell is shown in Figure 7b   www.advmat.de www.advancedsciencenews.com especially considering the large peak - to - peak voltage separations of cathodic and anodic events in the CV commonly observed for battery - like materials . [ 85,88 ] Peak - to - peak voltage separations distinctly larger than 59 / n ( n : number of electrons transferred in the redox process ) and the characteristic gradual voltage drift of cathodic and anodic peaks with increasing scan rates indicate quasi - reversibility and enlarged polarization of the NiCr 2 S 4 electrode . [ 91,92 ] The b values extracted from the logarithmic plot of peak currents versus scan rates ( Figure 7c ) are closer to 1 indicating high capacitive contributions to the Na storage mechanism . Interestingly , b values related to the redox pair Ni 2 + |Ni 0 ( b 1 = 0.91 and b 4 = 0.99 ) are higher than those for the pair Cr 3+/2 + |Cr 0 ( b 2 = b 3 = 0.83 ) . Because the uncompensated Ohmic polarization and quasi - reversible redox reactions limit the total capacity obtained from CV data at high scan rates ( compare Figure S18 , Supporting Information ) , the infinite scan rate analysis [ 93 ] ( see Note S6 and Figure S19 , Supporting Information ) was conducted using only data recorded for scan rates < 0.6 mV s â1 . [ 94][95][96 ] The resulting quantitative analysis ( Figure 7d ) reveals high capacity contributions of 78 % applying 0.1 mV s â1 to 90 % at 0.6 mV s â1 , in agreement with the b values , which could be explained by the nanosize effect well described in the literature . [ 86,97 ] The formation of nanosized domains enhances extrinsic pseudocapacitive contributions and result in beneficial charge storage properties . [ 97,98 ] The amorphisation process of NiCr 2 S 4 in the first cycle ( compare Section 2.3 ) results in a predominantly surface - controlled charge storage mechanism with significantly shortened diffusion lengths during subsequent cycling in contrast to the first discharge process , which involves mainly bulk redox reactions .	237443435	no
1 ' Universal ' here means that any massless theory can be written in the form ( 2.1 ) , where the integrand I ( 0 ) only depends on the kinematic data polynomially .	199577599	no
The data that support the findings of this study are available from the corresponding author upon reasonable request .	51970657	yes
The dilemma is this : if the world can only be represented , then correspondence is always uncertain because the world can never be known ' in itself ' ( Hacking 2001(Hacking , 2006 . In turn , inferences that connect a representation to worldly counterparts are uncertain ( i.e. , correspondence is always uncertain ) . To address this uncertainty , most QR practices rely on probabilities that are used to guide and justify three stages of a QR process : research design , which is a process of generating representations ( e.g. , sampling and measurement ) ; data analysis , which generates additional representations that synthesize those from the first stage ( e.g. , parameter estimation , such as a regression coefficient b ) ; and inductive inference , which summarizes how representations and the world correspond ( e.g. , hypothesis tests with generalizations to a population ) . Probabilities and probability theories bind these three stages together in practices designed to maximize correspondence at each stage ( Howie 2002 ) .	254380504	maybe
SynthFly is a synthetic dataset containing a single fly moving inside of a rectangular chamber with a stationary object located in the center . The fly is synthesized to move according to the control laws listed in Figure 2 . The purpose of this dataset is to test whether our model could learn generative control rules , particularly ones that enforce non - deterministic behavior ( see laws 4 and 5 ) . ( Liwicki & Bunke , 2005 ) contains handwritten text from 195 different writers , acquired using a smart whiteboard that records a list of ( x , y ) coordinates for each pen stroke . The data is weakly labeled , with each sequence separated into short lines of transcribed text . For consistency with our framework we hand annotated strokes of 10 writers , marking the start and end of the 26 lower case characters , which we use along with data from 35 unlabeled writers for our experiments .	16926563	maybe
Samples and data sets with clinical and molecular annotation are described in Supplementary Table 3 . The distribution of clinical and molecular data by the four consensus subtypes is shown in Supplementary Table 5 . Data was generated by each independent group or TCGA and aggregated with standardization as described below . We performed non - parametric tests for comparisons of continuous values ( Kruskal - Wallis ) and discrete counts ( Fisher 's exact test ) . Samples from each CMS were compared with the remaining samples , after confirming similar variance of the groups been compared . P values were adjusted for multiple comparisons as detailed in each section . All correlative analyses were carried out using R statistical software version 3.1.1 . â¢ Other genes ( exome level ): available in TCGA data set , as described above .	5092451	yes
After successfully retrieving all previously mentioned data , graphical and statistical analysis then follows , giving a detailed comparison of all 27 cities , along with an evaluation of the combined effects of city studied features on disease spread . This study accordingly employs the following tests : Pearson correlation , Spearman correlation , ANOVA test , Regression analysis ; multicollinearity , autocorrelation , that to highlight the key outcomes of this research and conclude effective recommendations in planning for a pandemic resilient city in post pandemic world .	237486613	no
"Note for 3.2 : Proportions of potentially missing outcome data and reasons for outcome data appeared different . According to the supplementary material ( Figure S2 ) , there was potentially missing outcome data for 13 % of participants in the control group vs. 5 % of treatment group ( lost to follow - up , investigator discretion , and participant withdrawal of consent ) . End points section of the published paper states that "" the primary efficacy analysis was restricted to patients with the V600E BRAF mutation who did not have brain metastases at baseline ( amendment 3.0 to the protocol ) . However , since no significant differences in outcome were observed between the primary efficacy population and the intention - to - treat population , data from the intention - to - treat population are presented . "" Results obtained from both sets of outcome measurements were available ."	202688139	maybe
In this study we have performed a global leading - order DGLAP analysis of the nPDFs using the EKS98 framework introduced in [ 5,6 ] . Motivated by our previous work , we have introduced a piece - wize parametrization for the nuclear effects in the PDFs . Originally , the fit functions contained altogether 42 parameters . With the help of momentum and baryon number conservation and the experience from EKS98 , we reduce the number of relevant fit parameters down to 16 . A best fit to the nuclear DIS and DY data was searched for this set of parameters through automated minimization of Ï 2 using the Minuit program [ 37 ] . As a result , a very good fit to the N = 514 data points at Q 2 â¥ 1.69 GeV 2 was found , giving Ï 2 /N = 0.789 ( or Ï 2 /d.o.f . = 0.82 ) . No essential improvement over EKS98 was found , however , as the EKS98 modifications lead to an equally good fit quality , Ï 2 /N = 0.809 ( for N = 479 datapoints at Q 2 â¥ Q 2 0,EKS98 ) . Relative to the old EKS98 , the present analysis suggests slightly less shadowing for the gluons and sea quarks . This , however , is merely due to the different forms of the fit functions adopted in the region where no stringent constraints from the data are available . We also compared the obtained nuclear effects to those obtained by other global analyses , HKM , HKN , and nDS . The valence quark modifications do not deviate much from one set to another but the smallest - x and large - x modifications of gluons and sea quarks differ in a major way . This reflects the fact that especially the nuclear gluons are badly constrained in these regions .	15842787	no
"The above methods gave us a total of 500 groups ( 100 groups per method ) for each dataset , with the exception of the "" random within class "" method for MNIST . Since MNIST has 10 classes , each with only 10 % of the data , we skipped over groups of size > 10 % just for the "" random within class "" groups ."	173188850	no
This results in a PDF line scan as shown in Figure 3a , b , the temperaturetype color corresponds to the amplitude of the PDFs ( arbitrary unit ) . This line - scan is input to the PCA / ICA using the FastICA code . [ 30 ] PCA processes the data as a 2D matrix ( X ) , where the rows are the PDFs as function of the atomic pair distance ( in units of Ã in this paper ) and the columns correspond to different sample locations . The experimentally measured PDFs are considered as a linear combination of PDFs from the individual structural components . PCA diagonalizes the covariation matrix X T X , where X T is the transpose of X. The eigenvectors represent the component PDFs in the data and the eigenvalues describe the statistical significance of each component . Figure S5a , Supporting Information shows the first four components yielded from PCA . The elbow in the scree plot ( Figure S5b , Supporting Information ) suggests the first two components are the most principal . The two principal components selected by PCA are further processed by ICA to ensure their statistical independence , that is , minimized information overlap between each other . The similarity between the ICs shown in Figure 2b and the PCA results ( Figure S5a , Supporting Information ) shows that the principal components from PCA are close to be statistically independent . The IC maps shown in Figure 2c , d are then obtained by multiple linear least square fitting the two ICs to the STEM - PDF data cube .	231962657	maybe
This idea has important consequences for the way data intelligence and analytics can help to improve decision - making . The underlying premise of our research is that intelligence from data analytics and from domain knowledge are both valuable and sometimes competing . Improving decision - making processes , then , is about creating synergy between these ( fallible ) sources instead of taking one of them ( i.e. data analytics ) to the centre of the analytical process .	239658990	no
Meanwhile , the following studies attempted to provide empirical analyses of major issues related to COVID-19 using social data such as RSV as quantitative data . Walker et al . ( 2020 ) noted that while initial reports describing COVID-19 symptoms mainly pointed to cough , breathlessness , and fever , there were as yet unverified reports suggesting that anosmia may also be a manifestation . Their study used Google Trends to investigate the presence of this unverified symptom , by tracking whether there was an actual surge in individuals searching for information related to smell loss during the COVID-19 epidemic in several major countries . The study found strong correlations between loss of smell and increases of daily COVID-19 cases and deaths in all of the major countries . The study by Hu et al . ( 2020 ) adopted a similar perspective and used Google Trends to investigate the global public perception of COVID-19 . The study analyzed the period of two months before and after January 30 , the date on which the WHO announced a Public Health Emergency of International Concern ( PHSIC ) , and claimed that the first peak was observed immediately after the WHO 's PHSIC announcement . This study examined the correlation between RSV and daily confirmed patients and found statistically significant positive correlations in many countries . The authors pointed out that the reaction time was different in each country and the overall duration of public attention was short , and argued that efforts should be made to strengthen public awareness on COVID-19 at the national level and to reinforce public vigilance and sensitivity to COVID-19 ( Hu et al . , 2020 ) .	232282755	no
where , F 0 is the normalization constant and Î´ = Î± + Î² . The optical depth Ï Î³Î³ is a function of E Î³ and z. F 0 and Î´ are the only parameters to be adjusted to fit the observed spectrum . However , strictly speaking the normalization constant is not a free parameter which can be fixed from the observed data . It is not necessary to know a priori the value of Î² but it can be constrained by fitting the observed data with the parameter Î´ . Moreover , the spectral index of the intrinsic differential spectrum can be defined as Î´ int = âÎ´ + 1 . The stability of the inner jet on large scales can be estimated from the ratio Ï of the magnetic stress ( Poynting flux ) and the kinetic stress and for BL Lac objects Ï 1 . By considering the generic values of the parameters , magnetic field B â¼ 1 G , proton density n p â¼ 10 â1 â 10 â2 cm â3 , and bulk Lorentz factor Î â¼ 10 we obtain Ï â¼ 0.4 which corresponds to a stable inner jet ( Cavaliere et al . 2017 ) . The photon density within the inner jet region can be constrained by comparing the jet expansion timescale t d with the pÎ³ interaction timescale t pÎ³ and assuming the high energy proton luminosity to be smaller than the Eddington luminosity ( Sahu et al . 2016 ) .	202734650	no
We also compare the light curves to the larger grid of shell and WD masses presented in the simulations of Polin et al . ( 2018 ) , including additional simulations performed to match the data ( using the radiative transfer code SEDONA ; Kasen et al . 2006 ) , as solid lines in Figure 5 . For the additional simulations , we model the explosion of a 50 % carbon + 50 % oxygen WD with an isentropic helium shell . The hydrodynamics and nuclear processes are modeled from the helium ignition until the ejecta reaches homologous expansion using the compressible hydrodynamics code Castro ( Almgren et al . 2010 ) . Once the explosion reached homology radiative transport calculations are performed using SEDONA to produce light curves and spectra from the ejecta .	119186753	maybe
where g w is the SU(2 ) L coupling constant . and represent degrees of freedom that are accessible only with Higgs data . First , the operators O ÏW and O ÏB modify the interaction between Higgs bosons and electroweak gauge bosons . At the LHC , they can be probed for example by means of the Higgs decays into weak vector bosons , h â ZZ * and h â W + W â , as well as in the vector - boson - fusion ( VBF ) process and in associated production with vector bosons , hW and hZ. In addition , the O ÏG operator is similar but introduces a direct coupling between the Higgs boson and gluons . It therefore enters the Higgs total width and branching ratios , the production cross section in gluon fusion channel , as well as the associated production channel tth . Finally , the O Ïd operator generates a wavefunction correction to the Higgs boson , which rescales all the Higgs boson couplings in a universal manner .	233481290	no
Let D be a space of domains . During training we get labeled data from a proper subset D â D of these domains . Each labeled example during training is a triple ( x , y , d ) where x is the input , y â Y is the true class label from a finite set of labels Y and d â D is the domain from which this example is sampled . We must train a classifier to predict the label y for examples sampled from all domains , including the subset D \ D not seen in the training set . Our goal is high accuracy for both in - domain ( i.e. , in D ) and out - of - domain ( i.e. , in D \ D ) test instances .	13754527	no
"According to "" male idiot theory "" ( MIT ) many of the differences in risk seeking behaviour , emergency department admissions , and mortality may be explained by the observation that men are idiots and idiots do stupid things . 16 There are anecdotal data supporting MIT , but to date there has been no systematic analysis of sex differences in idiotic risk taking behaviour . In this paper we present evidence in support of this hypothesis using data on idiotic behaviours demonstrated by winners of the Darwin Award . [ 17][18][19][20][21 ] Winners of the Darwin Award must die in such an idiotic manner that "" their action ensures the long - term survival of the species , by selectively allowing one less idiot to survive . "" 20 The Darwin Awards Committee attempts to make a clear distinction between idiotic deaths and accidental deaths . For instance , Darwin Awards are unlikely to be awarded to individuals who shoot themselves in the head while demonstrating that a gun is unloaded . This occurs too often and is classed as an accident . In contrast , candidates shooting themselves in the head to demonstrate that a gun is loaded may be eligible for a Darwin Award - such as the man who shot himself in the head with a "" spy pen "" weapon to show his friend that it was real . 18 To qualify , nominees must improve the gene pool by eliminating themselves from the human race using astonishingly stupid methods . Northcutt cites a number of worthy candidates . [ 17][18][19][20][21 ] These include the thief attempting to purloin a steel hawser from a lift shaft , who unbolted the hawser while standing in the lift , which then plummeted to the ground , killing its occupant ; the man stealing a ride home by hitching a shopping trolley to the back of a train , only to be dragged two miles to his death before the train was able to stop ; and the terrorist who posted a letter bomb with insufficient postage stamps and who , on its return , unthinkingly opened his own letter ."	8920651	no
To test hypothesis 1 with pooled data , we run the aforementioned two - part model on Eq . ( 1 ) with standard errors clustered at the county level . Table 2 shows these results . The regressions show coefficients ( not odds ratio ) in two columns : the logistic first part results , and the OLS second part results . These results confirm a few stark findings . Counties with higher health needs ( i.e. , lower access to health providers and a higher percentage of uninsured adults ) are less likely to be recipients of foundation health grants . Our pooled logistic regressions suggest that as the number of providers goes down by 10 for every 100,000 people , the odds of receiving health grants goes down by 12 % . 3 Similarly , as the rate of uninsured adults goes up , the odds of receiving health grants go down . For every one percentage point increase in the rate of uninsured adults , the odds of receiving health grants goes down by 9 % . Richer counties denoted by higher median household incomes are more likely to be recipients of health grants . However , as unemployment goes up , the likelihood of receiving grants goes up . We also find that more unequal counties , which are those with higher Gini coefficients , are more likely to   Turning to the OLS regression , we note similar results in terms of access to health - care providers , but insignificant results ( due to the clustering of standard errors at the county level ) with regard to the percentage of adults uninsured . Conditional on receiving grants , a decrease of 10 health providers for every 100,000 people is accompanied by a reduction of 2.1 % in the value of health grants . In a nutshell , counties with greater health needs are less likely to receive grants , confirming Hypothesis 1 that counties with fewer health resources receive less support through corporate health grants than counties with higher levels of health resources . The positive trend we observed with unemployment in the logit model reverses such that counties with higher unemployment are more likely to receive grants , but such grants are lower in value than counties with lower levels of unemployment .	233211151	no
"The results are shown in Fig . 1 . For the image at top right the high resolution model was created from SDSS g and r images . These are shallow but have few artifacts and enable a wide field subtraction . The images in the bottom panels were filtered using a combination of Canada France Hawaii Telescope ( CFHT ) and Beijing - Arizona All Sky Survey ( BASS ; Zou et al . 2018 ) imaging . The BASS data are only used to identify and remove artifacts and missing data in the CFHT images . The CFHT imaging comprises 2100 s in g and 1500 s in r. We carefully checked that no low surface brightness emission is contained in the high resolution model . The only low surface brightness object that we removed from the model is a previously - uncataloged dwarf galaxy .   curved Eastern stream that was discovered by Shang et al . ( 1998 ) ( see top right panel of Fig . 1 ) . We find that the stream continues on the West side of NGC 5907 at lower surface brightness . This Western stream reaches more than twice the length of the Eastern stream . This stream morphology is qualitatively different from the double loop structure reported by M08 ; we return to this in Â§ 5 . We also detect a thin feature extending from the brightest part of the stream to the East and a faint patch about 1 â¢ due East of NGC 5907 . These faint features are not artifacts and are seen in both g and r ; their nature is unclear . Finally , we tentatively detect continuations of the stream at both ends : there may be a thin extension of the Western stream toward the Northeast , looping back South toward the disk , and there is a likely continuation of the Eastern stream toward the disk . Both these extensions are labeled "" tentative "" in Fig . 1 , and they are not included in our analysis ."	195699963	maybe
"Before analysis of the trial data the trial steering committee developed and approved a detailed statistical analysis plan . Women were analysed in the groups into which they were randomly allocated , regardless of position recorded at any time during the second stage of labour ( an intention to treat analysis ) . We excluded women from the analysis if a valid consent form was not received by the central study team , consent to use their data was withdrawn , they were not in second stage of labour when randomised and did not reach second stage before delivery , or they were not in labour or without an epidural in place at the time of randomisation . All comparative analyses were performed using generalised linear models with centre as a random intercept . Binary outcomes were analysed using log binomial regression models , and results are presented as adjusted risk ratios with corresponding confidence intervals . Where possible we analysed continuous outcomes using linear regression models , and results are presented as adjusted differences in means with associated confidence intervals . Unadjusted Hodges - Lehmann median differences ( plus confidence intervals ) for skewed continuous variables are presented . The geometric mean indicates the central tendency or typical value of a set of numbers by using the product of their values ( as opposed to the arithmetic mean which uses their sum ) and is used for summarising skewed data . Comparative analysis uses a ratio of the geometric means instead of the mean difference and therefore a ratio of 1 indicates no difference between the groups . For the primary outcome we present 95 % confidence intervals , and for all other outcomes 99 % confidence intervals to allow for cautious interpretation of the results . 13 Positions recorded were categorised according to whether the women were lying down , upright , or in "" other "" positions for each 15 minute interval . Positions recorded as lithotomy were categorised as "" lying down "" since the pelvis is in a horizontal position . A summary of adherence to allocated position is reported by trial arm for the passive second stage ( ie , before pushing commenced ) , the active second stage ( ie , pushing ) , and the whole of the second stage . Summaries of adherence data were calculated as the proportion of 15 minute intervals a woman spent in the position to which she was allocated out of the total number of 15 minute intervals recorded in the passive , active , or whole of the second stage of labour . Medians and interquartile ranges are presented owing to the skewed distribution of the data . Hodges - Lehmann differences in medians with corresponding 95 % confidence intervals are presented by randomised group . The trial statistician and an independent clinical assessor reviewed and classified all reasons for changes in position as avoidable or unavoidable . Periods where changes to a non - allocated position were considered necessary for unavoidable reasons were treated as adherent ."	22986845	no
However , major gaps remain in our understanding of the catalytic mode of action of these enzymes because of the rarity and the lack of spectroscopic data on species formed during their catalytic cycles . The short lifetimes and especially low steady - state concentrations of putative reaction intermediates formed during enzyme - catalyzed halogenation , such as Fe II -OCl , Fe III -OCl and Fe IV = O , present an often insurmountable challenge to their characterization . Thus , biomimetic model complexes provide av aluable alternative to the elucidation of the chemical nature of these intermediates . [ 5 ] Thei ntermediacyo fs omewhat related Fe III -O - IPh species , which can undergo homolysis to form Fe IV = Os pecies , i s , however , precedented in the work of McKenzie and Lennartson , [ 6a ] and Nam and co - workers , [ 6b , c ] wherebythe former study included full characterization of the intermediate using crystallography .	14717152	no
It is generally believed that short - term exposure to air pollution can lead to acute events by destabilizing vulnerable plaques , while long - term exposure can accele Levels of PM 2.5 in the ten less polluted countries ( green tags ) and the ten more polluted countries ( red tags ) , according to the World Health Organization ( WHO ) Observatory data . For each country the air pollution attributable death rate ( expressed as number of deaths per 100,000 population per year ) for ischemic heart disease is also indicated . Created with BioRender .	255217734	maybe
Adv . Mater . 2021 , 33 , 2100677 Figure 2 . EQE max as a function of emitter orientation in OLEDs based on purely organic emitters . The figure was made using data from 53 separate reports that include EQE max and emitter orientation data on 124 materials systems . [ 20,[22][23][24 ] While there is no correlation between EQE max and anisotropy across all data , it is clear that the highest efficiency in TADFand non - TADF - based systems , respectively , is reached at low anisotropy factors .	236774690	no
Contributors : JW , JJG , and KB designed the study . JW and SKS processed the data . KB and JG directed the analyses , which were carried out by JW and SKS . All authors participated in the discussion and interpretation of the results . JW wrote the initial draft . All authors critically revised the manuscript for intellectual content , approved the final version , and meet the ICMJE criteria for authorship . JW is the guarantor . The corresponding author attests that all listed authors meet authorship criteria and that no others meeting the criteria have been omitted .	252684319	no
We are reliant on only a single item , a direct measure of loneliness , but this is highly correlated ( around 0.88 ) with the often - used three - item UCLA Loneliness Scale ( Office for National Statistics , 2018 ) . Our data set also comprises only a modest sample size of young people , and observations to only September 2021 . In addition , we are not able to track whether individuals ( re)engaged in in - person social interactions between and after the lockdowns , though it is encouraging that other studies find a recovery in mobility after the relaxation and removal of restrictions ( e.g. , Joshi & Musalem , 2021 ) .	256058696	no
As a result , the distributed BFS changes for different strain measurements are shown in Fig . 5c ; the data show that the demodulated BFS change in the strain segment at 10 - 12 m is clearly migrated away from a value of approximately zero in the non - strain segment . The strain dependences for the demodulated BFS changes are plotted in Fig . 5d , which reveals a good linearity with a fitting strain coefficient of 0.049 MHz / Î¼Îµ .	52136642	no
In this work , we argue that the frequency domain offers more than a computational trick for convolution : it also provides a powerful representation for modeling and training CNNs . Frequency decomposition allows studying an input across its various length - scales of variation , and as such provides a natural framework for the analysis of data with spatial coherence . We introduce two applications of spectral representations . These contributions can be applied independently of each other .	14049334	no
Score functions yield label - function derivatives : One of the main contributions of this paper is to obtain these expected derivatives in ( 1 ) using features denoted by S m ( x ) , for m â¥ 1 ( learnt from unlabeled samples ) and the labeled data . In particular , we form the cross - moment between the label y and the features S m ( x ) , and show that they yield the derivatives as 3	557587	no
In computer vision tasks , Convolutional neural networks have become the de facto standard . It has been shown that CNN models trained with a huge amount of data are able to learn common features shared across different domains . This characteristic is usually exploited by transfer learning approaches . For visual representation we explored 2 strategies : transfer learning and end - to - end training .	9401721	no
Daily rainfall and temperature data were gathered from the Met Office Integrated Data Archive System ( MIDAS ) , which is freely available for on - line access to UK academics . These data were collected through a network of meteorological stations spread all over the Thames catchment ( and the rest of the country ) . Detailed information on the collection methods and quality control is reported on the Centre for Environmental Data Analysis ( CEDA ) website . Most measurements are made with full traceability to national or international standards . The daily precipitation , minimum temperature and maximum temperature data from all the available stations within the Thames catchment were interpolated on a 5 Ã 5 km grid using the Thiessen polygon method , and then the daily average precipitation and temperature series were computed and used as model input .	4218795	yes
We then determined two in vivo induction curves of lac promoters controlled without DNA loops . Figure 1C : in the presence of wt tetrameric Lac repressor but only the first lac operator . Figure 1D : in the presence of all three lac operators but repressed by a mutant dimeric active Lac repressor . Neither combination allows DNA loop formation ( 24 ) . Both curves are hyperbolic at inducer concentrations above the dissociation constant ( $ 5 Â· 10 Ã6 M ) of the repressor - IPTG complex ( 37,38 ) , demonstrating that the sigmoidality of the induction curve of the wt system reflects cooperative repression through DNA loop formation . Consequently , induction data of the wt lac promoter do not allow straightforward inference as to the functional stoichiometry of inducer - Lac repressor dimer interaction . To address the question of how many molecules of inducer are required to abolish operator binding of a Lac repressor dimer , systems without DNA loops have to be analysed . Figure 2 demonstrates that , also in vitro , template binding of Lac repressor engaged in a DNA loop , plotted as a function of inducer concentration , yields a sigmoidal induction curve . Lac repressor forms DNA loops in vitro with a DNA template carrying two suitably spaced operators , here O 1 and the ideal lac operator O i d , with the centres of symmetry separated by 168 bp , corresponding to 16 helical turns . Loop complexes with a linear template are less stable than those that can be achieved with supercoiled templates ( 39 ) . Also , in contrast to the in vitro conditions , loops in vivo appear to be additionally stabilized by architectural DNA - binding proteins which increase the flexibility of the DNA ( 40 ) . Cooperative binding of Lac repressor in vitro is accordingly weaker than in vivo and the sigmoidality of the induction curve restricted to its initial part ( Figure 2A ) .	436469	no
In relation to security , we classified cloud technology where data are sent and stored remotely in the cloud ( i.e. servers belonging to private companies or institutions ) ; tokenization that refers to instances when additional security is applied to the data so that they are non - sensitive or anonymized ; and multiple - factors authentication that focuses on the application of an additional security protocol for data access , e.g. , access to various hardware points to authenticate the user .	233029680	no
"It is a pleasure to acknowledge A. Burrows for the many stimulating discussions , and B. Metzger for comments on an earlier draft of the manuscript . DR gratefully acknowledges support from a Frank and Peggy Taplin Membership at the Institute for Advanced Study and the Max - Planck / Princeton Center ( MPPC ) for Plasma Physics ( NSF PHY-1523261 ) . AP acknowledges support from the INFN initiative "" High Performance data Network "" funded by CIPE . DR and AP acknowledge support from the Institute for Nuclear Theory ( 17 - 2b program ) and from the Theory Alliance - Facility for Rare Isotope Beams ( Topical Program : FRIB and the GW170817 kilonova ) . AP thanks the Institute for Advanced Study for its hospitality and support . SB acknowledge support by the EU H2020 under ERC Starting Grant , no . BinGraSp-714626 . SAF acknowledges support from the United States Department of Energy through the Computational Science Graduate Fellowship , grant number DE - SC0019323 . LFR acknowledges support from U.S. Department of Energy through the award number DE - SC0017955 . The simulations were performed on Blue - Waters , Bridges , Comet , and Stampede , and were enabled by the NSF PRAC program ( ACI-1440083 and AWD-1811236 ) and the NSF XSEDE program ( TG - PHY160025 ) . The analysis employed computational resources provided by both the TIGRESS high performance computer center at Princeton University , which is jointly supported by the Princeton Institute for Computational Science and Engineering ( PICSciE ) and the Princeton University Office of Information Technology , and the Institute for Cyber - Enabled Research , which is supported by Michigan State University ."	85548401	no
Proteins from three independent preparations of r - particles from either wild - type ( UBI3 - HA ) or ubi3ÎN - HA cells were digested overnight with trypsin ( 76 ) . The digests were analysed by liquid chromatography - electrospray ionizationtandem mass spectrometry ( LC - ESI - MS / MS ) using a QExactive plus Orbitrap MS ( Thermo Fisher Scientific ) that was coupled to an Easy - nLC1000 ( Proxeon Biosystems ) . Peptides were separated on a C 18 analytical column ( 75 m Ã 50 cm ) at a 200 nl / min flow rate . The elution gradient was from buffer A ( 0.1 % formic acid in water ) to buffer B ( 0.1 % formic acid in 99 % acetonitrile ) as follows : from 100 % buffer A to 27 % of buffer B for 240 min , from 27 % to 90 % of buffer B for 9 min and from 90 % to 2 % of buffer B for 33 min . The spray voltage was set to 2.1 kV , and the temperature of the heated capillary was 270 â¢ C. The MS scanned a mass range of 200 - 2000 Da . The top 15 most abundant peptides ( ions ) , acquired every 80 ms during 240 min for each sample , were analyzed in data - dependent scan mode . The normalized collision energy was adjusted to 35 % , and the dynamic exclusion was set to a repeat count of 1 , repeat duration of 30 s , and Â±2 m / z exclusion mass width .	17378801	no
Looking to the future , two challenges are likely to constrain clinical surveillance of SARS - CoV-2 in the U.S. and around the world : ( 1 ) declining rates of reportable diagnostic testing as individuals become unwilling or unable to visit testing sites ( Becker et al . , 2021 ) or turn to at - home testing options and ( 2 ) lack of access to archived samples from diagnostic labs ( Abbasi , 2021 ) . This poses particular concerns for identification and characterization of variants of concern or interest . Our data suggest that implementation of wastewater surveillance , particularly with a combination of qPCR , ddPCR , and NGS tools , can mitigate the impacts of these constraints and lead to the development of an early warning system for SARS - CoV-2 , or other pathogens in the future . Overall , such measures can help determine what response to an outbreak is appropriate and evaluate the progress of mitigation or containment efforts . Our data illustrate how wastewater and clinical analyses can be integrated in a large community to evaluate trends in SARS - CoV-2 infections , estimate ascertainment ratios and assess testing adequacy , and rapidly detect the introduction of VOCs at the facility and community - scale . Van Vo , Richard L. Tillett , Katerina Papp are co - first authors and contributed equally .	248325387	no
In the first one , which we could carry to high level , the cancellation was very accurate and became almost perfect once we used additional numerical data provided by [ 14,15 ] . In the second example , carried to low level , the cancellation was less accurate but still convincing . Amusingly , one of the quartic couplings is equal to the area of V 0,4 in the canonical presentation . The cancellations were guaranteed to happen if closed string field theory reproduces a familiar onshell fact : the S - matrix element coupling four marginal operators vanishes . Closed string field theory breaks this computation into two pieces , one from Feynman graphs and one from an elementary interaction , thus giving us a consistency test . Our test has verified that the moduli space M 0,4 of four punctured spheres is correctly generated by the Feynman graphs and the region V 0,4 .	15273018	maybe
Hourly data were only used for the validation step . TROPOMI - based NO2 and SO2 data were compared with TAQMS ground - measurements for three test sites ( urban , urban - traffic and suburban ) in the city of Istanbul . To evaluate MODIS AOD 470 nm data , we applied AERONET data ( AOD440 and AOD500 ) with a time tolerance of Â±0.5 h. Since AERONET does not provide AOD 470 nm , the mean value of AERONET AOD 440 nm and 500 nm values were calculated for AOD 470 nm retrieval relevant to MODIS AOD 470 nm ( Equation ( 1 ) ) . . 3 . The monthly images of tropospheric NO2 column density over Turkey .	238664729	maybe
"Comparison to heuristic methods We first compare SEAL with methods that only use graph structure features . We include eight popular heuristics ( shown in Appendix A , Table 3 ): common neighbors ( CN ) , Jaccard , preferential attachment ( PA ) , Adamic - Adar ( AA ) , resource allocation ( RA ) , Katz , PageRank ( PR ) , and SimRank ( SR ) . We additionally include Ensemble ( ENS ) which trains a logistic regression classifier on the eight heuristic scores . We also include two heuristic learning methods : Weisfeiler - Lehman graph kernel ( WLK ) [ 34 ] and WLNM [ 12 ] , which also learn from ( truncated ) enclosing subgraphs . We omit path ranking methods [ 28 ] as well as other recent methods which are specifically designed for knowledge graphs or recommender systems [ 23,35 ] . As all the baselines only use graph structure features , we restrict SEAL to not include any latent or explicit features . In SEAL , the hop number h is an important hyperparameter . Here , we select h only from { 1 , 2 } , since on one hand we empirically verified that the performance typically does not increase after h â¥ 3 , which validates our theoretical results that the most useful information is within local structures . On the other hand , even h = 3 sometimes results in very large subgraphs if a hub node is included . This raises the idea of sampling nodes in subgraphs , which we leave to future work . The selection principle is very simple : If the second - order heuristic AA outperforms the first - order heuristic CN on 10 % validation data , then we choose h = 2 ; otherwise we choose h = 1 . For datasets PB and E.coli , we consistently use h = 1 to fit into the memory . We include more details about the baselines and hyperparameters in Appendix D.   Table 1 shows the results . Firstly , we observe that methods which learn from enclosing subgraphs ( WLK , WLNM and SEAL ) generally perform much better than predefined heuristics . This indicates that the learned "" heuristics "" are better at capturing the network properties than manually designed ones . Among learning - based methods , SEAL has the best performance , demonstrating GNN 's superior graph feature learning ability over graph kernels and fully - connected neural networks . From the results on Power and Router , we can see that although existing heuristics perform similarly to random guess , learning - based methods still maintain high performance . This suggests that we can even discover new "" heuristics "" for networks where no existing heuristics work . Comparison to latent feature methods Next we compare SEAL with six state - of - the - art latent feature methods : matrix factorization ( MF ) , stochastic block model ( SBM ) [ 18 ] , node2vec ( N2V ) [ 20 ] , LINE [ 21 ] , spectral clustering ( SPC ) , and variational graph auto - encoder ( VGAE ) [ 36 ] . Among them , VGAE uses a GNN too . Please note the difference between VGAE and SEAL : VGAE uses a node - level GNN to learn node embeddings that best reconstruct the network , while SEAL uses a graph - level GNN to classify enclosing subgraphs . Therefore , VGAE still belongs to latent feature methods . For SEAL , we additionally include the 128 - dimensional node2vec embeddings in the node information matrix X. Since the datasets do not have node attributes , explicit features are not included . Table 2 shows the results . As we can see , SEAL shows significant improvement over latent feature methods . One reason is that SEAL learns from both graph structures and latent features simultaneously , thus augmenting those methods that only use latent features . We observe that SEAL with node2vec embeddings outperforms pure node2vec by large margins . This implies that network embeddings alone may not be able to capture the most useful link prediction information located in the local structures . It is also interesting that compared to SEAL without node2vec embeddings ( Table 1 ) , joint learning does not always improve the performance . More experiments and discussion are included in Appendix F."	3573161	no
The Swift spacecraft ( Gehrels et al . 2004 ) started observations of the optical counterpart of LIGO / Virgo GW170817 ( Coulter et al . 2017b , a;Allam et al . 2017;Soares - Santos et al . 2017;Yang et al . 2017 ) with the X - ray Telescope ( XRT , Burrows et al . 2005 ) on August 18th , 03:33:33UT , 14.9 hrs after the GW trigger . Swift - XRT observations span the time range 0.6 â 11.5 days since trigger , at which point the target entered into Sun constraint . Swift - XRT data have been analyzed using HEASOFT ( v6.22 ) and corresponding calibration files , employing standard filtering criteria and following standard procedures ( see Margutti et al . 2013 for details ) . No transient X - ray emission is detected at the location of the GW optical counterpart ( Evans et al . 2017b;Cenko et al . 2017;Evans et al . 2017a ) , with typical count - rate limits of â¼ a few 10 â3 c s â1 . The neutral Hydrogen column density in the direction of the transient is NH mw = 0.0784 Ã 10 22 cm â2 ( Kalberla et al . 2005 ) . For a typical absorbed power - law spectrum with photon index Î â¼ 2 and negligible intrinsic absorption ( see below ) , the corresponding 3 Ï flux limit is â¼ 10 â13 erg s â1 cm â2 ( unabsorbed , 0.3 - 10 keV ) , which is L x < a few 10 40 erg s â1 at the distance of 39.5 Mpc . As we show in detail in Fong et al . ( 2017a ) , Swift - XRT observations constrain the X - ray emission associated with the optical counterpart of LIGO / Virgo GW170817 to be significantly fainter than cosmological short GRBs at the same epoch ( Margutti et al . 2013;Fong et al . 2015;D'Avanzo et al . 2014 ) .	119520159	maybe
As we computed the Alzheimer 's Disease Cooperative Study - activities of daily living scores by adding item responses , data were missing at the level of both items and scores . If five or fewer items were missing , we derived the score from non - missing items and reweighted the score to recover its true range , if more than five items were missing , we considered the score as missing . We then carried out the primary analysis using two statistical strategies , both done in agreement with the intention to treat principle . Firstly , we assessed the primary outcome by considering the crude change in the Alzheimer 's Disease Cooperative Study - activities of daily living score - that is , the score at 24 months minus the score at baseline . A missing score was then handled by imputing the mean value ( estimated from available data ) of the group to which the patient was allocated . We then used a mixed model to analyse data , thus taking into account the correlation within patients and the clustering effect . Secondly , we used a longitudinal mixed model to analyse the 24   Flow of participants through study RESEARCH primary outcome for data at baseline and at 12 and 24 months , which took into account the two levels of correlation : between repeated observations of individual patients and between patients within centres . In this second approach , we did not replace missing scores on the Alzheimer 's Disease Cooperative Study - activities of daily living scale . The statistical model was then used to assess available data only . For each group we estimated the intraclass correlation coefficient . We used Cox marginal models to assess time to admission to institutional care and death , taking into account the clustering effect . Statistical analyses were carried out using SAS software version 9.1 .	33526738	no
Before presenting the actual data , let us describe how low - mode averaging ( LMA ) can be used to reduce statistical fluctuations in the signal .	56129625	no
2 . The potential stability of surface liquid water on rocky planets in elliptical orbits is better characterized by a mean thermal approximation rather than the mean flux approximation . Using observational data , a planet is inside the HZ if their effective thermal distance r T , given by	119193237	no
Spectral Clustering ( Shi & Malik , 2000;Ng et al . , 2002;Von Luxburg , 2007 ) is a leading and highly popular clustering algorithm . It works by embedding the data in the eigenspace of the Laplacian matrix , derived from the pairwise similarities between data points , and applying k - means on this representation to obtain the clusters . Several properties make spectral clustering appealing : First , its embedding optimizes a natural cost function , minimizing pairwise distances between similar data points ; moreover , this optimal embedding can be found analytically . Second , spectral clustering variants arise as relaxations of graph balanced - cut problems ( Von Luxburg , 2007 ) . Third , spectral clustering was shown to outperform other popular clustering algorithms such as k - means ( Von Luxburg , 2007 ) , arguably due to its ability to handle non - convex clusters . Finally , spectral clustering has a solid probabilistic interpretation , since the Euclidean distance in the embedding space is equal to a diffusion distance , which , informally , measures the time it takes probability mass to transfer between points , via other points in the dataset ( Nadler et al . , 2006;Coifman & Lafon , 2006a ) .	3278749	no
The idea is to show that , provided a class of data points takes up enough space , nearly every point in the class lies close to the class boundary . To show this , we begin with a simple definition . Definition 2 . The -expansion of a subset A â â¦ with respect to distance metric d , denoted A ( , d ) , contains all points that are at most units away from A. To be precise	52169956	no
"Although heavily integrated into the consumer electronics market , the IoT extends far beyond handheld devices and home appliances . Indeed , the IoT is already supporting e - health ( e.g. , wearable , implantable , and swallowable smart devices ) , e - energy ( e.g. , smart meters , smart energy harvesting and storage ) , smart buildings ( e.g. , smart windows , smart heating , ventilation and air conditioning , and smart household appliances ) , smart cities ( e.g. , distributed air quality monitoring , smart cameras for traffic control and security , smart lighting , smart parking , and smart electric vehicle chargers ) , smart agriculture ( e.g. , vertical farming with smart lighting and distributed sensors for the monitoring of soil conditions and crops ) , connected cars , and Industry 4.0 . [ 2,3 ] Smart sensor systems [ 17 ] and wireless communications [ 18 ] including digital technologies , low - power microprocessors and microcontrollers , [ 19,20 ] passive and active radio - frequency identification ( RFID ) tags , [ 21 ] wireless sensors , and ZigBee [ 22 ] and Bluetooth low - energy ( BLE ) [ 23 ] wireless communication technologies - are playing a key a role in the global development of the IoT , leading to the proliferation of sensor - rich portable devices . Such sensor - rich devices , combined with or used www.advenergymat.de www.advancedsciencenews.com complementarily with an infrastructure - based computation substrate ( e.g. , the cloud ) , leverage mobility and processing power of the end - users to enhance their ability to sense , compute , and communicate even in the absence of reliable endto - end connectivity . The combination of sensing , data processing , and data connectivity is essential for the IoT to equip daily objects and environments with "" intelligence : "" by sensing key physical quantities , processing the associated signals into information , and finally relaying such information to the endusers , the IoT enables more informed decisions to the benefit of our quality of life . It is important to appreciate that local data processing alone would not be sufficient to equip objects and environments with "" intelligence . "" Indeed , much of this "" intelligence "" also rests on cloud computing and the interaction with the end - users , both of which require data connectivity ."	236302337	no
Upon irradiation with green laser light at 543 nm ( 275 mW cm â2 ) , the DPA / PdOEP doped nanodroplet - containing polymer displayed , even under ambient conditions , bright blue emission ( Figure 3c   www.advmat.de www.advancedsciencenews.com containing either PdOEP or DPA only displayed red phosphorescence or scattered green light , respectively ( Figure 3c , right ) . While dominated by the upconverted blue emission , the PL spectrum of the DPA / PdOEP - containing material shows a weak emission band at 666 nm ( Figure 3d ) , which is associated with residual PdOEP phosphorescence and suggests that the sensitizer - emitter TTET is not quantitative . Time - resolved phosphorescence experiments revealed a single exponential decay with a lifetime Ï ph = 1.50 ms , which is much higher than the value of 20 Âµs observed in the degassed BMB solution , but comparable to the radiative decay of PdOEP . [ 48 ] Thus , these findings suggest that the weak red luminescence belongs to a small portion of the sensitizer that is embedded in the polymer phase , where it is well protected from oxygen and solvent quenching ( Figure S7 , Supporting Information ) . [ 3 ] No fast emission component could be detected , which indicates that for the sensitizer molecules incorporated in the liquid phase , the TTET yield is 100 % and that emitter - to - sensitizers back energy transfer is negligible . [ 3 ] The same excitation conditions were used to acquire the upconversion emission spectra of degassed and non - degassed DPA/ PdOEP reference solutions in BMB ( Figure 3d ( 2 ) showing bright blue upconverted emission . In a polymer that was only doped with PdOEP ( 3 ) , red PL is observed through a 600 nm long - pass filter , while no PL is observed if only DPA is present ( 4 ) . d ) PL spectra of the DPA / PdOEP doped polymer ( solid line ) as well as degassed ( dotted line ) and non - degassed ( dashed line ) BMB solutions containing the same concentration of dyes ( 1.5 Ã 10 â2 m/2 Ã 10 â5 m ) . The laser stray light has been removed for clarity . The inset shows the decay of the upconverted emission from the polymer at 435 nm under modulated 532 nm excitation ( 30 mW cm â2 ) . The red and the blue solid lines show fits of data with the analytical functions used to describe the decay dynamic at high and low densities of triplet exciton , respectively . e ) TTA - UC quantum yield ( Î¦ UC ) of the DPA / PdOEP doped nanodroplet - containing polymer ( triangles ) and a standard system in solution ( dots ) as a function of the excitation intensity . The vertical line marks the excitation intensity threshold I th , where Î¦ UC is half of its maximum value .	205281835	no
Participants were asked about their acceptance of the measures that were implemented by the government during the pandemic . These items changed from W1 / W2 to W3 to do justice to the current situation at the point of data collection . All acceptance items were preceded by the sentence ' I think it is right that the following measures are implemented in Switzerland . ' The response scales ranged from 1 : ' Do not agree at all ' to 7 : ' Fully agree . ' At W1 and W2 , participants were asked about their acceptance of 1 ) closing all schools , 2 ) closing all restaurants and bars , 3 ) advising people not to leave their house , and 4 ) closing all shops except grocery stores and pharmacies . At W3 , participants were asked about the continued and new measures that were implemented at the time , namely 1 ) continued closure of universities and high schools , 2 ) fewer tables in restaurants , 3 ) only a limited number of customers allowed in shops , and 4 ) large events ( e.g. , concerts , football matches ) not being permitted . An overall acceptance score was calculated by taking the mean over all items with higher scores indicating high levels of overall acceptance of the measures put in place ( W1 : Î± = 0.92 , W2 : Î± = 0.88 , W3 : Î± = 0.69 ; cf . Table A3 in Supplement A ) .	234772092	no
In sensitivity analyses we re - analysed data ( 1 ) ignoring diagnoses obtained using primary care data , ( 2 ) limited to fatal endpoints only , and ( 3 ) using information collected after 2004 when financial incentives were introduced for recording patient data on alcohol consumption . We also compared findings obtained using imputed and complete case methods . We carried out a series of post - hoc analyses within subgroups defined by smoking status , BMI and diabetes .	25301376	no
Quantitative evaluation based on the LAR model was carried out for the response curves of the hybrid nanostructures investigated here . In Figure 4a - d the PL responses of the uncoated reference and the coated nanowires are shown as a function of the oxygen concentration for different temperatures . The circles in Figure 4 indicate the experimental data while the solid lines represent the fits according to Equation ( 2 ) .	139453043	maybe
All compoundsw ere purchased from Sigma - Aldrich ( analytical grade ) . All the spectroscopic data shown ( except Figure 3a)c orrespond to the reactions carried out by mixing PTA(0.76 mmol , 150 mL ) with TBAF ( 0.11 mmol , 28 mg ) in methanol ( 3.7 mmol , 150 mL ) and injecting about 2 mLo ft his mixture into the liquid sample cell unit . This particular concentration ( [ PTA ] = 2.53 m)g ave ah igh Rabi splitting and was devoid of any miscibility problems betweenP TA and TBAF solution at all temperaturesu nder investigation . The concentration - dependent experiments were carried out by varying the PTAconcentration from 0.87 m to 3.37 m at aTBAFconcentration of 0.36 m ( [ MeOH ] was varied to maintain [ TBAF ] ) . Thef low cell , compatible with temperature - controlledm easurements , w as purchased from Specac . T he Fabry - Perot cavity was obtained by sandwichingZ nSe windows , coated with aA u ( 10 nm ) film and 100 nm of glass to ensure chemical insulation from the metal , with Mylar spacers ( ca . 6 mm ) . Thes pectra of the cavity reactions were acquired with as tandard FTIR spectrometer ( Nicolet 6700 ) in transmission mode . T he transmission was collected with aD TGS ( deuterated triglycine sulfate ) detector with 1 cm Ã1 resolutiono ver 32 scans . T he gas chromatograms were obtained by GC - MS analysis on aG CS ystem 7820A ( G4320 ) connected to an MSDblock 5977E ( G7036A ) using an Agilent high - resolutiong as chromatograph . For GC - MS measurements , t he reaction was followed spectroscopically for 20 min before the reaction mixture was immediately injected into the GC - MS column . At [ PTA ] = 3.37 m , r oughly 2 mLo ft he sample were transferredtothe GC - MS by washing ( and diluting it ) in 1.5 mL isopropanol .	13995272	maybe
Our study also confronts some limitations , specifically in the data set we use . It should be noted that the data does not cover the contact activities of all populations . For example , the activities from people who do not opt - in to the data - sharing contract of the data provider can not be captured . Contact activities that occurred in non - points of interest may not be included in building the contact links in the network . These limitations in the dataset notwithstanding , fine - grained mobile phone data is widely adopted in modeling epidemics and informing public health policies [ 17 ] . In addition , although our model can accurately predict the pandemic using contact networks , the results do not imply the exact causal relation between contact activities and epidemic spread . Further studies are needed in improving the model to infer the in - depth mechanisms of epidemic spread and to substantiate effective policies in pandemic containment .	233025194	no
Discovering clusters in unlabeled data is a task of significant scientific and practical value . With technological progress images , texts , and other types of data are acquired in large numbers . Their labeling , however , is often expensive , tedious , or requires expert knowledge . Clustering techniques provide useful tools to analyze such data and to reveal its underlying structure .	3278749	no
An abundance of literature is already available on the relationship between wealth and incidences of stroke , with most of the prior studies concluding that greater wealth is generally associated with lower stroke incidence rates ( Ettner , 1996;McClellan , 1998;Meer , Miller , & Rosen , 2003;Smith , 1999;Wu , 2003 ) . The ' wealth effect ' on stroke incidence rates is invariably examined using micro - level survey data ; however , in the present study , we examine this relationship from a different perspective , using populationbased aggregate data to investigate the impact of stock market movements on incidences of cerebrovascular disease .	41103767	no
The EC - LUE ( Eddy Covariance LUE model ) is so named because it is a modified LUE model which was developed using the latent heat flux measured by EC towers in its calculation ( Yuan et al . , 2007 ) . The model relies on air temperature and evaporative fraction ( EF ) to modify LUE . Interestingly , the model constrains GPP by either temperature or water deficiency , depending on which is most limiting ( Yuan et al . , 2007 ) . In the original 2007 model the EF was calculated using latent heat flux and the Bowen ratio ( Yuan et al . , 2007 ) , but later versions of the model use net radiation from climate observation networks , modified by evapotranspiration parameters ( Yuan et al . , 2010 ) . This means Table 2 Simplified description of well - known RS GPP models , and their major strengths and weaknesses for use over peatlands . that the model can now be applied to large areas without tower data , and has also been shown to be more accurate than the 2007 EC - LUE model ( Yuan et al . , 2010 ) . The EC - LUE model was validated against fifty - four sites with EC towers , but these sites only covered six major biomes , and did not specifically include peatland or wetland sites . Yuan et al . ( 2010 ) found that the model overestimated GPP at high latitude sites , and suggested that this may be caused by a high proportion of mosses which have a lower LUE than vascular plants .	3966304	no
Moreover , Sarkar [ 35 ] describes a construction that embeds trees in two - dimensional hyperbolic space with arbitrarily low distortion , which is not possible in Euclidean space of any dimension [ 23 ] . Following this exciting line of research , recently the machine learning community has gained interest in learning non - Euclidean embeddings directly from data [ 28,8,33,29,38,6 ] .	43968607	no
"Adoption of shared decision making into routine practice has been remarkably slow , despite 40 years of research and considerable policy support . [ 1][2][3][4][5][6][7][8 ] In 2010 , the Health Foundation in the UK commissioned the MAGIC ( Making Good Decisions in Collaboration ) programme to design , test , and identify the best ways to embed shared decision making into routine primary and secondary care using quality improvement methods ( box 1 ) . 9 10 The learning from MAGIC derives from a variety of sources , including facilitated shared learning events , clinic and consultation observations , interviews with clinicians and patients , patient and public involvement panels , focus groups , and questionnaires . We assessed progress using "" plan do study act "" data collection tools , 11 monthly project team meetings ( including researchers , clinical teams , healthcare organisations , and patient representatives ) , and an independent evaluation report of phase 1 . 10 Here , we draw on our learning from the three year programme and subsequent experience to summarise the key challenges of implementing shared decision making and to offer some practical solutions ( table 1 â ) ."	11556525	no
"Error bars indicate 95 % confidence intervals estimated by bootstrapping . ( c ) Mean enrichment of all variants of the SSNG ESE motif in individual SRSF2 - mutant MLLrearranged human AML samples relative to the median of 28 SRSF2 - wildtype MLL - rearranged AML samples . Error bars indicate 95 % confidence intervals estimated by bootstrapping . ( d ) Spatial distribution of CCNG and GGNG motifs along cassette exons included or excluded in the SRSF2P95H - mutant samples relative to the median wildtype control amongst MLL - rearranged AML samples . ( e ) Schematic of secondary transplantation experiments of mouse MLL - AF9 leukemias in Srsf2 + /+ ( Vav - Cre + Srsf2 + /+ ) and Srsf2 P95H/+ ( Vav - Cre + Srsf2 P95H/+ ) backgrounds to test the effects of E7107 in vivo . ( f ) WBC counts ( left ) and percentages of WBC cells expressing GFP ( right ) following 10 days of E7107 administration . ( g ) Kaplan - Meier survival curves of recipient mice treated with vehicle or E7107 ( at 4 mg / kg ) in Srsf2 + /+ or Srsf2 P95H/+ backgrounds . Shaded area represents period of vehicle or E7107 dosing . Error bars represent mean Â± SD . * P < 0.05 ; * * P < 0.005 ; * * * P < 0.001 .   ( a ) RT - PCR and ( b ) qRT - PCR analysis of the effect of E7107 exposure ( 6 hours ) relative to DMSO treatment on expression of a cassette exon inclusion isoform ( "" poison "" exon ) of EZH2 in SRSF2 wildtype ( TF-1 ) or mutant ( K052 ) leukemia cell lines . ( c ) Schema of patient - derived xenograft ( PDX ) experiments using primary human acute myeloid leukemia ( AML ) samples wildtype or mutant for spliceosomal genes followed by engraftment into NOD - scid IL2R null ( NSG ) mice . ( d ) Percentage of BM human CD45 ( hCD45 ) cells in NSG mice following 10 days of vehicle or E7107 ( 4 mg / kg / d ) treatment based on spliceosome mutational status . Each point represents hCD45 values for one individual NSG mouse and each color represents PDX from a specific patient . Mutational data for each patient are listed below the graph . ( e ) Immunohistochemical and immunofluorescence analysis for hCD45 in BM sections of recipient mice as shown in ( d ) based on spliceosome mutational status . ( f ) Percentage of BM hCD45 + cells in S - phase based on in vivo BrdU - incorporation following 5 days of E7107 ( 4 mg / kg / d ) or vehicle treatment . ( g ) Bar plots showing percentage of hCD45 + cells that are Annexin V + /PI â or Annexin V + /PI + . ( h ) Representative FACS plots of Annexin V / propidium iodide ( PI ) staining of hCD45 cells following 5 days of E1707 ( 4 mg / kg / d ) or vehicle treatment in vivo . Error bars represent mean Â± SD . * P < 0.05 ; * * P < 0.01 ; * * * P < 0.001 ; * * * * P < 0.0001 ."	15655806	no
As a first step , we coded the data from the interviews and the archival of the responsible-investor.com website to identify major events and structural changes in the regulatory process . Data were ordered chronologically , paying particular attention to changes in the way ' sustainable ' finance was framed in the policy discourse and to the activity and strategic decisions of the key groups of actors shaping sustainable finance reforms . Second , we identified structural changes in the reform process : from voluntary to mandatory ; from sustainability to climate finance . Third , we used temporal bracketing ( Langley 1999 ) to make sense of different phases in the regulatory dynamics . Inspired by Yan et al . ( 2019 ) , we focused on shifts in the relationship between sustainability and financial institutional logics . Fourth , we aggregated our inductive categories , the three temporal phases and major structural shifts in the EU policy debate .	232036490	no
We compared the PV 2C hexamer to that of SV40 Large T - antigen . For T - antigen , a domain comprised of multiple helices contributes to stabilization of the hexamer ( Figure   3D ) . By comparing side views of the 2C hexamer ( Figure   3E ) to that of T - antigen ( Figure 3F ) , it becomes even clearer that T - antigen uses an entire domain to hold the subunits of the hexamer together . The solvent accessible surface area buried in forming the T - antigen hexamer is on the order   Supplementary Table S1 for additional details ) was mixed with increasing concentrations of 2C ( WT , N 39 , D177A , or N 39 D177A ) in the absence or presence of ATP ( 500 M ) . Milliporization ( mP ) was plotted and the data were fit to Equation ( 1 ) , yielding the apparent dissociation constants ( K d , app ) summarized in Table 1 . Error bars represent the SD ( n = 3 ) . ( E ) Stoichiometry of binding between N 39 2C and ssRNA-1 . N 39 2C was titrated into the RNA binding assay in which the total concentration of ssRNA-1 was 10â¢K d , app ( 3 M ) , and the mP was measured . Error bars represent the SD ( n = 3 ) . We defined lines for the two phases of the curve by linear regression and calculated the intersection ( 6 M ) algebraically . This value is twice the concentration of RNA , indicating that 2C binds RNA as a dimer . of 2600Ã 2 , but only 1200Ã 2 for the 2C hexamer . Determinants other than the interactions driven by the carboxyterminal helix of 2C may be required to form a stable hexamer .	252716738	no
Recall from Sec . 2 that we want D to spend enough capacity on both the real data manifold , and the current generated data manifold by G , as well as having adequate capacity in region where we do not currently observe real or fake points but might in future iterations . To enforce this , we apply R BRE on generated data minibatch , as well as random interpolation inbetween real and generated data . Specifically , let x k andx k be a real and a fake data points respectively , we sample Î± k â¼ U ( 0 , 1 ) and letx k = Î± k x k + ( 1 â Î± k ) x k , and apply R BRE on selected layer representation computed on interpolated data points { x k | k = 1 . . . , K } as well .	13669032	no
Procedures for conducting a convincing sensitivity analysis may depend strongly on the specific model and data , and such procedures are still being developed [ 89][90][91][92][93 ] . The choice of other priors to compare is crucial , yet can be controversial . In applications for which the duration of each individual MCMC is long , an exhaustive sensitivity analysis may take a very long time , and efficiencies may need to be introduced . Therefore the guidelines here are general , and the analyst is encouraged to explore the literature for model - specific recommendations . Ultimately , the analyst must be thoughtful in exploring plausibly interesting variations in the prior and be forthright in presenting the results . Because of the potential length of a thorough presentation , online supplementary material may be needed and is encouraged ( see ' Make it reproducible ' ( BARG step 6 ) ) . Reporting points are listed in Table 1 .	237149547	yes
"Our cohort of successfully sequenced tumors encompasses 62 principal tumor types and > 300 detailed tumor types , representative of the diversity of metastatic solid cancer patients treated at our institution ( Fig . 2a , Supplementary Table 2 ) . 43 % of all specimens were obtained from metastatic sites , most commonly liver , lymph node , and bone ( Supplementary   Fig . 5 ) . Two panels were used throughout this study , encompassing 341 genes ( 2,809 tumors , 26 % ) and 410 genes ( 8,136 tumors , 74 % ) , with all 341 genes included in the latter expanded panel ( Supplementary Table 3 ) . Tumors were sequenced to deep coverage ( mean=718X ) to ensure high sensitivity for detecting genomic alterations in heterogeneous and low purity specimens ( Supplementary Fig . 6 ) . Altogether , we detected 78,066 nonsynonymous mutations , with a median variant allele fraction of 0.21 ( Supplementary Fig . 7 ) , as well as 22,989 CNAs and 1,875 rearrangements . The number of mutations and CNAs per sample tended to be inversely proportional ( Supplementary Fig . 8) . 13 The breadth and depth of MSK - IMPACT , and the analysis of patient - matched normal DNA , allowed us to detect important genomic alterations that would have been missed by other approaches ( Supplementary Fig . 9 ) . 81 % ( n=63,184 ) of all mutations fell outside the combined target regions of commercially available amplicon - based "" hotspot "" panels , which are also unsuited for detecting most CNAs and rearrangements . 6,14 Moreover , compared to whole exome sequencing ( WES ) where coverage depth is typically limited , downsampling our data revealed that at least 9 % of all mutations would have been missed by WES to a mean target depth of 150X , including therapeutically targetable alterations in BRAF , EGFR , and MET . Further , while WES is capable of detecting many more mutations throughout the genome and is better suited to the characterization of certain mutation signatures , MSK - IMPACT produces more uniform coverage across the most clinically relevant genes and can also detect targetable gene fusions due to the inclusion of breakpoint - containing introns absent from current WES methods . Finally , as 69 % of somatic mutations detected by MSK - IMPACT were not previously reported in the COSMIC database ( v78 ) 15 , these mutations would have been difficult to distinguish from rare inherited variants in the absence of a patient - matched normal . In summary , our results represent a rich , comprehensive and unique genomic dataset of patients with metastatic cancer ."	7537779	yes
On spinning hard disks , sequential data access can be orders of magnitude more efficient than random data access or access to small files . In the Kaldi toolkit [ 4 ] , we try very hard to ensure that any high - volume data access takes the form of sequential reads or writes on large files .	15370378	no
Advocates and public officials suggest SOGI data can assist providers and staff in providing population - specific treatment based on patient gender and sexuality , yet this argument obscures the fundamental importance of background knowledge on SGM health for providing good care . Providers and staff at both sites confronted the SOGI data as limited information , in one context because of lack of understanding of health inequities in justifying data items , and the other because of data 's inability to stand in for acquired knowledge and experience .	237292347	no
"The general efficacy of supply side interventions in drug markets is , however , under - researched . 5 Although understanding has been limited by a lack of detailed information connected to illicit drug supply , knowledge has improved in recent years with the emergence of online illicit marketplaces , or "" cryptomarkets . "" These cryptomarkets share many characteristics with legal online marketplaces such as eBay , including the provision of a decentralised digital marketplace in which geographically disparate vendors create "" seller pages "" to advertise goods for sale , and the use of customer feedback scores to rank sellers in terms of perceived product quality and service . [ 6][7][8 ] Cryptomarkets facilitate anonymous use through their "" darknet "" location and payment by cryptocurrencies such as Bitcoin . [ 7][8][9 ] The internet has facilitated the sale of licit and illicit drugs for more than 15 years , [ 10][11][12][13 ] but when the first cryptomarket , Silk Road 1 , came online in 2011 , illicit drugs began to be traded in large quantities . The annual turnover of drug sales conducted through cryptomarkets is estimated to be in the hundreds of millions of dollars , 14 with most transactions involving doi : 10.1136 / bmj.k2270 | BMJ 2018;361 : k2270 | the bmj recreational drugs ( eg , cannabis , "" ecstasy "" ) . Before 2014 , prescription drugs represented slightly less than 10 % of all cryptomarket sales . 14 15 People who buy through cryptomarkets are believed to be predominantly male , young ( < 25 years ) , educated , employed , and white . [ 16][17][18][19][20][21 ] Since 2011 , cryptomarkets have been analysed through the digital traces they leave online , 22 using automated software "" crawlers "" that collect publicly available data hosted on websites . The wealth of data available to researchers employing digital trace analysis includes the aliases and purported country level locations of drug vendors and the countries to which they are willing to make shipments . From each product listing posted by vendors on the marketplace , the drug type , price , and quantity can be determined , alongside customer feedback . Using these data , researchers have been able to track the growth of drug trading through the darknet , 14 15 determining overall size , composition , and geographical distribution . [ 20][21][22][23][24][25 ] Feedback posted by customers are used by researchers as a proxy for estimating numbers of transactions and revenues generated by drug vendors ."	49183948	no
In this subsection we perform internal data consistency tests for each pipeline , in order to estimate the magnitude of systematic non - closing errors , e.g. , related to the uncalibrated polarimetric leakage . For that purpose , we inspect closure phases and log closure amplitudes derived from the SR1 data set and evaluate consistency between ( 1 ) RR and LL components , ( 2 ) low - and high - frequency bands , and ( 3 ) trivial closure quantities . For each test , we derive aï magnitude of residual errors , in excess to the reported thermal uncertainties . These values are then used to characterize the magnitude of non - closing errors in the data set , utilized in the downstream analysis .	115150503	maybe
For very slow motions the contributions to 15 N R 1Ï from fluctuations of dipolar couplings between nitrogens and protons that are not directly bonded to them ( including protons on IgG ) may be non - negligible . By considering x - ray structures of GB1 analogues with IgG fragments we estimated that typically the cumulative effect of such couplings should not exceed the effective coupling corresponding to a distance of ~2.5 Ã. In order to evaluate how such contributions would influence the above 3D GAF analysis we refitted the data including an additional term for all the residues corresponding to relaxation induced by 2.5 Ã NH dipolar relaxation . The isotropic S 2 for this contribution was treated as an additional fit parameter . In order to avoid solutions that may violate assumptions of Redfield theory we have also imposed an additional penalty for correlation times that approach the largest relaxation rates . The best fit yielded fluctuations of 3.1Âº , 5.3Âº , 5.6Âº with ÎÎ¸= 11.8 Â° , ÎÏ= 14.7 Â° ( i.e. axes similar to the ones presented in Fig . 3 ) , with a correlation time of Ï= ~54 Âµs and S 2 = 0.999 .	14734673	no
Overall , we found that time - dependent weighting did not improve the fit as the simple additive model provided a better fit in both environments ( Supplementary Fig . 6b ) . This suggests that the relative weighting of reward information did not change over time and thus , can be assumed constant during each reversal . used to generate the data . Except for 4ITl close to 1 , corresponding to a predominantly multiplicative model , magnitude - to - probability weighting can be retrieved accurately .    ( 4ITl ) and magnitude - to - probability weighting ( 4 < â ) used to generate the data , separately for the gambling task ( a ) and three environments of the PRL task ( b - d ; stable : L = 200 ; less volatile : L = 80 ; more volatile : L = 20 ) . ( e - l ) The same as in a - d but showing the likelihood of the additive ( eh ) or the multiplicative model ( i - l ) to be the identified model . ( m - p ) Plots show the differences between the likelihood of the additive and multiplicative models as a function of the parameters of the hybrid model used to generate the data ( the same convention as in a - d ) . Positive ( negative ) values correspond to higher likelihood for the additive ( multiplicative ) model to be assigned as the correct model . The solid black curve indicates parameter values for which â likelihood is equal to 0 , and the dashed horizontal line indicates 4ITl = 0.5 above which â likelihood should be negative . Overall , our fitting method identifies the hybrid model as the most likely model followed by the additive and multiplicative when 4ITl is close to 0 and 1 , respectively . Moreover , we found some bias in identifying the more dominant component ( additive vs. multiplicative ) only in the PRL task for 4ITl around 0.5 , but this bias depended on magnitudeto - probability weighting . For very small 4 < â values , the model identification was biased toward the multiplicative strategy whereas there was a bias toward the additive strategy as 4 < â increased .     There was no evidence that the excluded participants adopted strategies qualitatively differently than the participants included in our study .    	212628840	no
At the same time , the world contains an overabundance of sensory information , requiring organisms with limited processing resources to select and process only information relevant for survival Tsotsos ( 1990 ) . This selection process can be expressed as perceptual action or attentional filtering mechanisms . This might at first appear at odds with the goal of the dictionary learning task , since the selection process necessarily biases the set of observed data for the organism . However , the converse is also true : as better ( or different ) features are learned over the course of learning , the mechanisms for selecting what is relevant may change , even if the selection objective stays the same . If a dictionary learning task is to serve as a realistic algorithmic model of the feature learning process in organisms capable of attentional filtering , this mutual dependency between the dictionary learning and attentional sample selection bias must be taken into consideration .	201486	no
Choi and co - workers come to a similar conclusion with the isoindigo - based conjugated polymers P49 and P50 , in which TVT is utilized as the electron donor unit . [ 92 ] The branching point is separated from the N - position by -(CH 2 ) 6 for P49 , while the corresponding spacer is -(CH 2 ) 3 for P50 . As expected , P49 shows a shorter interchain Ï - Ï stacking distance and higher charge mobility than P50 . Pei and co - workers prepared conjugated polymers P51 - P56 ( Scheme 4 and Figure 4a ) with benzodifurandione - based poly(p - phenylene vinylene ) ( BDPPV ) as the backbone . [ 93 ] In P51 - P56 , the branching points of the side chains are gradually moved away from the respective N - positions . For P45 - P50 , the interchain Ï - Ï stacking is strengthened by prolonging the spacer between the branching points of the side chains and the corresponding N - positions . As shown in Figure 4a , P54 , P55 , and P56 , for which the spacers are -(CH 2 ) 4 , -(CH 2 ) 5 , and -(CH 2 ) 6 , respectively , show an unprecedentedly close Ï - Ï stacking distance , i.e. , as low as 3.38 Ã on the basis of GIWAXS data . P51 - P56 are air - stable n - type semiconductors . Unfortunately , the electron mobilities are not well correlated to the interchain packing distances . Actually , other factors including the polymer packing conformation , thin film crystallinity , and morphology show significant influence on the device performance . Among P51 - P56 , the thin film of P53 shows the highest electron mobility , i.e. , up to 1.40 cm 2 V â1 s â1 .	201831879	no
An exchangeable correlation structure was specified as it is the most appropriate when the data structure is one of repeated measures on the same sampling units using the same measurement approach on all occasions . As noted above a log - link function was used due as the dependent variable is a count variable . Incidence rate ratios were calculated for all models . Margins are statistics calculated from predictions of a previously fit model and summarize the average responsive change of dependent variable related to every one - unit increase of a covariate ( Williams , 2012 ) . Margins were calculated and plotted to present the interaction between monthly cases and IMD Quintile for Model 3 .	237610015	no
Following the colony candidate selection process outlined earlier , we cropped out candidate regions of 160 Ã 160 pixels ( ~267 Âµm Ã 267 Âµm ) across the four backpropagated consecutive frames and separated the complex field into amplitude and phase channels . Therefore , each candidate region is represented by a 2 Ã 4 Ã 160 Ã 160 array . This four - dimensional ( phase / amplitude - time - x - y ) data format differs from the traditional three - dimensional data used in image classification tasks and requires a custom - designed DNN architecture that accounts for the additional dimension of time . We designed our DNN by following the block diagram of DenseNet 28 and replaced the 2D convolutional layers with P3D convolutional layers 47 , as shown in Supplementary Fig . S9 . Our network was implemented in Python ( v3.7.2 ) with the PyTorch Library ( v1.0.1 ) . The network was randomly initialized and optimized using an adaptive moment estimation ( Adam ) optimizer 48 with a starting learning rate of 1 Ã 10 â4 and a batch size of 64 . To stabilize the accuracy of the network model , we also set a learning rate scheduler that decayed the learning rate by half every 20 epochs . Approximately , 16,000 growing colonies and 43,000 non - colony objects captured from 71 agar plates were used in the training and validation phases . The best network model was selected based on the best validation accuracy . Data augmentation was also applied by random 90 Â° -rotations and flipping operations in the spatial dimensions . The whole training process took~5 h using a desktop computer with dual GPUs ( GTX1080Ti , Nvidia ) . The decision threshold value after the softmax layer was set to 0.5 during training , i.e. , positive for softmax value > 0.5 and negative for softmax value < 0.5 , which implies equal penalty to false - positive and false - negative events . We adjusted the threshold value to 0.99 , empirically based on the training dataset before blind testing , to favour fewer false - positive events .	210942672	no
In this case , the experimental apparatus is being used for measurements in a way for which it was not designed . Rooney compares the expectations of the experimental apparatus against the contemporary performance of the collaborations , attributing the difference to creativity . Here we can begin to understand why creativity was expressed as a condition for knowledge formation , in the context of the considerable difficulties of measuring the self - coupling of the Higgs in practice : the predicted low production rate and difficult backgrounds result in very little data , requiring collaborations to model the measurement process such that more can be done with the available data . Creativity , following this understanding , is linked to novel transformations and in this particular case is a condition for a successful measurement outcome .	238769264	no
"Data were analyzed in GraphPad Prism 9 ( San Diego , CA , USA ) and the R software ( R Core Team , 2020 ) . A cosine curve was fitted to the data by a linear least - squares regression method , and a significant 24 - h rhythm was detected with an F - test by the rejection of the zero - amplitude hypothesis using an online cosinor analysis [ 65 ] . Mesor ( the 24 - h time series mean ) , amplitude ( one - half the peak - to - trough difference ) , and acrophase ( the peak time of the fitted curve ) of the significant rhythms , and their 95 % confidence intervals were derived from the cosinor analysis using the R packages "" cosinor "" and "" cosinor2 "" . The mesor , acrophase , and amplitude of significantly rhythmic variables were compared between CTRL and ALAN groups on the basis of 95 % confidence intervals and by Wald tests . To evaluate group differences in non - rhythmic variables , two - way analysis of variance ( ANOVA ) was used with the main factors : regime ( comparison of CTRL and"	253875923	no
In practice , however , finding a reasonable set of weights is largely an iterative procedure 2 : having first found a converging fit with a limited amount of free parameters and no additional weights , it is often easy to notice whether there are features in the data sets not satisfactorily reproduced . These data sets are then assigned some extra weight and , if needed , some previously freezed parameter can be freed and the minimization procedure repeated . In this way we have arrived at the weights listed in Table 1 .	14879958	no
C o l l e c t i n g a w i d e r r a n g e o f socioeconomic predictors may eliminate the need for race variables in models , but increasing the volume of data collected may be infeasible or aggravate concerns about privacy . Just as with differential privacy then , the pure engineering solution of imposing one fairness definition , given conflicting effects , can not solve the underlying value trade - offs .	232233931	no
Across species generalisations are therefore unlikely to be very reliable . In addition we must have enough data to estimate the factor weights reliably . The more factors there are , the more experiments have to be run . In practice , the second prerequisite will be particularly constraining because of the high cost of running experiments .	46975746	no
Of the 57 053 men and women enrolled into the study , 569 were excluded because of a recently recorded cancer diagnosis that had not been registered in the Danish Cancer Registry at the time of the invitation , and a further 37 were excluded because they did not fill in the lifestyle questionnaire . All participants with missing information on variables considered in the analyses where also excluded - a total of 960 men and women with missing data ( 343 for physical activity , 54 for diet , 23 for smoking , 44 for waist circumference , 26 for school education , 96 for first degree family history of cancer , 346 for use of non - steroidal anti - inflammatory drugs , and 26 women for use of hormone replacement therapy ) . Thus , 55 487 men and women were included in our analysis .	18776319	maybe
Adversarial perturbations are either instance - specific or instance - agnostic . The instance - specific attacks iteratively optimize a perturbation pattern specific to an input sample ( e.g. , [ 4,5,6,7,8,9,10,11 ] ) . In comparison , the instance - agnostic attacks learn a universal perturbation or a function that finds adversarial patterns on a data distribution instead of a single sample . For example , [ 12 ] proposed universal adversarial perturbations that can fool a model on the majority of the source dataset images . To reduce dependency on the input data samples , [ 13 ] maximizes layer activations of the source network while [ 14 ] extracts deluding perturbations using class impressions relying on the source label space . To enhance the transferability of instance - agnostic approaches , recent generative models attempt to directly craft perturbations using an adversarially trained function [ 15,16 ] . Figure 1 : Transferable Generative Adversarial Perturbation : We demonstrate that common adversaries exist across different image domains and introduce a highly transferable attack approach that carefully crafts adversarial patterns to fool classifiers trained on totally different domains . Our generative scheme learns to reconstruct adversaries on paintings or comics ( left ) that can successfully fool natural image classifiers with high fooling rates at the inference time ( right ) .	167217657	no
Headache NA Outcome data reported in review meta - analysis .	52883486	yes
"age specific disability weight for diarrhoea reported in the Global Burden of Disease Study 53 and a typical duration of symptoms of one week , 19 we used a disability weight of 0.0023 per symptomatic episode . Often , a threshold of one 28 49 51 to two 54 times a country 's per capita gross domestic product is used as a criterion to gauge whether the incremental cost of an intervention per life year saved or per DALY averted can be considered sufficiently cost effective . WHO describes interventions costing less than a country 's per capita gross domestic product per DALY averted as "" very cost effective "" and those costing between one and three times per capita gross domestic product as "" cost effective . "" 55 Though our main cost effectiveness measure was cost per life year saved - not per DALY averted - we chose a threshold of one times per capita gross domestic product . This approach is slightly more conservative than basing the threshold on DALYs averted as life years saved do not capture the nonfinancial benefits of reducing symptoms in non - fatal cases . 51 Sensitivity and uncertainty analyses To assess the overall robustness of our model and to identify influential parameters for which better empirical data are needed , we performed one way sensitivity analyses by individually varying each input parameter across the ranges shown in the tables ."	3235910	no
For each dataset , once the best - fit 0 is determined by maximizing the likelihood of the input data , we can predictÂ¯and its uncertaintyÂ¯ and covariance matrix at arbitrary position and measure the halo edges . Moreover , Gaussian process also allows one to sample random realizations of the velocity profiles around the mean function , which is convenient for taking the statistical uncertainty due to limited sample size into account . We refer the interested readers to Rasmussen & Williams ( 2005 ) for details .	234357641	no
Hypothesis 3 ( a ) Social impact and ( b ) environmental impact have a positive relationship with firm financial performance . Figure 1 presents the conceptual model that summarizes the proposed theoretical relationships reflecting our interpretation of the main assumptions underlying the sustainable BOP approach . In the next section of the paper , we discuss the data and methods used to test the relationships of the conceptual model .	239667060	no
where h ( 2 ) ij is obtained from ( 13 ) by fixing U = U max ( Ï = constant ) . In the limit U max â â one observes that ( 33 ) gives an additional contribution to the self energy density Îµ div self . To summarize , we have linearly divergent contributions to the self energy density ( 31 ) and to the potential energy density ( 32 ) , in addition there is a logarithmically divergence in the self energy density ( 33 ) . Since the self energy density is infinite in our set up from the beginning their renormalization does not look like a real problem . ( It can be absorbed in a redefinition of the infinite U -integration cut off U max . ) The part which is difficult to interpret is the linear divergence ( 32 ) . It does not introduce an additional scale since Î is dimensionless . However , our calculation seems to imply that in the AdS 7 Ã S 4 case the Maldacena conjecture needs to be supplemented by the information to what value the UV cut off ( in Planck units ) has to be taken in the near horizon limit . We do not know to which data of the M5 brane theory this information belongs .	2800306	no
"We undertook an ecological analysis of factors that predict infant and perinatal mortality , two related measures that include many of the same deaths . The finding from the multivariable analysis indicating that older maternal age is a protective factor was unexpected . Caution is clearly warranted here about drawing any conclusions on causation on this or any other included factors , because an association at the PCT level does not guarantee that the association will hold at the individual level . 22 Furthermore , it may not be possible to assess the strength of the exposure - outcome relationship using ecological data since , for example , the deprivation index value derived for the PCT might include pockets of extremes of deprivation and wealth . Our prior understanding of the likely risk factors for infant and perinatal mortality and the very strong and consistent effects of deprivation in the models makes it highly plausible that deprivation has a direct negative effect . The effect of maternal age , albeit strong statistically , is not in line with our prior understanding and thus may be considered likely to be confounded by other unmeasured factors aliased to that factor . Limitations with available data meant that we were not able to include mothers ' smoking behaviour or parity in the statistical models , factors which may have explained Estimated data on PCT spending on maternity services ( excluding fertility services ) is based on PCT "" PFR4 "" financial returns and strategic health authority "" HFR30 "" forms , sent to the Department of Health as part of the annual financial returns process , and may be subject to some inaccuracy . Nevertheless , the results are valuable , enabling us to draw inferences about the experiences of whole communities and in doing so provide information on the level of avoidable deaths experienced within communities ."	37638399	maybe
where i = j and M X is some high energy scale that we identify with the Grand Unification scale , M X = 2 Ã 10 16 GeV. The size of the off - diagonal elements depends very strongly on the flavour structure of the neutrino Yukawa couplings , which in the seesaw model is not directly connected to the flavour structure of the low energy neutrino mass matrix . In fact , there is an infinite set of neutrino Yukawa couplings compatible with a given set of low energy data [ 36 ] . Among all those Yukawa couplings , the minimal rate for Âµ â eÎ³ will clearly occur in the scenario where	14557250	no
factors including NP , can trigger endoplasmic reticulum stress ( ERS ) which can result in aberrant protein folding . The unfolded protein response ( UPR ) is a is a component of the ER adaptive system that is highly conserved in most eukaryotes . The UPR comprises the principal signaling pathways that involve inositol - requiring enzyme 1 ( IRE1 ) , ( PERK ) , and ATF6 [ 86 ] . All these genes play critical roles in the UPR adaptive system . We quantified the expression of the established ERS markers IRE1 , PERK , ATF6 , and ATF4 , to determine the effects of PtNPs on ERS in THP-1 cells incubated with various concentrations of PtNPs for 24 h. Platinum NPs obviously induced all of these stress markers at all applied concentrations ( Figure 8) . These data showed that PtNPs cause ERS and associated UPR induction in THP-1 cells . Christen et al . [ 87 ] reported that silica NPs induce ERS through the activation of ATF-4 , BiP , and X - box binding protein 1 ( XBP-1s ) in Huh7 cells . The IRE1 gene induces apoptosis by activating apoptosis signaling kinase 1 ( ASK1 ) and interacting with tumor necrosis factor receptor - associated factor ( TRAF)2 . Excessive and prolonged ER stress ultimately causes apoptosis by promoting the expression of CCAAT / enhancer - binding protein homologous protein ( CHOP ) [ 88][89][90 ] . Sustained and long - term ERS accelerates oxidative stress [ 90 ] , which in turn accelerates ERS and activates apoptotic signaling pathways [ 91,92 ] . Overall , PtNPs induced ERSmediated cell death through the expression of UPR genes responsible for adaptation in THP-1 cells .   ( ATF6 ) , and ( D ) ATF4 was analyzed using quantitative reverse - transcription polymerase chain reaction . After 24 h , the fold change in the expression was determined relative to GAPDH expression . Results are expressed as mean fold change Â± standard deviation from three independent experiments . The treated groups showed statistically significant differences from the control group by the Student 's t - test ( * p < 0.05 ; * * p < 0.01 ) . * significant ; * * highly significant .	210826572	no
In logistic regression , we write ( overloading the Ï notation ) log p(y n | x n , Î¸ ) = Ï logit ( y n x n Â· Î¸ ) , where Ï logit ( s ) : = â log(1 + e âs ) . For Poisson regression with log link , log p(y n | x n , Î¸ ) = Ï Poisson ( y n , x n Â· Î¸ ) , where Ï Poisson ( y , s ) : = ys â e s â log y ! . In both cases , we can not express the log - likelihood as an inner product between a function solely of the data and a function solely of the parameter .	44472109	no
Communications proximity , we assumed that these residues are involved in the same exchange process . Consequently , the exchange rate constant , k ex = k AB + k BA and minor - state population , p B , were assumed to be identical for all these residues , and only the chemical - shift differences between the major and minor states , Dd , which are sensitive to changes in the local environment , were assumed to be specific to individual residues . Solid lines in Figure 2 a show best - fit curves of this fit . The fit yields an exchange rate constant k ex of 8600 AE 1700 s Ã1 and a minor - state population p B of 3.1 AE 1.2 % . Residue - wise chemical - shift differences Dd are in the range of 2 - 5 ppm ( all values are reported in Table S1 ) . In order to investigate the reliability of these results , which were obtained from a single R 11 RD measurement , we explored the inclusion of additional , independent data sets : a first possibility , often used in solution - state NMR , would be the measurement of R 11 RD at additional static magnetic field strengths ( requiring , however , access to another spectrometer equipped with a fast - MAS probe ) . As an alternative , we use here a combined fit with CPMG RD data , obtained previously under similar conditions of fast MAS and deuteration . [ 11 ] CPMG RD is sensitive to exchange processes on msms timescales , making a combined fit with R 11 possible . Such an analysis of the present R 11 RD data with CPMG data , also obtained at a magnetic field strength of 14.1 T , yields values of Dd that are very similar to those obtained from the above fit of only R 11 RD data ( see Table S1 ) . The obtained exchange rate k ex is 2900 AE 140 s Ã1 , and the population p B is 9.3 AE 0.6 % . Although these values slightly differ from the values obtained from fitting only a single R 11 RD data set ( where k ex = 8600 AE 1700 s Ã1 , p B = 3.1 AE 1.2 % ) it is noteworthy that the fit curves of the combined R 11 /CPMG fit , shown as orange lines in Figure 2 a , are almost indistinguishable from the fits of R 11 data only , which shows that the present data are in excellent agreement with independent CPMG data . The differences of the fitted parameters point to the well - known fact that it is   ( PDB 3ons ) . Amides 24 and 25 ( black spheres ) are invisible in NH correlation spectra , presumably due to exchange broadening . [ 11 ] c ) Residue - wise differences of the N - H orientations in the crystal structure used here ( type - II b - turn ) and in a structure featuring a type - I b - turn ( PDB 1ubi ) . These angles were obtained by aligning the two structures to all secondary structure elements and extracting the direction of the respective NÃH bonds . -state exchange model using only R 11derived data , while orange lines are derived from a fit that includes CPMG data for residues 23 , 27 , and 55 at 600 MHz , as reported earlier ( see Figure S8 ) . Straight dashed lines ( constant R 11 rate ) in panels ( a ) and ( b ) show the relaxation rate constant obtained at 39.5 kHz MAS and 15 kHz spin - lock field strength , which is considered as free from exchange effects . b ) RD profiles obtained at 20 kHz MAS on a fully deuterated , 20 % reprotonated sample of ubiquitin . Solid lines show simulated R 11 RD profiles assuming an exchange rate k ex = 2900 s Ã1 and population p B = 9.3 % . All available RD profiles , as well as experimental details are shown in the Supporting Information .	6603953	yes
In studying zeolite - based materials with APT , o ne of the most important evaluations of the data is its statistical significance and evaluation in the context of other characterization studies of the ( same or the same type of ) materials . Thelarge size of the data sets generated by APT is one of the greatest assets of the technique as well as one of the potential pitfalls . T he importance of using randomized data sets in cluster analysis was already discussed , and allows for confidence in cluster detection . Other statistical tests can also assist in evaluating the significance of heterogeneities in the data , particularly the FDA .	13743110	no
Our study has several limitations . First , this study was based mainly on the demand side perspective , while the perspectives of the health system stakeholders were lacking . Second , we interviewed only one family member per household . Next , though we aimed to collect data from roughly an equal number of the JSY users and non - users , and also with institutional versus home deliveries , we could not identify sufficient number of JSY users with home delivery . Third , we anticipate that some socio - cultural norms relevant to Indian settings , including the stigma associated with accessing the benefits of programs meant for poor people , might have influenced in the under - statement by the participants of the importance of the cash incentive component in the decision to access institutional delivery care . Finally , as with all retrospective data , it is possible that the time since interview may have shaped both the accuracy and content of women 's reported birth experiences and knowledge of the JSY .	4032646	no
-we learn that in none of the three examples can the new physics strongly dominate over the SM contributions , that is , Îµb c f â« a u f , 1 . Thus , if the data makes a convincing case for a universal pattern of deviations , it would mean that either this pattern is accidental or that the new physics is different from the three specific scenarios discussed here .	119373590	no
Our aim in this paper is to provide a spatially explicit and generic model - coupling framework that can be adapted to virtually any region , following the theoretical workflow proposed by Langhans et al . ( in press ) and shown in Fig . 1 . For demonstration purpose , we illustrate the ultralight workflow , and discuss data requirements and future developments required for light or full applications .	56148378	no
It is well known that native chitosan is soluble in organic acids at pH lower than 6 , but it is insoluble in water , organic solvents , and alkaline medium ( Figure 6 ) . Preparation of different water - soluble chitosan salts is possible by its neutralization with hydrochloric acid , acetic acid , lactic acid , or formic acid [ 43 ] . Its solubility in diluted aqueous solutions can be correlated with the conversion of glucosamine units into the soluble form of R - NH 3 + . Experimental data proved that water insoluble chitosan shows antimicrobial activity in acidic medium , being appropriate for use as a preservative in acidic foods [ 48 ] .	236212916	no
A key strength of this study is that it uses admission data that cover the whole population ( therefore avoiding the potential for selection bias in survey data ) and data from GP practice information systems that provide information on area - level variation in prevalence rates for SMI . The main limitation of the study is its ecological nature ; area - level data will not capture all variation in socio - economic deprivation at the individual level , although this is Notes : Interaction Term denotes an interaction between the EDI Income score and the dummy variable for the year 2010 ; IRR denotes Incidence Rate Ratio ; SE denotes Standard Error ; statistical significance is denoted as Ã¾ ( 10 % ) , * ( 5 % ) , * * ( 1 % ) and * * * ( .1 % ) .	3174407	no
The structure of the evidence shows a clear separation between the regions in data space where the nonlinear damping model is more plausible relative to the linear resonant absorption model and vice versa . There is qualitative agreement between the regions of high marginal likelihood and Bayes factor for the nonlinear damping model and the location of measured data for damping ratio and oscillation amplitude . The evidence is quantified by application to 101 loop oscillations observed with SDO / AIA . The marginal likelihood for the nonlinear damping model is larger in the majority of the cases and conclusive evidence in favor of this model is obtained in 65 cases . The cases with conclusive evidence for the nonlinear damping model outnumber those in favour of linear resonant damping by a factor of 10 . The evidence for the nonlinear damping model relative to linear resonant absorption is therefore appreciable to a reasonable degree of Bayesian certainty .	235606294	no
"While Normalizers use data from a storytelling perspective , Experimenters are interested in granularity and completeness that makes data "" breakdown - able "" to the individual . As Parasie and Dagiral ( 2013 , 863 ) noted in relation to "" programmer - journalists "" in the US , they "" believe that intelligibility is the result of affording access â¦ to complete and granular data from which citizens are usually kept away "" . What matters most is the depth and scope of the legibility and assessability afforded by structured data rather than its ability to strengthen truth - claims ( Normalizers ) ."	149401418	no
Having established that osteoblastic cells were found in a higher density and in a more activated state with increased activation in PTH treated mice compared to control , we hypothesized that this could potentially expand the osteoblastic niche , resulting in an increased number of tumour cells homing to bone . To test this , 12 - week - old female mice were treated with PBS or 80 Âµg / kg PTH for 5 days before injection of DiD - labelled MDA - MB-231 - td tomato - luc2 tumour cells on day 5 into the left cardiac ventricle ( see outline in Figure 1B ) . PTH has a short half - life in vivo and was cleared from the circulation prior to tumour cell injection . Animals were culled on day 7/8 or 12 , and tumour cell numbers in the proximal tibia assessed by two - photon microscopy . We found that pre - treatment with PTH did not alter the number of DiD - positive cells detected in either the trabecular bone area ( Figure 5A ) . Figure 5C indicates examples of DiD positive events in bone imaged by multiphoton microscopy . These data suggest that the PTH - induced alteration of the osteoblastic component of the bone microenvironment does not affect the number of tumour cells seeding to the hind limbs .	52876921	no
To gain further insights on the disciplines contributing to this increasing area of research , we conducted a co - citation analysis of eligible articles to measure the frequency with which two sources are cited together by other documents . Co - citation analysis yields insight into potential disciplinary siloes and theoretical or methodological gaps in the literature . This was possible with 121 of the papers because 10 articles were not indexed on Scopus , where we extracted citation data from .	203580422	maybe
"In the second ( middle row ) , the EHT data are further from the average image than the typical snapshot image ; this model has a p AIS ï <ï 0.01 . This is a model for which no snapshots are likely to be an adequate description of the data , regardless of computational limits . In the third ( bottom row ) , the EHT data are closer to the average image than is typical ; again the p AIS ï =ï 0.01 , and this model is excluded . In this case it is likely that a snapshot could be found , given a sufficiently large number of images from this GRMHD model , that fits the EHT observations well . However , the fact that the reduced Ï 2 is much less than that expected implies that the "" noise "" model , the distribution of stochastic image fluctuations , is wrong . That is , this GRMHD model is too variable . This is akin to finding a reduced Ï 2 much less than unity in the standard fitting process ."	145969867	no
From a methodological viewpoint , this paper aims to fill the existing gap by proposing a new method to estimate a range of potential CO 2 emissions abated . Such range is calculated based on two displacement emission factors which are dynamically computed on an annual basis according to the evolution of the future energy mix . The first factor considers that WE will replace future high - carbon generation providing an upper limit of potential CO 2 emissions avoided . The second factor considers that WE will displace not only high - carbon but also other lowcarbon generation resulting in a lower limit . This method clearly outperforms the displacement estimation methods used in the literature from a scientific point of view since the displacement emission factors are updated periodically . Since this method takes into account how each technology generation evolves , it enables a meaningful comparison of potential CO 2 emissions avoided by WE across countries with high differences among their energy mixes . Furthermore , it avoids an overestimation of the CO 2 emissions abated in those power systems that will become highly decarbonised in the long - term . Additionally , the proposed method may be extended and used to other non - EU regions given the evolution of their respective energy mixes . The proposed method has been implemented in the case study of the European Union by using accurate data for the evolution of the energy mix provided by the EU Reference Scenario 2016 ( European Commission , 2016 ) by the PRIMES model ( E3Mlab , 2006 ) . As a result , this paper presents an exhaustive study of the potential CO 2 emissions avoided by WE in the EUMSs in the long - term . This estimation is a fundamental aspect to be considered by policy officers , when developing the climate change laws and the national energy and climate plans to meet the long - term GHG targets . To the best of the authors ' knowledge , this is the first manuscript estimating the potential CO 2 emissions avoided by WE in the EU by using a dynamic displacement estimation approach .	128352600	no
Given a data matrix X = [ x ik ] , i = 1 , â¦ , n ; k = 1 , â¦ , p , the first step of    The survey provided that the interviewee could assign two priority levels ( high and medium ) to each dimension ( environmental , economic and social ) . Therefore , the responses related to the high priority level were weighted as a single unit , while the responses related to the medium priority level were weighted with the value of 0.5 . The scores obtained were related to the number of cities belonging to each cluster and subsequently indexed on the scale from 0 to 5 .	256000583	no
The relationship between economic growth and energy consumption is considered an urgent issue because the relationship between the two implies many important policy implications ( Chiou - Wei et al . , 2008;Wang , Q. and Wang , L. , 2020 ) . Energy is indispensable for the functioning of the global economic system ( Haider and Adil Masudul , 2019;Mahmood and Ahmad , 2018 ) . Many production and consumption activities use energy as a necessary input . At the same time , economic growth may lead to more energy consumption ( Lee and Chang , 2005;Wang and Zhang , 2020 ) . With the growth of global economy , international trade has developed rapidly ( Shahbaz et al . , 2017;Wang and Zhang , 2021 ) . According to the data collected from the World Development Indicators database , the share of global imports and exports of goods and services in GDP increased from 38.53 % in 1991 to 59.65 % in 2014 ( The World Bank , 2020 ) . Through increased trade flows , the world economy is increasingly integrated ( Trung , 2019 ) . The deepening of globalization makes the economic fluctuations of countries not only limited to their own borders , but may also spread to other parts of the world . Therefore , the spillover effect between countries can not be ignored in the relationship between economy and energy consumption , especially for major economies like China .	231875597	no
The business of company M in manufacturing industry involves daily maintenance of engineering equipment at sites . Thus , the primary goal of its transformations in the pandemic period is to ensure operations continue through remote solutions . First , it has implemented AR to safeguard the virtual presence of safety engineers at its maintenance sites all over the globe . The concept of AR was not new to the company before the pandemic , but the company only had limited experience . Since the start of the pandemic , the company has prioritized the roll - out of this technology and scaled up the adoption throughout the company . Second , WFH has been adopted , however , at the cost of efficiency , as IT equipment in manufacturing industry requires specific adjustments to allow remote access and such adjustments are usually not optimal . For example , before the pandemic , most software in company M would only be used on local networks for security reasons and employees manually connect local databases to enterprise resource planning ( ERP ) systems . In the pandemic period , such a manual connection was impossible as engineers could not go to sites to get the offline data . Thus , the company has developed an interface which connects ERP to a part of its offline databases . Due to partial database availability , several standard business procedures of the company have been delayed . Third , the company has adopted IoT at its production sites , that is to collect critical production data and use cloud analytics to turn this data into valuable insights about the efficiency of the operations . It is worth mentioning that the adoption of IoT has already been underway for 2 years in the company , and the pandemic has just accelerated the roll - out of this technology . Fourth , using data on the state of its equipment , the company has adopted ML to find patterns that help predict and ultimately prevent equipment failures .	245617006	no
"Despite the obvious value of 1 H-13 CH SQC NMR spectroscopy for lignin characterisation , the information provided should not be over - interpreted . Thed ifficulty of performing quantitative analysis is indeed an important limitation of HSQC NMR in general . Semi - quantitative determination of integral ratios is , however , possible when the 1 H-13 Cpairs are located in similar chemical environments , e.g. ,Ca - Ha signals for lignin sidechains or C2 - H2 / C6 - H6 aromatic signals , because 1 J CH assumes similar values under this condition . [ 165,167,168 ] The 1 J CH dependence of polarisation transfer was previously an issue , w ith cross - peaks having different response factors . H owever , v arious adiabatic variants in particular minimise this problem . Indeed , progress has been achieved for quantitative HSQC NMR , using so - called QQ - HSQC and HSQC 0 , w ith pulse sequences allowing better quantification of the identified functionalities . [ 169][170][171 ] However , t hese methods still fail for rapidly and differentially relaxing samples . F or example , i nl ignins , c orrelation peaks from the more mobile endgroups , including the p - coumarates and p - hydroxybenzoates that adorn some lignin sidechains , relax much more slowly than those from units in the polymer backbone and are consequently overestimated by often large factors . Methods for overcoming such issues are still actively sought . Regardless , r egular HSQC NMR experiments still offer highly valuable semi - quantitative , r elative information on the linkage abundance , a llowing for comparison of lignin structures and whole plant cell compositions . [ 167,168,172 ] It should also be noted that 31 PNMR provides quantitative data on the nature of the various OH groups in lignin , and is also capable of quantifying various interunit linkage types in lignins . [ 173 ] Them ost common structural element in native lignins is the b - ether ( usually indicated by the letter "" A""i n HSQC NMR studies of lignins , S cheme 5 ) , accounting for 50 - 80 % o rm ore of the measurable interunit linkage types . The threo ( syn ) and erythro ( anti ) forms of the arylglycerol - baryl ethers are present in amounts that reflect the kinetics of the proton - assisted rearomatisation of the quinone methide ( by water ) ; b - guaiacyl ethers form in approximately equal proportions , w hereas b - syringyl ethers form with erythroisomers predominating by ca . 3:1 ; in both cases the thermodynamic ratio is close to 50:50 , indicating that lignification is not under thermodynamic control . [ 174,175 ] As for all the units in lignins , b - ether units do not possess any optical activity , implying that both the radical coupling itself and the addition of water to the quinone methide intermediate produce fully racemic products . L ignification is therefore concluded , as originally theorised , [ 176 ] to be simply ac hemical reaction , independent of proteinaceous control . [ 155,158,168 ] DFT calculations performed on molecular models have predicted values of bond dissociation energy ( BDE ) for the b - O-4 bond between 54 and 72 kcal mol Ã1 . [ 177][178][179][180 ] Notably , substituent effects can have as ignificant impact on the BDE of a b - O-4 bond . Fore xample , o xidation of the ahydroxy group to ak etone was found to lower the BDE by 15 kcal mol Ã1 . [ 178 ] Ap henylcoumaran unit B has afive - membered ring that results from internal trapping of the intermediate quinone methide by the phenolic - OH following the b-5 coupling   [ 160 ] ( Scheme 5 ) . Again it is racemic , but the ring - closure is transselective such that there is only asingle isomer of the dimeric unit . DFT calculations predict the a - O-4 bond of phenylcoumaran molecular models to have alow value of BDE ( 50 - 56 kcal mol Ã1 ) , suggesting that these structural motifs can easily undergo radical cleavage under conditions of high severity ."	7494868	no
Furthermore , as highlighted by our results , another concern related to user privacy is related to defining who has access to the data . As demonstrated by our review , the beneficiaries in this case are private companies supported or subsidized by governments in their public health protocols to promote public health in the time of the COVID-19 pandemic . Governments must make good use of the collected data and inform users of relevant aspect of the data collection process , such as further use of the data , frequency of use , and so on .	233029680	no
Due to the small difference in mRNA sequences , our pilot study showed that expression patterns of the two subtypes of C. carpio apoA - Ib were undistinguishable , and they consistently represented the overall level for C. carpio apoA - Ib . In this study , we selected one of the intron - spanning primers designed for qRT - PCR to analyze the expression level of C. carpio apoA - Ib ( Table 3 ) . The Î² - actin gene of common carp ( Table 3 ) served as the internal control . PCR was performed in a volume of 12 ÂµL using the StepOne TM Real - Time PCR System ( Applied Biosystems , Foster City , CA , USA ) , including 6.3 ÂµL Power SYBR Green PCR Master Mix ( Applied Biosystems ) , 0.25 ÂµM of each forward and reverse primer , 1.0 ÂµL diluted cDNA and 4.0 ÂµL sterile distilled water . The amplification program was 95 â¢ C for 10 min , 40 cycles of 95 â¢ C for 15 s and 60 â¢ C for 1 min . All samples were amplified in triplicate , and the mean values of the threshold cycle ( C t ) were obtained for further analysis . The relative expression levels were normalized to the quantification of Î² - actin using the 2 âââCt method [ 53 ] . A one - way analysis of variance ( ANOVA ) function in the SPSS 19.0 software ( SPSS Inc. , Chicago , IL , USA ) was applied to the data analysis , and a critical value of p < 0.05 was set as the criterion for statistical significance .	2920272	no
All data in this study are presented as mean Â± SD . In each experiment , all data points were normalized to the mean of the PS amplitude over the 10 min period directly before TBS . For statistical purposes , this baseline period was compared to the last ten minutes of recording ( 80 - 90 min post - TBS ) . The probabilities of significant difference between groups were calculated in GraphPad Prism 5 software , using one - way ANOVA ( one - way analysis of variance ) with a post hoc Bonferroni 's multiple comparison test and using Student 's t - test for probability ( p ) values displayed in Table 1 ; p values of < 0.05 were considered to represent significant differences .	248978256	no
In addition to the polarization , amplitude , pulse shape , and wavelength of light , the OAM can be used as an alternative degree of freedom for multiplexing modulation , enlarging the capacity of optical communication 39 , which is also referred to as mode / spatial - division multiplexing ( MDM / SDM ) 224 . Optical communication by OAM multiplexing has enabled breaking the Tbit level 43,44 , much beyond the conventional scheme , thus greatly broadening the application scope 225,226 . With the study of VB propagation in the atmosphere , free - space communication using vortices was gradually improved [ 227][228][229 ] . Furthermore , a sidelobe - modulated OV method was proposed for free - space communication with a significant increase in the data transmission capacity 230	203638286	no
The release of HRP from the cross - linked networks as well as the enzyme activity was analyzed by means of the HRP - mediated oxidation of colorless pyrogallol to give yellow - colored purpurogallin ( see the Supporting Information ) . Analysis of the data revealed that in hydrogels more than 98 % of the HRP was released within 24 h ( Figure 4 top ) . In contrast , HRP release from the nanogels was slower and incomplete , reaching a plateau at 80 % after 36 h ( Figure 4   	8038502	no
In the recent past , European countries , including Italy , have enacted laws with a growing focus on decentralized , community - based healthcare systems . However , these laws would not succeed in making telemedicine an interesting phenomenon , worthy of consideration . As discussed in this study , the emergence of telemedicine indicates the need to restructure existing health systems because these are perceived to be inefficient in terms of the related costs and benefits . In the case of Italy , 2009 is considered the year that third millennium drugs emerged in the country . However , it was in 2014 that the role of the pharmacy paradigm and its impact at the institutional level toward the territorial provision and de - hospitalization of Italy 's NHS were fully acknowledged . Thus , through this process , the value of the pharmacy in delivering services for primary care rehabilitation was emphasized . Against this background , Italy has encouraged the development of future services technologies applications focused on healthcare systems , which concerns doctors , hospital management , nurses , data management specialists , social security administrators and , certainly , patients , in terms of disease prevention or improved disease management ( Buccoliero , 2010 ) . Telemedicine is an innovation to which several disciplines , such as medicine , IT , and business economics and statistics , can contribute , and its development can not be planned without sufficient , timely information on this phenomenon ( European Commission , 2008 ) .	234818228	no
"If one is varying the quark mass so that q 2 stays negative ( â stable ) , the finite - volume corrections are exponentially small . However , if decreasing the quark mass , the quantity q 2 moves across the cusp from below , the effect blows up rapidly . In this case , the energy levels in a finite volume receive large corrections , which should be taken into account . On the other hand , the "" raw "" data on the energy levels at a fixed volume , which are depicted , e.g. in Fig . 4 , are smooth functions of the quark mass and do not exhibit any cusp ."	18496726	no
To generate the descriptive figures , we performed a binning procedure for each participant to ensure that each point on the x axis contained an equal number of elements . For each participant , we divided the y variable in question into quantiles and used the mean y value of each quantile as the binned value . To plot data from all participants on the same x axis , we first determined the median x value for each bin per participant , then took the average of the bin median values across participants . For some figures containing more than one plot , we shifted the x values of each plot slightly off - center to avoid overlap of points ( Figs 5 , 7f , g ) .	146116067	no
Experimental methods pp . S6 - S9 . Synthesis of reaction standards pp . S10 - S30 . Supplementary figures and tables Figure S1 . Biosynthesis of vanillin from glucose Figure S2 . Methylated catechols in APIs Figure S3 . Irreversibility of COMT - catalysed methylation Table S1 . Activity and regioselectivity of COMT mutants Figure S4 . Activity and regioselectivity of COMT mutants Table S2 . Kinetic parameters for selected COMT enzymes Figure S5 . pH profile of WT and K144A COMT Table S3 . Crystallography data for WT dimeric and Y200L dimeric COMT Figure S6 . Preliminary X - ray crystal structure of Y200L COMT with DHBAL and SAH Figure S7 . Gel filtration chromatogram for COMT monomer and dimer Figure S8 . Calibration for gel filtration chromatography Table S4 . WT monomer and dimer activity and regioselectivity Figure S9 . Oligomeric forms of COMT in solution Figure S10 . Stability of WT COMT under dilution and typical reaction conditions Figure S11 . Stability of WT and Y200L monomeric and dimeric forms Figure S12 . Regioselectivity of WT and Y200L monomeric and dimeric forms Figure S13 . X - ray crystal structure of dimeric COMT with DNC and AdoMet bound Figure S14 . AdoMet analogue assays Table S5 . Primers used for COMT mutagenesis Figure S15 . SDS PAGE of Ni - NTA purification of COMT Figure S16 . SDS PAGE of COMT anion exchange and gel filtration purification Figure S17 . HPLC analyses of COMT assays with authentic standards Figure S18 . Calibration curves for substrates 1a - d and products 2a - d and 3a - d Figure S19 . 1 H NMR of enzymatic 4a Figure S20 . HPLC chromatogram of 4a Figure S21 . 1 H NMR of enzymatic 4b Figure S22 . HPLC chromatogram of 4b Figure S23 . 1 H NMR of enzymatic 4c Figure S24 . HPLC chromatogram of 4c p. S31 .	9972763	maybe
â¢ The corrections factorize to yield the derived result . The goal is to perform a measurement that is unbiased and does not preempt the target model . Therefore all corrections are validated using complementary data from the LHC or other material sources , as well as physics models . Each correction is subject to uncertainties that bear on the precision of the simulation and that quantify the uncertainty of the derived measurement . 5 If the corrections are exhaustive , the derived measurement is thus ' valid ' , independent of any target model . â¢ The direct measurement is an a priori unknown part of the measurement process .	244199112	no
After excision of the hypothalamus and pituitary gland , brain tissue was homogenized in ice - cold saline with a tissue homogenizer . The whole - brain tissue homogenate , without the hippocampus , was centrifuged at 3000 rpm for 10 min , and the supernatant was subjected to measurement of superoxide dismutase ( SOD ) activity , malondialdehyde ( MDA ) level , and total antioxidant capacity ( T - AOC ) using SOD , MDA , and T - AOC kits ( Jiancheng Biotechnology , Nanjing , China ) , according to the manufacturer 's instructions . All antioxidative data was normalized to the protein concentration of the supernatant and quantified using a BCA protein assay kit . All experiments were performed in at least four parallel replicates and repeated three times .	254808058	no
where x ( k ) , y ( k ) are samples from data , and q ( Â· ) denotes the estimate for q ( Â· ) .	6714375	no
All data were converted in Matlab ( The MathWorks Inc. ) and analyzed with an Igor Pro 6.7 ( from David Sulzer , Columbia University ) . A 1 - kHz ( binomial sm . ) filter was applied to all amperometric traces and the threshold for peak detection was 3 times the standard deviation of the noise . Amperometric traces were inspected manually after peak selection to avoid false positives . All statistics were performed in GraphPad Prism 8 ( GraphPad Software Inc. , San Diego , CA ) with unpaired Mann - Whitney rank sum test . Statistical significance was designated at p < 0.05 and all data are presented as mean of median Â± SEM . There is no significant difference between 5 - HT and 5 - HT + cisapride treated cells ( p = 0.41 ) . Pairs of data sets were compared with a Mann - Whitney rank - sum test . n > 35 cells . * p < 0.05 , * * p < 0.01 , * * * p < 0.001 , and * * * * p < 0.0001 . Pairs of data sets were compared with a Mann - Whitney rank - sum test . n > 19 cells . * p < 0.05 , * * p < 0.01 , * * * p < 0.001 , and * * * * p < 0.0001 . Figure S3 . Amperometric peak analysis . Comparisons of ( A ) peak current ( p = 0.34 ) , ( B ) half peak width ( p = 0.032 ) , ( C ) rise time ( p = 0.24 ) , ( D ) fall time ( p = 0.057 ) from SCA from control ( white ) and 100 nM cisapride treated ( ash grey ) BON cells . The rise time of each spike , trise , is defined as the time spent from 25 % to 75 % of the peak height on the rising part of the peak and corresponds to the opening time of the fusion pore . The fall time of each spike , tfall , is defined as the time spent from 75 % to 25 % of the peak height on the falling part of the peak . Pairs of data sets were compared with a Mann - Whitney rank - sum test . n > 19 cells . * p < 0.05 , * * p < 0.01 , * * * p < 0.001 , and * * * * p < 0.0001 . Figure S4 . Amperometric pre - spike foot analysis . ( A ) The foot current , Ifoot , which is proportional to vesicle content , was significantly increased after 5 - HT preincubation ( p = 0.047 ) and 5 - HT + cisapride treatment ( p = 0.045 ) . ( B ) The duration of the foot , tfoot , was slightly but not significantly increased in both 5 - HT ( p = 0.25 ) and 5 - HT + cisapride ( p = 0.60 ) treated cells . ( C ) The charge of prespike feet , Qfoot , which is correlated to the number of 5 - HT molecules released during pre - spike foot , was significantly increased in 5 - HT ( p = 0.0093 ) and 5 - HT + cisapride ( p = 0.039 ) treated cells . The percentage of spikes with prespike foot was 80 % in control BON cells , 76 % in 5 - HT treated cells , and 78 % in 5 - HT + cisapride treated cells . Pairs of data sets were compared with a Mann - Whitney ranksum test . n > 35 cells . * p < 0.05 , * * p < 0.01 , * * * p < 0.001 , and * * * * p < 0.0001 .	236951809	no
As shown in Figs . 6 , 88 % of the research articles reviewed in our study adopted a qualitative rather than a quantitative approach to provide analysis regarding the implications of COVID-19 for sustainability . As a result , the lack of quantitative methods in examining the COVID-19 crisis and its impact on the environmental , social , and economic dimensions of human lives and making projections on the future of world sustainability aftermath of COVID-19 are highly visible . Employing quantitative methods to conduct more data - driven research and using real data to provide an adequate and reliable assessment of the changes made to various aspects of sustainability due to the pandemic is highly recommended for future research . In this regard , mathematical and statistical analysis and simulation models informed by real data can harmonize the research results in this area .	233664324	no
Google Trends : Google Trends provides a comparison of the search volume of different queries over time . Google assigns a popularity index ranging from 0 to 100 to keyword searches in which 100 represents the maximum search interest for the selected location and time ( Google Trends , 2021 ) . Fig . 5 represents the Google Trends values for our focal search terms in the three cities as a time - series . The data represent the relative search interest for that specific term in that specific geographic region as a proportion of all searches on all topics in Google . We build on the literature on the use of Google Trends data for pandemic - related studies ( e.g. , ( Ahmad et al . , 2020 ) , ( Asseo et al . , 2020 ) ) . However , in contrast to extant literature that studied the effect of Google Trends on cases / incidence , we use the search trends data to measure consumers ' risk perception and analyze its impact on retail mobility .	255441206	no
Descriptive characteristics of cities and sub - cities are displayed in Table 1 . Overall , the median population size and growth among cities is similar across countries . On the other hand , urban form and transport characteristics such as population density and travel delay varied considerably across countries , with lower population density in Argentina and higher in Colombia , and travel delay lowest in Argentina and Brazil and highest in Colombia . The level of fragmentation and the percentage of built - up area also varied among cities and countries . The distribution of the greenness index ( NDVI ) varied from a median of 0.33 in Peru to 0.85 in Central America . For a smaller subsample of cities in three countries for which data on motorization rates were available , we observed that Brazil had the highest median , followed by Mexico and Chile .	231919930	no
The asymmetry of companion - stripped material introduces a viewing angle dependence of the narrow emission line profiles . Figure 3 shows the synthetic nebular spectrum of the day 200 MS38 model as observed from a number of viewing angles . While the total integrated luminosity of HÎ± is independent of viewing angle in optically thin ejecta , the line profiles do depend on the orientation . At Î¸ = 0 â¢ , the bulk of stripped material is moving toward the observer , resulting in a blue - shifted HÎ± peak . For Î¸ = 180 â¢ , that region is moving away from the observer and the HÎ± peak is red - shifted . For intermediate angles , the feature is broader and has lower peak luminosity . In general , we expect that the HÎ± peak will be shifted by â 10Ã from its rest wavelength due to orientation effects , which should be taken into account when trying to extract flux limits from observational data .	119196949	no
HTVS approaches have been used predominantly to predict the performance of materials for a variety of applications . These approaches provide a perspective pathway to demonstrate the predictive performance of various ML algorithms for battery material application . HTC works as an important tool to minimize the developmental cost of new materials for battery electrolytes and interfaces . Further these tools not only support futuristic material discovery and corresponding experimental setups , but also the underlying statistical approaches may lead to interpretation of relations between feature and prediction parameters that could be used as an input to theoretical models . The elementary building blocks of such analyses , that is screening , calibration with experimental data statistical analysis - based ( ML or regression ) and feedback loops can be adapted to the problem of interest , lending these approaches large flexibility . Clearly , several challenges remain to be addressed for future applications to further improve the capabilities of HTVS approaches . For instance , the studies discussed above mainly focused on bulk quantities such as redox stabilities or solvation properties . However , for battery chemistries such as LIBs and LMBs , interfaces and interphases are extremely important to the overall cell performance . Therefore , incorporating interfacial properties - although challenging - will likely be extremely rewarding for future approaches . In this context , it is also important to stress that the vast majority of HTVS approaches in the field of battery science relied on ab initio techniques . To assess , e.g. , interfacial properties on larger scales , approaches based on classical MD or even ML - derived force fields seem to provide another thriving avenue of research .	243997418	no
To check that these large correlations are not a cutoff effect -there is after all a large cancellation taking place at short distance in the subtracted correlator -we have repeated the 1.24 T c calculation at a finer lattice spacing . The comparison is shown in Fig . ( 5 ) . We see that the different data sets fall on top of eachother within errors in the interval 0.4 < T r < 1.2 . We thus conclude that the strong , finite - temperature induced enhancement of the correlation is a true physical effect .	15942514	no
In summary , an optical network that includes K diffractive surfaces can be optimized using deep learning through training examples of input / output fields that correspond to a target transformation , A. Starting with the next section , we will analyze and compare the resulting all - optical transformations that can be achieved using data - driven ( deep learning - based ) as well as datafree designs that we introduced .	237267110	no
Cellular - resolution , cross - sectional imaging using small - diameter catheters has been elusive in the field owing to the narrow usable imaging range when the beam emanating from the optical fibre is focused onto a small spot . This issue is further problematic when imaging luminal organs inside the body , where the device is at an unknown distance from the lumen wall and the luminal surface is irregular . In this study , we demonstrated a technique that overcomes these problems by implementing few - mode interferometry that increases the DOF by more than an order of magnitude . The novel mode division multiplexing / demultiplexing method enables the use of multiple time - delayed circular modes for imaging signal encoding and decoding in a single - modemultimode fibre system . Because of its small footprint , depth - encoding capability , and transmission stability , this optical configuration has important applications in depthresolved endomicroscopy . A clinically adaptable system based on few - mode interferometry for intravascular imaging was developed . The multiple propagation modes with encoding image information transmitted in parallel substantially increase the system acquisition capacity without adding an extra physical data path . Though the pseudo - Bessel beam fields corresponding to the highorder modes could present reduced collection efficiency and produce side - lobe artefacts compared to the conventional Gaussian beams 23	208225029	no
8 On the other hand , a forward - model including only LkCa 15 bc , resembling the reconstructed images from 2009 November SAM data ( Kraus & Ireland 2012;Sallum et al . 2016 ) , is morphologically inconsistent with our real 2009 November data , as it would reveal the planets as separate point sources . The SAM image reconstructions in some cases are therefore not faithfully reproducing the spatial distribution of astrophysical signals near LkCa 15 .	152282903	maybe
Additionally , we note strong instrumental effects present in the UVES data , particularly those affecting the wavelength solution , require us to implement SVD techniques to mitigate their influence on the transmission signal . These techniques are known to remove part of the exoplanet signal . Indeed , we determine signal losses â¼10 - 20 % for |v offset | > 16 km s â1 . A stabilized spectrograph would not suffer from such instrumental effects , which may improve the S / N per transit .	119537582	maybe
The NuSTAR pulse properties differ from the 2003 measurements . Although the linear increase in modulation with energy is also evident at the earlier epoch , at roughly the same slope , the modulation for the newer data is half ( e.g. 22 % vs. 46 % at 3 keV ) that measured during the previous outburst . This might be due to the larger area of the present emitting region , additional flux from the whole NS surface , or a different location of the emitting region during this early epoch of the 2018 outburst . The energy dependence of the modulation and phase shift of the pulse profile also suggests that the spectral components are currently not precisely co - aligned , unlike the previous outburst . This may be transitory , as no phase shift with energy is evident following the 2003 outburst .	119354518	maybe
Communications neutrophils , w hich are immune cells that are an essential component of the antitumoral action of ingenol mebutate ( 2 ) . [ 19 ] This is supported by findings in cultured human endothelial cells , w here 2 induces secretion of the neutrophil - attracting chemokine IL-8 and surface expression of the adhesion molecules E - selectin and ICAM-1 in aPKC - dependent manner . Knockdown of PKCd by small interfering RNA ( siRNA ) completely abolished neutrophil recruitment to endothelial cells subsequently treated with 2,t hus proving the essential role of this specific isoform in the process . [ 20 ] Comparison of the activity of ingenol analogues 5 , 6 , 9 , 10 , 13 with the reference ingenol ester 3 in the PKCd activation and the keratinocyte IL-8 release assay revealed ac lear structure - activity relationship ( Figure 4 ) . Removal of asingle hydroxy group at either position C5 or C4 ( compounds 5 and 6,r espectively ) only resulted in am oderate loss of potency , and removal of both the C4 - and C5 - hydroxy groups ( 9 ) resulted in am arked loss in activity : a pproximately 100 - fold in PKCd activation and 16 - fold in IL-8 induction when compared to 3.Anear - complete loss of activity was observed for analogue 10,inwhich the ester function was moved to the C19 position , and C3,C4,C5 - des - hydroxy ingenol 13 was totally inactive . S urprisingly , d espite previous literature data , [ 11 ] removal of the C18 - methyl group ( compound 3 ' ' ) d i d not negatively affect the potencyof3 .	15989169	no
"To probe the magnetic field dependence of lasing in the rubrene : DBP slab waveguide , we modulate the pump power and magnetic field simultaneously with the apparatus depicted in Figure 4a . To avoid changing the number of lasing modes ( which would in turn affect the lasing threshold ) , we maintain a constant sample position , with pump power controlled using a variable neutral density filter attached to an automated 1D translation stage . Input pulse energy is measured using a portion of the incident beam diverted with a 90:10 beamsplitter , while output pulse energy is detected on a thermoelectrically cooled silicon camera . Figure 4b shows the magnetic field dependence of the laser response , demonstrating switching between sub - threshold and above - threshold operation and a +360 % enhancement in output intensity at an input pump energy of â2.4 nJ. Error bars represent the standard deviation of ten data points , due to noise in the collected emission and pulse - to - pulse variation in excitation power . The inset shows how the edge emission spectrum changes with applied magnetic field for the highlighted data points . Fitting the rightmost four data points of each curve , we estimate the lasing threshold of the device to be 2.49 nJ at zero applied magnetic field and 2.31 nJ at 0.4 T applied magnetic field , representing an â7.2 % decrease in lasing threshold with applied field . These results are in good agreement with theory based on the â8 % modulation in steady - state rubrene : DBP photoluminescence from Figure 1c . ( See the Supporting Information for a derivation of the expected change in lasing threshold with magnetic field . ) Finally , we demonstrate that our rubrene : DBP laser can be repeatedly modulated between "" off "" and "" on "" states with an external magnetic field ( Figure 4c"	244402577	no
Sections in the video - recorded data relating to the internet were selected for additional transcription using the Jeffersonian system ( Jefferson 2004 ) , which includes details such as overlaps in talk , pauses , emphasis on particular words and changes in the tempo of interactions . A key to the notation is shown in figure 1 . The additional transcription facilitated conversation analysis ( CA ) to consider how actions were constructed and produced in the consultations ( Sidnell2010 ) .	231818279	maybe
Quantitative label - free liquid chromatography - mass spectrometry ( LC - MS ) was then used to identify and quantify the HC composition as reported before . [ 3 ] NCS was used as the control serum . HCs from the GO , GO - N 3 , GOâ¡ , and C 2 GO were detached from the graphene using a buffer solution at 95 Â° C for 5 - 10 min ( see Table S1 in the Supporting Information for formulation ) and analyzed in technical duplicates . The profiling results obtained by LC - MS were expressed as relative protein abundance ( RPA ) in percentage , as shown in Figure 2A. The top 30 proteins with more than 0.5 % total protein RPA in at least one of the HC samples were selected for further analysis . The protein recovery from the top 30 proteins was 99+% for all HC samples . Other HC proteins found with < 0.5 % total protein RPA were neglected for further analysis . Each of the selected 30 HC proteins was ranked within each HC sample by the RPA ( relative protein abundance among the 30 proteins ) , color - mapped and compared with the RPA of the control serum ( see Table S2 in the Supporting Information for summarized protein information ) . Each graphene - HC RPA profile was regarded as 30 variables and analyzed using multivariate analysis ( MVA ) , i.e. , principal component analysis ( PCA ) . PCA reduces the data into a smaller number of artificial variables known as the principal components ( PC ) , that is , the linear combinations of the original variables ( 30 protein RPA per graphene type ) . The PC that accounts for ( explained ) the most , and the second most variances in the data ( i.e. , most of the data variances are happening along the PC coordinate ) is known as the first PC ( PC-1 ) and the second PC ( PC-2 ) , respectively . [ 19 ] Two PC analyses were performed . First , RPA% of the control serum and the graphene - HCs was first analyzed to see if the serum RPA% is significantly different from the graphene - HC RPA% , i.e. , to verify if graphene - HC RPA% is uniquely different from the serum . Second , the 4 graphene - HC RPA% were compared with each other to verify if the HC profile is significantly different . In brief , each HC profiling RPA% data can be considered as a vector in 30D space ( each sample has 30 RPA measurements ) . Dimensionality reduction was performed by Eigenanalysis of the correlation matrix ( where the variables are standardized ; otherwise the proteins with small RPA would not contribute much to the analysis ) . The Eigenvalues ( the fold changes / stretches of the Eigenvectors after linear transformation , i.e. , the vector scalar ) and the Eigenvectors of each PCs were obtained . Eigenvalues are shown in the PC screening plots ( Figure S5A1 , Supporting Information ) , to identify the number of the PCs needed to explain most of the variance in the data . The higher the PC Eigenvalue , the more variances are explained ; for the first PCA analysis , since the PC-1a and PC-2a combined would cover +80 % of the total Eigenvalues combined , the 30D vector can be dimensionally reduced into a 2D subspace while still capturing +80 % of the variance in the data , i.e. , the critical data information was maintained . The loading plot provides additional visual interpretation of the PC correlation by plotting the Eigenvectors of each variable for PC-1a and PC-2a ( Figure 2B1 and Figure S5A2 ( Supporting Information ) ) . The PC-1a and PC-2a scores ( shown in Figure 2B2 ) are the linear combinations of the original data . The larger the absolute value of the variable Eigenvector ( either positive or negative ) , the greater importance of the corresponding variables ( proteins ) in calculating the PCs . Positive and negative Eigenvectors contribute to positive and negative PC scores , respectively . From Figure 2B2 , a clear separation between serum - RPA profile and graphene - RPA profile based on PC-1a can be seen , i.e. , there is a definite difference in the protein composition for the control serum and all the graphene - HC . Proteins with positive PC-1a Eigenvector values ( 24 out of 30 proteins tested ) were found to have higher RPA on graphene derivatives , i.e. , to have higher graphene binding affinity resulting in uniquely different graphene - HC profiles that are significantly different from the background serum protein profile ( Figure 2B2 , xaxis ) .	205288041	no
( d ) DRDDS @ 15 dim . Figure 6 : Classification summaries of PCA , IG , MI , CST , and CFS on four EHR data sets by varying both feature normalisation methods and classifiers . The left column summarises the classification statistics presented in Fig . 5 , and the right columns lists the feature rankings provided by CFS in a descending order over each data set for intuitive explainability . Best viewed in colour .	231573178	maybe
We derived a range of further demand - side variables . For each LSOA , we recorded the SMI prevalence , ethnicity , the percentage who are married , and the percentage of single person households . SMI prevalence is available at GP practice level from the Quality and Outcomes Framework dataset ; we attributed it to LSOAs on the basis of the number of patients in the practice residing in each LSOA area , as indicated by the Attribution Data Set ( ADS ) . For example , if 50 % of a practice 's patients are resident in a particular LSOA , 50 % of its SMI patients were apportioned to that LSOA . We also derived the count of the population aged 15Ã¾ , and a vector of percentages of the population aged 15Ã¾ in various age - sex groups . 5 - year age bands were used for these groups from age 15 upwards , with wider bands of 65e74 and 75Ã¾ in the older age groups , resulting in a roughly equal proportion of the sample in each group . Information on age and gender distributions was derived from the ADS , whereas information on LSOA characteristics is provided from Census data by the Office for National Statistics .	3174407	maybe
As baselines , we compare to gradient descent with restarts on the nonconvex objective ( Eq . 3 ) and the EM algorithm from Miao and Rao [ 11 ] run for 20 iterations and augmented with the SVD based disentangling method ( Theorem 3.4 ) . These two methods represent the two classes of existing approaches to estimating general linear transformations from pairwise data [ 11 ] .	11078274	no
"is identifiable from the inputs , and C(X Y ) = 0 otherwise ( neither are identifiable ) . We conjecture that the ACI rules ( 1)-(11 ) are "" order-1 - complete "" , i.e. , they allow to deduce all ( non)ancestral relations that are identifiable from oracle inputs for all conditional independences of order â¤ 1 in observational data . For higher - order inputs additional ACI rules can be derived , however , our primary interest in this work is improving computation time and accuracy , and we are willing to sacrifice completeness for that . A more detailed theoretical study of the completeness properties is left as future work ."	949525	no
Remarkably , the slope of the fitted data is 0.75 in Equation ( 2 ) with a standard error of Â±0.04 . For UPS , the slope of 0.62 Â± 0.09 is also less than unity ( Equation ( 3 ) ) , and consistent with the value reported by Yoshida . [ 52 ] Hence , both SWV and UPS experiments reveal that for these DPP polymers , and their solar cells with PCBM , the linear correlation between V oc and ( E HOMO , D â E LUMO , A ) has a slope less than unity . In contrast , we note that Scharber et al . , in a study on 26 different bulk heterojunction blends , found a correlation with a slope equal to 1 between V oc and the redox potential difference . [ 21 ] A linear correlation between V oc and the HOMO and LUMO energies with slope 1 has also been seen in various other studies , [ 6,54 ] usually for a smaller set of materials , but deviations with slope < 1 have also been reported . [ 52,55 ] At present , it is not possible to resolve the discrepancies between these various studies . Nevertheless , it is of interest to consider possible explanations for our finding of a slope < 1 . One effect to be considered is the dependence of the generation rate G on the HOMO level . DPP polymers with higher HOMO energy tend to have lower optical band gap and can therefore generate more charges . For solar cells of the polymers in Table 1 , 2PyT ( E g = 1.73 eV ) gave the lowest short - circuit current density ( J sc ) ( 7.00 mA cm â2 ) , [ 56 ] while TDTPT ( E g = 1.23 eV ) gave the highest J sc ( 20.5 mA cm â2 ) , [ 57 ] i.e. , a factor of â3 . Assuming that G is proportional to J sc , one would expect a difference of ( kT / q)ln(3 ) = 28 mV via Equation ( 1 ) , which is an order of magnitude too low to explain a change in slope from 1 to 0.75 .	104323766	no
Our approach employed Bayesian procedures to combine independent inputs from three data sources : diagnostics timing estimators , gag - pol - based sequence timing estimators and rev - env - nef - based sequence timing estimators . The sequence - based estimates were first fit using the frequentist methodology implemented in Poisson Fitter by employing the steps described below , with the aim of optimizing the estimate of infection time . These Poisson Fitter estimates were then converted to corresponding Bayesian Poisson process regression models to yield probability assessments for incorporation into downstream analyses , maintaining high concordance in both point estimates and uncertainty intervals across the Bayesian and frequentist implementations . When the two sequenced regions yielded distinct time estimates ( that is , the 95 % posterior credible intervals did not overlap ) , the gag - pol region was chosen for the final time estimate since it does not encode proteins targeted by the VRC01 bnAb , and therefore the rates of evolution over this region of the viral genome may be impacted to a lesser extent by targeted selection .	251742233	no
"This procedure is similar to the "" sky scramble "" technique used in pulsar timing searches for very lowfrequency gravitational waves ( Cornish & Sampson 2016;Taylor et al . 2017 ) . In pulsar timing experiments , the analogue to the overlap reduction function is the Hellings and Downs curve , which quantifies the expected correlations between pulsars as a function of their angular separation on the sky ( Hellings & Downs 1983 ) . By artificially shifting pulsar positions on the sky , one can seek to disrupt this spatial correlation and produce null data devoid of gravitational - wave signal but that retains other ( possibly correlated ) noise features ."	119096711	no
A very effective tool in achieving circularity and higher efficiency of operation during the pandemic is the Agriculture 4.0 tool . This offers a multi - disciplinary approach , with a greater focus on precision agricultural practices like positioning , sensor technologies , and satellite navigation technologies . According to Tseng et al . ( 2019 ) , Agriculture 4.0 technology employs the use of artificial intelligence ( AI ) in coordinating agricultural activities bordering from procurement of inputs down to the post - consumption stage , intending to reduce potential FLW through the operation of intelligent and agile food supply chain . Precision agriculture is an important element in this category , as it encourages excellently optimized management of agricultural inputs in farmland , based on exact crop requirements . It covers the extensive use of spatiotemporal knowledge through gathering , processing , and analyzing remotely - sensed data and ground - based data . The operations of the tool are combined with other factors to create effective management decisions in crop production , pesticide application , fertilizer use , ecosystem services , and agricultural water conservation at the right place and the right time . When precision farming is adapted to suit the circular economy approach in agricultural applications , it produces a very powerful tool that can produce optimal performance within the soil - water - plant continuum with lesser use of resources and inputs . Thereby , reducing possible pressure and pollution in the environmental footprint of such an area ( Garcia - Garcia et al . , 2020 ) .	238661251	no
Interview data were collected from 31 respondents selected from various job categories including pilot , air combat officer ( ACO ) , engineer , security , intelligence , logistics , administration ( PCO ) and medical . This cross - section of the Royal Australian Air Force ( RAAF ) provided a sample size enabling deeper analysis . The sample included executive officers ( N = 9 ) , senior officers ( N = 5 ) and junior officers ( N = 17 ) , both male ( N = 24 ) and female ( N = 7 ) . Table 1 illustrates the demographic data of participants .	235593740	yes
Our results strongly suggest that many reads carrying a non - reference allele fail to map to the standard reference . This might significantly affect the overall expression levels of the genes with a high density of polymorphic loci . Table 4 shows a few loci in our results from actual RNA - Seq data that support this hypothesis : in each instance , our approach was able to map > 100 reads , whereas the other methods mapped 20 reads . It is reasonable to expect that these differences can significantly affect the expression levels of the genes containing these loci . In our analysis of actual RNA - Seq data , we considered only heterozygous loci . There could be many more instances such as these if homozygous loci are also taken into consideration , thus underscoring the importance of the enhanced reference approach .	15707384	no
Conversely , Chen et al . ( 2013 ) used the PÃ³lya - gamma augmentation in conjunction with the logistic normal transformation for correlated topic modeling , exploiting the conditional conjugacy of a single entry Ï k | Ï k , Ï Â¬k with a Gaussian prior . Unlike our stick - breaking transformation which admits block Gibbs sampling over the entire vector Ï simultaneously , their approach is limited to single - site Gibbs sampling . As shown in our correlated topic model experiments , this has dramatic effects on inferential performance . Moreover , it precludes analytical marginalization and integration with existing Gaussian modeling algorithms . For example , it is not immediately applicable to inference in linear dynamical systems with multinomial observations . 7 . Conclusion . These case studies demonstrate that the stick - breaking multinomial model construction paired with the PÃ³lya - gamma augmentation yields a flexible class of models with easy , efficient , and compositional inference . In addition to making these models easy , the methods developed here can also enable new models for multinomial and mixed data : the latent continuous structures used here to model correlations and state - space structure can be leveraged to explore new models for interpretable feature embeddings , interacting time series , and dependence with other covariates . APPENDIX A : TRANSFORMING BETWEEN P ( Ï ) AND P ( Ï )	17551686	no
High - quality ( Q ) factor optical microresonators capable of significantly enhancing light - matter interaction have attracted strong interest in photonics community 1 . The novel photonic devices are highly in demand for both fundamental research and practical applications , such as cavity quantum electrodynamics 2 , highly sensitive sensor 3 , nonlinear devices , or filter elements 4 for optical telecommunication systems , in which the high - Q factors are crucial for achieving high spectral resolution and sensitivity as well as strong nonlinear light - matter interaction . For highly functional optical microresonators , the important requirements of the material platforms are ultralow optical loss , wide transparent window , high index contrast , high nonlinearities , and industry compatible fabrication processes . In the past few years , we have witnessed the great success of on - chip microresonators on various photonic platforms such as Si 4 , Si 3 N 4 5 - 7 , GaAs 8 , and LiNbO 3 [ 9][10][11 ] , etc . Recently , silicon carbide ( SiC ) has generated significant attention for its superior material properties to match all the essential requirements . As a mature wide bandgap material , SiC has a wide bandgap ( 3.26 eV for 4H polytypes ) , a high refractive index ( 2.6 at 1550 nm ) and a wide transparent window ( 0.37 - 5.6 Î¼m ) 12 , which can avoid multiple photon absorption that bothers the Si photonics . SiC is a CMOS - compatible semiconductor material which holds promise for realizing the monolithic integration of electronics and photonics with low fabrication costs via CMOS foundry 13 , giving rise to more competitiveness than LiNbO 3 photonics . The non - centrosymmetric crystal structures of SiC grants both second - order ( 30 pm V â1 ) and third - order ( on the order 10 â18 m2 W â1 ) nonlinear effects 14 , and this enables an efficient light frequency conversion and on - chip generation of nonclassical light states . Moreover , unlike Si 3 N 4 and Si , SiC exhibits the Pockels effects and thus can be used for low loss , ultrafast and wide bandwidth data transmission 15 , which is unachievable in Si 3 N 4 and Si photonics . In addition to the above advantages , the combination with its opticallyaddressable spin qubits 16 , high breakdown voltage ( 3 Ã 10 â6 V cm â1 ) , high thermal conductivity ( 4.9 W cm â1 K â1 ) , and high optical damage threshold ( 80 GW cm â2 ) further makes the SiC platform a unique and ideal candidate for realizing monolithic integration of electronics , quantum , and nonlinear photonics 17,18 .	235738158	no
Signs , be they spoken words , written , symbols , or data , depending on the storytelling conventions of each era , present the means for articulating and communicating knowledge . Each era is driven by its own storytelling conventions , which are frequently considered superior to the storytelling conventions of prior eras . As is commonly known , Socrates despised the written word , for he considered writing to be a deeply inhuman practice and found that true knowledge could only emerge through words as spoken between active human minds engaged in conversation . By contrast , Plato valued Socrates ' use of allegory and saw the written word as a way of preserving the power of the spoken word as a pathway to knowledge . In modernity , visual depictions of knowledge come to be considered truer and thus superior to other verbal or written forms of knowledge ( e.g. Ong , 1982 ) . Big Data visualizations reflect and amplify these tendencies . Visual depictions of knowledge are not exempt from the same fallacies to which oral and print cultures of communicating knowledge are susceptible , especially when they are often rendered out of audiovisual representations of words . Neither are Big Data analyses , which are in fact meta - analysis of words , put together in a curious and novel blend of interpersonal communication and broadcasting practices -of oral and written storytelling traditions . But they do reinforce and reproduce a form of communicating knowledge that I have been referring to as a digital orality . 1 Orality is used to describe forms of storytelling and knowledge sharing that characterize every epoch . If our goal is to grasp how the technologies of an era afford opportunities for communicating knowledge , then orality describes the form , the texture , the tonality that communication takes on . For example , oral storytelling traditions were driven by a fluidity , spontaneity , and reflexivity in sharing knowledge . Ong ( 1982 ) explained that within a primary orality , the nature of the word is not visible but lives in the world of sound . Thus , storytelling ' comes into being in the present even though it normally may derive variously from a tradition , a past ' , and evolves as the voice of storytelling changes ( Ong , 1995 : 1 ) . So knowledge is communicated and constantly evolves as it is communicated . The form of sharing organically changes and evolves as knowledge is reproduced through the spoken word , to listening publics who are aware that this evolving continuity is part of the essence of communicating knowledge . By contrast , the logic and technologies of secondary orality introduced and reproduced the deliberate spontaneity of a writing and print culture , which evolved as electronic and computermediated texts accompanied by a secondary orality with a secondary visualism . Ong ( 1982 ) had suggested that the logic of a secondary orality is not dependent on sounding out stories , in the way that primary orality was . So , in this sense a secondary orality mutes out the subjectivity inherent in voicing this stories , in favor of generating ' technologized ' , ' permanent ' , and thus ' silent ' stories that distance ( Ong , 1982 ) . An example of this form of distance is encountered within the paradigm of journalistic objectivity , which requires narrators to establish objective distance from the story so as to ascertain accuracy and thus electronically reproduce and share verified information . This distance is eliminated in the subjective form of oral storytelling , however , which affectively evolves as it circulates in the oral tradition . Different forms of orality open up different avenues to knowledge , in fact , to situated knowledges . No one form of orality leads to truer articulations of knowledge . What is important is to understand the texture of the path to ( situated ) knowledge each orality opens up .	55890248	no
Reaction phase diagram . In addition to the observed phase transitions , t he gradual shift in the Bragg peaks to lower q during the BzMA polymerization indicates progressively larger domain spacings . M ore detailed analysis of the SAXS patterns enables the varying dimensions of these ordered phases to be assessed . In the early stages of the polymerization , the system comprised ad isordered array of micelles which most likely possess ap seudo - spherical morphology . T he mean distance between nearest neighbor micelles ( D DIS ) c an be estimated from the structure factor peak maximum ( q * ) using the simple relationship D DIS Â¼ 2p/ q * . SAXS patterns recorded in situ during the polymerization indicate the presence of aBCC phase between 60 and 74 min , with the unit cell size increasing from 24.1 to 26.6 nm during this interval . From these dimensions , t he nearest neighbor center - to - center distance ( D BCC ) c an be calculated from the   Figure 3B ) . B ) Additional peaks ( black squares ) that are observed in coexistencewith the BCC ( upper pattern , gray diamonds ) and hexagonal ( lower pattern , gray triangles ) phases can be assigned to Miller indices originating from the HCP sphere phase ( see black squares ) . SAXS patterns are offset by an arbitrary multiplication factor to avoid overlap of the data . C ) Correlation between the theoretical q values for Bragg peaks corresponding to an HCP phase and the experimental data determined from ( A ) . The HCP phase comprises the unit cell shown in the inset , in which spheres are arranged within an HCP lattice with characteristic unit cell dimensions ( a HCP and c HCP ) . unit cell size using the equation D BCC Â¼ ffiffi 3 p a BCC 2 . [ 57 ] Similar structural parameters can be calculated for the HEX phase , which becomes the dominant phase within 80 min . Themean center - to - center distance for nearest neighbor cylinders ( D HEX ) can be calculated using a HEX Â¼ D HEX Â¼ 2d 10 ffiffi 3 p . [ 57 ] Finally , within the coexisting HCP phase , t he center - to - center distance ( D HCP ) f or neighboring spherical micelles is simply the unit cell parameter a HCP , i.e. , D HCP Â¼ a HCP . [ 57 ] Mean inter - micelle distances increase from 20.9 to 23.1 nm between 60 and 74 min . This greater inter - separation distance between neighboring micelles is the result of the mean micelle core radius increasing by approximately 1.1 nm as the core - forming PBzMA block grows longer . There is also am odest increase in the mean inter - cylinder separation distance , f rom 22.2 nm after 80 min to 23.2 nm at the end of the BzMA polymerization .	232262823	no
"In our first Review on this theme , [ 1 ] we endeavored to make the case why synthesis laboratories of today need to change by adopting am achine - assisted approach to more efficiently use human resources . B yr ecognizing synthesis as aholistic system and by integrating chemistry with engineering and informatics , g reater safety and enhanced efficiencies arise while also opening up new pathways to discovery . O ur modern world is evolving rapidly . T he "" internet of things "" ( IoT ) is with us today , w hich provides previously undreamt opportunities in consumer services through the advanced connectivity of equipment and devices linked through the internet . [ 2 ] Communication between machines and neural networking will be acomponent of any future laboratory . The acquisition and the mining of "" big data "" along with technology developments , s uch as cheap microprocessing devices [ 3 ] and material - handling robots , are poised to revolutionize how we will design and optimize chemical processes ."	1207266	no
Recovering positive examples for low - sparsity data In this experiment we aim to show that the nonsymmetric model is just as capable as the symmetric model when it comes to learning negative correlations when trained on data containing few negative correlations and many positive correlations . We choose a setting where the symmetric model performs well . We construct a dataset that contains no large disjoint collections of items , with 100 baskets of size six , and a catalog of 100 items . To reduce the impact of negative correlations between items , we use a categorical distribution , with nonuniform event probabilities , for sampling the items that populate each basket , with a large coverage of possible item pairs . This logic ensures few negative correlations , since there is a low probability that two items will never co - occur . For the nonsymmetric DPP , the oracle expects the model to predict a low negative correlation , or a positive correlation , for a pair of products that have a high co - occurence probability in the data . The results of this experiment are shown in Figure 1 . We see from the plots showing the transformed K matrices that both the nonsymmetric and symmetric models recover approximately the same structure , resulting in similar error plots , and similar predictive AUC of approximately 0.8 for both models .	170078866	no
While it may be tempting to revert back to a parametric setup and work with simple , easy to interpret models , we argue that a different approach is possible : we stay within a nonparametric framework , exploit the irregular and complicated nature of real life distributions and encode invariances to sources of variation assumed to be irrelevant . In this contribution , we focus on invariances to symmetric additive noise on each of the data generating distributions . Namely , assume that the i - th sample { X ij } Ni j=1 we observe does not follow the distribution P i of interest but instead its convolution P i E i with some unknown noise distributions E i assumed to be symmetric about 0 ( we also require that it has a positive characteristic function ) . We would like to assess the differences between P i and P i while allowing E i and E i to differ in an arbitrary way . We investigate two approaches to this problem : ( 1 ) measuring the degree of asymmetry of the paired differences { X ij â X i j } , and ( 2 ) comparing the phase functions of the corresponding samples . While the first approach is simpler and presents a sensible solution for the two - sample testing problem , we demonstrate that phase functions give a much better gauge on the relative comparisons between bags of observations , as required for learning on distributions .	12037058	no
We recently harnessed intramolecular metal - catalyzed carbenoid reactions in the ADS of androgen receptor ( AR ) agonists . A DS drove the discovery of both novel ligandsbased on scaffolds with no annotated activity against the receptor - and associated high - yielding syntheses ( Fig - ure 1A ) . However , i nt his validation work , reliance on intramolecular reactions meant that the structural diversity of possible products was largely encoded by the substrates used . We envisaged that ADS would be enhanced by exploiting intermolecular reactions as the range of possible reaction outcomes - and thus the chemical space exploredwould be dramatically increased . It was proposed to exploit ADS to drive the productive elaboration of the 4 - cyano-3trifluoromethylphenylacetamide fragment found in many modulators of AR . [ 7 ] Although the core motif displayed only modest agonism ( 1;E C 50 = 92 AE 13 mm ; E C 50 = concentration of ligand needed to induce the half - maximal observed effect ) , we reasoned that intermolecular reactions of related diazo acetamides could help identify productive strategies for fragment growth ( Figure 1C ) . [ 8][9][10 ] The a - diazo amides 2 - 5 incorporate the 4 - cyano-3 - trifluoromethylphenyl fragment and bear agroup ( N - methyl or N - cyclopropyl ) expected to suppress intramolecular reactions . [ 11 ] In round one , weperformed an array of 192 reactions randomly chosen from 480 possible combinations of four substrates ( 2 - 5 ) , ten co - substrates ( 6a-6i or no co - substrate ) , six catalysts , a nd two solvents ( CH 2 Cl 2 or toluene;F igure 2A ) . Thec o - substrates were selected on the basis of diversity of possible intermolecular reactions with metal carbenoids [ 12][13][14 ] and the catalysts on the basis of their diverse reactivity . W ei nitially showed that the diazo substrates and Abstract : Activity - directed synthesis ( ADS ) , anovel discovery approach in whichbioactive molecules emerge in parallel with associated syntheses , w as exploited to develop aw eakly binding fragment into novel androgen receptor agonists . H arnessing promiscuous intermolecular reactions of carbenoid compounds enabled highly efficient exploration of chemical space . Four substrates were prepared , yet exploited in 326 reactions to explore diverse chemical space;guided by bioactivity alone , the products of just nine of the reactions were purified to reveal diverse novel agonists with up to 125 - fold improved activity . Remarkably , o ne agonist stemmed from an ovel enantioselective transformation;t his is the first time that an asymmetric reaction has been discovered solely on the basis of the biological activity of the product . It was shown that ADS is as ignificant addition to the lead generation toolkit , enabling the efficient and rapid discovery of novel , yet synthetically accessible , b ioactive chemotypes . Angewandte co - substrates were all inactive in our assay ( see the Supporting Information ) . Thea rray was performed in 96 - well plates with reactions involving ad iazo substrate ( 100 mm ) , ac osubstrate ( 1.0 m ) , and ac atalyst ( 1 mm ) . To demonstrate significant exploration of chemical space , w es howed that ar andom selection of reactions yielded several products , including , ing eneral , those of both inter - a nd intramolecular reactions ( see the Supporting Information ) . After 48 h , the crude reaction mixtures were scavenged to remove metal contaminants , e vaporated , and assayed for agonism of AR ( total concentration of products:1 0 mm in 1 % DMSO in pH 7.5 aqueous buffer ) using an established assay . [ 15 ] Remarkably , o nly two of the 192 reactions yielded products that were significantly active ( Figure 2B;s ee also the Supporting Information ): both reactions involved diazo substrate 3 , [ Rh 2 { ( S)-DOSP } 4 ] , and CH 2 Cl 2 , t ogether with either cyclohexene ( 6a)o ri ndole ( 6f)a st he co - substrate . These data suggest that the fate of 3 - both with 6a and 6fdepends critically on the specific catalyst and solvent used , which determine whether the substrate is steered towards active products . T he lack of activity without ac o - substrate strongly suggests that the active products are derived from intermolecular reactions . A tt his stage , n op roducts were isolated or identified;i nstead , the most promising reactions informed subsequent reaction array design .	2681047	maybe
While most older people today are living longer and healthier lives than previous generations , the proportions of those living with low and high levels of dependency have increased ( Kingston et al . , 2018 ) . In England , for example , older men will on average spend about 2.1 years and older women about 3.7 years with substantial care needs by 2025 ( Kingston et al . , 2018 ) . High - quality community and residential care are costly , which increases longstanding concernsexpressed across many countriesabout how care should be paid for and by whom . This study focussed specifically on the situation in England , where a continuing failure to implement changes to the funding system for adult social care , care of older people particularly , means that such questions are live issues for both policymakers and the public . When the data reported here were collected , the government was committed to publishing policy proposals by the end of 2020 , specifically to honour an election promise to end the situation where an individual 's housing assets are used to meet the costs of their care . Such a promise is particularly relevant to older people who are the most likely in society to need costly residential care and to have significant housing assets . Unsurprisingly perhaps , the demands of the coronavirus pandemic have delayed government action .	232160850	no
Computed d - orbital energies in the low - spin forms of complexes in this work , and the average energies of the t 2 g and e g subshells ( all in kcal.mol -1 ) . These data are plotted in Fig . 6 of the main article , and in Fig . S4 .    ( Table S4 ) . The average orbital energies of the t 2 g and e g subshells are also shown , along with their best fit correlations and slopes .	43007051	yes
An evacuated crystalline sample of 1 shows a very significant degree of nitrogen adsorption at 77 K , especially at low relative pressure ( 3.3 mmol at P / P 0 = 0.1 ) , which is consistent with microporosity . At first glance , and by following the general classification of adsorption isotherms , the general shape of the adsorption isotherm appears to be a simple Type I isotherm ( Figure 3 ) . [ 25 ] A Brunauer - Emmett - Teller ( BET ) surface area of 278 m 2 g Ã1 and a micropore volume of 0.16 mL g Ã1 can be calculated from these data . The total amount of nitrogen adsorption of 4.4 mmol g Ã1 at P / P 0 = 1 represents the greatest amount adsorbed by a crystalline material composed of a low - molecular - mass organic compound reported to date . The fundamental parameters derived from the nitrogen adsorption data of the crystal from 1 with those of the previously reported examples are compared in Table 1 . A closer look at the low - pressure region of the nitrogen adsorption isotherm reveals two distinct inflections ( Figure 3 , inset a ) , which can be correlated with the filling of the two different micropore structures within the crystal : firstly the channels of 4 diameter , and secondly , the 11 voids . Analysis of these low - pressure nitrogen adsorption data by using the Horvath - Kawazoe method [ 26 ] gives a bimodal pore size distribution . The well - defined peak centered at a diameter of 11 is consistent with the maximum size of the voids within the crystal ( Figure 3 , inset b ) . The channels between these voids are too narrow to be modeled because of the limitations of this technique , but they are represented by the distorted peak at 6 .	9132688	no
The data collection process for the case study included interviews with different stakeholders , field observation , and a desk review of secondary sources on the alternative practice performance on water reuse . Data analysis was conducted using the CE framework ( Table 1 ) . The case study revealed : i ) alternative practices that gave an added benefit to the specific urban context , and ii ) the practicality of the proposed framework for identifying the incremental shifts promoted in water systems .	244084326	no
AGAe nabled the fast assembly of 19 F - labeled Lewis type 2a ntigens for the high - throughput screening of protein binding . Mammalian and bacterial lectins as well as enzymes were analyzed . 19 FNMR screening of Fglycans permitted aq uick qualitative evaluation as well as ar eliable quantification of lectin binding ( K d ) . Thea ssay does not require labeled proteins or complex 2D NMR experiments . All NMR experiments can be performed in an extremely small scale ( few nmol of glycan and protein per experiment ) . Enzymatic reactions , i ncluding sialylation , were monitored in real - time , demonstrating that 19 F - labeled glycans hold agreat potential as molecular probes to uncover enzymatic processes and for high - throughput screening . [ 27 ] Protocols for the selective 19 Flabeling of monosaccharides are available ; [ 73][74][75 ] the implementation of these novel BBs in AGAwill fuel the production of new classes of glycan probes . Given the high dispersion of 19 FNMR signals , libraries of F - glycans with diverse chemical shifts can be designed to increase the high throughput of this approach . [ 76 ] Theability of 19 Fglycan probes to reveal binding or enzymatic transformation in solution and in real - time could open the way to in cell NMR applications , o ften hampered by high background signals . [ 14,77,78 ] Overall , these probes are valuable tools for ab etter molecular understanding of the interactions of complex glycans with protein receptors . Sites 1a nd 2c orrespond to the carbohydrate - bindingsites within amonomer and between two monomers , respectively . B ) 19 FNMR screening of F - glycansalone ( gray ) and in presence of BambL ( blue ) . BambL binds F - Le x , F - Le y , and F - H type 2 strongly as shown by CSP in presence of protein ( orange line ) . The 19 FNMR titration spectra shows F - H type 2 undergoingslow exchange on the chemical shift timescale upon increase of BambL concentration . C ) The K d of F - H type 2 was calculated from the changes in peak intensity and fitted to one - and two - site models resulting in a K d of 9 AE 2 mm . D ) TROSY NMR verified F - H type 2 binding to 15 19 FNMR using F - glycans . A ) 19 FNMR of F - Lac incubated with b - galactosidase . 19 FNMR real - time tracking of product formation ( black arrows ) upon incubation of F - Lac with b - galactosidase ( right ) . Kinetic data were derived plotting the product formation rate as afunctiono fthe substrate concentration . The best fit of the experimental data provides a K M value of 86.5 AE 10.5 mm according to the Henry - Michaelis - Menten equation ( left ) . B ) 19 FNMR of F - Lac incubated with Pma23ST in presence of CMP - Neu5Ac . The formation of F - sLac ( black arrows ) can be followed by 19 FNMR in real - time . Product formation was confirmed by HPLC ( Figure S9 ) .	232431373	no
To understand the dependence of conductance on the light intensity , we perform experiments where the maximum light intensity in each illumination circle is gradually increased . The maximum conductance in each circle increases approximately linearly with the light intensity , as shown in Fig . 2a . When the light intensity changes smoothly in a sinusoidal form , the conductance of the nanocontact follows the trend of the light intensity and sinusoidally varies , as shown in Fig . 2b . Additional repeatable data of the current as a function of the light intensity is observed in the Supplementary Video S1 and Figure S3 . Based on these results , we conclude that the conductance of the quantum contact is regulated by the light intensity .	89617151	yes
The flow chart in Fig . 1 could have helped us make the following decisions : Because the survey did not collect data about expectations of others , we had to develop a gender norms proxy . The practice of working outside of the household was visible , thus we could cluster attitudes at the provincial level . Because the health concern was related to avoiding a positive action ( working outside of the household ) for fear of sanctions ( violence ) , we tested associations between residing in a normative cluster and carrying out the positive practice of interest .	245040445	no
In recent years , a lot of research has been devoted to the role of BAs and BAs receptor FXR , in NAFLD [ 45][46][47 ] . However , there is currently no explanation for the alterations in BAs composition in blood , the decreased ratio of secondary / primary BAs observed by us ( Extended Data 7f - j ) and others 45,47,48 , and whether it correlates with changes in tissue morphology 47 . Our data shed new light on this problem . The altered BC microanatomy and consequent pericentral micro - cholestasis may hamper BAs secretion into BC , as apical pumps ( BSEP , MRP2 ) have to operate against elevated luminal BAs concentrations . This would lead to back - flux of primary BAs into the blood , reducing their availability for conversion into secondary BAs by the intestinal microbiota ( Extended Data 7j and 8 g ) , thus contributing to the changes in BAs composition observed in NAFLD 45,47,48 . Bile flow is essential for normal liver function . Bile accumulation , due to its detergent - like properties , can cause liver damage 49,50 and bile pressure can affect metabolism 51 . Indeed , the accumulation of LD 52 and BAs 53 could induce oxidative stress and trigger apoptosis 29 , which is consistent with the reduction in pericentral hepatocytes observed in STEA and eNASH . The occurrence of pericentral micro - cholestasis is a new piece in the NAFLD pathophysiology puzzle that contributes to clarify some aspects of the disease so far without explanation , e.g. increase of GGT levels 54 , BAs in serum 55 , upregulation of MRP3 in NASH 56 and the beneficial effect of UDCA treatment in NAFLD 57 , all signs of ongoing cholestasis 41,58 .	91821024	yes
The recent pandemic has created an extraordinary level of anxiety and panic , which has not only produced negative repercussions for the tourism sector on a short - term basis but also threatened its future growth by impeding the post - pandemic recovery process . The sector 's recovery and growth largely depend upon tourists and their behavioural responses ; among the key factors that can be expected to influence such responses are personality traits . This follows from the fact that personality traits , which are innate as well as consciously nurtured , can be triggered by the situations that occur in people 's lives ( McLeod , 2016 ) . Although past research has examined the influence of personality traits in a variety of contexts , such as consumer behaviour and intentions in the hospitality sector ( Rojas - MÃ©ndez et al . , 2013 ) , stock trading performance ( Tauni et al . , 2020 ) , digital autopreneurial intentions ( Yeh et al . , 2020 ) and job burnout ( Khedhaouria & Cucchi , 2019 ) , a paucity of research considers the influence of the Big Five personality traits on tourists ' travel intentions during a health crisis . Our study attempts to bridge this gap by addressing two research questions . RQ1 sought to ascertain whether the identified traits - neuroticism , conscientiousness , extraversion , agreeableness and openness to experience - influence tourists ' intentions to travel during and after the pandemic . The results of the ANN analysis of data collected from residents in Japan confirm the impact of all five traits on individuals ' intentions to travel during and after the pandemic . RQ2 , meanwhile , considered the differences in the relative influence of the five traits on tourists ' intentions to travel during and after the pandemic . These results indicate that extraversion has the strongest relative influence and neuroticism has the weakest relative influence on travel intentions during the pandemic . In comparison , openness to experiences has the strongest and conscientiousness has the weakest influence on travel intentions after the pandemic . These findings entail useful implications .	245008959	no
Thus , words in different forms would not be wrongly identified as different ones . All the sentences after data pre - processing were lowercase , with punctuations removed .	236251116	no
Recall the motivating discussion in Section 2 , in which we considered generative model p Î¸ ( x , z ) and inference model q Ï ( z|x ) , the former used to model synthesis of the observed data x and the latter used for inference of z given observed x. In recent deep architectures , a hierarchical representation for cumulative latent variables z = ( z ( 1 ) , . . . , z ( L ) ) has been considered ( Rezende et al . , 2014;Ranganath et al . , 2015;Zhou et al . , 2015;Ranganath et al . , 2016b;Cong et al . , 2017;Zhang et al . , 2018 ) . As an example , there are models with p Î¸ ( x , z ) = p Î¸ ( x|z ( 1 ) ) Lâ1 l=1 p Î¸ ( z ( l ) |z ( l+1 ) ) p Î¸ ( z ( L ) ) . When performing inference for such models , it is intuitive to consider first - order Markov chain structure for q Ï ( z|x ) = q Ï ( z ( 1 ) |x ) L l=2 q Ï ( z ( l ) |z ( lâ1 ) ) . The discussion in this section is most relevant for variational inference , for computation of â Ï E q Ï ( z ( 1 ) , ... , z ( L ) |x ) [ f ( z ( 1 ) , . . . , z ( L ) ) ] , and consequently we specialize to that notation in the subsequent discussion ( we consider representations in terms of z , rather than the more general y notation employed in Section 4 ) .	58028743	no
Abstract : Interfacial water in the vicinity of lipids playsa n important role in many biological processes , s uch as drug delivery , i on transportation , and lipid fusion . Hence , molecular - level elucidation of the properties of water at lipid interfaces is of the utmost importance . W er eport the twodimensional heterodyne - detected vibrational sum frequency generation ( 2D HD - VSFG ) study of the OH stretch of HOD at charged lipid interfaces , w hich shows that the hydrogen bond dynamics of interfacial water differ drastically , d epending on the lipids . T he data indicate that the spectral diffusion of the OH stretch at apositively charged lipid interface is dominated by the ultrafast ( < ~100 fs ) component , followed by the minor sub - picosecond slow dynamics , w hile the dynamics at a negatively charged lipid interface exhibit sub - picosecond dynamics almost exclusively , i mplying that fast hydrogen bond fluctuation is prohibited . These results reveal that the ultrafast hydrogen bond dynamics at the positively charged lipid - water interface are attributable to the bulk - like property of interfacial water , w hereas the slowd ynamics at the negatively charged lipid interface are due to bound water , which is hydrogen - bonded to the hydrophilic head group .	13848411	no
Augmented intestinal permeability 7 and dysbiosis of the intestinal microbiome 6 contribute to human and mouse NAFLD progression [ 4][5][6 ] . Although , histological analysis of the small intestine revealed no housing temperature or diet driven differences in immune cell infiltration ( Supplementary Fig . 6a ) , T N housing , compared to T S , exacerbated para - cellular intestinal permeability , as evidenced by translocation of FITC - dextran across the epithelium , and lowered trans - epithelial resistance on both chow and HFD ( Fig . 3a and Supplementary   Fig . 6b ) . Further , T N housing , compared to T S housing , changed intestinal microbiome in as little as 2 weeks , prior to being placed on HFD ( Supplementary Fig . 6c , d ) . Extended exposure ( 12 weeks ) of randomly separated WT C57BL/6 mice to differential ambient temperatures or HFD further exacerbated these differences , with obvious differences observed in every phyla analyzed after 24 weeks of exposure ( Fig . 3b and Supplementary Figs . 6e - k ) . Notably , T N housing enriched the representation of Bacteroidetes , while T S housing preferentially enriched for Firmicutes . Linear discriminant analysis effect size ( LEfSe ) analysis , which was employed to analyze data with specificity to the genus level , revealed congruent differences beyond the phylum level ( Supplementary Fig . 7 ) .	4435385	maybe
For squaraine SQ5 , Yang and co - workers demonstrated both H - and J - type aggregation according to their optical and X - ray diffraction data in the solid state in dependence on the solvent used for spin - casting . [ 86 ] On the one hand , the use of the high boiling solvent ortho - dichlorobenzene ( oDCB ) led to the formation of a thermodynamically stable H - type aggregated state as suggested through hypsochromically shifted and narrowed absorption band . On the other hand , the use of low boiling solvents such as dichloromethane favored a kinetically selfassembled meta - stable J - type aggregation state [ 87 ] as suggested by a red - shifted absorption band . Hereby it is worth noting that due to a large distance between parallely oriented SQ5 chromophores in the single crystal ( 9.44 Ã ) and a Ï´ of 53 Â° close to the magic angle , [ 88 ] the resultant J Coulomb is negligible while a mismatched overlap of the donor and acceptor units resulting in possible CT - mediated coupling may explain the observed dual - band absorption feature within the aggregate film . Planar heterojunction ( PHJ ) OSCs with active layers of H - or J - type coupled SQ5 and C 60 showed an increase in PCE from 0.5 % to 1.8 % , respectively , again coinciding with an increase in J sc from 3.8 to 6.5 mA cm â2 due to improved NIR absorption and the more 2D percolation pathways of the presumably slip - stacked J - aggregates .	239035480	no
In order to define isoconcentration surfaces the data must be binned into voxels so that local composition can be determined . Thevoxel size must be selected with the trade - off that smaller voxels lead to better spatial resolution with an increase in the statistical error as asmaller voxel will contain as maller number of ions . W eg enerally used a3 3 3 nm delocalization and 1nmv oxel size . H owever , t here were instances in which the voxel size was reduced to create ah igher polygon density to increase the signal to noise ratio because the edge polygons are not included in the proximity histogram analysis . T he delocalization remained the same , so the shape of the interfaces was not significantly altered with the reduced voxel size .	13743110	no
stations , ( v ) workplaces , and ( vi ) residential places . These data have been constructed by comparing visits and lengths of stays at certain places relative to a baseline ( Google Mobility , 2021 ) . The retail & recreation cate - gory provides data on mobility trends for places such as restaurants , cafes , and shopping centers . Grocery & pharmacy category provides data on mobility trends for sites considered to be essential trips , including grocery markets , drug stores , and pharmacies . Similar subcategories of related locations are grouped within parks , transit stations , workplaces , and residential places ( Google Mobility , 2021 ) . The use of such types of consumer mobility data is also in vogue in the extant literature ( e.g. , Persson et al . , 2021 ) .	255441206	maybe
The affinities of ARTD2 FL , ARTD2 WGR+CAT and ARTD2 FL point mutants were first measured using fluorescence polarization assay ( FP ) with a fluoresceinlabelled 5 -phosphorylated blunt end DNA ( Supplementary Figure S1 and Supplementary Table S1 ) . Previously , we showed that N - terminus of ARTD2 interacts tightly with DNA ( 13 ) , and as a result point mutations in the WGR domain do not affect the overall affinity of the protein - DNA - interaction ( Table 2 ) . Due to the unspecific binding via the N - terminus , the K D of ARTD2 FL and the point mutants were within same range ( â¼50 nM ; 100 mM NaCl ) . On the contrary , the K D of ARTD2 WGR+CAT was significantly higher ( 5 M ) , highlighting the high affinity and non - specificity of the N - terminus to DNA as earlier reported ( 13 ) . When we repeated the measurements at higher salt concentration for the WT and selected mutated enzymes , the affinities measured were significantly lower at the M range , but the affinities were all again at the same level ( Table 2 ) . This indicates that the DNA - ARTD N interaction is primarily ionic in agreement with the overall positive net charge based on the protein sequence . When salt concentration was increased even more to 300 mM the binding was very weak with estimated affinities at 100 M range ( data not shown ) .	53502448	no
The data samples in this paper consist of the balance panel data of 279 prefecture - level cities from January 1 to February 19 , 2020 , and the descriptive statistics of related variables are shown as follows ( Table 3 ) .	235915166	yes
Variational Auto - Encoders ( VAEs ) are latent - variable models that define a joint density P Î¸ ( x , z ) between observed variables x and latent variables z parametrized by a vector Î¸ . Training such models requires marginalizing the latent variables in order to maximize the data likelihood P Î¸ ( x ) = P Î¸ ( x , z)dz . Since we can not solve this marginalization explicitly , we resort to a variational approximation . For this , a variational posterior density Q Ï ( z|x ) parametrized by a vector Ï is introduced and we optimize the variational Evidence Lower - Bound ( ELBO ) on the data loglikelihood :	44005913	no
After applying panel data unit roots tests , we can conclude that the COVID-19 index series is stationary , while the data for the rest of the variables are integrated of order 1 . Therefore , cointegration between employment expectations and the rest of the variables is checked to establish a possible long - run relationship .	237473259	no
where tRNA ij denotes the concentration of the jth tRNA that recognizes the ith codon , s ij is a selective constraint on the efficiency of the codon - anticodon coupling , with each value adopted from ( 21 ) and related to one wobble pairing ( Supplementary Table S1 ) . The codon - anticodon recognition pattern is defined according to Crick 's Wobble rules ( 22 ) , with codons grouped into blocks of four elements reflecting all possible interactions ( Supplementary Figure S1 ) . Formulas for the calculation of adaptiveness values , W i , for each element n in a block are defined in Supplementary Table S2 and taken from ( 21 ) . As an exception , the adaptiveness value for the AUA codon is calculated as W AUA Â¼ Ã°1 Ã s L : A ÃtRNA LAU . The s - value for recognition of the CGA codon by the ACG anticodon is high resulting in a low rate for this codon ( about two orders of magnitude smaller than the next highest rate ) . This rate is sensitive to this particular s - value , and owing to its extremely low value , it dominates the analysis . This has been recognized previously ( 10,20 ) and therefore we set the s - value for this interaction to 0.9172 as used by ( 10 ) , which better matches experimental data .   To obtain the rate r i for each type of codon i , the adaptiveness values are normalized by the sum of the values over all codon types , giving the probability for the coupling of a matching tRNA ( 20 ) . To account for variations in total tRNA pool size between data sets , this value is multiplied by the sum of all tRNA concentrations in the pools	8953532	no
We ran two secondary analyses . First , we repeated the analysis in the restricted set of cities in which we had data on population growth 5 years before the study period , instead of concurrent with the study period , to compare associations of population growth during and before the study period . Second , we ran the analysis of predictors of proportionate mortality in the restricted set of cities with a lower proportion of ill - defined deaths ( defined as < 90th percentile or 13 % ill - defined deaths ) .	231711401	no
In addition to our findings , we highlight a number of our study 's limitations that present opportunities for future research . First , the relationship between the effort protest supporters make and the protest 's effect on the target firm is a yet to be tested . Kristofferson et al . ( 2014 ) , for example , discuss the difference between token support and meaningful support , whereby meaningful support is postulated as requiring a significant effort from a participant and as a prerequisite for bringing about change . A second limitation is the conceptualization of firm responses ( Oliver 1991 ) . There are , however , many other dimensions of firm responses , such as whether firms communicate their response to individual consumers or to the public at large . Future research may examine impression management ( McDonnell and King 2013 ) and greenwashing effects in relation to firm response strategies ( Lyon and Montgomery 2013;Seele and Gatti 2015 ) . A third limitation is the access to data on the impact of protests on firms and on the strategies they have employed . We have therefore chosen to assess a wide range of cases , whereby we were unable to delve into each case in great depth . In - depth case studies , such as process studies , would complement our quantitative study . We urge researchers to study how corporate decision makers are influenced on an individual level , and how changes in their perception result in a response to protest . A fourth limitation is the inability of our approach to capture the full richness of online protests . Event studies assume that all other factors remain equal and hence may overemphasize the effects of recent events , while not accounting for long - term effects ( the ceteris paribus bias ) . Hence , we should be careful with strong causal claims . A fifth limitation of our study is that we do not assess multiple rounds of protests and responses . Future research may study multiple protest cycles and subsequent firm responses . Last , our study assessed the short - term effects of online protests . Future research may focus on the long - term effects , such as organizational stigmas perceived by stakeholders .	254384444	no
The results of our investigation show that a multiplicative switch model fits well the experimental results obtained in reporter gene assays . The results of the tests with random noisy data underline the biological impact of the fitted parameters and the model predictions .	2609726	no
On the other hand , the expected large deployment of ML models for battery manufacturing faces a new challenge associated with the availability of public databases . Such databases are needed for appropriate training and testing of such models . Academic initiatives , such as the ARTISTIC project , [ 91,92 ] is already making significant amount of battery manufacturing experimental and modeling data openly available and offer free online services for battery manufacturing simulations from an Internet browser . While this trend of giving open access to data helps in generating large volumes of data , and thus in building data - driven models , it is felt that it should be followed by the academia and industry as a whole in order to facilitate and accelerate the data - driven models implementation .	245112757	no
In machine learning many classification tasks present inherent label confusion . The confusion can originate from a variety of factors , such as incorrect labeling , incomplete annotation , or some fundamental ambiguities that obfuscate the ground truth label even to a human expert . For example , consider the images from the ImageNet data set ( Russakovsky et al . , 2015 ) in Figure 1 , which illustrate the aforementioned factors . To mitigate these issues , one may require the model to predict the k most likely labels , where k is typically very small compared to the total number of labels . Then the prediction is considered incorrect if all of its k labels differ from the ground truth , and correct otherwise . This is commonly referred to as the top - k error . Learning such models is a longstanding task in machine learning , and many loss functions for top - k error have been suggested in the literature .	3384895	no
According to Mulvenna et al . ( 2000 ) , at present , we live in the period of mass personalization , as users ' web page data on the Internet provide rich information about people , including their demographic , psychographic , and lifestyle data . As argued by Arya et al . ( 2019 ) , digital marketing strategies that analyze Big Data can effectively segment Internet advertising using remarketing technology . For example , live text analysis techniques are applied to the chats in applications such as WhatsApp , Messanger , TikTok , or Telegram and instantly segment advertising in such applications ( Rashidi and Vaniea , 2015;Kang and Yang , 2020 ) . Users , regardless of their being aware of it , accept that companies monitor and carry out a keyword research and textual analysis on users ' input , e.g. , through monitoring of calls to identify keywords that will be used to segment ads ( Vargo and Hopp , 2020 ) .	233029680	no
After collecting all judgments , they were sorted into cases that were withdrawn before a preliminary hearing and those that went to a preliminary hearing or beyond ( n = 603 cases ) . The cases that did not go to a preliminary hearing were not included in the sample as they contained very limited information ; only respondent , claimant and jurisdiction codes . The sample cases were subject to content analysis using a code book developed by the authors . The code book was based initially on the coding used in the Survey of Employment Tribunal Applications ( Buscha et al . , 2012 ) and expanded to include additional interesting variables specific to whistleblowing cases , such as'was the claimant subject to a detriment ? ' Each case was coded and after data cleaning , was analysed using SPSS . The coding was carried out by the first author and research assistants . The interrater reliability was 97 % and any disagreements between coders was resolved through discussion involving both authors .	245506098	maybe
To address these limitations of previous studies , this paper includes undesirable outputs into DEA window analysis to calculate CEE by utilizing a linear transformation in the Yangtze River Delta ( YRD ) , China , during the period of 2000e2010 . Urbanization has increased moderately , while CO 2 emission has grown rapidly since 2000 in the YRD Tian et al . , 2011 ) . Thus , we investigated the effect of urbanization on CEE since 2000 . Due to data availability , the study covered the period of 2000e2010 . Different from most previous studies , this study takes the prefecture - level city as the basic study unit . Then , we analyze the relationship between urbanization and CEE . Finally , to take into account spatial spillover effect , a spatial lag panel Tobit model is constructed to analyze the impact of urbanization on CEE . The results are helpful for evaluating the carbon reduction task in the YRD , guiding policymakers to establish a plan to improve CEE , and providing a scientific basis for the development of low carbon urbanization .	158288388	no
The frequency with which the data are collected . Ranges from weekly or monthly to real - time data . The latter allows the automatic management of data with the use of AI applications . Storage	233029680	no
All procedures for all studies were administered using Qualtrics.com data - collection software and were approved by the Institutional Review Board of the New York State Psychiatric Institute , indicating compliance with ethical guidelines . In all studies , participants indicated their informed consent to participate via an online form . Qualtrics settings were used to build random assignment of participants to experimental conditions into the study procedures , and because this process was computerized and participants completed the studies online , performing the data collection blind to condition was not a concern .	198983723	no
Artificial intelligence ( AI ) , automation , deep learning , big data , machine learning : these buzzwords are dominating the media , in news articles and are already connected to nearly every field and application ( see Table 1 for definition of the most important terms ) . Consequently , it is not surprising that science in general is not excluded from this trend and there are already first promising results . [ 1 ] Exemplarily , a deep learning software can be utilized for the identification of specific genetic diseases , [ 2 ] artificial intelligence can be utilized for the interpretation of images in clinical routines [ 3,4 ] or the development of new drugs , [ 5 ] big data handling simplifies the understanding of geographic questions [ 6 ] or cognitive computing enhances the speed of life science research . [ 7 ] All these examples show the great potential of the ongoing digitalization for significant advancements in science and one can simply conclude that this process will also influence materials science and the way research will compounds . [ 16][17][18 ] Both approaches can also be combined as shown in a very recent study . [ 19 ] Herein , a robotic arm is utilized to enable flow chemistry approaches . Additionally , the system features an AI - software enabling an improvement in the experimental planning . However , this system can only be utilized for organic synthesis protocols and can not easily be adapted for other material classes such as metals or ceramics .	230820946	no
We employ the contrastive loss function ( Chopra et al . ( 2005 ) ; LeCun et al . ( 2006 ) ) for training our network . The Siamese configuration comprises of two identical networks of Figure 3 computing signatures for two separate inputs of data . Associated to each input pair is a label which indicates whether or not that pair is a positive ( Î» = 1 ) or a negative ( Î» = 0 ) example ( Figure 2 ) . Let C 1i and C 2i be the curves imputed to first and second arm of the configuration for the i th example of the data with label Î» i . Let S Î ( C ) denote the output of the network for a given set of weights Î for input curve C. The contrastive loss function is given by :	9665638	no
Moovit data are available at the city level . Moovit covers 87 major cities worldwide , spanning across four ( 4 ) continents ; North America ( New York , Miami , San Francisco , Washington , etc . ) ; South America ( Brasilia , Buenos Aires , Santiago , Bogota , etc . ) ; Europe ( London , Paris , Berlin , Rome , etc . ) and Asia ( Singapore , Bangkok , Jakarta , Kuala Lumpur , etc . ) . For the present study , we utilized five ( 5 ) PT service attribute variables ( Variables 7 - 16 in Table 1 ) , that pertain to the years 2019 ( pre - pandemic ) and 2020 ( pandemic ) . These five ( 5 ) variables are regularly estimated by Moovit and they are closely related to PT quality of service :	255826268	yes
The secondary data known as academic results of students and collected from the university are used for evaluating academic performance . Student 's job - ready performance is examined through primary data collected using standardised tools developed by professional bodies . These tools include the results of ' experimental tests ' and apprenticeship scores . To analyse the data and present them in the findings , simple statistical parameters known as ' mean ' and ' median ' are used . The educational grading system , such as CGPA / GPA and scoring in examinations , follows a standard procedure set up that does not essentially require the t - test value to justify the significance . In the event of perception survey , t - test value is generally used to define the ' standard deviation ' and its significance , which may not ineludibly be needed for the scores achieved via scholastic and aptitude tests as argued by Alam and Parvin , 2021 . Since this research compares the ' grades ' achieved by the two groups of students ( before and during COVID-19 ) in the three domains , namely academic , aptitude and practicum , the t - test value was not the key focus here .	237493243	no
More broadly , recent technological advances are transforming retailing ( Shankar et al . , 2020 ) , and understanding the drivers of consumer mobility data can enable organizations to further optimize technology - driven tools to manage market disruptions . Our method is scalable to include more risk perception indicators to predict retail mobility , which could be a starting point toward developing actionable retailing strategies . Although we do not focus on the impact of retail mobility on specific retail strategies , we believe that the outcomes from our predictive model could be used as strategic inputs to optimize several retail decisions , such as staffing , inventory , and location - based online and in - store advertising decisions .	255441206	no
"We conducted a CFA using data from an independent sample of 160 employees ( snowball sampling ) . This CFA also showed a good fit for the four - dimension HLB model ( CFI = 0.94 , TLI = 0.93 , RMSEA = 0.07 , SRMR = 0.05 ) . Further investigating the nomological net , we administered the 20 - item HLB measure ( see Table 4 ) . Knowledge sharing was measured with 5 items by Connelly et al . ( 2012 ) . A sample item is : "" told him / her exactly what s / he wanted to know "" . Knowledge hiding was assessed with a 12 - item measure ( Connelly et al . , 2012 ) . A sample item is "" said that I did not know , even though I did "" . The response scale ranged from 1 ( "" totally disagree "" ) to 5 ( "" totally agree "" ) . Psychological safety was assessed with a Brazilian 6 - item version of Edmondson 's ( 1999 ) measure . A sample item is "" If you make a mistake on this team , it is often held against you "" ."	235671763	maybe
Current data mining approaches provide hardly any support for incorporating the knowledge of domain experts in the approach to process data explicitly . Often these stepwise approaches assume that knowledge creation and knowledge transfer happens one after the other . An important risk of taking only a functional view is that professionals consider data science approaches as a threat to their profession and will not fully cooperate with data science initiatives . Another risk is the loss of important real - world knowledge when analyzing the data . Both risks consider the human ( and subjective ) influence of each contributor to the data science process .	239658990	no
Each bootstrap sample is a result of drawing M data points from D with replacement . Finally , we approximate the distribution of â by evaluating it on a large number of bootstrap samples , in our case ten thousand . We use this information to construct bias - corrected and accelerated ( BCa ) 95 % confidence intervals for â. BCa ( Efron , 1987 ) is a fairly advanced second - order method that accounts for bias and skewness in the bootstrapped distributions , effects we did observe to a small degree in certain subtasks .	108299957	no
"Our topic modeling algorithm is based on the latent Dirichlet allocation ( LDA ) ( Blei et al . , 2003;Blei and Lafferty , 2007 ) , which is an unsupervised machine learning procedure for parsing text data for co - occurrences of words and word patterns to derive latent structures . The algorithm delineates a distinct number of topics represented in our 1 See https://www.COVIDinnovations.com . sample of innovation projects , which we call "" domains of innovations . "" Each domain is characterized by a list of frequently occurring keywords , and each of the 707 individual innovation projects receives posterior scores ( from 0 to 1 ) , indicating its coherence to the 16 identified domains ( henceforth , coherence score ) ( Blei and Lafferty , 2009 ) . Following Maier et al . ( 2018 ) , we compute a number of different candidate models based on differing prior parameters defining the shape of the posterior distributions . Based on our data , we calculate the optimal number of topics considering the metrics proposed by Cao et al . ( 2009 ) and Griffiths and Steyvers ( 2004 ) . We find that a final model with 16 topics optimally captures the heterogeneity of our text data using a prior alpha value of 0.25 to shape the posterior distribution . We run this final specification of our topic model for 10,000 iterations to ensure the reliability of our model results ."	235513294	yes
The FundÃ£o dam disaster has been extensively covered by Brazilian academia . Much of it has covered the ( in)justice and legal aspects as well as the more social movement perspectives ( see Lyra , 2019;Fontoura et al . , 2019;Zhouri , 2015;Zhouri et al . , 2018;Garcia and Fonseca 2018;Bortolon et al . , 2021 ) . Of particular relevance to this paper , Miranda et al . ( 2017 ) focused on how the disaster led to de - territorialization , with hundreds of families losing their homes and settlements . Such an impact has incommensurable cultural implications from the perspective of the atingidos . From a more political angle , some authors provide a critique of the mining sector in Brazil , indicating the support it receives from state institutions that seem to place corporate rights to mine above human rights ( Wanderley et al . , 2016;Zhouri et al . , 2016;Zhouri , 2018 ) . These authors , much like others who have written about the FundÃ£o disaster , have highlighted the fissures within the handling of corporate - led remediation process and negative social impacts , including exhaustion for the atingidos who are fighting for justice . Although there is a lack of narrative studies that consider how Renova has influenced and manipulated victims through its deliberative process , this paper aims to address that gap . I use the next section to detail the methodology undertaken for this case study along with relevant contextual data necessary for comprehending the story .	254384500	no
After the data was prepared , the descriptions of the apps were analyzed qualitatively to discover informational themes in the text . First , the description of each app was independently read by two researchers for finding keywords in the text using the qualitative approach of open coding , and then , the common keywords were further categorized into 63 broad categories . These 63 broad categories were mapped to create a new COVID-19 mobile app taxonomy comprising of eight emerging themes . These keywords and categories are presented in Fig . 5 . Appendix A provides a list of all the apps and the detailed categories developed . The eight categories or themes of the apps were used to identify the following types of information support : statistics / descriptive analytics , e - Health literacy , telehealth , self - evaluation , symptoms monitoring , resource management , geo - referencing and contact tracing .	236296279	maybe
"NW11 said that since the early days of data journalism , there had been a move from a more open , exploratory approach to a more explanatory , author - driven approach . To test that observation , we draw on Segel and Heer 's ( 2010 ) approach to narrative , and place a range of six data journalism formats that we are proposing ( Table 3 ) on a spectrum between "" author - driven "" and "" reader - driven "" design ( Figure   1 ) . Segel and Heer 's ( 2010 ) identify the properties of the author - driven approach as "" linear ordering of scenes , heavy messaging and no interactivity "" , while the readerdriven approach is characterised by "" no prescribed ordering , no messaging and free interactivity "" . To these , we have added the "" explanatory "" vs "" exploratory "" functions and the semantic operations "" direction "" vs "" discovery "" ."	156033788	no
Finally , testing our results across sectors could be very interesting and useful in order to identify sector - based variations . Unfortunately , our data set did not include sector - based data either for SARS or EBF . Therefore , in a future study , sector - based results can be compared with a different data set .	254386181	no
As the top - down approach is dependent on external data sources for the trade component ( i.e. , EXIOBASE ) , years beyond 2015 can not be included in the assessment as extrapolation methods should be used , as already applied for the period 2012e2014 . In this sense , enlarging the time period would include further uncertainties to the assessment .	198689284	no
"A quick online query confirmed the impression that this was a crazy attempt at "" sextortion "" . The very same mail had been sent to thousands of recipients , whose mail addresses and old passwords had been retrieved from a data breach on some abandoned website . Of course , failure to make the donation did not result in the spread of any video footage . The web is replete with millions of scams like this , and the threat of displaying intimate images is one of the most popular strategies for blackmailing someone . Yet , despite rationally knowing that no hacker could possibly have access to such nasty materials , it took a while to shrug off the sense of uneasiness accompanying the threat ."	255905192	no
In particular , we note that HfTe5 films in few - layer thickness have recently been theoretically predicted as a promising large - gap topological insulator . [ 23 ] HfTe3 bulk probably displays superconductivity . [ 24 ] Interesting , these two materials have a layered configuration in the a - c plane . In the a - c plane , a HfTe5 layer can be considered as a HfTe3 layer linked via Te - Te chains Submitted to 3 ( see models in Fig . S1 in the Supplementary Information , SI ) . [ 23,[25][26][27 ] These data from literatures provide hint for the possibility of the HfTe3 / HfTe5 layered heterostructures with combined properties of topological insulator and superconductor . Besides the bulk materials , however , either HfTe3 or HfTe5 films are not reported experimentally yet . This stimulates us to explore a spontaneous way to construct such layered materials and their heterostructures . This idea may lay the groundwork for the construction of novel 2D systems with integrated properties in fewlayer thickness , suitable for superconducting devices and experimental realization of Majorana fermions .	11143548	maybe
Science is a social enterprise : independent and collaborative groups work to accumulate knowledge as a public good . The credibility of scientific claims is rooted in the evidence supporting them , which includes the methodology applied , the data acquired , and the process of methodology implementation , data analysis and outcome interpretation . Claims become credible by the community reviewing , critiquing , extending and reproducing the supporting evidence . However , without transparency , claims only achieve credibility based on trust in the confidence or authority of the originator . Transparency is superior to trust .	6326747	no
The usual approach to setting the moments for use in batch - norm layers in inference mode is to keep a running average through training . When not learning batch - normalization parameters , we found a small benefit in calculating the batch - normalization moments used in inference only after training had finished . We simply form as many minibatches as possible from the full training - set , each with the same data augmentation as used during training applied , and pass these through the trained network , averaging the returned moments for each batch .	3476061	no
"intervention is the main explanatory variable , namely mobility restrictions and other non - pharmaceutical interventions ( O - NPI ) . Î² 1 is the coefficient estimated , if Î² 1 < 0 , then it indicates that the prevention and control measures have effectively reduced the growth of cumulative cases and mitigated the outbreak of the epidemic . X k is control variable , including population size ( pop ) , GDP per capita ( pergdp ) , number of medical institutions ( hospital ) , number of beds in medical institutions ( bed ) , effective distance from Wuhan ( distance ) to control the city characteristics on the spread of the epidemic . Î² 2k is coefficient of control variable . Although the data structure is a wide panel , the time span is relatively long , and the development of the epidemic itself has a time trend , so we introduced the time trend "" t "" to control the variation trend of the explained variable over time . It is common in econometric studies to consider time trend in modeling . For example , when exploring the influence of economic development on the degree of democracy , BrÃ¼ckner and Ciccone ( 2011 ) also introduced t into the econometric model considering that democratic development itself has time trend . Î´ i is a region fixed effect to control the characteristics of provinces constant over time , Î´ t is a time fixed effect to control to control the time factors that do not vary from individual to individual . Îµ it is error term , we use cluster - robust standard error to estimate the standard deviation ( Cameron & Miller , 2015 ) . In addition , we also set some classified variable : GDP per capita ( PerGDP ) , Baidu Index of "" COVID-19 "" ( Information ) , Baidu Index of "" the correct way to wear a mask "" ( Awareness ) , Baidu Index of "" Zhong Nanshan "" ( Confidence ) to explore more interesting findings ."	235915166	no
As previously mentioned , we use SR plant capacity concepts to assess the efficient use of existing hospital capacity in Hubei province and test their correlation with mortality . Then we use LR plant capacity concepts to assess the build - up of new hospital capacity . We now turn to a discussion of available data to implement these different plant capacity models .	231706096	no
As mentioned in [ 18 , Section 4.3 ] , when training neural networks it is helpful to normalize the input data so that it is zero mean and so that more important dimensions of input data have a larger variance . We wanted a generic way to achieve this that would be invariant to arbitrary affine transforms of the input . The technique we developed requires as statistics a within - class covariance W and a between - class covariance B , accumulated from the class - labeled data as if in preparation for multi - class Linear Discriminant Analysis ( LDA ) . Assume in what follows that we have already normalized the data so that it is zero - mean . For the technique we are about to describe to make sense , the number of classes should not be much smaller than the feature dimension ; fortunately , in our case it is much larger-5000 > 300 , to give typical numbers .	15370378	no
"Once the networks are trained , the sO 2 predictions from the testing set obtained by a FNN and CNN are plotted in Fig . 4a , b , respectively , along with the ground truth oximeter spO 2 readings and the LSF estimates for comparison . Our DSL models were trained by a combination of both datasets from refs . 13,15 . We optimized the LSF model parameters on the same data pool to ensure a fair comparison between the two methods . The detailed descriptions of the LSF model and parameter optimization are provided in the "" Materials and methods "" section . The first 248 testing spectra are from ref . 13 , and the remaining 254 are from ref . 15 . In general , the sO 2 estimations made using both DSL models ( FNN and CNN ) and LSF agree with the spO 2 readings . A closer look reveals that DSL predictions have lower variations than that of LSF , which we attribute to the DSL 's improved robustness to noise and other random signal fluctuations . The absolute errors between the sO 2 predictions and the corresponding spO 2 are plotted in Fig . 4c   The first 248 spectra were from ref . 13 , and the rest were from ref . 15 .   Fig . 3 Oximeter spO 2 readings ( ground truth labels ) for training and testing . a The readings of rat retinal arterioles from normoxia to hypoxia from ref . 13 . b The readings of rat retinal arterioles from hyperoxia , 5 % CO 2 , normoxia to hypoxia from ref . 15 . c Histograms of all spO 2 readings for both the training and testing sets ."	181990850	no
Data were collected at two different time points . At Time 1 , employee 's perceptions of their leader 's behaviors were measured . At Time 2 , 6 months later , hard data of unit absenteeism of the first semester of 2017 was collected . The time lag design made it possible to study the relation between leader behaviors and stress - related absenteeism in the period after survey data collection .	235671763	no
On the other hand , when the amount of training data is limited , learning the syntax produces significantly better performance . By incorporating syntactic structure in the model architecture and objective , more leverage is gained from small training data . Interestingly , the learned syntax model even outperforms the handwritten syntax model . We posit the syntaxLSTM is free to learn a richer syntax . For example , the syntaxLSTM could learn to model the distribution of programs and discourage the prediction of not only syntactically incorrect programs , but also the unlikely ones .	21671720	no
Convolutional layers in DNNs are used to extract high level abstractions and features of data . In such layers , the connectivity between neurons follows a pattern inspired by the organization of the animal visual cortex . It was shown that the computation in the visual cortex can mathematically be described by a convolution operation ( LeCun et al . ( 1989 ) ) . Therefore , each neuron is only connected to a few neurons based on a pattern and a set of weights is shared among all neurons . In contrast , in a fully - connected layer , each neuron is connected to every neuron in the previous and next layers and each connection is associated with a weight . These layers are usually used to learn non - linear	17262272	no
A detailed spectrally resolved analysis of the photocurrent enhancement was carried out in order to determine the incident photon - to - current conversion efficiency ( IPCE ) and the internal quantum efficiency ( IQE ) of the system . Figure 5a shows the measured absorbance spectra of the metasurface and the film with the Pt cocatalyst . The IPCE ( Figure 5b ) was extracted from a set of chronoamperometry measurements under chopped light with 10 nm bandwidth filters ( Supporting Information , Section S17 ) . The results confirm the strong photocurrent enhancement for the metasurface across the visible range , consistent with the optical characterization of the photoelectrodes ( shown in the previous section ) . From these values , the IQE was calculated by the IPCE / absorbance ratio , shown in Figure 5c . We attribute the significant IQE enhancement by the metasurface to the near - surface absorption hot spots in the nanoresonators created by the engineered photonic states , as elaborated in Figure 3c . We believe that these hot photoelectrodes under dark conditions and red , green , and white light illumination . c ) Photo - enhancement factor ( photo divided by dark currents ) for the three different wavelength ranges at V = â0.7 V versus Ag / AgCl . d ) Linear power dependence of the photo - enhancement factor , with s representing the slope for each of the three investigated illumination conditions . e ) Metasurface to film enhancement factors calculated from the data in ( d ) as the ratio between the slopes of power - dependent photo - enhancement factors from metasurfaces and continuous films ( Section S15 , Supporting Information ) . f ) Choppedlight chronoamperometry curves for an a - GaP metasurface compared to continuous a - GaP film at a potential of â0.7 V versus Ag / AgCl under simulated AM 1.5 G 1 Sun illumination . spots facilitate highly efficient and near - surface generation of electron - hole pairs , thereby reducing their recombination probability during migration on the - now shorter - path to the solid / liquid interface compared with the continuous film counterpart . A comparison of the IQE values reported here with previous studies investigating metallic nanoparticle systems [ 36][37][38 ] reveals similar to up to two orders of magnitude higher IQE from our electrodes .	240140340	no
Further , consumer behavior changes may vary based on the social and demographic characteristics of different communities and the rate and extent of transmission in the early stages of the pandemic . Thus , it may be essential to study consumer mobility patterns in distinct geographical areas to understand commonalities and differences in the underlying drivers of consumer mobility , specifically retail mobility ( Clemons , 2008 ) . In this paper , we study the effect of pandemic health metric information and consumers ' perceived risk due to the pandemic on consumers ' mobility decisions in three distinct geographic locations . We use real - time data from Google Mobility , Google Trends , and Twitter to develop a novel prediction algorithm for consumers ' mobility patterns . While Google Trends data have been popular input in several studies to measure public interest , the risk of multicollinearity escalates with the addition of more relevant terms in such studies . Therefore , effective methods must be developed and implemented to maximize the benefit of the information from such data sources . With the developed novel algorithm , our methodology effectively handles multicollinearity and lags in covariates while ensuring that all model - included covariates are statistically significant . These considerations allow the results to be readily interpretable . Consumer mobility is defined as the aggregated , and anonymized movement pattern observed among consumers based on their mobile device location . Further , retail mobility refers specifically to consumer movement trends for retail locations such as grocery stores , restaurants , and shopping centers .	255441206	no
We contrasted this ' functional view ' with an ' institutional view ' on data science and decision - making , that is more oriented to interaction and synergy between different and sometimes competing knowledge sources , of which data science is one and domain knowledge by professionals another . How to amplify synergies between data analysts and domain professionals ?	239658990	no
Encouraging D to use its capacity in a constructive way is non - trivial . One theoretically sound potential approach to regularize D is to use a Bayesian neural net , whose model capacity away from data is not degenerate . However , computationally scalable deep Bayesian neural networks are still an active area of research ( HernÃ¡ndez - Lobato & Adams , 2015;Hasenclever et al . , 2017 ) and are not easy to use . Alternatively , we can use auxiliary tasks to regularize D 's capacity usage . If given labelled data , semi - supervised learning as an auxiliary task for D , as shown in Salimans et al . ( 2016 ) , improves GAN training stability and the resulting generative model . We hypothesize that if the data domain has other structures that can be exploited as supervised learning signal , Exploiting these structures could as well potentially improve the GAN training stability like in Salimans et al . ( 2016 ) .	13669032	no
"One may expect that the same argument carries over KBDT . Unfortunately this is not the case . Assume that you know all the relevant facts about the case ( the number of tickets , the price , that the lottery is fair ) . In a KBDT , Naoko 's decision could be represented as follows 38 : 36 These data are explicitly used by KBDT theorists as evidence for their view . We do not consider here a range of further data traditionally deployed in support of knowledge - action principles , such as direct criticisms of the reasonability of one 's actions . An example is Hawthorne and Stanley 's restaurant case , in which a driver is criticized for taking the wrong street on the basis that she did n't know that was the right direction . The reason is that even philosophers endorsing such principles tend not to consider these as compelling cases for KAP . For recent examples see Littlejohn ( 2020 , Â§ 1 ) and Moss ( 2018a , p. 197 ) , who claims that such cases are "" suggestive but not decisive "" , since they are susceptible to alternative equally intuitive explanations ( cfr . Brown , 2008 , Cresto 2010 , Fassio 2017 , Gerken 2011 , Neta 2009 , Schiffer 2007 ) . 37 The present example is a variant of one discussed in Hawthorne and Stanley ( 2008 , p. 572 ) . 38 For simplicity 's sake in this representation of the situation we assume that in this specific situation utility is equal to monetary value . One may argue that this is an unrealistic assumption : monetary value has always a decreasing marginal utility due to risk aversion . This consideration may be correct , but does n't affect the validity of our general point . We can obtain the same result by modifying specific details of the case , such as the number of tickets or the lottery price . Assuming decreasing marginal utility would just add unnecessary complications . In this case , the expected value of selling the ticket is higher than that of keeping it ( 0.5 > 0.4 ) . Thus , in a KBDT , it is fully rational for Naoko to sell her ticket for few cents : this is the choice that maximizes expected value . This verdict conflicts with our ordinary folk appraisals about the case , according to which Naoko should n't sell her ticket for a few pennies . Far from providing the best explanation of such appraisals , KBDT provides diagnoses which conflict with such intuitive judgments ."	232292483	no
A third alternative is to assume the non - monotonic judgments commonly found in everyday situations as data and try to devise a non - monotonic logic that could account for them . The difficulty in this case is that , by selecting non - monotonicity as a normative principle for correct reasoning in everyday situations , abductivists and predictivists would be eliminating from their data sample exactly that minority of cases where people draw indefeasible conclusions in accordance with reasoning practices that have proved to be fruitful in mathematical and scientific contexts . This could be seen as a kind of pluralism : perhaps everyday reasoning relies on a logic other than the one employed in mathematics and some sciences . But , in this case , why should it be wrong to apply a monotonic logic in everyday contexts ?	238769910	no
"Step 2 : aggregating the "" information intersection "" : after we obtain the best h , g , p that maximizes M IG f ( h , g , p ) , we use them to construct a data - crowds forecaster Î¶ that forecasts ground truth based on both the datapoint and the crowdsourced labels ."	68205758	no
An alternative approach involves an objective or loss function suited for the target task ( Akata et al . , 2014;Frome et al . , 2013;Kiros et al . , 2014b;Mao et al . , 2014;Socher et al . , 2013;Zheng et al . , 2014 ) . These strategies usually assume that there exists a common latent space where modalities can express the same semantic concept through a set of transformations of the raw data . The semantic embedding representations are such that two concepts are similar if and only if their semantic embeddings are close ( Norouzi et al . , 2014 ) . In ( Socher et al . , 2013 ) a multimodal strategy to perform zero - shot classification was proposed . They trained a word - based neural network model ( Huang et al . , 2012 ) to represent textual information , whilst use unsupervised feature learning models proposed in ( Coates & Ng , 2011 ) to get image representation . The fusion was done by learning an image linear mapping to project images into the semantic word space learned in the neural network model . Additionally a Bayesian framework was included to decide whether an image is of a seen or unseen class . Frome et al . ( 2013 ) learn the image representation using a CNN trained with the Imagenet dataset and a word - based neural language model ( Mikolov et al . , 2013b ) to represent the textual modality . To perform the fusion they re - train CNN using text representation as targets . This work outperforms scalability with respect to ( Socher et al . , 2013 ) from 2 to 20,000 unknown classes in the zero - shot learning task . A modified strategy of Frome et al . ( 2013 ) was presented by Norouzi et al . ( 2014 ) . Instead of re - train the CNN network , they built a convex combination with probabilities estimated by the classifier and semantic embedding vector of the unseen label . This simple strategy outperforms state - of - the - art results . Because the cost function involves both multimodal combination and supervision , these family of models are tied to the task of interest . Thus , if the domain or task conditions changes , adaptations are required .	9401721	no
Raman spectroscopy also provides a useful approach to measure microstructure alignment . Many reports acquire a sense of the anisotropy simply by changing the direction of polarization of the inbound Raman laser to the sample , with the polarization parallel and then perpendicular to the direction of microstructure alignment . The intensity change of some Raman spectra feature , typically the G peak at â1580 cm â1 , indicates the degree of microstructure alignment . For aligned MWCNTs , Raman anisotropy values range between 1 and 10 [ 134,275,209,274,315,316,317 ] and , again for aligned FWCNTs , they range higher between 1 and 107 . [ 14,27,28,181,186,190,196,209,218,277,318 ] For the nearly perfectly packed and aligned SWCNT bucky paper , the Raman spectroscopy alignment ratio rose to 160 . [ 9 ] Within specific studies it has been shown that increasing the Raman anisotropy value leads to increased material Adv . Mater . 2021 , 33,2008432   properties . [ 92,294,316,319 ] This Raman technique does not consider the CNT 's significant optical absorption of the inbound laser , which itself is alignment - dependent . Further , this technique does not take into account polarized Raman - shifted radiation going from the sample to the spectrometer . These factors make comparison across different studies difficult and render Raman anisotropy values more of a qualitative indicator of anisotropy than relating directly to a physical material property . Addressing these subtleties , more sophisticated treatments [ 9,181,276 ] of Raman spectroscopy yield physical alignment metrics , although are not widely enough utilized in the literature for analysis here . Still , we plot the simple Raman G peak anisotropy values across the literature ( Figure 8b ) versus conductivity and strength ; correlation data are provided in Tables 15 and 16 . For aligned FWCNT materials , while no correlation is apparent for strength , there is the expected positive correlation between conductivity and Raman anisotropy . The correlation does not survive the weighted adjustment however and this signals undue bias from specific studies . For aligned MWCNT materials , again there is the opposite behavior of what was expected - a negative correlation between conductivity and Raman G peak anisotropy that is marginally maintained after the weighted adjustment .	236090435	no
We performed all optimization with Adam ( Kingma & Ba , 2014 ) and used hyperparameter sweeps to select learning rates and batch sizes .   For the switching controller and control fragments approach we used a standard set of four policies trained from motion capture which imitated stand , run , left and right turn behaviors . In the switching controller , pretrained transitions were created in the reference data . For the control fragments approach , we were able to augment the set without any additional work and the selected policies are described in Table 2 .   A.2 HETEROGENEOUS FORAGE TASK In the heterogeneous forage task , the humanoid is spawned in a room with 6 balls , 3 colored red and 3 colored green . Each episode , one color is selected at random and assigned a positive value ( +30 ) or a negative value ( -10 ) and the agent must sample a ball and then only collect the positive ones .	53792719	no
A Cronbach 's alpha reliability - coefficient test returned a reliability score of 0.843 As this exceeds 0.70 , a high degree of internal consistency within the scaled data is assumed ( Field , 2018 ) , with data being amenable to parametric statistical analysis .	244615298	no
Modelling Framework : All models were constructed using numerical calculations in MATLAB where the catalyst and absorbent beds were discretized into differential segments where the concentration of all species is considered constant . The number of discretizations in each bed was a minimum of 100 , but typically â1000 unless many beds were considered in series ( i.e. , combined catalyst - absorbent system ) . The time step of the numerical models was calculated as the time for the gas phase to pass through each discretization such that the effect of void volume in the reactor / absorber was also considered . For the catalyst model , a conventional power law relation was implemented in which each kinetic parameter was determined using a distinct characteristic in the temperature - conversion profile obtained ( Figure 1d ) . The order of reaction for N 2 and H 2 in the forward reaction was determined by varying the pressure of N 2 and H 2 independently and measuring rate of reaction ( Figure 1f ) . These orders were confirmed by the increased catalytic activity as the N 2 : H 2 ratio increased from 1:3 to 1:1 and 2:1 . The rate constant for the forward reaction was calculated from an Arrhenius plot when conversion is < 5 % . Generating a model for the catalyst which included high conversion required discretization in 1000 segments because the reactor is no longer differential when the reverse reaction becomes significant . The reverse rate constant was determined assuming that the forward and reverse rates must be equal at equilibrium for 1:3 N 2 : H 2 . The order of reaction for NH 3 in the reverse reaction was determined by matching the discretized model with the curvature of the maximum conversion data . A higher order results in a model that reaches higher peak conversions because the reverse reaction requires a higher concentration of ammonia before it becomes significant relative to the forward reaction . Conversely , a lower order model achieves lower conversions because the reverse reaction needs to begin resisting the forward reaction at lower conversions if it will also maintain a hardstop at equilibrium . Finally , the order of reaction for H 2 in the reverse reaction due to inhibition was determined using the constraint that the equilibrium is followed for N 2 : H 2 ratios of 1:1 and 2:1 ( i.e. , a negative reaction order causes the conversion at high temperatures to decrease as N 2 : H 2 increases because the reverse reaction becomes faster ) . This catalyst model is applicable at the wide range of temperatures , pressures , and N 2 : H 2 ratios expected for a typical analysis .	233828232	no
"The comparison of the parameters denoting partial correlation between the logarithm of taxation level and cotinine level 1 and taxation and cigarettes consumption 1 allows for informing if tax hikes result in more intense smoking and/or lower consumption of cigarettes . These regressions have been estimated on data from National Health and Nutrition Examination Survey ( in particular , NHANES III and NHANES 1999 - 2000 that cover , respectively , the periods between 1988 to 1994 and 1999 to 2000 and deliver data for approximately 20,000 individuals ) merged by the econometricians with a database reporting the levels of excise tax on cigarettes for each state ( adjusted for inflation ) . Even though more recent data had been available , Cornaglia ( 2006 , p. 1016 ) decided not to use them because "" [ t]he later waves contain less information on individual characteristics , which restricts our analysis in some cases . "" Otherwise , they would have to lower the number of explanatory variables ( X ist ) what could potentially lead to model"	236249427	yes
Besides the degree of perovskite crystallinity , trap density and charge collection in a solar cell can also impact the device 's V OC and FF . We quantified the trap - state densities of the reference , control , and target devices by spacecharge - limited current ( SCLC ) measurements in the dark , which are very close to each other ( 2.7 Ã 10 16 , 2.4 Ã 10 16 , and 2.5 Ã 10 16 cm â3 ) ( Supplementary Fig . S20a ) . Meanwhile , we determined from time - resolved PL data 38 that , on average , control films have a surface recombination velocity ( SRV ) of â¼800 cm s â1 , whereas the Au@PAT - treated target films exhibit an average SRV of â¼700 cm s â1 ( Supplementary Fig . S20b ) . In addition , we observed from ultraviolet photoelectron spectroscopy results that the energy - band alignment in perovskite layers remains unchanged after the incorporation of plasmonic NPs ( Supplementary Fig . S20c ) . However , a notable change in the charge recombination dynamics was found from the transient photovoltage measurements ( Supplementary Fig . S21 ) . For the target devices , lifetimes span from 4 to 360 Âµs under a given illumination intensity , while the control devices exhibit a lifetime range from 2 to 110 Âµs under the same illumination condition , indicating decreased carrier recombination in the plasmonic cells under operation . This implies that the plasmon - enhanced light - molecule interaction , rather than the nanostructure itself , might be the main source of suppressed trap - state density .	240076239	no
The first step in the framework ( figure 3 ) is ' enlargement of individual knowledge ' . At NVWA this was already put in practice . Inspectors and data analysts were already interacting , however not in a structured way . We considered this step an ongoing activity that takes place during all days that the respondents work at the NVWA . The knowledge of each individual that works at the NVWA is enlarged during their work . It consists of their work experience and their interactions with their colleagues and other stakeholders .	239658990	no
Most of the recent studies about the statistical dependence of COVID 19 risk with natural and anthropogenic factors have been done by investigating the characteristics of involved variables . It is also rare to find any study which incorporates the time - varying probabilistic characteristics of COVID 19 cases . The association of the pandemic with the environmental and socioeconomic factors is not only intricate but is also varies with time in space . For instance , the climatic variables itself are time and space varying ; therefore , their relationship with the exponentially evolving COVID cases also tend to vary . Many studies in different areas have shown that time - varying probabilistic models often prove to be more productive in comparison to their stationary counterparts ( Das et al . , 2020b;Jha et al . , 2020;Ragno et al . , 2019;Song et al . , 2020 ) . In this study , we utilize a nonstationary extreme value model to estimate the COVID 19 risk in India . The major objectives of this study can be summarized as ( i ) to assess the association of climatic factors ( pressure , relative humidity , temperature and wind speed ) in augmenting the COVID 19 risks in India at rural , urban and total ( rural and urban ) population scales . ( ii ) to estimate vulnerability and exposure elements by assessing the socioeconomic condition of the population ( iii ) to prepare the high resolution ( district - wise ) map of the pandemic risk by combining the nonstationary COVID 19 hazard measure and the vulnerability and exposure elements . The recent study can help the policy makers in identifying the possible high risk hotspots of the COVID 19 like pandemics as well in understanding the possible reasons governing the risks . The current study provides a simple , computationally efficient , data intensive and feasible mechanism to perform risk analysis at several scales . This can help policy makers in deciding the response measures at different administrative division scale and identify the natural as well human factors to keep an eye on to minimize the risk .	231965779	no
More precisely the analysis was conducted as follows . It started with the word for word transcription of the recorded interviews . This was accompanied by initial note - taking to document interesting statements to be remembered for the deeper analysis to come . Once this was done , interesting parts of each interview were coded in a systematic approach across the entire data set . Each data item has been given equal attention in the coding process and the data items were analyzed independently . Next , the codes were assorted into thematic groups . The topics were constantly refined and checked for internal homogeneity and external heterogeneity to ensure a coherent and meaningful analysis ( Braun & Clarke , 2006 ) . This was a two - stage process of revision and refinement . First , preliminary topics were examined at the level of encoded data items , with all transcription extracts read for each topic to provide a consistent model . If data items had no relation to the current topics , new topics were created . On the other hand , topics that were similar in content were summarized to enable the identification of overall themes . Second , after all the topics had been reviewed , an overview of the generated topics was applied , where the preliminary topics were examined in regard to the total data set to review if the provided analysis is competent enough to reflect the data holistically . This means that the remarks of a single interviewee could not lead to a topic . That is , the researcher often switched between the transcribed data set and the candidate topics , including any additional data that may have been omitted during the analysis process . As a result , the outcomes were subsumed under overarching themes , namely financial management , crisis management , stakeholder management , and solidarity and society .	231706267	no
We use the cross - sectional regression model , logistic regression model and logistic growth curve in our analysis . Our dataset is collected from the Oxford Martin School and British Broadcasting Corporation . We compare the British Broadcasting Corporation classification on lockdown in association with the stringency index to reassess the appropriateness of this classification . We find evidence that during the period March to June 2020 , the total number of cases has a positive relationship to the growth of new confirmed cases . We find that this represents a reproduction rate that is an influencing factor against the number of confirmed cases which appears to decrease as the months go on . In addition , we find that as a result of lockdown , there is a negative relationship between GDP per capita and new cases . More significantly , we find that regional differences exist in the spread of the virus . In using the logistic regression model , we find strong support that Europe is approximately three times more likely to adopt a national lockdown than America . In contrast , Asia and Africa are less likely to adopt a national lockdown . As a consequence , there is a direct relationship between the reduction of confirmed cases per million and national lockdown across continents . We have therefore looked at countries which have implemented a national lockdown and compared the effectiveness of this against countries that have not implemented this measure . We focus on Europe as the majority of countries implemented a national lockdown . Our findings from the logistic growth curve reaffirm that in Europe , the daily number of new cases continuously began to decline after the first inflection point and second following the month of April .        Simple is the three - parameter S - shaped logistic growth model . Double is the six - parameter S - shaped logistic growth model . Inflection indicates the point of inflection and growth rate indicates the maximum growth rate defined in the logistic growth curves . Date indicates the date that the point of inflection or maximum growth rate is reached . Day indicates the number of days taken to reach the point of inflection or maximum growth rate since the number of new cases was reported in Europe . Our data set shows that there were three coronavirus cases reported in France on 25 th January 2020 which is the first day in the observational period . Estimated is the number of daily accumulated or new cases estimated by using the logistic growth models ( Meyer , 1994;Meyer et al . , 1999 ) . Confirmed indicates the number of daily accumulated or new cases collected from countries that have imposed a national lockdown . Point 1 and point 2 indicate the first or second point of inflection and its maximum growth rate . Maximum indicates the maximum number of accumulated cases or daily new cases over the observational period .	234683604	yes
Here we proposed a simplified OLID system based on polarization modulation of the dipole excitation or linear dichroism . Polarization modulation is achieved with a rotary , linear polarized light that irradiated the sample at different polarization angles ( Fig . 1a ) by a rotatory halfwave plate ( HWP ) . The hardware was identical to a linear dichroism system , in which the fluorescence signal excited at specific polarization angle was simultaneously recorded under a custom Epi microscopy ( Supplementary Note 1 ) . The HWP was mounted on a motorized rotation stage in synchronization with camera ( Fig . 1b ,   top ) . To ensure linear polarization after the dichroic filter , a Berek Polarization Compensator ( BPC , New Focus TM ) was employed ( Fig . S3b ) . According to the truth , each rotation of the motor generates a pulse , the rising or falling edge between the two pulses could be considered as a motor period , so the modulation angle of excitation at each frame was determined by the captured frame pulse of the camera recorded synchronously . The motor rotates once and the polarization direction of excitation rotates twice , that is 4 modulation cycles , named as 4 OLID cycles ( Supplementary Note 1 ) . The lower panel in Fig . 1b shows the periodic sinusoidal response of fluorescence emission from the rotational polarized excitation ( Supplementary Note 2 - 3 ) . This signal can be exactly used for accurate frequency domain lock - in amplification because it carries a fixed frequency . The orientation was obtained by extracting the phase difference between the fluorescence intensity curve ( Fig . 1b , bottom ) and the standard modulation curve . Here the standard modulation curve is the optical response of a standard polarizer / dipole on the focal plane , and the direction of the polarizer / dipole is parallel to the X - axis of the imaging system ( Fig . 1b , middle ) . Calibration of the absolute polarization angle is conducted by the standard curve ( Supplementary Note 3 ) . In the case of the significant noise or background signal in the acquisition images , as shown in Fig . 1c , we kept the zero - frequency and modulation frequency components to separate the noise and improve orientational accuracy .   Fig . 1 Principle of OLID . a Rotary - linear - polarized illumination scheme of OLID . b Top : the sync signals of camera readout ( blue line ) and motor rotation pulse ( red line ) . Middle : intensity curve of the laser after passing through a polarizer parallel to the X - axis of the system on the focal plane . Bottom : the emission intensity curve of a GFP molecule on the focal plane under polarization modulated excitation . There are four modulation cycles in one motor rotation cycle . c Alexa Flour 561 labeled F - actin in fixed mouse kidney sections , with wide - field image on the left , OLID image on the right . Scale bar : 5 Î¼m . d The flowchart of OLID - SDOM . The data of four modulation cycles at each pixel were transformed by 1D Fourier transform , and then we extracted the modulated frequency component and generated a 1D single period data . After processing each pixel , 3D deconvolution of the obtained single period image , named as OLID image , was carried out to obtain the G dc ( R ) , and G ac ( R , Î¸ ) , and orientation mapping was extracted by FFT phase extraction . e The flowchart of SDOM . 2D sparse deconvolution was performed for super - resolution reconstruction and the least - squared fitting was performed for orientation mapping its polarization invariant ( DC ) component g dc ( r ) , polarization variant ( AC ) component g ac ( r ) , and its orientation Î±(r ) . The fluorescence anisotropy of the fluorescent dipole is defined as pÃ°rÃ Â¼ g ac Ã°rÃ = Ã°g ac Ã°rÃ Ã¾ g dc Ã°rÃÃ . We use r , R to describe the position of the sample plane and the camera acquisition plane , respectively . g(r , Î¸ ) and g(R , Î¸ ) are the modulation intensity of the sample intensity and the camera acquisition plane under polarization angle Î¸ of excitation light respectively . G dc ( r ) , G ac ( r , Î¸ ) , G dc ( R ) , and G ac ( R , Î¸ ) are the polarization invariant and polarization variant intensity of the sample plane and the camera acquisition plane by the polarization angle Î¸ of excitation light respectively .	245617420	no
The contribution of digital technology to the COVID-19 pandemic management can take many forms and bring significant value ( Ting et al . , 2020 ) . Thus , the investigation of big data and AI is connected to epidemic disasters ( Shaluf , 2007 ) , which have been plaguing our planet for decades ( e.g. the Spanish flu , avian flu , Ebola , SARS , MERS and SARS - COV-2 ) , as an interesting and important research - stream .	234046079	no
In generative adversarial networks ( GAN ) ( Goodfellow et al . , 2014 ) , the goal is to learn a generative neural network that can model a distribution of unlabeled training examples . The generative network transforms a random input vector into an output that is similar to the training examples , and there is a separate discriminative network that tries to distinguish the real training examples against samples generated by the generative network . The generative and discriminative networks are trained jointly with gradient descent , and at equilibrium we want the samples from the generative network to be indistinguishable from the real training data by the discriminative network , i.e. , the discriminative network does no better than doing a random coin flip .	53483414	no
"With the rapid increase in OPV performance during the last decade , there has been an increasing awareness in the research community for the growing need to establish generalized stability testing conditions , enabling improved comparability between lifetime values reported from different research labs . Based on reports and discussions from the fi rst three International Summits on OPV Stability ( ISOS ) in 2008 , 2009 and 2010 , the so - called "" ISOS - protocols "" were defi ned . These were summarized in a publication entitled "" Consensus stability testing protocols for organic photovoltaic ( OPV ) materials and devices "" in 2011 . [ 5 ] In response to the lack of practical guidelines for intercomparable OPV stability tests , the aim of the ISOS community was to establish standard procedures for accurate lifetime estimations of organic thin fi lm solar cell devices . The protocols were intended to provide more tailored criteria to investigate OPV stability than was outlined in the existing IEC 61646 , [ 1 ] which is intended for the commercial qualifi cation of terrestrial thin fi lm photovoltaic modules but not for elucidating degradation pathways and identifying key mechanisms limiting device lifetimes . One major motivation for developing the ISOS protocols was to identify parameters which infl uenced device stability in order to enable reasonable accuracy in the comparison between reported stability and lifetime data for organic thin fi lm devices . The ISOS study aims to coordinate efforts to gather as much information about OPV degradation and stability in a controlled manner such that qualifi cation tests , which may be more suitable or detailed than the IEC 61646 , can be developed ."	97325601	maybe
The popular rectified linear unit ( ReLU ) , f ( x ) = max(0 , x ) , is an example of such a function , while the sigmoid functions satisfy this property approximately . The following theorem shows that each standard DNN layer performs a stable embedding of the data .	15654042	no
The seventh category of apps includes apps focusing on geo - referencing . Apps using location data to monitor a user 's physical movement and to identify COVID-19 hotspots fall into this category . Smartphone GPSes are used to collect user location information , which is automatically transmitted to a server to create aggregated results . Users are required to provide a one - time consent before using the app that allows the app to gather their location information . Some apps also allow users to manually add data about locations they visited in the past few days . For instance , users can report the places they visited in last 14 days , in addition to consenting to mobile location detection , in the Care19 Diary app . Similarly , Canada 's BC COVID-19 Support app requests devices ' location data in order to provide users with location - based alerts . Over 15 % of the apps in our dataset are used for geo - referencing , with this feature as either their primary or secondary objective . However , only three apps in our entire dataset were classified with this category as their primary objective . This category of apps continuously generates data and provides active information support during a pandemic .	236296279	no
We used a spectroscopic approach to assess nanoparticle leaching and the long - term stability of these nanoparticleloaded hydrogel systems . Iron oxide nanoparticles strongly www.advmat.de www.advancedsciencenews.com absorb in the 300 - 400 nm wavelength range ; we assessed UVvis absorbance of supernatants taken from gels incubated in calcium - supplemented saline for up to 6 months ( Figure S2 , Supporting Information ) . NP and NP - COOH capsules were stable , with no detectable nanoparticle leaching over a 6 month timeframe . In contrast , leaching of NP - PEG from the NP - PEG hydrogel capsules occurred over a 6 month timeframe ( < 0.2 mg mL -1 , Figure S3 , Supporting Information ) . These data suggest that the NP - PEG alginate hydrogel system is not stable , and that NP - PEG are able to move within and out of the hydrogel matrix over time .	212416638	maybe
Beside Google Trends indexes reflecting searched of COVID-19 keyword each month , other control variables are used in the models : harmonized unemployment rate , harmonized index of consumer prices and economic sentiment indicator . The Google Trends indexes are computed by authors as geometric means of the daily values provided by Google Trends ( https://trends.google.com/trends/ ) . For each month we selected the values of the Google Trends indexes registered each day in each country . The period of one specific month and the country are directly selected in the Google Trends website . The data for the rest of the variables are provided by Eurostat .	237473259	yes
â¢ The contents of perception are not a function of cognition ( as in Fodor , 1984;Raftopoulos , 2019 ) . â¢ The contents of data are a function of likely unconscious racial bias in particular social sciences ( as in Gould , 1981 ) . â¢ The contents of phenomena may be not a function of prior beliefs ( as in Franklin , 2015 ) .	238651842	no
Data were analyzed using an inductive approach , in which themes were developed from raw data and then grouped into higher - order clusters ( Miles and Huberman 1994 ) . Interviews from all stakeholder groups were analyzed separately , as well as combined into one body of data to identify themes that were important to all stakeholders participating in the research , in line with previous studies that have researched multiple stakeholder groups for the development of a theory applicable across groups ( e.g. , Chun and Davies 2006;Gardberg and Fombrun 2002;Hillenbrand et al . 2012 ) . The data analysis revealed that business leaders and industry representatives expressed many similar views , as did NGOs / think tanks and special interest groups , and it was therefore seen as appropriate to summarize these two groups as the business group view and the community group view , respectively ( as they have been referred to in this study throughout ) . The issue of unity of sample was further examined after careful consideration of potential alternative interpretations . It emerged that respondents across groups talk about corporate tax approaches in terms of similar themes ( such as contributions to society , transparency , power ) , but differ in some of the specific opinions and expressions of them , as detailed later . As such , it was possible to identify a number of themes that speak across groups , but which required separate interpretations of their nuances and expressions with business groups and the societal stakeholder view . We followed the guidelines for inductive data analysis by Easterby - Smith et al . ( 2002 ) and Miles and Huberman ( 1994 ) , and we analyzed transcribed text through an iterative process of first applying codes and then identifying trends and themes in the data via a qualitative clustering approach . No prior theory was used as a basis for the coding process , and therefore , all coding and emerging themes are the result of the applied cluster analysis procedure . The data analysis process was conducted separately by two of the authors who produced unique coding and clustering protocols . This provided the basis for comparison , interpretation , and labeling of emerging themes . During the data analysis process , any commentary that diverted from the focus of this study , i.e. , corporate tax approaches , was carefully excluded from the data analysis . Mutual agreement on the labeling of themes was achieved in line with the procedure described by Ravasi and Schultz ( 2006 ) in discussion between all authors . This process led to a reduction in the total number of themes from ten to eight , to more succinctly represent the data .	158680894	no
This section presents the data and the methodology used to predict mobility as a function of consumers ' perceived risk . Prior research has identified that perceived risk plays a vital role in consumer behavior . Based on the stay - at - home order issued by the state and county governments , one significant behavioral change relates to their mobility decisions . Therefore , due to individuals ' perceived risk , individuals may restrict or change their mobility for different activities . We first describe the risk perception dimensions and then discuss data sources that map onto these dimensions .	255441206	maybe
The dataset was based on information offered by the partners on a structured form designed by the Agentschap NL staff . Between 2010 and 2013 , one of the authors was invited , in her capacity as a researcher , to provide suggestions for improvement by Agentschap NL . This provided access to a unique dataset that included information on 205 projects developed by international joint ventures formed between 2006 and 2011 in 44 countries . 55 % of the 205 projects were in agriculture and agro - processing , and 40 % were distributed across different types of industry . As the Dutch government had plans to change the rules applied to PSOM - PSI policies in 2013 , we limited our sample to those projects developed between 2006 and 2011 to ensure that data on PSOM - PSI were comparable in terms of project performance .	239655312	maybe
In step three , we pilot tested the index with a sample of 524 UK employees , checking for convergent validity ( with a re - test sample ; N = 100 ) and external validity through correlation with an organizational justice scale ( Moorman , 1991 ) and with the nepotism scale developed by Spranger et al . ( 2012 ) . We also examined reliability estimates for each variable , ( comprised of at least three items per category ) and checked for multicollinearity . For reasons of space , the full procedure and results are not included here , but all data is available from the authors on request .	238408791	yes
Considering the above , in this paper we investigate the reasons which led to the discontinuation of PT use after the start of the COVID-19 pandemic , by considering a worldwide dataset which combines both local specific socioeconomic characteristics as well as PT service attributes . We synthesized PT mode choice , service characteristics and passengers ' perceptions data from Moovit subscribers , along with socioeconomic and COVID-19 related variables , to compile a crosssection dataset that covers 87 cities worldwide . We study the changes in PT service characteristics before ( year 2019 ) and after the outbreak of the pandemic ( year 2020 ) , the passengers ' views on the desired service conditions under post - pandemic circumstances , and we develop linear regression models to identify the PT service aspects along with the macro socio - economic factors that might explain the abandonment rates on PT use , which were observed globally by the end of the year 2020 .	255826268	no
Stochastic gradient descent ( SGD ) [ 1 ] is a dominant approach for training large - scale machine learning models such as deep networks . At each iteration of this iterative method , the model parameters are updated in the opposite direction of the gradient of the objective function typically evaluated on a mini - batch , with step size controlled by a learning rate . While vanilla SGD uses a common learning rate across coordinates ( possibly varying across time ) , several adaptive learning rate algorithms have been developed that scale the gradient coordinates by square roots of some form of average of the squared values of past gradients coordinates . The first key approach in this class , ADAGRAD [ 2,3 ] , uses a per - coordinate learning rate based on squared past gradients , and has been found to outperform vanilla SGD on sparse data . However , in non - convex dense settings where gradients are dense , performance is degraded , since the learning rate shrinks too rapidly due to the accumulation of all past squared gradient in its denominator . To address this issue , variants of ADAGRAD have been proposed that use the exponential moving average ( EMA ) of past squared gradients to essentially restrict the window of accumulated gradients to only few recent ones . Examples of such methods include ADADELTA [ 4 ] , RMSPROP [ 5 ] , ADAM [ 6 ] , and NADAM [ 7 ] .	166228264	no
Training time per epoch . We report the average training time per epoch in Table 3 . We decided to only compare the training time per epoch since all hyperparameters were solely optimized for accuracy and the used early stopping criterion is very generous . Obviously , ( exact ) PPNP can only be applied to moderately sized graphs , while APPNP scales to large data . On average , APPNP is around 25 % slower than GCN due to its higher number of matrix multiplications . It scales similarly with graph size as GCN and is therefore significantly faster than other more sophisticated models like GAT . This is observed even though our implementation improved GAT 's training time roughly by a factor of 2 compared to the reference implementation .	67855539	no
"For this same reason , one can only construct what its originator calls "" rough scenarios "" ( Weimer - Jehle 2006 , p. 359 ) . Weimer - Jehle , the originator of the CIB method , also notes that since expert data not only supplies the information for the pairwise judgments but also structures the logic of the system itself , CIB analysts should keep the uncertainties surrounding such data firmly in mind . Because the analysis relies so completely on expert judgments , it is crucial that those judgments be gathered in such a way that they are serious and carefully considered , and not "" the result of little reflected guessing "" ( Weimer - Jehle 2006 , p. 359 ; see Sects . 3.1 and 3.2 ) . 8 An additional possible drawback to the CIB approach is that it may be more demanding for the analyst , or party convening the scenario exercise , than the Intuitive Logics method : Surveys of experts take time , effort , and commitment of the CIB analysts , plus the cooperation and commitment of experts completing the surveys . All of this , versus the relatively simple task of inviting experts together for a workshop or meeting to discuss a variety of possible scenarios - as is done for the Intuitive Logics approachseems to require a distinct difference of effort by the conveners of the two approaches . In addition , it is possible that more is demanded of the experts in question ; in the CIB method , they are put on the spot and asked to semi - quantify forced judgments in pairwise interactions or correlations , which can be a daunting task in comparison to an open discussion of the same . On the other hand , much is also demanded of experts in the Intuitive Logics method ; they are required to entertain various largescale collections of variables in alternate global scenarios . It may be too early to say which approach is more demanding , but the CIB method , as carried out in the climate case by Schweizer and O'Neill ( 2013 ) , proved to be fairly demanding , as it required developing instruments and protocols to define the scope of the scenarios as well as to collect 1,404 distinct judgments , recruitment of experts to participate in the exercise asynchronously , and data entry of the experts ' responses into a CIB software package . We may wish to say that this level of detail is actually the strength of the approach ; nevertheless , that does not change the fact that it is costly to achieve ."	797453	no
Funding The data in this paper were collected as part of a wider research project into corporate tax practices , funded by the University of Reading . The overall project benefitted from a financial contribution by Deloitte toward the cost incurred in conducting the study . The study was designed and conducted solely on the guidance and principles of academic faculty at the University of Reading and in accordance with the ethical guidelines stated above .	158680894	no
In an initial test , we fed the algorithm only with emitterrelated parameters from the systems included in this study ( i.e. , no host - related data was considered ) . Clear correlations of a were observed with various parameters ( N E , MW E , L E , and the dimensions of the emitter molecules , x E , y E , and z E ) . We note that the correlation between a and N E is likely to come from clustering of the data , since we took N E = 100 wt% for neat films and its largest value in doped films was 30 wt% . The only parameters with statistically significant coefficients in the multiple linear regression were MW E , L E , z E , and N E , in that order	236774690	no
As one of the popular topics in Natural Language Processing , many different approaches to achieve sentiment analysis have been proposed . One algorithm is to consider sentiment analysis as a classification problem - determining a Tweet as positive , negative , or neutral / subjective or objective . Bertrand et al . ( 2013 ) implement the classifiers using the Natural Language Toolkit ( NLTK ) , train feature sets with different labels , and generate sentiment measure by combining the output value of each feature set . Neppalli et al . ( 2017 ) use Naive Bayes and Support Vector Machine as the two supervised machine - learning classifiers and use a combination of bag - of - words and sentiment features as input to the model . Gandhe et al . ( 2018 ) propose a hybrid approach that combines supervised and unsupervised learning in the sentence - level sentiment analysis model . This method takes partially labeled training data as input and allows researchers to classify unlabeled data based on lexical methods . The other type of sentiment analysis algorithm is list - based instead of classifier - based . The sentiment value of words in the annotated wordlist is predefined , and the initial seed of annotated sentiment words is grown by techniques like clustering . Nielsen ( 2011 ) has developed such a list by manually examining Tweets with high sentiment values and adding the antonyms / synonyms of such sentiment lexicon to the list . This sentiment - word list has 2477 unique emotional words ( mathematically ranging from +5 to â 5 ) . It is worth noted that Nielsen 's matching approach performs better than the more comprehensive list , Affective Norms for English Words ( ANEW ) , developed by Bradley and Lang ( 1999 ) .	236251116	yes
Informed Consent Not applicable . This article does not contain any identifiable personal data .	235459410	no
RiceGrip in Real World . In this environment , we need to come up with a sequence of grip configurations , where each grip contains positions , orientation , and closing distance . The method to sample the candidate control sequence is the same as when generating training data of RiceGrip , and N fill is chosen as 768 . Different from the previous case , the physical parameters are always unknown and has to be estimated online . After selected the best performing control sequence , we first use RMSprop optimizer to optimize the control inputs for 20 iterations using a learning rate of 0.003 . We then use model - predictive control to apply the control sequence to the real world using Algorithm 1 , where N is selected as 10 .	52917627	no
The order of all of the preceding questions was fixed . This is because we were interested in the true / false judgments of our target counterfactuals by scientists who were aware of modal distinctions and their own views about the ( im)possibility of non - integer rabbits ; we wanted our respondents to evaluate the counterfactuals right after they had said one of their assumptions was , or was not , impossible . This meant that we could only collect this data after we had first introduced our participants to the distinction between nomic and metaphysical possibility and solicited their judgments about the modal status of non - integer rabbits . We could have varied the order of ( 3 ) and ( 4 ) , but we did not . We do not claim that our data is independent of the order in which we asked the questions .	255802252	no
More generally , it is questionable whether this bias , however it is described , covers the formation of delusional beliefs in the way envisaged . Consider a case of anosognosia where , for example , a subject denies that her left arm is paralyzed . There may be an absence of experienced motor failure to alert the subject to the issue . Nevertheless , there are also a whole range of experiences - seeing the arm inactive while still feeling sensation through it , failures to clap , and so on - where there is observational data crying out to be explained . If there is a bias at work here , it is not properly characterized as privileging what is observed ( Davies et al . , 2005 , pp . 217 - 227 ) . Equally , as Davies and Coltheart point out , if subjects with delusions had a straightforward bias in favour of observational adequacy so understood , we would expect them to be taken in far more frequently by visual and other illusions . There is no evidence that this is so ( Davies & Coltheart , 2000 , pp . 25 - 27 ) .	237820651	no
Future work should include improving the complexity of the modeling techniques introducing theory of Recurrent Neural Networks that might capture better the correlation of the predictors and their evolution in time . For instance , the possibility of including mobility data at the AACC level and for a number of years can contribute largely to improving the predicting capabilities of the model .	233916124	no
"By using a transparent risk model the cycle from data preparation to evaluation can be done interactively with all actors involvedincluding data analysts and inspectors . Of course , this can be done with just a limited amount of persons . It will be a transparent process for the few . The challenge here is how to entice the larger part of the organization to understand the reasoning behind the model . This means that ' evaluation ' and ' justification ' will be long - lasting processes . These processes will have two functions : improving the model and spreading the word ( "" networking knowledge "" ) ."	239658990	no
By preparing solutions , containing different concentrations ( 100 fm to 10 nm ) of the miRNA miR-19b and miR-20a , incubating them at 37 Â° C and applying them to the functionalized channel , different calibration curves were recorded ( Figure 2 , Figures S15 and S16 , Supporting Information ) . By fitting the measured data points to a four or five - parametric sigmoidal curve , a LOD of 10 pm equivalent to an amount of 500 amol of miRNA , was achieved for the miR-19b within 3 h incubation   Time dependency of the CRISPR - based off - chip miRNA targeting . a ) Calibration curve of the off - chip cleavage scenario for 1 h , using the miR-19b as a target miRNA . The reporter RNA ( reRNA ) is applied at a concentration of 250 nm , for the enzyme Cas13a and the crRNA : a ) concentration ratio of 1:2 and 1:4 with respect to the reRNA is used , respectively . The results are fitted with a five - parametric logistic fit , gaining a limit of detection of 18 pm with an interassay coefficient of variation ( CV ) of below 9 % . With n = 4 replicates , error bars represent Â± SD . b ) Off - chip calibration curve , as described in ( a ) , using the miR-19b as target miRNA . The incubation time for the cleavage process was 3 h. The results are fitted with a four - parametric logistic fit , resulting in a limit of detection of 10 pm , along with a CV of below 10 % . All error bars represent Â± SD of n = 8 replicates . c ) Calibration curve of the off - chip cleavage method as in ( a ) , using the miR-19b as target miRNA . The incubation time for the cleavage process was 24 h. The results are fitted with a five - parametric logistic fit , resulting in a limit of detection of 2 pm and a CV of below 8 % in the dynamic range . All error bars represent Â± SD of n = 4 replicates . time and an overall interassay coefficient of variation of less than 10 % ( Figure 2b ) . As the cleavage of the reporter RNA is a time - dependent process , the prolongation of the incubation increases the amount of cleaved RNA and , therefore , reduces the amperometric signal ( Figure S14 , Supporting Information ) . To decrease the limit of detection furthermore , a calibration curve with an extended incubation time of the mixture solution for 7 h ( Figure S15 , Supporting Information ) and 24 h is recorded ( Figure 2c ) . Contraintuitive , we could not observe an improvement of the LOD for a 7 h cleavage time . In our opinion , this is due to the very low concentration of the target miRNA and the therewith resulting lack of active Cas13a enzymes in the solution . This leads to an unsatisfactory total catalytic activity of the effector with a very low reaction rate , which is not sufficient for a further significant signal reduction at very low concentrations of the target miRNA within 7 h of incubation . Comparing the different cleavage times in terms of sensor performance , a minimum LOD of 2 pm was achieved after a 24 h incubation , while a maximum dynamic range of roughly two orders of magnitude can be seen , at a cleavage time of only 1 h , along with a LOD of 18 pm ( Figure 2a ) . In general , the longer the cleavage time , the lower the limit of detection and the lower the dynamic range of the resulting calibration curve ( Table S6 , Supporting Information ) . With that , our CRISPR / Cas13a - powered biosensor is able to reach the stated LOD of 10 pm after 3 h , showing its capability to detect picomolar concentrations of miRNAs , without any preamplification procedure of the target miRNA , while consuming reagent volumes less than 0.6 ÂµL per incubation .	204966460	maybe
To acquire domain / ellipsometric knowledge , the SUNDIAL is first trained offline on a large amount of simulated data which however may significantly deviate from the real - world experimental data . We applied data augmentation to increase the robustness of the trained model . The protocol is as follows : 1 ) Shift the input left or right randomly by a few wavelength which is not greater than 3 in our experiments ; 2 ) Multiply the input features by a small random scale ( 1 + g * N r ) , where g is a random number generated from a standard normal distribution , and N r denotes the noise level not greater than 10 â3 here .	232201390	no
DFT Calculations : All spin - polarized calculations were carried out via using the Vienna Ab - initio Simulation Package ( VASP ) package . [ 29 ] The projector augmented wave ( PAW ) [ 30 ] pseudopotential and the RPBE exchange - correlation functional [ 31 ] were used in the calculation with a 500 eV cutoff energy . More relevant details , references , and data are given in the Supporting Information .	103905968	yes
In this framing , 5 G in part causes the problem to which it is presented as being the solution ( i.e. dramatic traffic growth ) . The dominant view in our corpus however is that 5 G efficiency improvements can indeed counteract traffic growth and its energy use implications and so render mobile networks sustainable . The requirement for action that stems from this framing is to ensure that 5 G energy efficiency improvements and other measures ( e.g. renewable electricity purchasing ) are sufficient to render the data traffic growth that is at least partly caused by 5 G sustainable .	254302320	no
We examine the correlations between demographic profiles and mobility behavior to explain heterogeneity across communities predicted by the meta - population model and our pro - posed BD model ( Fig . 1e ) . We find that the percentage of older adults negatively correlates with per capita mobility ( r = â0.29 ) , and thus neglect of demography - specific mortality risk will lead to inaccurate estimation of risk for different age groups . By contrast , our proposed BD model finds differences in mobility behaviors outweighed by the change in IFRs due to age structure and predicts higher mortality risk in communities with higher percentages of older adults , consistent with previous research ( 24,40 ) . Moreover , communities with lower average household incomes and higher percentages of essential workers are associated with higher levels of mobility , likely following from limitations in their ability to significantly reduce mobility during the pandemic ( 26,31,32 ) . Therefore , both the meta - population model and proposed BD model reproduce higher risk associated with low - income communities , while the risk associated with essential worker percentages remains complicated due to the joint effect of demographic and mobility profiles , e.g. , essential workers generally have higher mobility but younger demographic profiles . In view of this , considering the joint effect of both mobility behaviors and demographic profiles should enable improved prediction of the heterogeneous risks facing different communities . By incorporating both into the epidemic model and utilizing large - scale real - world mobility data for calibration , the proposed BD model is effective in generating accurate daily predictions and capturing heterogeneous risks faced by distinctive communities and provides a framework from which we can analyze the impact of differing vaccine distribution strategies on social utility and equity .	244102867	no
Experimental insight can provide guidance into which systems are synthesizable , allowing selection of materials , but , further , experimental data are incredibly important both for validation of predictions , and revisiting of approaches , and to build databases of materials and their properties for training by ML models . Here , automation and robotics provides the potential to vastly increase the scale , and decrease the timescale , with which data are collected . Integrated programmes can best utilize this opportunity , ensuring that data are collated and archived in a consistent fashion , including the recording of the system , the synthesis conditions , and any known details of the structure and properties . Very often , this information is not recorded electronically and certainly not made open - source . Computational www.advancedsciencenews.com	231871676	no
Limitations and future research Our study is not exempt from limitations , many of which offer opportunities for future research . First , we selected a particular set of potential factors which will affect the success of business transformation . We also selected a particular theoretical framing focused on the direct impact of a factor on the transformation . However , we admit that there might be additional and alternative factors such as organizational culture and trust , and arguments on how they affect the transformation . Extending our framework with additional theorizing might enable future research to further tease out the critical factors for the success of the transformation . Second , the effects of individual behavior on organizational transformations in difficult times were underexplored in our study . The micro - level of analysis may provide additional insights into how managers should make decisions in times of crisis and this should be incorporated in future research . Third , similar to other qualitative research on COVID-19 related business transformation , data in our study is subjective . We tried to overcome the potential bias in our interviewees ' responses by considering companies in a variety of industries and interviewing multiple people from different departments in each company . Future research might focus on one company and obtain detailed financial data for testing hypotheses .	245617006	no
Regarding the thermal stability , the fabricated solar absorbers were characterized in terms of their phase , morphology , and optical properties before and after annealing them at 600 Â° C for 7 days at a vacuum pressure of â5 Ã 10 â3 Torr using a tubular furnace . The XRD patterns were obtained using a PANalytical multipurpose diffractometer with an X'Celerator detector and Cu KÎ± radiation ( Î» = 1.54056 Ã ) operating at 45 kV and 40 mA. Raman scattering spectra measurements were carried out on a T64000 Raman system ( Horiba Jobin Yvon ) at room temperature . The excitation source was the 514 nm laser line of an air cooled Ar - ion laser . The thickness of the cermet fi lms were measured with an Alpha - step 200 Profi lometer ( Tencor ) . The growth rates of metal and dielectric layers were measured by a quartz crystal monitor equipped in the sputterring system . The morphology and roughness of the fi lms were measured with a Veeco Dimensions 3000 AFM . The spectral bidirectional refl ectance were measured at room temperature with a spectrophotometer by Varian ( Cary 500i , angle of incidence 8 Â° , absolute spectral refl ectance accessory ) covering the wavelength range of 0.3 - 1.8 Âµm , and with an FT - IR Spectrometer by Thermo Scientifi c ( Nicolet 6700 , angle of incidence 12 Â° ) covering the wavelength range of 1.8 - 20 Âµm . The latter ( relative measurement ) required a reference with known spectral refl ectance , which was chosen to be a specular gold mirror ( Thorlabs ) . The indirectly obtained emittance values of solar absorbers from spectral refl ectance data measured close to room temperature signifi cantly underestimated the emittance at elevated temperature because it ignored the temperature dependence of the dielectric constants . [ 2,16 ] For that reason , the solar absorptance and total hemispherical emittance of a fabricated solar absorber ( S - W / SS ) with thermally stable and most promising spectral refl ectance data was directly measured at elevated temperatures ( up to 500 Â° C ) using simple steady state calorimetric methods . [ 16 ] The sample was attached to a heater assembly and suspended in a vacuum chamber . The electrical heater power input was directly related to the radiation heat loss from the sample surface . Thus , the total hemispherical emittance could be calculated with the electrical heater power inputs and the measured sample and surrounding temperatures . The solar absorptance was measured at elevated temperatures using a solar simulator . The sample / heater assembly was suspended in the vacuum chamber facing a viewport allowing the solar simulator beam to irradiate the sample surface . The solar absorptance could be obtained by varying the incident radiation power onto the sample and measuring the corresponding electric heater power adjustments to maintain the sample surface at a constant temperature .	98438953	no
We verifi ed this effect fi rst by measuring the conductivity of a pristine PCBM fi lm and a PCBM fi lm containing a controlled amount of I â . The latter was realized by adding a Adv . Energy Mater . 2016 , 6 , 1501453 www.MaterialsViews.com www.advenergymat.de wileyonlinelibrary.com methylammonium iodide ( MAI ) solution ( 10 mg mL â1 in isopropanol ) to the pristine PCBM solution ( 30 mg mL â1 in CB ) with a ratio of 1:30 . In Figure 6 a , we compare the J -V plot of the two fi lms . For this test we chose symmetric gold contacts with a channel length of 200 Âµm in order to avoid contact resistance effects . The addition of the MAI salt to the PCBM results in a markedly increased conductivity , which changes from 6.43 Ã 10 â7 S m â1 for the pristine fi lm to 4.35 Ã 10 â6 S m â1 for the PCBM / MAI fi lm . This effect may be ascribed either to a chemical doping of the PCBM , i.e. , an excess of free carriers , or to an improved mobility , or both . In order to get deeper insights we tested the electronic properties of a PCBM fi lm and a PCBM / MAI fi lm in top gate / bottom contact fi eld - effect transistors ( FETs ) . By comparing the measurements ( Figure 6 b ) of the pristine PCBM and the MAI doped devices , we are able to extract useful information regarding the PCBM interaction with ions that validate the aforementioned PCBM / perovskite interaction . The extracted saturation mobility ( at V G = V D = 60 V ) results in being 5.9 Ã 10 â2 cm 2 V â1 s â1 for the pristine PCBM transistor - in agreement with literature values [ 27,28 ] -and 0.15 cm 2 V â1 s â1 for the doped PCBM / MAI device . The latter value is more than two times higher than the pristine PCBM one . The pristine PCBM device shows poorer subthreshold slope values and a higher threshold voltage ( 36.3 V , which reduces to 8.1 V upon doping ) , likely owing to deep trap states . The holes current tail exhibited at low gate voltages in the saturation regime by the pristine PCBM device ( V D = 60 V curve in Figure 4 c ) disappears in the MAI doped one , resulting in a suppressed hole conduction . At the same time , a marked increase of the nongateable OFF current in saturation in the MAI doped devices denotes a conductivity increase of the semiconducting fi lm , confi rming the results reported above for the two terminal devices ( in the linear regime the OFF currents are at the level of leakage and can not be compared ) . The generally increased performances ( Table 2 ) of the doped device , with respect to the pristine one , can be attributed according to the literature [ 29 ] to an increased concentration of excess carriers , as a consequence of chemical doping which shifts the Fermi level closer to the LUMO level of PCBM . To confi rm this we used ultraviolet photoelectron spectroscopy ( UPS ) to investigate the energy levels of the same fi lms used in the transistors ( Figure 6 c ) . The limited penetration depth characteristic of UPS makes this investigation more suitable to explain the FET data , where a nanometer thick channel accumulates at the Adv . Energy Mater . 2016 , 6 , 1501453 www.MaterialsViews.com www.advenergymat.de   semiconductor - dielectric interface , rather than the two terminal samples data . By linear extrapolation from the high binding energy region of the spectrum we derive the position of the Fermi level for pristine PCBM and for the PCBM : MAI fi lm to be , respectively , at â4.27 and â4.13 eV. This is a relatively small but consistent shift of the Fermi level toward the vacuum level when the methylammonium salt is added to the fi lm , indicating a clear n - doping effect . From the Fermi level position , as a fi rst approximation , we have estimated the charge carrier density at thermal equilibrium in both fi lms on the basis of a single - crystal lattice model . [ 30 ] In the case of the pristine PCBM we determined an electron density of 2.5 Ã 10 11 cm â3 ; while for the PCBM : MAI fi lm a concentration of 5.7 Ã 10 13 cm â3 , two orders of magnitude higher respect to the pristine sample ( see the Supporting Information for the calculations ) . Thus , in the transistor deep trap states are fi lled by chemically introduced excess carriers , and as a consequence , for the same applied gate voltage , electrostatically accumulated carriers in the channel occupy more mobile states , thus producing a net shift in the threshold voltage and an increased fi eld - effect mobility . These results confi rm the interaction between ions and the PCBM that occurs at the interface between the perovskite and the PCBM , with the increased conductivity of the PCBM phase owing to an increased number of free carriers induced by I â doping .	97979989	no
To confirm the imaging capability of our L - PAM - GS system using the agent - free localization method , we imaged black polystyrene particles in vitro and a mouse ear in vivo ( Supplementary Fig . S8 and Fig . 5 ) . In the in vitro experiment ( Supplementary Text ) , the standard deviation of the localized positions of a single particle , determining the enhanced spatial resolution , were 0.4 , 0.7 , and 2.5 Î¼m ( x , y , and z directions , respectively ) 33 . We applied our localization method to the label - free PAM of small animals in vivo by localizing the PA signals induced by RBCs . L - PAM - GS is able to capture the RBCs instantaneously based on its fast temporal resolution and high SNR ( Fig . 5a ) . In addition , the PA signals in each frame , generated from the same RBC , can be localized at different positions under the flow condition . The L - PAM - GS image is finally rendered by superimposing all points localized in each frame ( Fig . 5b ) . In this experiment , a sequence of 60 images , each with a size of 1.5 mm Ã 1 mm ( x - and y - axis , respectively ) , was obtained , with a volumetric imaging speed of 2.5 Hz ( Fig . 5c ) . Our localization algorithm was applied to each volumetric frame to determine the local maximum points , and the maximum points were superimposed to render localization 2D PA MAP and 3D PA volume images ( Fig . 5d , e ) . Supplementary Movies 5 and 6 illustrate the actual 2D and 3D formations of the improved L - PAM - GS image from the sequence of 60 frames . The rotation movie of the localization volume image also shows the enhanced microvascular structures ( Supplementary Movie 7 ) . Supplementary Figure S9 shows the conventional and localization PA MAP images of the mouse ear along the yaxis . The imaging depths of both approaches are at least 320 Î¼m , but these are not the maximum imaging depth because the thickness of the mouse ear is too thin to show the maximum imaging depth . To emphasize the enhanced   resolution , we enlarged two regions in Fig . 5c ( Fig . 5f , i ) and corresponding regions in the localization MAP image in Fig . 5d ( Fig . 5 g , j ) . The line profiles marked in the magnified images are displayed in Fig . 5h , k. The profiles of the green dashed line a - aâ² in Fig . 5f and the blue dashed line b - bâ² in Fig . 5 g are compared in Fig . 5h . Likewise , the profiles of the green dashed line c - câ² in Fig . 5i and the blue dashed line d - dâ² in Fig . 5j are compared in Fig . 5k . As shown in Fig . 5h , the microvessels were clearly resolved into two separate microvessels by L - PAM - GS but were not resolved in the regular PA MAP image . In Fig . 5k , the regular PA profile shows only two microvessels , but the localization profile shows three detached microvessels . We also compared the B - mode images of the region highlighted by the green dashed line in Fig . 5c ( Fig . 5l ) with its corresponding localization Bmode image ( Fig . 5 m ) to prove the improvement in the axial direction . We compared the profiles of the green dashed line e - eâ² in Fig . 5l and the blue dashed line f - fâ² in Fig . 5 m ( Fig . 5n ) . The blood vessels that could not be resolved in the regular PA B - mode image are well separated in the localization B - mode image , and the profiles confirm this enhancement ( Fig . 5n ) . We compared the Bmode images of the conventional and localization OR - PAM , where a microvessel begins to bifurcate into two , to quantify the improvement in the spatial resolution ( Supplementary Fig . S10 and Supplementary Text ) . These results demonstrate that the improvement in the spatial resolution by a factor of 2.5 was achieved in vivo by an agent - free localization approach . To render a localization PA microvascular image , multiple volumetric data had to be acquired . Thanks to the fast imaging speed ( e.g. , B - scan rate of 500 Hz ) and high SNRs , our system could quickly track the localized PA signals from RBCs by obtaining multiple volumetric data within seconds .	208210153	maybe
Census data were obtained from the official Census website ( http:// censusindia.gov.in/ ) of Government of India . All the data sets are freely available on the given websites .	231965779	yes
"Our data analysis , however , presents a notable contradiction in journalists ' construction of the audience in UX design , which future studies should seek to unpack . Despite reporting a move away from interactivity , data journalism producers were seen to offer experiences in whose meaning negotiation the reader takes centre stage . This "" audience first "" approach somewhat paradoxically co - exists with increased efforts to control the UX and guide the reader through the narrative , invoking the traditional gatekeeping role of journalism ."	156033788	no
"In section Â§ I , I lay out some familiar Sellarsian dilemmas that raise questions about how our sense experiences provide warrant for our empirical beliefs about the world . I then suggest that Sellars 's critique has subsequently been assumed to be inapplicable to widespread views of two opposed kinds . It is assumed or objected that either ( 1 ) the Sellarsian critique targets an irrelevantly "" thin "" nonconceptual form of the given ( e.g. , ' sense data ' ) that is simply irrelevant to more phenomenologically adequate or conceptually "" thick "" conceptions of the experiential given ; or conversely , it is assumed ( 2 ) that Sellars 's myth had an irrelevantly "" thick , "" overintellectualized target concerning conditions on inferential reason - giving justification that makes the myth inapplicable to sufficiently "" thin "" or non - epistemic versions of the experiential given ."	237823662	no
Because use of multiple imputation remains the most rigorous approach to analyzing data involving a large percentage of missingness , and to remain consistent with our pre - registered approach , we report the original results in the manuscript , noting our new sensitivity tests on page 9 - 10 of our revision , and directing readers to our openly - available , reproducible analytic code and full results on Open Science Framework .	242291039	yes
Though a number of studies have focused on the global economic and energy changes brought about by COVID-19 , most studies have focused on the interior of a single country or collective but have ignored the interconnection between countries . In fact , in the context of economic globalization , the country is no longer an island ( Chica - Olmo et al . , 2020 ) . In previous studies in other fields , the global vector autoregressive ( GVAR ) method was used to assess the relationship between economies ( Chudik and Fratzscher , 2010 ) . Feldkircher and Korhonen considered that how shock from the world economy influence China 's economy and how shock from China influence the world economy on the basis of GVAR model . They found China 's economic growth benefited its trading partners ( Feldkircher and Korhonen , 2012 ) . Gurara and Ncube unveiled that global growth spillover on Africa mostly came from Eurozone and BRICS economies ( Gurara and Ncube , 2013 ) . Kempa and Khan aimed to explore two - way spillover effects of public debt and growth in eurozone by GVAR model on the basis of quarter data from 1991Q2 to 2014Q4 ( Kempa and Khan , 2017 ) . Timo Bettendorf developed a GVAR model to identify spillover effects of credit default risk in nine European Union members , Japan , the United States , and the United Kingdom . The results indicated the spillovers presented stronger within European Union members ( Timo Bettendorf , 2019 ) .	231875597	no
D ik is a series of time interval dummy variables referred to above , with values ( 0 , 1 ) to control the interval between each day and the lunar new year . For example , D 2020;1 is the first dummy variable representing the first 3 - day interval from the lunar new year in 2020 . The data for 37 days after the Spring Festival are collected in this study . Therefore , it is divided into 10 interval periods . The coefficient of concern in the trend effect test was b k , which represents differences in air quality between the COVID-19 period in 2020 and the reference years of 2018 or 2019 in the K - th period after the Lunar New Year , to characterize the dynamic change of air quality in the COVID-19 period and the previous year .	233029637	no
The database consists of 637 employee questionnaires , out of a total 687 questionnaires collected after discarding 38 substantially incomplete questionnaires and the elimination of a further 12 through a process of outlier detection using a Z - score threshold value of 3.75 ( Tabachnick and Fidell 2001 ) . Missing data - which accounted for 3 % of total observations - were treated through computer generated mean substitution ( Peugh and Enders 2004 ) . The sample data are evenly distributed by gender ( male 47%/female 52 % ) . Nearly three quarters ( 72 % ) are British with the next largest group being European ( 17 - 6 % of which were Irish ) . The average tenure is 4.8 years ( s.d . 3.8 ) . The mean age of the respondents is 34.35 ( Std = 10.85 ; max = 66 ; min = 15 ) . Most respondents occupy non - managerial positions ( 69 % ) . Supervisors ( 16 % ) and senior managers ( 7 % ) make up the remainder . This translates into a ratio of junior to middle and senior staff of 14:4:1 , which is broadly in line with what might be expected in these types of organizations . 90 % of the employees work full time and 8 % part time . Unaccounted for percentages refer to missing data .	234120882	no
"The self - diffusion coefficients of ions measured in carbons by PFG NMR are summarized in Table 2 . The full set of diffusion data including attenuation curves , aspects of their processing and detailed discussion of obtained values in the The electrochemical characterization of the model carbons C micro ( triangle , grey ) , C meso ( circle , blue ) , and C hierarch ( square , red ) measured in the two different electrolytes . Painted symbols represent the 6.6 m EMIM - BF 4 , empty symbols represent the 1 m EMIM - BF 4 . a ) Nyquist plot ; b ) specific capacitance calculated with different specific charge - discharge currents ; c , d ) imaginary part of the capacitance Câ²â² at different frequencies ; e , f ) real part of the capacitance Câ² at different frequencies . www.advenergymat.de www.advancedsciencenews.com context of electrolytes structure and pores confinement is provided in the method section and in Supporting Information . Depending on the type of electrolyte and confinement the absolute values of diffusivities span over four orders of magnitude , being expectedly rapid in the diluted bulk electrolyte ( e.g. , 1.74â10 â9 m 2 s â1 for anion ) and least mobile when measured with a neat IL diffusing in micropores ( e.g. , 4 Ã 10 â12 m 2 s â1 in C micro ) or perpendicular to the orientation of mesopores ( e.g. , â2â10 â13 m 2 s â1 in C hierarch ) . It is worth noting that in C meso and C hierarch the data revealed pronounced anisotropic diffusion consistent with their 1D mesopore channel architecture ( Figure 1 ) . This allowed the measurement of ionic diffusivities in the directions parallel ( D || ) and perpendicular ( D â¥ ) to the orientation of primary carbon nanorods . If not stated explicitly , D || is used in all further considerations . When diffusivities are compared between different carbons the following common trend is observed C micro < C hierarch < C meso . The dilution of a neat electrolyte with the solvent ACN always resulted in higher diffusivities from approximately threefold in C micro to â39 - fold in the bulk solutions . This enhancement , introduced as the ratio of respective diffusivities D 1 m / D 6.6 m and called a "" DUTY - factor "" , revealed differences when the cations and anions and compared with each other . The DUTY - factors obtained for anions are always higher than those of cations suggesting that dilution of EMIM - BF 4 by ACN increases the anionic mobility more efficiently . This is probably due to more isotropic shape of a BF 4 -ion , which can easier form a solvation shell around itself promoting the ionic diffusion , compared to the elongated shape of EMIM - cation ."	236550603	no
For IT specialists , we relied on data from Habrahabr , a collaborative IT platform used by Russian - speaking developers from the post - Soviet states . As of July 2021 , Habrahabr has 1.3 million users registered ( Habrahabr 2021 ) and is viewed as the largest information resource for IT specialists from Russia ( Minak 2020 ) as well as Russian speakers from other post - Soviet countries . It hosts both individual and corporate blogs of the largest post - Soviet IT companies ( e.g. , Yandex ) and is valued both for its important role for soliciting feedback from the IT community and the possibility of generating traffic for company websites ( ni404 2014 ) . While HabraHabr offers a less comprehensive overview of IT discussions compared with the one provided by Google Scholar for academic ones , it is still the largest information resource for Russophone IT specialists in the region .	239186570	no
"Data pre - processing is the preparation of data for analysis or use in training a machine learning algorithm ; other terms for the process are ' data wrangling ' , ' data transformation ' , ' data cleaning ' , and ' tidying ' . It is often stated that this stage takes 70 - 80 % of the time in a data analysis or machine learning project ( Wickham , 2014 ) . No standard approach encompasses all of the data pre - processing that might be required ; as Hadley Wickham states , "" [ l]ike families , tidy datasets are all alike but every messy dataset is messy in its own way "" ( Wickham , 2014 , p. 2 ) . Common subtasks of data pre - processing include reshaping the data , re - formatting the data , removing or imputing missing values in data , dealing with outliers , augmenting the data , and feature engineering . Let us consider a dataset containing information about people 's features , such as their age or height : should the age of a person be a number or an age interval ? If a person 's height is missing in the data , should the person be excluded from the dataset or should her height be imputed from the mean height of people in the dataset ? If a person is reported to be 210 years old , what should be done with this obvious outlier ? Should more features , such as body mass index , be added to the data ? Such questions are just a few simple examples of how such pre - processing could be conducted . While some steps in pre - processing data can be performed without any domain - specific expert knowledge , such knowledge is often required in dealing with ( and discovering ) missing values and outliers . For instance , different contexts may require data to be imputed in different ways ; a missing temperature reading on a particular day could often be replaced with the mean temperature of the surrounding days , but a missing sales number reported on a particular day might indicate a closed shop , which would lead the missing value to be replaced with a zero rather than a mean from the surrounding days . Finally , it should be noted that training a machine learning algorithm is an iterative process that often involves researchers going back to perform additional data pre - processing ."	256060110	no
Functional hierarchical organization . Using the above methods describing NDTE flow , we can establish and study the functional organization of data where the different levels of directed flow to and from a given brain region i are given by G in ( i ) , G out ( i ) , and G tot ( i ) .	230509029	no
In contrast , WFPs estimated based on the WFN state level are much more diverse . Using CFTW with limited user input and global datasets reduces the RMSE of the WFP by over 70 % for all crops in comparison of WFN estimates ( Table 4 , Fig . 6 ) . This shows the differences between local WFPs and average state level WFPs presented by WFN , but also the benefit of using field level yield data as well as more local climate , soil and management information . Therefore , WFN state level WFP data can not be used as approximation for individual fields within one state as it does not reveal the variability of WFPs on state and even individual field level .	146803893	no
In order to clarify the notation of transverse and longitudinal responses ( electrical and thermoelectric ) , in the below table , we define all of the transport parameters with their corresponding directions used in this study . A more detailed discussion on the transport coefficients is presented in ref . S4 .   Figure S4 . Magnetic - field - dependent Nernst thermopower ( Sxy ) data discussed in the main text at selected temperatures up to room temperature .	143422224	yes
Finally , prescriptive algorithms aim at delineating what should be done in light of different possible scenarios . Prescriptive algorithms go beyond forecasting future outcomes by also suggesting different courses of action to benefit from alternative scenarios and demonstrating the consequences of each possible decision ( Davenport 2013;Krumeich et al . 2016;Souza 2014 ) . Prescriptive algorithms stem from the academic subfield of operations research and are based on similar methods as predictive algorithms ; however , they add simulations and scenario - based techniques to the repertoire ( Stewart and McMillan 1987 ) . One HR - related example stems from the logistic firm UPS . UPS uses an artificial intelligence technology to shorten parcel delivering routes , thereby saving time and fuel ( Konrad 2013 ) . To do so , UPS equipped its parcel delivery cars with sensors , registering all brakes and turns as well as the car users ' personal driving habits . These data are matched in real time with other data , such as weather and traffic news . UPS does not only use the results to make the driving routes more efficient , but it also uses these results as part of the key performance indicators to rate their drivers ' performance ( Zax 2013 ) .	189902940	no
The following themes emerged after the analysis of data : peripheral actors adopting journalistic discourses ; data - powered fact - checking strategies ; and expanding the meta - journalistic discourse . The respondents here are identified using codes : CA ( Code for Africa ) , AC ( Africa Check ) and OU ( Open Up ) .	158951976	no
where nT is the number of data points in a testing set ; i is the item index ranging from 1 to the total number of items ( n ) ; t is the time index of the time series ranging from 1 to the final time in the evaluation period ( T ) ; Å· i , t is the predicted value at point ( i , t ) ; y i , t is the observed value at point ( i , t ) .	235499813	no
With the two - view projection , the data acquisition of T - CUP can be described as	52137013	no
Discriminative ANNs are algorithms that can capture data relationships of the form y = f(x ) When x specifies a device pattern and y is its optical response , the discriminative ANN serves as a surrogate electromagnetic ( EM ) solver , solving the forward problem 432 . To train a discriminative ANN , a training set of known device patterns and optical responses is first created using a conventional EM solver . The ANN is then trained to minimize error between the outputted and known optical responses , for given device pattern inputs . Mathematically , the loss function is defined to be the mean square error between the outputted and ground truth optical responses , and this function is minimized during the training process by applying back - propagation algorithm 148 . While the training data collection and ANN training are computationally expensive , a trained ANN can perform computations orders of magnitude faster than a conventional solver . A challenge to training an accurate and generalized ANN is curating a sufficiently large and diverse training set that properly represents the desired computation space . A basic and typical strategy is to use a random , uniformly distributed set of devices 432 . If there are known , statistically rare features pertaining to the device geometry or optical response , these features can be learned by the ANN by augmenting the training set with a disproportionally large number of examples of these data .	244479950	no
A schematic description of the whole - body ROAT is presented in Fig . 1a with its detailed outline available in Supplementary Fig . 1 . The illumination system comprises a dual - output ( output1 : 1064 nm and output2 : 700 - 900 nm ) custom - made optical parametric oscillatorbased laser ( Innolas Laser GmbH , Krailling , Germany ) capable of generating pulses with a repetition frequency ( PRF ) up to 100 Hz and < 10 ns pulse duration with energy approaching 30 mJ. Imaging at 1064 nm was performed for anatomical labelling of the different internal organs of the mother mouse and embryo . Multispectral imaging was achieved with fast sweeping of the laser wavelength on a per pulse basis within the NIR spectral window ( wavelengths 700 , 730 , 755 , 800 and 850 nm ) , which enabled rendering functional information from different foeto - maternal regions . Tissue excitation was carried out using a guided custom - made optical fibre bundle ( Cer - amOptec GmbH , Bonn , Germany ) bifurcated and terminated into 12 separate optical outputs placed at equiangular distances at the top and bottom surface of the US transducer array . Each fibre - tip output provides a Gaussian illumination profile with a diameter of~12 mm ( full width at half maximum ) at a distance of~30 mm when immersed in water . The pressure ( US ) waves generated within the mice via thermal expansion were acquired using a ring array transducer ( Imasonic SAS , France ) covering a~360Ëangular view around the imaged object . The ring array transducer consists of 512 adjacent piezoelectric sensors with a central detection frequency and â6 dB detection bandwidth of 5 MHz and~80 % , respectively . The individual array elements have a size of~15 Ã 0.47 mm 2 ( height Ã width ) . The pressure waves for all elements were simultaneously sampled at 2032 instances with a sampling frequency of 40 MHz using a custommade data acquisition system ( Falkenstein Mikrosysteme GmbH , Taufkirchen , Germany ) . The acquired signals were subsequently transferred to a host PC through a 1 Gbit Ethernet connection for reconstruction and postprocessing . The imaging system can acquire images at frame rates of up to 100 Hz determined by the PRF of the laser . Faster frame rates could be achieved with higher PRF lasers by sparsely acquiring signals from a reduced number of channels 41 .	199547598	maybe
Finally , the data of confirmed cases and the number of deaths caused by COVID-19 are recorded . The data has been extracted from the website of the World Health Organization ( WHO ) . This organization presents the registration of data for the incidence of COVID-19 , which facilitates comparison between countries . In this way , the number of confirmed cases ( Infected ) and the number of total deaths ( ' Death ' ) registered on July 13 , 2020 have been obtained . Both magnitudes are relativised per thousand inhabitants .	233550712	yes
The preceding discussion can be summarised in two key observations : ( a ) consumer behaviour in terms of their readiness to travel is a key consideration for assessing the trajectory of the tourism sector 's recovery after being devastated by the pandemic , and ( b ) personality traits may facilitate examining the behaviour of tourists in the COVID-19 context . Building upon these observations , we argue that scholars must examine the readiness of consumers to travel in the context of the pandemic by investigating the personality traits proposed by the fivefactor model as drivers of their intentions to travel during and after the pandemic . This approach enables us to respond to calls for research related to the recovery of the tourism sector even as the pandemic and its effects continue to loom large . We propose advancing this investigation via two research questions ( RQs ): RQ1 : How do the Big Five personality traits influence individuals ' intentions to travel for leisure during and after the pandemic ? RQ2 : What are the differences in the relative influence of the five traits on individuals ' intentions to travel for leisure during and after the pandemic ? To respond to the above research questions , we collected data from 500 individuals residing in Japan and analysed it using an artificial neural network ( ANN ) approach .	245008959	no
The simulation results for the pollutant NO 2 were compared with the average yearly concentration recorded in four pollutant monitoring stations located in Turin ( Rebaudengo , Lingotto , Rubino , and Via Consolata ) , during the period 2015 - 2019 and the COVID-19 lockdown period . These monitoring stations record the total ambient concentration of pollutants , which is the result of multiple sources present in the area , as well as the interactions between chemical species and the atmosphere . The comparison is reported in Fig . 10 These results are also comparable with the source apportionment data reported in Piedmont Regional Plan for Air Quality ( Piedmont Region , 2018 ) . Source apportionment methodology adopted in this document is based on an integration of modeling and analytical techniques . For the modeling source contribution , the methodology adopted is the 3D sensitivity runs / Brute Force Method -BFM . This method involves the creation of a reference simulation ( base case ) and a suitable number of sensitivity simulations , one for each emission category to be analyzed . The contribution of each category is calculated by analyzing the differences between the results of the sensitivity simulations and those of the base case . Table 3 shows the source apportionment of NO 2 concentrations measured on an annual basis at each of the monitoring stations considered .	236179718	maybe
"8 Compared with the ILCD recommendations , the "" land use "" impact category has been excluded because of the high uncertainty related to the life - cycle inventory data available in LCA databases . The impact category "" resource depletion "" has been split into "" abiotic depletion potential ( ADP ) "" ( CML , 2015 ) and "" primary energy demand from renewable and non - renewable resources ( gross cal . value ) [ MJ ] "" ."	158828025	no
"The reconciliation of ideal journalism with an actual working practice based on reproduction and retransmission of knowledge claims made by other sources strengthens the "" epistemological paradox of journalism "" ( â¬ Ornebring 2017 , 85 ) . The increasing adoption of data - powered processes is amplifying the epistemological shift ( Parasie 2014 ) in which the power to explicate knowledge is placed on data rather than on the journalist ."	158951976	no
For data comparison , a one - way ANOVA analysis ( Sigma Plot , Systat Software ) was applied on the two genotypes , wt and mdx , with a post hoc Bonferroni test ( equal variance ) or post hoc Tukey test ( no equal variance ) where indicated . p < 0.05 was considered significant ( * ) , and p < 0.01 was considered highly significant ( * * ) . The normality of data was tested using the Shapiro - Wilk test . Data are presented as box plots ( median value : line , quartiles : whiskers 5 - 95 percentiles , minimum / maximum values :x , mean : rectangle ) . Pearson correlations were calculated using the online tool http://www.socscistatis tics.com/tests/pearson/Default2.aspx , or SigmaPlot .	53101046	maybe
We equipped a cube - shaped DNA origami structure ( obtained from GATTAquant ) with DNA PAINT binding sites . On two opposing sides of the DNA cube with a side length of 24 nm , we placed 8 nt binding sites at a height of 19.2 nm above graphene . On the other two opposing sides , we placed binding sites at a height of 16.5 nm ( Figure 7a ) . For DNA PAINT imaging , we used an 8 nt long ATTO542 labeled imager strand . We generated 2D images via fitting of the point - spread function and determined the z - position from the fluorescence intensity excluding the first and the last frame of each binding event ( see the Supporting Information for details on experimental procedures and data analysis ) . An overview image of the DNA origami cubes is shown in Figure 7b , in which the height information is color - coded . The exemplary magnified views of the x / y and x / z projections ( Figure 7c - e ; Figure S10 , Supporting Information ) show that the structure is resolved in xy ( Ï â 5 nm ) and in z with a demonstrated resolution better than 3 nm . To the best of our knowledge , this is the finest structural detail in the axial direction that has been resolved by optical microscopy . Another advantage of measuring DNA PAINT on graphene is that unspecific surface binding of imagers goes along with complete quenching instead of creating unspecific localizations .	233482830	no
"It is also important to note that IoE business models are not static . Instead they are continually being enacted through the resource integration practices of the actors . Indeed business models "" define the resources that an individual market actor possesses and the ways that actor can interact with other actors - and their resources "" ( Storbacka & Nenonen , 2011 , p. 247 ) . In the IoE , resource flows from connected and smart things often include data flows that dictate how connectivity creates value and how the business models that integrate data create complementarity or conflicts at the meso level ."	213757082	no
With regards to databases containing properties , these are comparably sparse in the field of organic materials , certainly compared to inorganic materials , where there are large - scale databases such as NOMAD [ 40 ] and the Materials Project . [ 41 ] One difficulty is the lack of a uniform way to represent the structures of organic materials and potentially complex device architectures , and the fact that large numbers of materials have not been synthesized and characterized , certainly not in a consistent fashion suitable for training data . Specific databases with experimental data often only contain a few hundred data points , thus the majority of organic material databases instead contain computed data , where there are 10 000s of data points for a specific application , for example , the electronic band structures in the Organic Materials Database . [ 42 ] This means computational studies that aim to use ML to predict properties typically have to start by building their own training data first , taking care to have a diversity of systems such that the scope of the model is as broad as possible . With regards to the representations of the materials , these need to capture key chemical features of the material , which will often include solid - state structural arrangements . The representation required will be dependent on the properties being predicted , in some cases a 2D graph representation will be sufficient , but this is unlikely in the case of electronic properties that depend on molecular conformation , or even crystal packing . The development of improved descriptors for molecular packing is required for many systems to be adequately modeled by ML , for example , the SOAP kernel includes how similar the 3D arrangement of a system is . [ 43 ] Deep learning ( DL ) algorithms can generate their new representations of structures through automated feature extraction . [ 44 ] DL has thus far been mostly applied for the prediction of molecular properties , such as energies , but is likely to see increasing use in organic materials .	231871676	no
Plots depicted here were typically logarithmic scales due to the great spread of values typical for CNT materials and in the interests of identifying power - laws . Colored ovals are sized to encompass 90 % of the data points and help identify trends . In the discussion of ampacity , ovals indicated 95 % confidence intervals . On the logarithmic data , for a given CNT category , the strength of the Pearson correlation coefficient and the probability ( p - value ) that it is significant were calculated . Probabilities less than or equal to 0.05 ( p â¤ 0.05 ) are deemed significant and colored green ; probabilities between 0.1 and 0.05 ( 0.05 â¤ p â¤ 0.1 ) are deemed possibly significant and colored gray . The fitted slope and standard error of the logarithmic data set were also calculated ; this slope is the exponent of the power - law . Different studies offer different amounts of data points , opening the possibility some studies could unduly skew the aggregated correlations by simply offering more points . To guard against undue bias from specific studies , correlation strength , power - law fit , and their probability ( p - value ) with a weighting function were also calculated . The weight is assigned to give each paper , within a material category and within the properties in question , equal impact to the correlation and fit . Correlations and fits that remain statistically significant and do not change much between unweighted and weighted calculation imply that the trends apply across the literature , opposed to a few specific studies . If the correlation loses its significance before or after the weighted adjustment , the trend may still be useful although its applicability across the literature is taken less assuredly . The weighting function was calculated as follows . For a given CNT category , and for the two material properties in question , the number of data points offered in each contributing paper n was determined and the reciprocal calculated , n â1 . The weight assigned to each data point is then n â1 divided by the sum of every n â1 across all data points being considered . This ensures that the sum of the weights is unity and that the sum of the weights within each paper is equal . In some cases when comparing categorical data t - tests were used ; this analysis is in the Supporting Information section . Box plots were also used in the main text to help compare categorical data , particularly to visually show differences from doping . The t - test and box plots should be considered in the context that the material categories , which may have fundamental differences , are in continual development across multiple research groups with varying degrees of quality . Considering the larger picture of averages , standard deviations , maximum values , and paths to improvement are necessary when evaluating material categories .	236090435	no
It comes to no surprise that implementing any lockdown decision is controversial as it will affect the well - being and economic welfare of the country and the people living there . However , this is all in an effort to slow the spread of the virus , prevent the health sector from being overwhelmed by the number of patients infected by this virus , and to buy time for a vaccine to be developed and distributed . Studies have shown that different forms of lockdown affect the infection rate IMF , 2020 ) . A massive decline in economic activity has hit many countries 3 along with an increase in unemployment rates ( Auray and Eyquem , 2020;Eichenbaum et al , 2020;IMF , 2020 ) .   debates the importance over lives saved over job losses .   support strong risk control strategies which are likely to lower the infection rates and economic costs in containing the virus . However , the medical costs come at a steep price and are equivalent to about 14 % of GDP , or over â¬ 1,500 billion ( â¬ 1.5 trillion ) for the EU . To put matters into perspective , in Germany , each case would cost on average , â¬ 50,000 which is about 100 % of ( annual ) GDP per capita per infection . This is about two thirds of Spain 's GDP per capita per case . Meunier ( 2020 ) views the lockdown decisions made in France , Italy , Spain and the United Kingdom as having no adverse effect on the daily death growth rate when national lockdown is first implemented in these countries . Meunier ( 2020 ) goes on to suggest that social distancing measures have had approximately the same effect as police - enforced home containment policies . When these lockdown measures were implemented , the growth rate of daily deaths in the United Kingdom was at a constant slope . In contrast , the growth rate decreased in France , Italy , and Spain . Vinceti et al . ( 2020 ) collect mobile phone mobility data during the period 1st February 2020 to the 27th March 2020 to investigate the daily positive tests in Italy . Their findings show that the spread of the coronavirus largely depends on the degree of stringency and how extreme the lockdown restrictions are . As the degree of mobility reduces , this leads to a decrease in transmission . This data was collected when lockdown measures were first imposed following a peak in cases , taking into consideration nine to fourteen days later . As a consequence , the growth trajectory speeds up and then flattens as a result of these measures . Further , Vinceti et al . ( 2020 ) point out that the lag time of observed days between lockdown and the epidemic peak results due to the natural history of the disease and the incubation period . Kucharski et al . ( 2020 ) show that in China the reproduction number declined from 2.35 to 1.05 in one week before travel restrictions came into force on the 23rd January 2020 . Further , Kucharski et al . ( 2020 ) find that the coronavirus transmission rate declined in Wuhan in late January 2020 as a result of these travel control measures and the implementation of local lockdown .	234683604	no
A crisis is understood as an unexpected , publicly known , and harmful event that exhibits high levels of uncertainty , and potentially disrupts firm operations ( Bundy & Pfarrer , 2015;Bundy , Pfarrer , Short , & Coombs , 2017 ) . While most crises are attributable to firm - specific or regional events , such as supply chain disruptions , data breaches , or environmental misconduct ( Bode , Wagner , Petersen , & Ellram , 2011;Gwebu , Wang , & Wang , 2018;Lo , Tang , Zhou , Yeung , & Fan , 2018 ) , firms have also experienced a series of global high - impact crises over the past decades . Well - known examples include the burst of the first dot - com bubble in 2000 ( e.g. , Dowell , Shackell , & Stuart , 2011 ) , the 9/11 terrorist attacks ( e.g. , Li & Tallman , 2011;Vergne & Depeyre , 2016 ) , the 2007 - 2009 financial crisis ( e.g. , de Figueiredo , Feldman , & Rawley , 2019;DesJardine , Bansal , & Yang , 2019 ) , or the Brexit aftermath ( e.g. , Tielmann & Schiereck , 2017 ) , as well as the ongoing climate crisis ( e.g. , Reid & Toffel , 2009;Wright & Nyberg , 2017 ) . All of these had ( or have ) substantial effects on individuals , politics , and the economy ( Bansal , Kim , & Wood , 2018;DesJardine et al . , 2019;Wenzel , Stanske , & Lieberman , 2020 ) .	255571157	no
The measured data show that slit widths well below 10 mm can be set with very high precision ; the small variations of the measurement points around the fitting curve Figure 8b result from the limited resolution of the optical microscope used to measure the slit width . All slits within the plotted range showed parallel edges over their full length .	52134675	no
Participants ' emotion ratings can be represented on two different timescales , an absolute timescale and a normalized timescale . The absolute timescale binned participant 's ratings to the nearest 10ms window , and represents individual trajectories through the emotion space on the dARM . However , because trials were self - paced , some trials took longer than others . As a consequence , the absolute timescale results in fewer datapoints at longer time windows ( Supplementary Figure 12 ) . Therefore , for the main analysis participants ' data were normalized to 101 time bins , where 1 represents the start of a trial and 101 represents when the participant made their rating .	236219670	maybe
Motivated by the above SCXRD results , we followed the transformation of 1 â DMF crystals exposed to MeOH by PXRD . Remarkably , the SCSC transformation from 1 to 2 could also be observed by PXRD ( Figure S5 , Supporting Information ) . Recorded profiles obtained by treating 1 in MeOH at different immersion times were compared with the calculated PXRDs patterns from single - crystal data of structure 1 ( Supporting Information ) . The analysis of data reveals that 1 gradually transforms into 2 and other intermediate phases when exposed to MeOH for 2 - 5 d ( Figure S5b - d , Supporting Information ) . Crystals were then further treated at 40 Â° C under vacuum for 20 h ( Figure S4e , Supporting Information ) ; however , complete transformation to phase 2 was only achieved after heating at 80 Â° C ( Figure S5f , Supporting Information ) . The heating step is fully consistent with the above SCXRD results ( Figure 2 ) , as uncoordination of water ( or any other solvent ) from the cobalt centers in intermediate stages , such as , e.g. , 1b , is required in order to obtain 2 . Hydration / dehydration of the Co(II ) centers with displacement / coordination , respectively , of a 4,4â²-bipyridine has been previously observed . [ 17 ] In addition to the PXRD data , unit cell determination by SCXRD of up to 16 crystals of the transformed phase provides further support for the conversion of 1 to 2 (   www.advmat.de www.advancedsciencenews.com Furthermore , optimization of the framework transformation from 1 to 2 is achieved by solvent exchange of 1 â DMF with MeOH or CHCl 3 under ambient conditions for 5 d followed by heating at 80 Â° C under vacuum for 20 h ; or by straight treatment in a flow of scCO 2 at 20 MPa and 45 Â° C ( Figure S6 and Table S2 , Supporting Information ) . FT - IR , thermogravimetric analysis ( TGA ) , elemental analysis , and nitrogen sorption measurements ( Figures S7 and S8 , Supporting Information ) of 2 confirm the nonporous nature of this phase , only containing residual water ( < 5 % ) .	44165803	maybe
To reach our goal , we combine survey - based evidence with theory to provide an alternative view of algorithm - user interaction process . In Section 2 , we review the premises of the filter bubble discussion . Using evidence from the Netherlands , in Section 3 we show that , contrary to the assumptions commonly made by the followers of the filter bubble argument , the diversity of recommendations is an important factor in citizens ' evaluations of news recommenders . In Section 4 , we also use our data to demonstrate that not all users are equal , and that the current debate about algorithms and filter bubbles fails to acknowledge that the audience is heterogeneous , and has diverse personal preferences and propensities not just in terms of their interests and ideologies , but also in terms of their attitudes toward news personalization and expectations vis - a - vis news services . We then use theoretical arguments in Section 5 to show that there are ample incentives for the business entities that operate algorithms to	149488005	no
We have estimated the incremental profits based on LHC - related procurement orders ( categorized according to activity and technological intensity codes ) , which we forecast up to 2025 , and then used these values to determine incremental turnover for the suppliers through estimates of economic utility / sales ratios from Bianchi - Streit et al . 1984 andAutio et al . 2003 ( based on surveys to CERN suppliers ) and EBITDA margins data ( a measure of gross profits / sales ratio ) for companies in related sectors , extracted from the ORBIS database ( BVD ) of companies balance sheets 16 ( see Fig . 4 ) .	84176509	maybe
To ensure the sustainability of higher education during an emergency , an application - driven regulatory framework is suggested by this project . Although , this regulatory framework may require continuous revisionary work , its implementation is essential to ensure a decent functionality of HE during an emergency period . The limitations of this study and what future analyses could do are noted here . This case study was conducted in one developing nation , Bangladesh . Due to nonavailability of data , it was not possible to compare what actually happened to the HE sector in terms of technology usage in Bangladesh with other developing countries . While this case study provides some generic insights into a widespread problem in developing nations , a larger - scale research project that encompasses several such countries could generate more concrete comparative evidences .	237493243	no
"The first challenge to trying to apply a data - driven approach to MOF synthesis is the absence of abundant data on the effect of different synthesis conditions on the reaction outcome . In particular , while successful reaction conditions are reported in the scientific literature , failed experiments , or those that resulted in the material but with suboptimal properties , are not reported . This absence of the "" failed data "" is a common issue in chemical problems , where indeed the successful , desired , event is likely to be the exception to the experimental attempts , but is the only event typically recorded in the literature . We can hope that an increase in uptake of electronic laboratory notebooks can help with this missing data in the future . To fill this gap in the data , Moosavi et al . used robotic synthesis to collect data on 120 different syntheses of a Cu - based MOF , HKUST-1 , which can have a Brunauer - Emmett - Teller ( BET ) surface area ranging from 300 to 2000 m 2 g â1 depending on the solvent composition , reaction temperature , and synthesis method , despite all powder diffraction patterns appearing identical . [ 51 ] With this synthetic data in hand , Moosavi et al . then used a random decision forest method to determine the relative impact of the different experimental conditions on the synthesis outcome . This uncovered that temperature changes were three times as important as the reactant composition on influencing crystallinity , providing insight that could be applied to future searches . This learning was taken forward to the synthesis of a related Zn - based MOF , and only 20 samples of the search space were required to find optimal synthesis conditions , compared to an expectation of thousands of samples without the prior insight . Future application of this approach relies upon the availability of databases where successful and failed material syntheses are reported in a common format . Driving uptake of such databases and data - sharing by the broader community is a significant hurdle to be overcome ."	231871676	no
This study offers three theoretical implications . First , it is one of the earliest empirical studies to examine the drivers of travel intentions during and after the pandemic using data collected at a single point in time . By doing so , we attempt to capture and assess whether the fear induced by the pandemic has only short - term effects or is likely to reverberate long into the future . Such an investigation opens new vistas for research by focussing on the necessity of understanding the longevity of the effects of COVID-19 on individuals ' psyches and , in particular , on their intentions to travel for leisure .	245008959	no
Through a multiple linear regression model , we correlated the share of users who abandoned PT during 2020 , with income equality variables , PT service characteristics , quality of service aspects and pandemic severity data . Empirical findings revealed that the presence of income inequalities resulted in lower abandonment rate , which could mirror the behaviour of captive users . Simultaneously , regarding PT trip characteristics , results imply that PT vehicle transfers and waiting time are the two most critical trip segments as per user opinion , for continuing or not using PT modes . Additionally , results confirm our initial hypotheses that : ( a ) in cities with higher pandemic impact ( as per number of deaths ) users were deterred to use PT and ( b ) improved disinfection in vehicles could contribute to sustaining ridership . Based on the empirical findings of the regression model analysis , specific policy implications can be derived . The methodology of this paper aims at identifying the key factors that influenced travel behaviour , in terms of abandonment of PT , during the COVID-19 era . These factors may highlight suitable measures , which can be followed by PT and governmental agencies , towards maintaining PT ridership during pandemic and post - pandemic circumstances . At first , the proper and frequent disinfection of vehicles could enhance the perception of safety to PT users and convince them to select PT . Likewise , changes in the PT network , towards the direction of providing more direct trips , can contribute to limited interaction between passengers and thus minimize the possibility of infection . In the same sense , PT operators should ensure that waiting facilities ( bus stops , metro platforms , etc . ) adhere to the health and safety protocols ( clean surfaces , proper ventilation , etc . ) , in order to build confidence among users that PT is not a hotbed of COVID-19 contraction . Furthermore , in regions with higher income inequalities , operators should expect a comparatively lower decrease in PT ridership and thus , the application of PT preferential treatment measures ( dedicated bus lanes , traffic signal priority , etc . ) ( Pulichino & Coughlin , 2005 ) would increase commercial PT speeds and ultimately improve PT service frequencies so as to address crowding events .	255826268	no
The results of Breitung test indicates that the data series in level for COVID-19 index is stationary at 5 % level of significance , while the rest of the data are non - stationary . The Levin - Lin - Chu in unbalanced panels suggests that for all the variables excepting COVID-19 index the data in the first difference are stationary ( Table 3 ) .	237473259	no
Although we are aware of the many promising digital technologies available today to fuel epidemic management in the healthcare ecosystem , we decided to restrict our analysis to the following technologies : Internet of Things , big data analytics and artificial intelligence .	234046079	no
The results of the present study have theoretical implications for future research . First , the technologies identified , and concepts defined in this study allow for the development of new studies focused on what is known as surveillance capitalism and massive data collection .	233029680	no
Energy metrics for applications such as grid - storage , EVs , electronics , and many other needs of modern society have to be matched with costs , supply chain and environmental sustainability . When complete devices are analyzed , NIBs result to be more sustainable , with respect to conventional LIBs if comparable energy densities could be achieved . Other post - LIBs , based on other metals which include Al , Mg , Ca , K , and Zn , are still in their infancy preventing to have reliable data . Investigating the energy impacts of different metals , it was found that Ca has the most promising values of all analyzed metrics ( i.e. , CED , GWP , YGCE ) sensibly lower compared to the ones for Li . On the other hand , Al presents slightly higher values in different figures of merits .	236329656	no
Author Contributions All authors designed research , performed research , and wrote the paper ; C.B. and K.H. analyzed data .	46836503	no
Assigning key phrase weights by the terms ' frequency ( TF ) of appearance in a document is a popular method in text mining ( Weiss et al . , 2010 ) . Regarding the fact that each paper can have a different number of pages and words , it is reasonable to conclude that the size of a paper and the average number of words , can affect the frequency of the keywords . As a remedy , this study used the method proposed by Trappey et al . ( 2011b ) , which normalizes the weights for the frequency of key phrases by the number of words in each document . The function normalized TF - IDF or NTF approach is expressed by Eq . ( 4 ) where tf ik is the number of key phrases i in document k , WN k is the number of words in document k , n is the total number of documents in the document set , and df i is the number of documents of key phrase i in the document set . With this function , the effect of the size of a paper can be eliminated ( Trappey et al . , 2010 ) . . A correlation between a set of data is a measure of how well and to which extent they are related . The correlation between keywords of documents has been used in many studies for clustering and discovering the relationship between the keywords . In these studies , the correlation , similarity or cooccurrence are calculated between all dictionary keywords ( DubariÄ et al . , 2011;de Miranda Santo et al . , 2006;Trappey et al . , 2011a;Daim et al . , 2006;Andrade and Bork , 2000 ) . In the present study , however , the research methodology of each paper is used as the clustering variables . Using this method , the correlation of each research methodology with dictionary keywords can be determined , which is important to support effective research planning . Further information will be given	65495165	no
The review process was started with the identification of essential properties that may be imposed on the leather based materials owing to the COVID-19 pandemic . Also , the effect of same on the automotive industry which utilizes the leather products in its production was also considered for shortlisting of the functional properties that may become the need of the hour . Accordingly , the research articles giving solutions to such problems were identified from databases such as Google scholar , Web of Science and Science Direct using the keyword such as ' Antimicrobial leather ' , ' functional leather ' , ' self cleaning leather ' , ' flame retardants ' , ' thermo regulation in leather ' . The identified literatures were then grouped as per the property that is imparted to the leather by manually going through the data provided in the abstract initially . Further , it was categorized and tabulated based on the following parameters .	236604093	maybe
Because ordinary multiplication is commutative , a Â· b = b Â· a , so is pointwise multiplication for elements of C(M ): Ï Â· Ï = Ï Â· Ï . The algebra contains a great deal of information about the space on which the fields live . In fact , the algebra contains all the information that we typically take to characterize a topological space . Topology , understood as characterizing relations between points , can be reconstructed from purely algebraic data as maximal ideals 7 , the neighborood of a point can be likewise inferred from the relations among ideals . Global characteristics are also encoded in the algebra ; for example a closed compact space ( such as a circle ) is described by an algebra which contains a multiplicative identity element . By contrast open spaces such as the real line are described by algebras which lack such an element . In short , this representation theorem states the logical equivalence of a space topology and its algebra C(M ) .	255062435	no
[ CCDC 2051611 contains the supplementary crystallographic data for this work . These data can be obtained free of charge from The Cambridge Crystallographic Data Centre via www.ccdc.cam.ac.uk/data_request/cif . ]	244908066	yes
"The value of immediacyi.e . the ability to quickly react to the latest developments in society and to provide reliable information about them ( Usher 2018)and the related values of actuality and speed were referenced by interviewees as important components of ANR design and as "" kind of inherent to a newspaper . "" Similar opinions were also expressed in relation to journalistic depthi.e . the provision of detailed insights and wide - ranging information on a subject ( Hoskins , 2017)which is also viewed as a classic journalistic task , although one data scientist noted that immediacy and depth can potentially be conflicting values and that this should be reflected in ANR design ."	237282779	no
In this section , we examine the results of the Google Mobility models , beginning with retail mobility and followed by grocery and pharmacy mobility . Two results are presented with each type of mobility : predictive performance results and analytical results . The predictive performance results show the training and testing performance of each model . As we have mentioned , the test set consists of the last seven days of our data -May 23rd to May 29th ( inclusive ) .	255441206	no
Oxygen diffusion in the outer retina can be described by a one - dimensional three - layer diffusion model based on Fick 's second law 34 ( 6 ) where QO 2 is the oxygen consumption normalized by tissue weight ( mL O 2 â¢min â1 â¢100 g â1 ) ; D is the diffusivity of oxygen in tissue ( 1.97 Ã 10 â5 cm 2 s â1 ) ; k is the solubility of oxygen ( 2.4 Ã10 â5 mL O 2 /(mL retinaâ¢mmHg ) ) ; P is PO 2 ( mmHg ) ; and x is the distance from the choroid . The photoreceptor outer segments , which do not consume oxygen , occupy layer 1 in the model , between x = 0 and x = L 1 . The oxygen - consuming inner segments are between x = L 1 and x = L 2 . The third layer is the outer nuclear layer ( photoreceptor cell bodies ) , which do not consume oxygen , and is between x = L 2 and x = L , where L is the thickness of the outer retina . The averaged QO 2 in outer retina ( Q av O 2 ) under light adaption has been characterized by fitting this model to microelectrode data 34 .	17028996	no
The proliferation of an infection disease such as COVID-19 also has a significant impact on public psychology ( Katafuchi et al . , 2020 ) . First , studies on psychological changes among the public using social big data include the following examples . Li et al . ( 2020b ) studied the changes in the results of sentiment analyses of posts written by Weibo users before and after the WHO pandemic declaration . The results demonstrated that after the WHO 's pandemic declaration , indicators of anxiety , depression , and indignation increased significantly . In addition , the study found that social risk judgment was significantly increased , and life satisfaction was significantly decreased . Hamidein et al . ( 2020 ) conducted a survey of participants who regularly checked COVID-19 - related news and found that they generally felt negative emotions in response to the news but were also deriving problem - solving strategies through the news , identifying what can be done at an individual level to prevent the spread of the virus . Brodeur et al . ( 2020 ) focused on the lockdown implemented by many governments in response to COVID-19 . The authors found that lockdowns may help to contain the spread of the virus but warned that it may result in substantial damage to the population 's well - being . To assess the level of such damage , this study used Google Trends data to analyze the causal effects , tracking how topic search terms related to well - being changed before and after the lockdown policy . Based on this analysis , the study evaluated the impact of governments ' lockdown policies on the public 's mental health . Chen et al . ( 2020 ) evaluated public perception of COVID-19 through Weibo , a Chinese social media platform . This study underscored the importance of how experiences of outbreaks of similar diseases in the past affect the public 's perception of the outbreak of a new infectious disease .	232282755	no
This framing of the problem implicitly suggests that 5 G is not responsible for expected data traffic increases but is the solution to rendering such increases sustainable . The requirement for action that stems from this problematisation is to deploy 5 G as quickly and widely as possible .	254302320	no
Over the past several decades , complex forecasting methods have been developed to improve sales forecasts in the retail industry . As Ma & Fildes ( 2021 ) have stated , retail forecasting has focused on sales forecasting . However , no method dominates for all types of products and time periods . Therefore , the performance of the predictions is hugely dependent on the data available , products under study , and the geographic trends in which the demand emerges . In addition to testing various techniques to find the most accurate forecasting method specific to the product and the business , newly emerging data sources can definitely provide value in studying the retail industry 's demand and sales phenomenon . Brea et al . ( 2020 ) underscore the significance of these new data sources during uncertain times , especially when a pandemic hits . Incorporating these data ( e.g. , mobility and , more specifically , retail mobility data ) requires a systematic approach to analyzing the timing of information and the optimal lags with the outcomes of interest . As demonstrated in this study , machine learning and forecasting techniques used in the retail industry can address this challenge .	255441206	no
Despite these unique advantages , the majority of the published PACT prototypes have not been demonstrated for non - invasive cardiac imaging of the detailed anatomical or functional phenotypes due to suboptimal illumination and detection schemes . This limitation has been recognized by the previous PACT studies , including in vivo imaging of mouse hearts with suboptimal clarity for anatomical / functional details 17,18 and ex vivo imaging of excised / perfused heart with no intracardiac flow dynamics 19,20 . There are 3 challenges for in vivo cardiac PACT . ( 1 ) Ribs and lungs surrounding the heart partially block and disturb PA signals . The same limitation exists in echocardiography ; however , PACT only suffers from one - way acoustic disturbance since the PA signals are generated in hearts . ( 2 ) The high concentration of hemoglobin and myoglobin renders the myocardium highly absorptive to light . This property may produce high PA signal amplitudes ; however , it reduces optical penetration into the heart . ( 3 ) The periodic heartbeat requires real - time imaging or motion - correction mechanisms to give the imager 's spatial resolution full play for dynamic cardiac structures . For example , the time - gating is widely used in CT 21 , MRI 22 , and PET 23 , dividing every cardiac cycle into multiple phases and collating all the data from a specific phase for imaging reconstruction .	255415294	no
to a highly active CO oxidation catalyst . [ 24 ] Comprehensive characterization methods including high - angle annular dark - field scanning transmission electron microscopy ( HAADF - STEM ) , X - ray absorption near - edge structure / extended X - ray absorption fine structure spectroscopy ( XANES / EXAFS ) , Fourier - transform infrared spectroscopy studies of CO adsorption revealed that the positively charged single Pt atoms occupy vacant iron atom lattice positions . Density functional theory ( DFT ) calculations indicated that the Pt atoms were most probably located at the threefold hollow site on the O 3 -terminated surface of FeO x , which is consistent with experimental data . The DFT calculations also indicated that the high catalytic activity of Pt - SAC/ FeO x correlates with the partially vacant 5d orbitals of the positively charged Pt atoms , which reduce both the CO adsorption energy and the activation barriers for CO oxidation . In a later seminal example , Bao and colleagues used an iron - SAC deposited on amorphous silica ( 0.5 wt% Fe - SAC / SiO 2 ) for the selective CîH activation of methane to give value - added products , such as alkenes and aromatic compounds . The iron species are redistributed from the original iron oxide ( Fe 2 O 3 /Fe 3 O 4 ) NPs to isolated atoms during catalyst activation ( Figure 2 ) . The study beautifully demonstrates the immense challenges and efforts required to understand structure , bonding , and reactivity of the SAC surface sites . [ 40 ] In another example , single Au atoms supported on CeO 2 ( Au loading : 0.05 wt% ) were prepared by Liu , Zhang , Li and co - workers . The group demonstrated that the system has a high selectivity for preferential CO oxidation over H 2 oxidation when operated in CO / H 2 mixtures in the pres - ence of O 2 . [ 41 ] This ability is critical for providing high - purity H 2 ( by oxidative removal of CO ) , e.g. , for fuel cells . As next step , it would be important to fully understand the atomic causes for this behavior and utilize this to access designer SACs with tuneable reactivity and selectivity .	236569756	no
where the indicator w ijk = 1 if , in the data matrix , both measurements x ik and x jk , relating to the kth variable are present , and w ijk = 0 otherwise . The quantity c ijk is the contribution that kth variable gives to the similarity between units i and j ; in our application , in particular : a ) for polytomous characters , c ijk = 1 if units i and j share the same category , c ijk = 0 otherwise ; b ) for dichotomous variables the rule is the same , but , in addition , w ijk = 0 if both x ik and x jk are zero ( so reducing the denominator of the similarity , s ij ( G ) ) . Gower 's index ranges from 0 ( minimum similarity between the units ) to 1 ( maximum similarity ) . Once Gower 's similarity score s ij ( G ) was obtained , it was possible to find the corresponding dissimilarity measure , d ij ( G ) , by simply putting d ij ( Kaufman & Rousseeuw , 2005 ) . The research used R software routine daisy in the cluster package , which gives as output the Gower 's dissimilarity matrix	256000583	no
"It appeared that the respondents did not have a unified view of the sustainable manufacturing capabilities of Company F , although "" pollution prevention "" and "" zero - waste production in a circular economy "" may partly overlap . The low response rate and the variability of the main input data ( the capability ) to the questionnaire suggested that composing an aggregate OSR score and OSR s for Company F was not practical at the testing stage ."	229426053	no
The MEGAFRAME32 high - performance sensor was smaller ( 32 Ã 32 SPADs ) but adopted a radically different architecture , based on 50 ps , 10 - bit in - pixel TDCs , working at a maximum rate of 500 kfps 21,81 , and recording either time - correlated data ( one time - stamp per pixel ) , or time - uncorrelated data ( 6 - bit counting ) . In the former operation mode , up to 0.5 billion timestamps could be generated per second 82 . The fill factor ( 1 % ) was adversely affected by the large in - pixel electronics ; on the positive side , this demonstration stimulated pioneering microlens research to bring the fill factor back up . MEGAFRAME32 was extensively employed to explore bio - applications and subsequently extended to a 160 Ã 128 array ( MEGA - FRAME128 ) , adding peripheral intelligence ( data compression and CMM pre - processing ) 33 50,51,86 illustrated how firmware - based rapid lifetime estimation algorithms , such as CMM ( centre - of - mass method ) , make full use of the large number of available timestamps to enable video - rate ( 50 fps ) real - time FLIM operation . An example of the corresponding in vivo two photon FLIM data , with both the intensity and the lifetime , is shown in ref . 86 using an FITC - albumin probe , which was injected into a rat bearing a P22 tumour and measured 100 min after the injection . A clear distinction between the blood vessels and the tumour tissue could be observed in the lifetime image ( biexponential decay ) , in contrast to the intensity image .	202670835	no
There are no analogs , as far as I am aware , of adding a new physical feature as part of the model that can , like the existence of Neptune , be easily checked by other means . This is in part due to the observational inaccessibility of the early universe , but also to the lack of a canonical choice of the inflaton field . Given a fixed choice for the inflaton field , discrepancies with observations would force theorists to elaborate the model , possibly identifying new features of the early universe in the process . At present the choice of inflationary models is too flexible to support this kind of approach . ( Smeenk 2017 , p. 222 ) The point , then , is that while , given a choice of inflaton field , eternal inflation may be falsifiable , the hypothesis is not falsifiable tout court , given the great flexibility in said choice of inflaton field . The fact that ( coarsely speaking ) , for each choice of empirical data , there is one eternal inflation model compatible with it ( with a particular choice of inflaton ) , means that the hypothesis is not straightforwardly falsifiable in its entirety ; it also gives rise to concerns regarding underdetermination : if the empirical data gathered thus far is compatible with many choices of inflaton field , which is the correct one ? However , the lack of present falsifiability of eternal inflation does not amount , to our minds , to a defect in the scientific status of the hypothesis , so long as the research programme relies on empirical data to develop a framework consistent with it , which could potentially in the future be more constrained by further empirical data ( for a similar line of reasoning , see Carroll 2019 ) . 45	234815857	no
Overall , the use of various data collection technologies and collective analysis can be used massive behavioral modification where users are recommended not to visit a place due to a higher risk of contagion . In fact , it is with this objective that many national governments and large corporations , like Apple and Google , have launched many tracking initiatives .	233029680	no
"Our careful mapping of the role of expert knowledge in the discussion above adds further arguments to this debate . We have seen how experts ' theoretical background is involved in data generation , problem formulation , and algorithm evaluation . This observation implies that even if arbitrariness can be imputed to human - induced factors ( at least at the current state of the art in big data and machine learning methods ) , preand post - analytic human involvement can not be avoided in practice . As Rob Kitchin ( 2014 ) suggests , arguments that emphasise the need for theoretical underpinnings when formulating a scientific problem and selecting an algorithm are usually based on the observation that no methodologically sound scientific inquiry can be based solely on ' raw data ' , because raw data never occur in a ' scientific vacuum ' but are always "" discursively framed by previous findings , theories , and training ; by speculation that is grounded in experience and knowledge "" ( p. 5 ) ."	256060110	no
Since AACC in Spain can implement policies to control CO 2 emissions in their territory , this paper used data retrieved at the AACC level so that the models developed here could be used by the regional authorities to design custom emission regulation policies that could be optimized for their individual characteristics . This approach resulted in training 19 different prediction models . From a modeling perspective , it is not a big issue . But having different models for each AACC complicated drawing conclusions about their similarities and differences regarding CO 2 emissions . Focusing on the variables that entered in the anthropogenic CO 2 and nonrenewable CO 2 estimation models as shown in Tables 4 and 6 , it was expected that the inclusion of the levels of CO 2 coming from non - renewable generation would be the key predictor for the 19 anthropogenic models . But the relevance of GDP related variables was also significant and somewhat less predictable . It seems that for those AACC with a quite predictable emission model of nonrenewable CO 2 , GDP and time of the year variables are enough to get an accurate prediction . For those communities with less predictable emissions , several extra variables related to financial products , state agent transactions or service sector levels were   required in addition . It should also be noted that the estimation of non - renewable generation emissions was more challenging , as shown by the increased number of variables required per model . Variables related to energy demand , the number of mortgages or affiliations to the social security become more relevant then . The information coded on those two tables could be of great value when designing emission reduction plans per AACC . Two major difficulties were found : apportioning in monthly figures the yearly amount of CO 2 emissions and the lack of mobility data available in Spain . To cope with the first one , a model to estimate these monthly figures was also developed . Unfortunately , despite the evident influence of traffic related emissions in the global CO 2 emissions , the availability of information about mobility patterns per month and per AACC in Spain was very limited and did not allow us to establish any sensible method of estimating them . Initially , data related to the number of yearly crashes and victims were used as proxy variables for mobility , as there is literature pointing to the existing relationship between exposure and injuries ( Segui - Gomez et al . , 2011 ) . However even if this data is available up to 2018 it did not end up contributing to the significance of the models . Some local administrations report the actual figures of private and public transportation use , unfortunately the number of informed cities is still too low to include this predictor in the models .	233916124	no
In response to COVID-19 , a new method is required to investigate the equality of access to food stores . However , studies analyzing the fairness of access to food stores in terms of consumer demand are rare , and little research attention has been given to access to food stores in Taipei City . In this study , the Gini coefficient was used prospectively to quantify the equality of access to food stores at the city and village levels in Taipei . The experience of older adult citizens was also considered , and the Gini coefficients of older ( over 65 years ) and non - older subpopulations were investigated . This approach allowed us to obtain accurate data on Taipei as an aging society and to examine whether specific groups face worse fairness than others do .	256000608	no
Due to the direct relationship between the fill - factor FoM Î± and l dif /d ( Equation ( 3 ) ) , the ratio of the effective diffusion length and the active layer thickness can be used on its own for correlating with FF . Figure 4a demonstrates this correlation for a range of organic solar cells with thicknesses ranging from 80 to 550 nm at the 1 Sun - equivalent illumination . The simulated points in the FF - l dif /d plot were obtained via driftdiffusion simulations for the V OC values of 0.7 - 0.9 V and at balanced carrier mobilities . [ 51 ] The impact of increasing the mobility imbalance on the simulation results may be seen in Figure S3a in the Supporting Information . In addition , Figure 4a shows the analytical FF - l dif /d dependencies , assuming balanced mobilities , according to the following expression [ 12 ]   A good overlap of the experimental data both with the analytical expression ( Equation ( 6 ) ) and the simulation results is observed . According to Table 1 and Figure 4a , the l dif values - at the 1 - Sun equivalent condition - for the systems examined in this work are generally smaller than the device thicknesses , with the PM6 : BTP - eC9 and PPDT2FBT:[70]PCBM systems having the highest relative effective diffusion length and , concomitantly , the highest FF values . [ 30,52 ] The presented results in combination with the definition of the FoM Î± , according to Equation ( 3 ) , show that as l dif approaches d , the value of Î± gets closer to unity , indicating the transition to a Shockley - type solar cell . [ 12,53 ] The consideration of Î± in terms of the relative effective diffusion length enables to formulate an alternative definition of a Shockley - type cell as the cell for which l dif /d is close to or exceeds unity .	235570216	no
Within the context of supply chain , the relationship between LPI and the international economy has been the subject of intense discussions ( Ãelebi , 2019 ) . Coto - MillÃ¡n et al . ( 2013 ) employed a global aggregate production function to capture the effect of LPI on world economic growth . Collecting data from 2007 to 2012 , they estimated that a 1 % rise in the LPI index induces an increase of the world economic growth ranging between 0.011 % and 0.034 % . MartÃ­ et al . ( 2014 ) used a gravity model finding that improvements in any of the components of the LPI are positively associated with trade flows , and highlighting that the efficiency and quality of logistics operations do matter . Ãelebi et al . ( 2015 ) confirmed that Foreign Direct Investment ( FDI ) plays a mediator role in the LPI - economic growth nexus . Khan et al . ( 2017a ) collected LPI and GDP data for 15 selected global ranked logistics countries showing that logistics competence and infrastructure boost economic growth and sectoral value added . Munim and Schramm ( 2018 ) considered 91 countries with seaports and inspected the economic effect of seaborne trade , from a port infrastructure quality and logistics performance perspective . Findings demonstrated that the quality of port infrastructure contributes to a better logistics performance . Based on Commonwealth and Independent States ( CIS ) countries , Sharipbekova and Raimbekov ( 2018 ) highlighted that LPI and economic indicators share closed linkages , which is congruent with Tang and Abosedra ( 2019 ) . Indeed , they concluded that the export - led growth hypothesis is confirmed for 23 Asian countries . Tightly linked to this view , using disaggregated exports data for Turkish trade with 174 countries , TÃ¶ngÃ¼r et al . ( 2020 ) ended up to the same conclusion using a gravity model . More recently , Goel et al . ( 2021 ) explored the nexus between supply chain performance and economic growth , with a specific focus on the implications for public policy and COVID-19 initiatives . Based on data collected for 130 economies , findings suggested that improving supply chain logistics performance imply positive growth . Similarly , Laeeq Razzak Janjua et al . ( 2021 ) employed a univariate time series forecasting model and investigated the impact of COVID-19 pandemic on logistics performance and economic growth in Thailand . Results confirmed the strong connections between these two indicators , notably through the channel of tourism flows , predominant in Thailand 's GDP . Sergi et al . ( 2021 ) assessed the causal relationship between logistics performance and selected factors in the Global Competitiveness Index ( GCI ) , which were grouped into three clusters : infrastructure , human factor , and institutions , with data covering Africa , Asia , and the EU . Evidence drawn from the ANOVA method claim that improving all three clusters increase efficiency , although human factor plays a predominant role .	239254708	no
"The OCDC is fabricated with a silicon - on - insulator ( SOI ) process . Fig . 2a shows the packaged OCDC and its periphery circuits . Common metal wires on the bottom provide voltages for the chip . Transmission lines on the top are used to transfer high - speed signals . The layout of the chip is shown in Fig . 2b . Optical splitters , push - pull modulators , combiners , couplers are systematically integrated on the chip . Two optical splitters ( shown in Fig . 2c ) are used to divide optical power into the nine modulating branches and the reference . A multi - mode interferometer split half of the optical power to the reference . The left power is split into nine branches by cascaded directional couplers ( DCs ) . The coupling length of each DC is designed so that the optical power vertically as the red block shows . Every modulator contains four phase shifters , two of which are used to conduct push - pull modulation and the remaining two are used to control the bias voltage . Tail phase shifters are appended to compensate for the phase difference among branches . c The structure of light input and splitter . d Characterization of evenness of optical power splitting . e Modulator characterization with push - pull driven . The experimental result is fitted with a curve formulated by a * sin(b * x + c ) + d. The information on fitting is also given in the plot . f The effect of constructive interference of three branches . Three curves are obtained one by one . Firstly , only the first branch is modulated to the highest transparency when the other two branches are closed . By changing the voltage on its tail phase shifter ( PS-1 ) , the yellow curve is shown . It denotes the interference result of branch 1 and reference branch . Secondly , keep the voltage on the PS-1 at the constructive interference point ( black circled ) ; modulate the second branch to its highest transparency ; change the second tail phase shifter ( PS-2 ) . The purple curve is recorded . By operating the same process for the third branch , we obtain the green curve is divided evenly . Figure 2d provides the measured splitting ratio of the cascaded DCs , showing an evenness lower than 1.2 dB. At each modulating branch , we fabricate a tail phase shifter to compensate for the phase difference between branches and the reference . More details of chip fabrication and characterization are provided in the Supplementary Section . In the OCDC , stable push - pull modulation is important to keep the constructive interference for photodetection . Figure 2e shows an example result of push - pull modulation ( see "" Methods "" ) . This result is yielded by complementarily changing voltages on the upper and lower arms of a single modulator with other modulators staying static . The amplitude of the output optical field varies along a cosine curve when the applied voltages change . The R 2 of the fitting is 0.9994 , indicating that the push - pull modulation is accomplished with high stability . Then the constructive interference of multiple branches is inspected in Fig . 2f . It is shown that , with proper configuration of the tail phase shifter , the output optical fields of different branches can match in - phase , performing a jointly constructive interference . Implied by the results , the OCDC is capable of amplitude modulation and coherent detection , laying the basis for calculations of the real - valued dot products . We implement AUTOMAP as a representative example of deep learning regression to validate the OCDC . Figure 3a shows the structure of the AUTO - MAP containing two FC layers , two convolutional layers , and a de - convolutional layer . Details of the neural network can be found at the ref . 30 . and "" Methods "" . Given that the linear part of FC layers and convolutional layers can be decomposed to dot products ; we can realize these layers by reusing the OCDC temporally . Figure 3b - d shows the method of conducting MVMs and convolutions via temporal multiplexing . The decomposition of MVMs is straightforward since they are naturally calculated via vector - vector dot product . The input vector is loaded onto the second row of modulators marked "" slow mod . "" , and a vector from the matrix is modulated onto the "" fast mod . "" modulators . By temporally changing the vectors loaded on the "" fast mod . "" modulators , the result of MVM is eventually calculated . When the size of vectors is too large to be loaded onto these modulators in one time , the vector and the matrix can be divided into small parts as depicted in Fig . 3c . For convolutions , the process of patching 33,34 can rearrange pixels of the feature map into a matrix . The kernel is flattened as a vector . In this way , MVMs and convolutions can be similarly conducted by the OCDC . Figure 3d is the experimental setup ( detailed in "" Methods "" ) for temporally multiplexing the OCDC . A signal generator ( max . bandwidth is 20 MHz ) is used to provide signals for amplitude modulation and a voltage source ( VS ) supplies the bias voltages . A computer ( the gray block ) is adopted to carry out programs . It controls the signal generator and the VS to work as a whole . It also records and processes the output data from the OCDC ."	235195637	no
Hypotheses of the form ' Substance S causes cancer in humans ' are very unspecific because cancers can occur at numerous sites and , at each site , have a variety of morphologies . It is often difficult to rule out alternative hypotheses concerning the causes of cancer because cancer can have a very large number of causes . Liver cancer , for example , is caused by birth defects , alcohol abuse , aflatoxins , chronic infection with liver diseases such as hepatitis B and C , hemochromatosis , cirrhosis , obesity and diabetes , fatty liver disease , and other factors . It will be difficult to find data sets that control for all these factors , experiments testing for toxicity are unethical and even if one could conduct them , they would be unlikely to provide reliable information due to the large number of plausible confounders .	46975746	no
The early time spectra ( 0.4 - 1 Âµs ) for both the unannealed and annealed blend samples show a DRCN5 T triplet spectrum which is consistent with an ISC mechanism . At later time intervals of 1 - 2 Âµs , the DRCN5 T triplet polarisation pattern is harder to ascribe as being either eea / eaa or eaa / eaa ( which would be consistent with an ISC or recombination triplet , respectively ) . Furthermore , the weak trEPR signal at room temperature means only time averaged signals can show clear spectra and this makes observation of the evolution of the triplet harder . However , the radical or charge signal at 3465 G is non - Boltzmann populated and therefore this could be indicative of a CT state . As such , a recombination triplet may indeed be present . A full EPR study is ongoing , the results of which will be the subject of a future publication . Regardless , the trEPR is in agreement with the TA data , as both show the simultaneous existence of triplet and charge states in the blends . We do not directly observe PC70BM triplets in the TA data , but this could be because their absorption cross - section is much lower than the DRCN5T. The full trEPR analysis discussion , including the orientation effect , as well as the trEPR of the pristine samples , is in the SI ( Figure S17 , Supporting Information ) .	235549357	maybe
Measuring the complex issue of EBF with a single item rather than a more comprehensive measurement can be considered as a limitation of the study . However , due to the large number of societies used to provide a cross - cultural comparison , it was essential to use the WCI as the most reliable data source , which included cross national data .   The Moderating Role of National Culture 69 Therefore , EBF measurement by WCI was considered the most appropriate alternative for the current study . Also , as indicated in the '' Introduction '' section , our independent and dependent variables depended on perceptions , not the absolute indicators . Although , perceptions could be subjective and misleading , they reflect the opinions of executives who have deep knowledge of business environment in their countries . Still , our results can be tested with different indicators in a future study .	254386181	no
"Second , predictive algorithms are used to forecast what might be the result of certain past - or real - time observations on future outcomes . Predictive algorithms determine the likelihood of such outcomes ( or situations ) to occur . Applied methods are advanced regression techniques , machinelearning algorithms , and data mining approaches ( Davenport 2013 ; Souza 2014 ) . Typically , predictive algorithms provide a score that represents the probability of an event to occur . An example of a predictive algorithm is fraud prediction . JP Morgan , for instance , uses an application to identify potential future rogue traders by relying on an algorithm that analyzes multiple data points , such as whether employees skip compliance classes , violate personal trading rules , or breach market - risk limits ( Son 2015 ) . Another example is a recruitment algorithm developed by the technology firm Xerox Services . This algorithm works as an advanced support system for hiring staff in Xerox 's call centers by offering a score of how well the applicant would fit the job ( Peck 2013 ) . The algorithm behind this HR tool analyzes data provided by applicants via an online application tool and offers a cognitive skill assessment , personality test , and multiple - choice questions to see how well the applicant would deal with specific challenges on the job . Teri Morse , vice president of recruiting at Xerox Services , stated that the company was "" getting to the point where some of our hiring managers do n't even want to interview anymore "" because they would rather rely on the scores provided by the software ( Peck 2013 ) ."	189902940	no
Our study is structured as follows : Section 2 begins with a literature review of plant capacity concepts in the medical sector ; it briefly explores medical literature on the relationship between capacity utilization and mortality . Section 3 then defines the technology and efficiency measures needed to establish the four focal plant capacity concepts , then provides detailed definitions of output - oriented and input - oriented SR and LR plant capacity concepts and a discussion of nonparametric frontier specifications , to estimate the various plant capacity concepts . Section 4 details data from Hubei province , because the quality of the data conditions our inferences . Section 5 presents our empirical results , and Section 6 concludes .	231706096	yes
Path âµ in Fig . 2a shows the cases where it is possible to open the ' black box ' directly by having a suitable background and fine scientific intuition for extracting effective features from experimental data via supervised training . Domain knowledge requires an in - depth mechanistic understanding of phenomena in addition to the phenomenological parameters of the studied materials , such as the size , shape , composition , and optical properties . New ML algorithms can subsequently determine the correlations between features and outputs . When the number of features is large and when they may include redundant members , pairwise relevance analysis allows one to reduce the number of features . This ability yields improved ML output performances and can reveal invaluable novel information . We present two examples pertaining to the connection between atomic or molecular characteristics and electronic behaviors .	202509867	no
The model fits the sample data fairly well as NFI ( normed fit index ) is well above 0.7 , Standardized Root Mean Square Residual ( SRMR ) Â¼ 0.079 , the model is significant ( Table 5 ) .	233910673	no
there can be a negotiable market price for the animal , as for every means that is incapable of becoming an end in itself , whence the virtual cruelty of this pure practical reason ( Derrida 2002 , p. 101 ) Although contentious , our data illustrates how veterinary surgeons are subject to financial , economic and clientcentred imperatives . Consequently , they may consciously or unwittingly aid the exploitation of animals , rather than grant a form of consideration to their wellbeing unless this is directly linked to their productivity . This is partly because veterinary work is predominantly commercial , where the language of profit and growth tends to dominate . Many large animal vets reproduced commodified narratives , turning animals and themselves , into productive beings , Clients are used to calling you when they have a problem and see you as an expense , whereas you 've got to try and make that transition to them seeing you as a resource â¦ by working closely with you they can actually make themselves more profitable , so that your expense is negligible .	234287184	no
Nevertheless , one might be concerned that manifestations just do not stretch to precisely those cases we should wish to say the respective power is instanced . One would think this especially if one took zero - values of the manifestation variable to be instances where the power is not manifesting . As was mentioned at the end of the previous section , this concern effectively amounts to the the final issue raised in Sect . 2 that Megarian powers get the data wrong : power variables can exhibit zero - values of their manifestation variables , but zero - values just are not cases of manifestation . In response , the Megarian has two options . One ( problematic ) option is to limit the instances where a power is instantiated after all , specifically to those cases where manifestation does not take a zero value . But this seems to give rise to precisely Molnar 's and Aristotle 's original concerns that powers would not be able to explain their manifestations , because they would be dependent on them and would also thereby have counter - intuitive acquisition and loss conditions . The second and more plausible option is to argue that zero - values are in fact genuine instances of manifestation . In what remains of this section , I want to show why this is a reasonable thing to think .	237873402	no
This research is based on an observational investigation of COVID-19 in the Dharavi sector in Mumbai , India as of the end of 31st July 2020 . Fig . 1 shows the geographical location of Mumbai in India and a satellite image of the Dharavi sector . The Brihanmumbai Municipal Corporation ( BMC ) is Municipal Corporation of Greater Mumbai which is a local governing body . The BMC is monitoring and responsible for the implementation of the public health and economic activities in the wards . During the COVID-19 outbreak in this region , BMC is closely monitoring the situation and plans and executes the policies to control the spread of disease . The information about COVID-19 cases updated and informed to the ' corona war room ' in the control unit through the BMC 's Health Department team . The data for analysis of COVID-19 cases is extracted from the official portal of BMC . 8 The BMC publicized its data for public use on its website . The nationwide data for COVID-19 is extracted from the Ministry of Health and Family Welfare ( MoHFW ) , India . 9 The United Nation Population Report is used to extract the population data . 10	231705661	yes
B. Temperature dependence : Thermal desorption data Fig . 2 shows thermal desorption spectroscopy data which demonstrate the enhancement of the thermal stability of capped DIP films compared to uncapped layers . In these experiments the mass spectrometer is tuned to the mass of DIP molecules ( 400 amu ) , and the signal is recorded as a function of time , while the temperature is ramped at a constant rate of 0.5 â¢ C / sec . While the uncapped DIP shows a well - defined desorption peak around 190 â¢ C the capped film shows no desorption until 240 â¢ C. The shape of the spectra also reveals differences in the desorption process . The spectrum of the uncapped film shows only one sharp peak that can be attributed to the DIP ' bulk ' desorption . In contrast , the desorption spectrum of the capped film extends over a broader temperature range and has multiple features with the main feature centered at 300 â¢ C.	95585436	no
Bringing together electronics , micro - electromechanical systems , and microfluidics into one functional system can disrupt the area of personalized medicine and portable sensing . [ 53 ] A smart microfluidic system is composed of ( i ) sensors to detect www.advmat.de www.advancedsciencenews.com the desired phenomenon , ( ii ) actuators to introduce and translate fluids , ( iii ) microstructures to combine and mix fluids , ( iv ) filters for purification and separation , and ( v ) interface electronics to interpret and carry out certain actions based on the acquired data from sensors . These components together form a complex microsystem incorporating mechanical , fluidic , and electronic functions . [ 7 ] CMOS - based microfluidic platforms bring together the best of these multiple disciplines to create a unified single - chip platform capable of performing complex biomedical tasks . CMOS has played an integral part in the realization of portable and versatile microfluidic platforms . As it will be seen in the following sections , a tremendous amount of work has been done to integrate microscale sensors , interfaces , and actuators with microfluidic devices using CMOS technology . Several sensors and actuators based on optical , electrochemical , electrical , and magnetic principles have been made using CMOS technology . [ 10 ] Integrated circuits ( ICs ) , made by interfacing CMOS technology with microfluidic devices , form what we call a smart system . Sensors may be embedded inside the ICs , while actuators can be controlled by producing electronic or magnetic fields for controlling the movement of objects inside the microfluidic channels . Furthermore , by adding interface electronics on the same CMOS chip , we can build a universal platform for LOC devices . The use of such ICs provides flexibility for making changes or optimizing microfluidic systems without having to alter the physical structure of the device . [ 11 ] The beauty of CMOS is that , in a chip much smaller than most microfluidic devices , it can make high - resolution measurements and support large arrays of sensors . [ 54 ] CMOS has also shown potential for implementation in applications involving high voltage generation and switching of a high voltage CMOS chip , which allows system miniaturization of the cumbersome high voltage equipment needed for genetic analysis . [ 55 ] Figure 1b shows an illustration of how different CMOS based technologies can be envisioned to perform multiple functions in a single chip platform capable of performing POC diagnostics .	3559860	no
The complete device combines two of the above described pre - printed paper webs . For top and bottom side , one and the same design can be used . Thus , the more than 500 m long web was split into two rolls with â260 m of pre - printed material each . These rolls were fed to two separate unwinding units of our 15 m long R2R machine LaborMAN 1 . Besides four printing units , the machine consists of different post - press units including a hot lamination unit . Both webs were brought into contact in the nip of this unit with the printed P(VDF - TrFE ) top and bottom electrode surfaces face to face . According to the data sheet of the manufacturer , the used P(VDF - TrFE ) material has a melting point of 150.5 Â° C . Varying the web speed , nip pressure , and lamination temperature , the process was optimized w.r.t . piezoelectric and mechanical performance of the T - PAPER laminate . The final lamination settings for this work were 3 cm s â1 , 1 bar , 160 - 180 Â° C for the web speed , the pressure of the impression roller and the surface temperature of the lamination cylinder , respectively . It is important to notice that both in - fed webs as well as the laminated out - fed web have to run well - controlled through the whole machine to achieve good alignment of the pre - printed structures , especially the register of the bottom and top electrodes , and to avoid the formation of wrinkles .	231633101	no
MCF7 concentrations of 0 mL â1 ( negative control ) , 10 mL â1 , 100 mL â1 and 1000 mL â1 were tested , where three samples for each concentration were prepared and independently measured . Figure 5 shows the results of the   . At each scanning position , 120 frames of raw holograms were taken at 26.7 frames per second . Computational drift correction was applied to mitigate the horizontal shift caused by the fluid drift , where the vertical movement caused by the magnetic field was kept unmodified . The lateral position of each MCF7 candidate was located by CMA , maximum intensity projection and threshold - based detection . d - g Zoomed - in preliminary processing for the example region labelled â  in b , c. h - k Classification process for the two cell candidates labelled â  and â¡ in c. The axial location for each cell candidate was determined by autofocusing . A video was formed for each cell candidate by propagating each frame to the in - focus plane . The classification was performed by a densely connected P3D convolutional neural network , as detailed in the Methods section blind testing of our technique using serial dilution experiments . The blue data points correspond to a onetime testing result , where the error bars correspond to the standard deviations of the three detected concentrations at each spiked concentration . Without the detection of any false positives in the negative control samples , our technique was able to consistently detect MCF7 cells from 10 mL â1 samples , measuring a target cell concentration of 1.98 Â± 1.06 mL â1 . At this low concentration ( 10 cells / mL ) , the detection rate was~20 % . The experimentally measured detection rate dropped to~5 % at a higher concentration of 1000 cells / mL. Because the training of the deep neural network inherently includes randomness , we further evaluated the repeatability of our network training process . For this , we randomly and equally divided our training data into five subsets , and then we trained five individual networks by assigning one different subset as the validation data set and the combination of the remaining four subsets as the training data set . Each of the five networks was blindly tested to generate the serial dilution results . The mean and standard deviation of the detected concentrations resulting from the five networks are shown in Fig . 5 ( orange data points ; for each trained network , three detected concentrations are averaged at each spiked concentration ) . Overall , good consistency between the different network results is observed .	203638272	no
This new situation may affect the relationship of democracies with large technology companies , as has already occurred in the case of Cambridge Analytica ( Isaak and Hanna , 2018 ) . This case taught the world that the ability to combine demographic and psychographic data of users , with their online habits and behaviors , could predict their voting intentions ; it also showed that users could be a strategic target of political campaigns . Therefore , these technologies can cause dramatic social , political , and economic changes worldwide ( Blair et al . , 2017 ) . Taking advantage of the new circumstances that broaden companies ' possibilities of monitoring and managing user personal data , the corresponding techniques can be later expanded to other purposes ( Blazquez and Domenech , 2018 ) .	233029680	no
The identification of key parameters that can inform the longsought guidelines is not straightforward . Qualitative descriptors such as linearity or planarity do not have a well - established , quantitative definition . Moreover , even in systematic studies of structurally related molecules , variations in linearity and planarity can not be readily decoupled from variations of other parameters such as molecular weight ( MW ) and size . Additionally , each of these parameters influences the T g of the films , rendering the problem of identifying key parameters even more complex . Over the last few years , a substantial body of literature has been published that reports on the orientation of a wide variety of fluorescent and TADF emitters from a range of systems . Cross - comparing the available orientation data from these studies may well provide relevant insights beyond the conclusions that can be drawn from individual studies .	236774690	no
To ensure that the signals were not due to ablative , cavitation , or vaporization mechanisms , the focal fluence was maintained below the ablative threshold levels ( o1 J cm â 2 ) , and it was typical of previous OR - PAM systems 42 . With carbon fiber phantoms , only approximately 1 nJ pulses were focused to an~3 Î¼m spot size , leading to a focal fluence of 14 mJ cm â 2 , which was significantly below the ablation threshold 44 . Although we performed phantom experiments to demonstrate that the source of PARS signal follows model predictions from Equation 1 , transient bubble creation could occur for high focal fluences and further contribute to probe beam scattering modulation . Nevertheless , such micro - or nanobubbles were not observed in experiments ( Supplementary Information , Section 4 ) , even for focal fluences as high as 500 mJ cm â 2 . Such fluence levels are commonly used in other photoacoustic microscopy systems 42 . Moreover , all of the images shown in this manuscript had limited surface fluences of 20 mJ cm â2 , consistent with the ANSI limit ( Supplementary Information , Section 1 ) . A camera system was installed to simultaneously provide reflectance images , and it revealed no evidence of bubble formation ( Supplementary Information and Figure 3 ) . Figure 4a demonstrates in vivo images of the chorioallantoic membrane ( CAM ) of chicken embryos 14 days post incubation at 38 Â° C . This imaging session was performed using galvanometer scanning mirrors ( details are outlined in the Materials and Methods section ) . In this model , larger blood vessels are located deeper than capillaries . Confocal microscopy images of fluorescently labeled microvasculature in the CAM were acquired in the same chicken embryo ( Supplementary Information , Section 5 ) , and they were comparable with label - free PARS images . Figure 4b demonstrates a snapshot of real - time imaging of capillary beds at 30 frames per second ( FPS ; Media 1 ) . To achieve real - time imaging , the field of view was restricted to~50 Î¼m , and the laser pulse repetition rate was set to 600 KHz with 15 Hz and 1.2 KHz slow and fast axis galvanometer mirror scanning rates , respectively . Real - time implementation of the scanning mirror captures were performed using the same hardware . The data acquisition card was operated in a data streaming mode ( eXpert FPGA DSP , Gage Applied ) , which was interpreted in real - time by software developed in house using the Photoacoustic remote sensing P Hajireza et al Gage Applied C / C++ SDK . To maintain higher frame rates , a more basic scatter point interpolation was used , which resulted in lower resolution over single captures . Translational motion observed in the video was ascribed to subtle embryo motion captured over the 2 s observational window . Intensity fluctuations were attributed to redblood cell number density variability in the small vessels observed . Further development work , including faster data steaming and multithreaded implementation of analysis , would generate improvements in performance ; however , this technique is ultimately limited by the maximum tilt speed of the fast scanning mirror axis .	52131320	maybe
In addition to the literature review process , we also performed the HOMALS analysis using SPSS ( v20 ) software for each group of keywords found in the articles . HOLMAS is a well - known method of multiple correspondence analysis ( MAC ) procedures to analyze qualitative data ( Kiessling et al . , 2019 ) . Specifically , it is an exploratory analysis process for the elaboration of graphical display of multivariate categorical data .	233029680	no
"Content sensitivity Respondents ' concerns can increase when the data contain potentially sensitive information , where potentially sensitive means the individuals might not understand the inherent risks of initially uploading the data because of the difficulty in estimating the potential damage due to an increase in accessibility to private content . Through later evaluations of content containing sensitive information , individuals can update their initial risk assessments , which can lead to adjusting the content . Respondents expressed apprehensions , for example , that "" the facts on [ sensitive ] content are wrong "" and "" the content includes private information . "" These concerns arise mostly from individuals ' evaluation of their content ."	231744099	no
Participants were recruited through CSR networks , industry conferences and networking . Ethical procedures were followed in data collection and storage , and all interviews were recorded ( with the permission of participants ) and then transcribed . Two Romanian researchers conducted the interviews , but as not all the research team spoke Romanian , transcripts were independently translated into English for analysis purposes .	237363721	no
Once the incident field is retrieved , OAM sorting can be performed by applying spatial mode decomposition 37 . For instance , when the data - carrying OAM field E S is precisely recovered , the complex - valued coefficients c n can be calculated by	71715926	no
Recent studies argue that both objective and subjective measures should be included when possible , because different associations were found between the objective measures and perceived measures of the same environmental attributes with active travel behavior ( Barnett et al . , 2020;Ma & Dill , 2015 ) . In this study , subjective built environment factors were investigated . Subjective measures have often been considered a substitute for objective measures when objective data are unavailable , while in order to evaluate the effects of the built environment characteristics on active travel during the COVID-19 outbreak , both objective and subjective measures are necessary . Furthermore , it is recommended that future studies evaluate the effect of bike - sharing in the resilience of bicycle during the critical situation , as well as the effect of cycling background in the resilience of this mode . In addition , considering the change of travel behavior such as the number of trips , travel distance , the share of major transport modes , the share of trip purpose , and regional deference of them in future research are essential ; especially travel behavior of older people who are more vulnerable to bacteria and viruses due to the weakening of their immune system .	236256030	no
"There might be a strange man who sometimes feels pain , just as we do , but whose pain differs greatly from ours in its causes and effects . Our pain is typically caused by cuts , burns , pressure , and the like ; his is caused by moderate exercise on an empty stomach . Our pain is generally distracting ; his turns his mind to mathematics , facilitating concentration on that but distracting him from anything else . [ â¦ ] [ H]e feels pain but his pain does not at all occupy the typical causal role of pain . He would doubtless seem to us to be some sort of madman [ â¦ ] I said there might be such a man . I do n't know how to prove that something is possible , but my opinion that this is a possible case seems pretty firm . If I want a credible theory of mind , I need a theory that does not deny the possibility of mad pain . ( Lewis 1983 , p. 122 ) Lewis thus introduces the possibility of mad pain and goes on to use it as a touchstone for a theory of mind , he speaks of "" the lesson of mad pain "" being an argument against functionalism ( p. 123 ) . In so doing he treats that possibility as a phenomenon . We may grant that already the possibility , not just the actual existence , of a case of mad pain has intriguing consequences for the philosophy of mind , as Lewis claims . Within our modelling framework , we can however also assess how successful Lewis has been in establishing the existence of the phenomenon in question . He states that he does n't know "" how to prove that something is possible""-read : how to establish the possibility of something as a phenomenon . Now clearly there are established methods for this task ; medieval philosophers already knew that ab esse ad posse valet consequentia . Lewis however does not point to an actual case , or even just to a case that is relevantly similar . Instead he argues in favour of his supposition from the fact of his "" pretty firm "" conviction of the possibility in question ; he later repeats that he is concerned here with his "" naive opinions about this case "" ( p. 129 ) . Lewis thus brings forward a piece of data - and a relevant one too . However , by this he has not succeeded in establishing the phenomenon that he needs for his argument against functionalism . Since Lewis in the mentioned article gives no further support for the possibility that he presupposes , his argument should be rejected as methodologically unsound - which , of course , is not the same as rejecting its conclusion ."	12017797	no
Secondly , it becomes clear that specific uncertainties arise from the actions of the actors involved and of the institutions guiding such actions . Urban water professionals are confronted with a wide diversity of actors with different responsibilities and interests , but also with actors who work from different institutional backgrounds , and thus are likely to consider different rules to be correct and valid ( Klijn and Koppenjan , 2004 , p. 88 ) . Both the diversity of actors and the diversity of institutions involved with systems integration introduce uncertainty . Informational systems integration , for instance , involves uncertainty related to the sharing of data from different urban systems . The parties involved may have different IT systems and ontologies , and thereby introduce institutional uncertainty 6 for the urban water decision - makers involved . Moreover , such sharing of data highlights the issue of privacy that comes with informational systems integration . Privacy regulations are key to reduce the risk of cybercrime ; however , regulations typically develop slowly . They thus involve uncertainty as to whether , when , and how they will be enforced and/or adapted .	228885500	no
"tests suitable for comparing variables in two dependent groups such as the ones in this study ( before and during COVID-19 ) . They are nonparametric tests suitable for ordinal variables and non - normal distributions of the differences between pairs of data . Since we perform before - during COVID-19 comparisons on 11 different dependent variables , we applied the Bonferroni Correction to reduce the likelihood of type I error . We therefore consider significant differences those with a pvalue smaller than 0.00455 . For the second analysis , we used multiple linear regression , in which built environment characteristics , sociodemographic characteristics , and area socioeconomic status were treated as independent variables , and health and well - being measures were treated as the dependent variable . Measures of health and well - being represent ordinal variables but can be used as an approximation of continuous variables , and parametric analyses including linear regression are considered robust ( Ferrer - i - Carbonell & Frijters , 2004 ; Norman , 2010 ) . In fact , research has shown that using linear regression or ordinal regression in models with well - being as the dependent variable makes little difference ( Ferrer - i - Carbonell & Frijters , 2004 ) , therefore using linear models that treat health or well - being variables ( measured on scales such as 1 - 5 or 0 - 10 ) as continuous is common practice ( Cao , 2016;Poortinga et al . , 2021 ) . A preliminary analysis with multilevel modelsconsidering area socioeconomic status on level-2 -was also performed but results showed that there was no between - cluster variance when level-1 variables were added , so this method was eventually not appropriate . Linear regression analyses were performed independently for Athens and Thessaloniki due to differences in urban structure , size , and socioeconomic characteristics . Independent analyses for these two main metropolitan areas of Greece were conducted for comparative purposes since preliminary analyses showed that results differed for the two regions . Built environment variables were included in the models in two steps based on relevant theoretical considerations ( Mouratidis & Poortinga , 2020;Naess , 2019 ) . The first step includes the variables "" distance to city center "" and "" neighborhood density "" , while the second step additionally includes the variables "" public transport "" , "" local facilities "" , "" park area "" , "" tree cover "" , "" apartment "" , and "" dwelling size "" all of which might be influenced by distance to city center and neighborhood density . In models of the second step , distance to city center and neighborhood density play the role of control variables . Variables on health and wellbeing that were examined as dependent variables in regression models are : "" life satisfaction "" , "" personal relationships satisfaction "" , "" leisure satisfaction "" , "" overall health "" , "" happiness "" , "" anxiety "" , "" headache "" , and "" back pain "" . The other three health and well - being variables in our dataset were considered less relevant to the built environment so were not included in this analysis in order to reduce complexity . The analysis was conducted for health and well - being : before COVID-19 , during COVID-19 , and for the change before - during COVID-19 . For the dependent variables that decreased during COVID-19 , the change was calculated by subtracting the value of the variable during COVID-19 from the value of the variable before COVID-19 . For the dependent variables that increased during COVID-19 , the change was calculated by subtracting the value of the variable before COVID-19 from the value of the variable during COVID-19 . Independent analyses for the urban regions of Athens and Thessaloniki are presented in each table . All the analyses control for individual sociodemographic variables and area socioeconomic status(their coefficients are not presented here to reduce the size of the tables ) ."	238530423	maybe
where A is a multiplication factor depending on the amplitude of the excitation field and the SHG susceptibility tensor Ï ( 2 ) of the material . For the analyzer orientations Î¶ = 0 and Î¶ = Ï/2 , we obtain the two normal components of the SHG field , that is , I X ~ c os 2 ( 3Î¸ â 2Ï ) , and I Y ~ s in 2 ( 3Î¸ â 2Ï ) , respectively . The graphical representation of Equation ( 1 ) at a fixed analyzer position of Î¶ = 0 and the corresponding visualization in a polar diagram ( Figure 2b ) demonstrates a fourfold symmetry for the SHG intensity that rotates for different armchair orientations Î¸ ( for different armchair angles and choice of Î¶ = Ï/2 , see also the polar diagrams in Supplementary Fig . S2 of Supplementary Materials ) . Thus , each armchair orientation corresponds to a characteristic fourfold symmetric polar diagram . Consequently , by fitting pixel - by - pixel the PSHG experimental data to Equation ( 1 ) , we can acquire the armchair angle Î¸ for every pixel of the image . We note that the armchair directions differing by 60 Â° produce the same polar diagrams ( that is , the armchair direction can be determined modulo 60 Â° ) , reflecting the threefold rotational symmetry of the WS 2 crystal ( that is , the fact that Ultrahigh - resolution nonlinear optical imaging in 2D transition metal dichalcogenides S Psilodimitrakopoulos et al there are three equivalent armchair axes ) . Furthermore , the excitation polarization for Ï between 0 Â° and 90 Â° provides the same PSHG intensity modulation as for Ï between 90 Â° and 180 Â° . This is also the case for Ï between 180 Â° and 270 Â° or 270 Â° and 360 Â° (fourfold symmetry ) . Therefore , Ï sampling in the range 0 Â° -90 Â° is adequate to retrieve all possible armchair orientations , that is , Î¸ â [ 0 Â° -60 Â° ] .	52134764	no
We then grouped the PACT data into multiple heartbeat phases based on the synchronized ECG cardiac cycle and reconstructed a volumetric heart image for each phase ( Fig . 1c ) . Since the heart rate was around 5 Hz and the pulsed laser illuminated at 50 Hz , each cardiac cycle can be divided into 9 - 11 phases , enabling the reconstruction of 9 - 11 volumetric images to depict the beating heart . The variations in cardiac cycle duration were caused by differences in weight ( e.g. , obese versus regular rats ) and anesthesia ( i.e. , light versus deep anesthesia ) . However , the ECG signal shows that the heart rate was relatively stable during the 10 - second scan .	255415294	no
The data on confirmed cases , deaths , and test recipients were also collected daily . As shown in Table 1 , such data was collected by the ECDPC from 37 OECD countries . However , collection of data was omitted on some dates , in some countries . For comparison of all these variables across countries , the data on both new cases and deaths were standardized to represent incidence per 1 million people . The number tested was standardized to be expressed as the rate of tests per 1000 individuals . 5 In the determinant factor analysis , due to the weak normality of the distribution , we converted the data to the square root values , as explained above . 6 Table 2 shows the changes in the RSV , the key variable of this study , from just before the event week to the mid - point , in the 37 OECD countries we analyzed . In addition , Table 2 shows the dates when the peaks of new cases and deaths existed during the analysis period . In Table 2 , we see that RSV showed rapid changes in many countries around March 11 and March 12 . 17 out of 37 countries ( 45.9 % ) also exhibited their peak immediately following the declaration ( within 2 days ) and 28 out of 37 countries ( 75.7 % ) reached their peak of RSV within a week . These results confirm the likelihood that the WHO 's pandemic declaration had a significant effect on the changes in RSV , while also indicating that there were differences among countries . Table 2 also presents the duration of the analyzed RSV . Duration is defined as the period ( in days ) until the RSV was restored to that of March 10 , a date just preceding the event week . Table 2 also shows significant differences by country : it is notable that Italy , Japan , and Korea , where a large number of confirmed cases had already been reported , experienced a very short duration . The durations presented in Table 2 had a very high correlation with the RSV increase rate in the event week ( Pearson correlation coefficient 0.808 , p - value < 0.000 ) , and this can be confirmed by referring to Fig . 3 . We thus confirmed that the greater the increase in RSV , the longer the duration , and in consideration of multicollinearity , we did not add RSV duration as a variable in our analysis .	232282755	maybe
Tailored for the practical development of strong and conductive CNT materials , this meta - analysis surveys a wide body of CNT , conductive polymer , and graphitic interaction compound literature to statistically compare characteristics of these materials at an extrinsic and intrinsic level . Metrics are catalogued in a database provided in the Supporting Information section with references . Composite CNT materials such as CNTs combined with polymers , metals , or other matrices will largely not be considered . The paper is organized as follows : in Section 2 , we first review the mesoscopic , intrinsic characteristics of CNTs with details potentially overlooked in the bulk CNT textile community to include transport in : Section 2.1 metallic single - wall CNTs ( SWCNTs ) ; Section 2.2 semiconducting SWCNTs ; Section 2.3 multi - wall CNTs ( MWCNTs ) ; Section 2.4 CNT bundles ; Section 2.5 CNT junctions . This answers the question of how an assembly of CNTs ( forming a mesoscopic bundle and then forming a macroscopic cable ) compares to the assembly of graphene ( forming into single - crystal graphite crystallites and then into macroscopic graphite or carbon fiber ) . Next , we discuss the meta - analysis on the aggregation of data across the literature on the experimentally reported extrinsic characteristics of CNT materials to include : Section 3.1 bulk conductivity , strength , and multi - functionality ; Section 3.2 thermal conductivity and ampacity ; Section 3.3 density and specific properties ; Section 3.4 purity ; Section 3.5 anisotropy and microstructure alignment ; Section 3.6 average CNT dimensions and graphitic perfection ; Section 3.7 intercalation doping and junction enhancement . In Section 4 , we integrate the previous topics together with : Section 4.1 partitioning of intrinsic and extrinsic characteristics in CNT material ; Section 4.2 leading properties of the ultimate CNT material ; Section 4.3 CNT 's analogy to graphene and single - crystal graphite ; Section 4.4 briefly mentions CNT - metal composites for context ; and Section 5 concludes with a summary of the meta - analysis findings and the path ahead . Meta - analysis methods are provided in detail at the end .	236090435	maybe
Conceptual negotiation could be employed to address issues surrounding data gathering , including their neutrality . In this paper , however , we shall focus on higher - levels of conceptual disagreement , which have so far escaped the attention of scholars and that involve negotiations concerning data and methods as a sub - part .	238810809	no
Finally , we demonstrated that by combining our technique with fast neuron programming , differentiated cortical tissues can be constructed within weeks , whereas organoids take months to develop . Although organoids can yield most brain cell types following developmental progression , later - born cells can take months or more to reach significant numbers . Indeed , 2D culture still has an advantage over 3D culture for the mass production of homogeneous cells . However , by taking advantage of advances in the 2D culture of diverse brain cell types , brain tissues from later stages of differentiation might be generated through prepatterned constructs in a fast manner . Together , our data suggest that 3D bioprinting can be applied to spatially position distinct cells to construct 3D tissue models and guide self - organization . The approach can be applied to study human brain developmental processes such as cortical expansion and astrocyte migration / segregation . Finally , diseases could also be modeled by incorporating reprogrammed patient cells with specific genetic mutations .	219704613	no
Finally , we estimate the absolute change in oscillator parameters . From the fits to experimental data in the main text we measured the products âÏ 0,2 /2Ï Â· d = 9 Ã 10 â4 T Hz Â· Âµm , âÎ³ 2 /2Ï Â· d = â9.1 Ã 10 â3 T Hz Â· Âµm , and âA osc,2 Â· d = â6.7 T Hz 2 Â· Âµm , where d is the photoexcited film thickness . In the main text we used the estimate of d = 100 nm based on the direct gap and 400 nm excitation wavelength . Using this thickness , a direct calculation of âA osc,2 from âA osc,2 Â· d yields a negative oscillator amplitude after photoexcitation .	231603155	no
We tested our hypotheses using cross - sectional survey data of > 20,000 enterprises across 42 countries from the World Bank 's ongoing COVID-19 Tracking Survey . This novel dataset is dominated by small and medium enterprises with < 100 employees , which make up 80 % of the sample . The data was collected over the period of April 2020 -March 2021 and tracks innovation adoption and utilization over the same time period . The COVID-19 Tracking Survey uses the same sample of firms as the World Bank 's Enterprise Survey ( WBES ) , which is a comprehensive survey dataset that has been collected since 2006 . We matched the COVID-19 Tracking Survey with the WBES , which provided us with an extensive number of control and other relevant variables for the prepandemic period . Table 1 summarizes the measurement of variables and their data source . Here we briefly recap the measurement of key variables used in the analysis .	256275626	yes
In this work , we presented a new in situ electrolyte assessment method for the fast , reliable , and precise assessment of the key electrolyte state parameters SOC E and SOH E based on an FT - IR device equipped with an ATR flow cell , enabling a measurement even at high analyte concentrations , as encountered in flow battery electrolytes . The proposed IR method is expected to be transferrable to a wide range of different RFB chemistries based on organics and applicable to nearly all solvents . With Figure 9 . Comparison of different SOH determination techniques . CC ( diamonds ) , OCV half cycle fitting ( triangles ) and IR spectroscopy ( circles ) are compared to the theoretically expected drop off ( black lines ) during the artificially induced SOH changes . The total duration of the experiment was 266 hours . Orange lines / symbols denote data collected during battery charging while green lines / symbols denote data collected during battery discharging .	236259860	no
Considering the relevance of the impact of COVID-19 on the cryptocurrency market , this research explores the dynamic return and volatility connectedness of the three most relevant cryptocurrencies ( Bitcoin ( BTC ) , Ethereum ( ETH ) and Ripple ( XRP ) ) and coronavirus news proxied by the Coronavirus Media Coverage Index ( MCI ) , as applied in Cepoi ( 2020 ) , among other recent studies . For comparison purposes , this study also analyses the dynamic return and volatility connectedness of the fiat currencies of the euro , GBP and Chinese yuan and the MCI . These dynamic connectedness measures are estimated in the context of the COVID-19 pandemic crisis by using the TVP - VAR methodology ( Antonakakis and Gabauer , 2017;Gabauer and Gupta , 2018;Antonakakis et al . , 2020 ) , which is suitable for short time series data , in comparison with alternative approaches such as that proposed by Yilmaz ( 2012 and2014 ) . Thus , the main advantage of this methodology is that it allows us to compute the dynamic spillovers without using the rolling window technique ( as a modification of the original Diebold - Yilmaz approach ) . Given the short time series of the COVID-19 pandemic , the use of this methodology is appropriate . In addition , the approach is robust and has been used in many other studies to determine connectedness .	236449955	no
The study variably supports Nehf ( 2007 ) view that consumers make decisions about distributing their data in exchange for different benefits like , e.g. , information on web sites and access to databases . Trust , credibility , privacy issues , security concerns , the nature of the information on the website , and the e - commerce firm 's reputation directly influence consumers ' internet trust ( Kim et al . , 2008 ) . Trust is the focal point of online consumers ' decision - making ; the observation endorses Larose and Rifon ( 2007 ) creation of privacy alerts as part of consumer privacy self - regulation initiatives and the use of a social cognitive model to consider consumer privacy behaviours . Besides , data privacy and trust breaches adversely affect the firm 's market value ( Tripathi & Mukhopadhyay , 2020 ) also hold good in the present context . Figure 7 demonstrates a diagrammatic model of trust of the consumer on e - commerce transactions leading to his decision - making .	235784924	no
Self - rated health ( during last 12 months ) . Self - report of 9 illnesses ( heart disease , diabetes , cancer , asthma , arthritis , stroke , bleeding ulcer , tuberculosis and hepatitis ) . ( 2 ) Infant 's level of negative reactivity and self - regulation during the Lab - TAB Toy Removal task ( reaction to interesting toy taken away but still in sight ) . BMI at age 1 : BMI - for - age z - scores . Weight gain by age 3 : data collected from medical visits . Seeyave et al . ( 2009 ) 336 360 The Netherlands Latent construct of behavioural and attentional regulation ( Flanker Fish task and Hearts & Flowers task ) . Word Decoding by the 3 - Minutes - Reading - Test , summed .    361	53238424	maybe
The remainder of this paper is organized as follows . We discuss the research background and related literature in Sects . 2 and 3 , respectively . Section 4 presents the two competing hypotheses . Section 5 describes the data collection and research design . Section 6 presents the empirical results at the provincial level . In Sect . 7 , we further examine the factors affecting philanthropic decisions at the organizational level and explore the implications of donation destinations . Section 8 presents a series of robustness tests . The final section concludes the study and discusses its implications , contributions , and limitations , as well as outlines avenues for future research .	231985056	no
Since AACC in Spain can implement policies to control CO 2 emissions in their territory , this paper used data retrieved at the AACC level so that the models developed here could be used by the regional authorities to design custom emission regulation policies that could be optimized for their individual characteristics . This approach resulted in training 19 different prediction models . From a modeling perspective , it is not a big issue . But having different models for each AACC complicated drawing conclusions about their similarities and differences regarding CO 2 emissions . Focusing on the variables that entered in the anthropogenic CO 2 and nonrenewable CO 2 estimation models as shown in Tables 4 and 6 , it was expected that the inclusion of the levels of CO 2 coming from non - renewable generation would be the key predictor for the 19 anthropogenic models . But the relevance of GDP related variables was also significant and somewhat less predictable . It seems that for those AACC with a quite predictable emission model of nonrenewable CO 2 , GDP and time of the year variables are enough to get an accurate prediction . For those communities with less predictable emissions , several extra variables related to financial products , state agent transactions or service sector levels were   required in addition . It should also be noted that the estimation of non - renewable generation emissions was more challenging , as shown by the increased number of variables required per model . Variables related to energy demand , the number of mortgages or affiliations to the social security become more relevant then . The information coded on those two tables could be of great value when designing emission reduction plans per AACC . Two major difficulties were found : apportioning in monthly figures the yearly amount of CO 2 emissions and the lack of mobility data available in Spain . To cope with the first one , a model to estimate these monthly figures was also developed . Unfortunately , despite the evident influence of traffic related emissions in the global CO 2 emissions , the availability of information about mobility patterns per month and per AACC in Spain was very limited and did not allow us to establish any sensible method of estimating them . Initially , data related to the number of yearly crashes and victims were used as proxy variables for mobility , as there is literature pointing to the existing relationship between exposure and injuries ( Segui - Gomez et al . , 2011 ) . However even if this data is available up to 2018 it did not end up contributing to the significance of the models . Some local administrations report the actual figures of private and public transportation use , unfortunately the number of informed cities is still too low to include this predictor in the models .	233916124	no
In general , the complete dataset is divided into three parts : 1 ) training , 2 ) cross validation , and 3 ) test . The model is trained on training datasets using optimization methods . For example , fitting a polynomial on training datasets using steepest descent optimization method , where optimization is carried out to obtain values of prefactors of the polynomial . During the optimization procedure one needs to fix a set of hyperparameters , e.g. , the parameters characterizing a steepest descent process . For this set of hyperparameters , the prediction quality is obtained from comparison of the predictions with the information of the cross validation dataset that is not observed by model during training . Subsequently , by minimizing the error , hyperparameters will be updated and optimized . The relevant final error is then determined from predicting the so - far unused test dataset . If the optimization of hyperparameters is not relevant one may just work with a training and a test set . In this case we will separate the N measured data in M training data and N â âM test data . The desired but unknown relation between a feature x and the experimental or numerical outcome y is denoted f(x ) . In general , the outcome is additionally hampered by noise commonly taken from a normal distribution , thereby incorporating uncertainty so that the outcome is given by	243997418	no
stations , ( v ) workplaces , and ( vi ) residential places . These data have been constructed by comparing visits and lengths of stays at certain places relative to a baseline ( Google Mobility , 2021 ) . The retail & recreation cate - gory provides data on mobility trends for places such as restaurants , cafes , and shopping centers . Grocery & pharmacy category provides data on mobility trends for sites considered to be essential trips , including grocery markets , drug stores , and pharmacies . Similar subcategories of related locations are grouped within parks , transit stations , workplaces , and residential places ( Google Mobility , 2021 ) . The use of such types of consumer mobility data is also in vogue in the extant literature ( e.g. , Persson et al . , 2021 ) .	255441206	yes
"In fact , a global travel preferences ' survey , during the outbreak of the COVID-19 pandemic , indicated a significant shift from public to private and non - motorized passenger transport modes , and highlighted that the likelihood of using PT was comparatively higher for females , non - car owners , and longer trip distances ( Abdullah et al . , 2020 ) . Montero - Lamas et al . analysed bus PT ridership and GIS data in A Coruna , Spain , during the COVID-19 lockdown , and they found that in areas with low - income population , high population densities and important concentrations of hospitals , offices and supermarket facilities , the PT demand was relatively higher ( Montero - Lamas et al . , 2022 ) . In Lisbon , Aparicio et al . compared demand figures between 2019 and 2020 for bus , tram and metro networks and found reductions of up to 80 % , but at stations located in peripheral regions with relatively more low - income users , the decrease was lower ( Aparicio et al . , 2021 ) . The fear of COVID-19 infection and the teleworking opportunities were among the key reasons that explained the significant reduction of PT trip frequency levels ( up to 90 % ) in Gdansk , Poland ( Przybylowski et al . , 2021 ) as well as in Warsaw , Poland , where travellers also emphasized their limited personal security on - board due to the crowding and the non - adherence to the rule of wearing masks ( KÅos - Adamkiewicz & Gutowski , 2022 ) . The crowding of PT vehicles and the possibility of teleworking also explained the decreased PT demand figures in Sicily , Italy , which continued to exist until the last months of the year 2020 ( Basbas et al . , 2021 ) . Across the twenty largest metropoles of the USA , the PT demand decreased between 45 and 80 % during the first months of the COVID-19 outbreak , and this decrease was positively correlated with the spread of the disease ( number of cases and deaths ) and the educational level of the users in the respective areas ( Qi et al . , 2021 ) . In Chicago , USA , Hu and Chen estimated an average 72 % drop of rail PT users ( of the "" L "" train system ) during the first wave of the pandemic , with that decline being higher in regions with dominance of white , educated and high - income residents ( Hu & Chen , 2021 ) . Heavy rail PT usage also decreased in Hong Kong , China , both among students and adults , who reduced their rail PT trips by up to 48 % ( Zhang et al . , 2021 ) . When analyzing the ridership decline of the New York subway during the spring of 2020 , Sy et al . discovered that among essential workers , who are generally associated with lower incomes , the mobility levels were comparatively more increased ( Sy et al . , 2021 ) . A study in Belgium examined the hypothesis that women are disadvantaged in the face of COVID-19 and found that females used PT more to commute or shop ( Assoumou Ella , 2021 ) . A nationwide survey , after the end of the first lockdown in Canada , showed that PT demand remained decreased when compared to the pre - pandemic levels , while certain mitigation measures , such as meticulous cleaning , hand sanitizing and mask - wearing would encourage people to continue using PT modes ( LabontÃ© - Lemoyne et al . , 2020 ) . A survey in Cardiff , UK , showed that PT was among the least preferable modes during the pandemic , due to having the highest perceived risk of infection ( Angell & Potoglou , 2022 ) . In Santiago , Chile , during the first week of the anti - COVID-19 restriction measures , the PT ridership decreased by 30 % -40 % within lower income groups , but among higher income users the drop was > 70 % ( Tirachini & Cats , 2020 ) . Duenas et al . studied passenger demand data for the PT services of Bogota , Colombia , during the first half of the year 2020 , and explained that the users with worse socioeconomic conditions ( e.g. , poverty , informal work ) had comparatively increased mobility levels after the relaxation of the first lockdown measures ( DueÃ±as et al . , 2021 ) . The greatest reduction of trip frequency and PT demand figures was observed in the wealthier neighbourhoods of Daejeon , South Korea , during the first wave of the pandemic ( Kim et al . , 2021 ) . Though that PT was rated as the most unsafe travel mode before the first COVID-19 lockdown in India , there were no important modal shifts from private to PT modes , possibly due to the lack of other alternatives ( Pawar et al . , 2020 ) . Munawar et al . analysed data from Moovit and other sources for Australia and found that due to the physical distancing rules and the fear of virus transmission by fellow passengers , the PT use was reduced by 80 % in April 2020 ( Munawar et al . , 2021 ) ."	255826268	no
Additionally , we need to add a new threat to these potentially fragmenting approaches , rare at the time Martin Barbero was writing : the availability and easy access to data . It takes a researcher less than 45 minutes to find data demonstrating how the KONY 2012 video went ' viral ' immediately after Oprah Winfrey ' tweeted ' about it ( Rainie et al . , 2012 ) . Today 's social movements and their uses of ICTs have become a gold mine for researchers looking for big data . A study conducted by the University of Zaragoza 's Institute for Biocomputation and Physics of Complex Systems ( BIFI ) between 25 and 26 April 2011 monitored 70 Twitter hashtags related to the M15 movement in Spain . The study documents the patterns , hubs , and connections of 581,749 Twitter messages and 87,569 users , in an attempt to understand the formation of complex networks ( TarrancÃ³n et al . , 2011 ) . 2 As researchers in the area of CfSC , we need to recognize that this type of data is insufficient for answering complex research questions about the cultural negotiations , hegemonic forces , anti - hegemonic resistances , and political economy frameworks that traverse uses of media technologies . We need research that takes seriously the idea that ICTs are used within historical conditions . We need to explore how media technologies are bent in specific ways according to local power dynamics , levels of expertise , cultural negotiations , and social interactions . In the following pages , we highlight a few studies that assume the challenge of situating ICTs within complex historical contexts .	145594952	no
The effect of wavevector filtering has been confirmed also experimentally using a WSS - metamaterial sample that closely resembled the modeled ASR - array both in terms of its size and design parameters . The obtained images of the transmitted wavefronts are presented in Figure 3g-3i . Evidently , the patterns of the wavefronts , as well as their spatial - frequency spectra plotted in Figure 3j-3l   very good agreement with our simulations . The appearance of noise in the phase data at 0.23 THz ( and higher frequencies ) coincides with the diffraction minima due to the finite size of the pinhole aperture . Additional experimental data , including the wavefront images obtained at other frequencies and their comparison with the results of our simulations can be found in Supplementary Information . Although the limited bandwidth of the spatial - frequency filtering might be an issue for some practical applications , this problem could be addressed by employing the so - called double - continuum Fano resonance approach 32 , where the bandwidth of the effect is increased by stacking 2D - chiral versions of the metamaterial ( i.e. ASR structures lacking reflection symmetry ) 33 with adiabatically varied resonance frequency . Unlike the wavevector manipulation performed by the lenses , the demonstrated principle of k - selectivity does not rely on gradient structuring . As a result , metamaterials with strong inter - metamolecular coupling can extract plane - wave components from arbitrary shaped wavefronts . A remote analogue of WSS functionality and the associated ' tunnel vision ' effect might be found in conventional rayoptics systems such as astronomical telescopes : for the same magnification the telescopes with higher f - ratio ( i.e. slower telescopes ) will allow an observer to see stars and nebulas on a much darker background yielding overall higher contrast images . Such telescopes have smaller field of view , which limits the directions of the admitted light rays to those nearly parallel to the axis of the ' tunnel ' ( i.e. telescope ) hence blocking most of the light scattered by the atmosphere and immediate surrounding .	2888993	yes
Lim 's research on Egypt emphasizes the complexity of communication processes in situations of dissent and social mobilization . Communication is required for social movements to gain momentum and galvanize collective political action , but this generally implies a multiplicity of forms of communication , from the performative communication of bodies in the street to the disembodied informational act of texting a meeting time and place ; according to Tufekci and Wilson ( 2012 : 370 ) , 48.4 % of participants first heard about the Tahrir Square demonstrations through face - to - face communication , 28.3 % through Facebook , and 13.1 % via telephone . In Egypt , Lim identifies taxi drivers and food vendors as key communicators , and coffee shops , mosques , and soccer fields as crucial spaces for information dissemination ( Lim , 2012 : 242 - 3 ) . Similarly , Gerbaudo ( 2012 ) identifies how anti - globalization activists played key roles during the Indignados movement in Spain ; so did anarchists during the Occupy movement in the United States ( Gerbaudo 2012 : 143 ) . Based on ethnographic data from various case studies , Gerbaudo ( 2012 ) insists on the need to understand how media practices happen in interaction with specific localities ; his study centers on how interactions between movements and media choreograph specific forms of mobilization .	145594952	no
Emissions during pyrolysis . Emissions of air pollutants during pyrolysis were included in the assessment with proxy data from a Stockholm pilot plant , and contributed significantly to human health impacts ( Fig . 4 ) . Concerns about emissions exist on the farmer 's side , as was revealed during stakeholder interaction . However , no funds are currently available for monitoring of emissions from plant operation .	228975451	no
Next , we investigate the k i ||B|| [ 001 ] geometry for a singlecrystalline sample , which reveals the structure within the biskyrmion plane . When studying chiral skyrmions in helimagnets using the same geometry , the skyrmions form a long - range ordered hexagonal lattice , leading to sixfold - symmetric SANS peaks . [ 5 ] In SANS , the magnetic scattering factor F m ( q ) = f motif ( q ) Ã f lattice ( q ) is the convolution of the form factor of the biskyrmion motif , f motif ( q ) , and their lattice order f lattice ( q ) . [ 29 ] If the biskyrmions are not forming a periodic lattice , e.g. , as in the disordered skyrmion phase hosted in the geometrically frustrated spin liquid material Co 7 Zn 7 Mn 6 , [ 11 ] f lattice ( q ) smears out into an isotropic distribution in the q x -q y plane , while the contribution of f motif ( q ) to F m ( q ) becomes more pronounced . Therefore , the nonlattice state offers a unique opportunity to study the form factor of the biskyrmion motif . [ 30 ] Figure 2o shows the experimental biskyrmion SANS pattern obtained at 0.4 T. First , no diffraction peaks are observed , suggesting that in MnNiGa bulk crystals the biskyrmions are not long - range ordered in the hexagonal plane . Note that in LTEM imaging , owing to the small field - of - view , biskyrmions may form a distorted hexagonal lattice , [ 18][19][20][21][22][23 ] which is not in contradiction to the SANS data . In such a disordered state , a possible scenario is that individual biskyrmions have a random in - plane direction due to spontaneous symmetry breaking . Consequently , there would be no preferred direction of the biskyrmions when averaging over all quasiparticles . In this scenario , the scattering intensity is equally distributed forming a ring .	76662510	no
Increasing the concentration of building blocks in solution can result in the formation of a hydrogel network owing to the entanglement and bundling of assembled fibers ( Figure 2a and Figure S2 , Supporting Information ) . We altered the ratio between the building blocks at a fixed total concentration of 5 wt% , to study the effect of co - assembly . Hereafter , we denote   Hydrogels formulated from different ratios of supramolecular building blocks . a ) Schematic illustration of different supramolecular formulations at network and molecular levels . Blue linkages between fibers at network level indicate interfiber cross - links formed by B - type molecules , and labels of black arrows at molecular level indicate the rate of molecular exchange dynamics for different formulations . b ) Frequency dependence of storage ( Gâ² ) and loss ( Gâ³ ) moduli of different compositions of supramolecular hydrogels . c ) Gâ² and damping factor ( tan(delta ) ) values of hydrogels measured at 1 rad s â1 and 1 % strain . d ) Stress relaxation behavior of supramolecular hydrogels measured by subjecting the hydrogels to 1 % strain . e ) Quantification of stress relaxation in hydrogels after 10 min . f ) Fluorescence recovery after photo - bleaching ( FRAP ) tests performed on hydrogels containing 20 Âµm of UPy - Cy5 supramolecular additives . g ) Quantified FRAP results showing the rate of fluorescence recovery during the first 60 s after photo - bleaching ( Initial rate ) , the timespan during which the Cy5 fluorescence intensity recovers to half its mobile fraction ( Ï 1/2 ) , and the fraction of fluorescence intensity that recovers when fluorescence intensity curves reach plateau values ( Mobile fraction ) . b - g ) All hydrogels contained a total polymer content of 5 wt% , and all measurements were performed at 37 Â° C . All data are shown for n = 3 independent tests per group , and as mean Â± s.d . e , g ) * , p < 0.05 ; * * , p < 0.01 ; * * * , p â¤ 0.001 ; one - way analysis of variance ( ANOVA ) followed by Bonferroni post hoc . the samples as BZMW , where Z and W indicate the wt% of B - and M - type molecules in each composition , respectively ( see Table S1 , Supporting Information , for an overview of hydrogel compositions ) .	236773304	no
This also entails that there will be negative eigenvalues corresponding to negative covariance . To ascertain whether each component was significant , we determined whether it reliably captured positive covariance in a separate ( held - out ) sample of ratings . We generated p - values corresponding to the null hypothesis that the out - of - sample covariance explained by each component was no greater than zero by applying PPCA in a leave - one - rater - out fashion . Specifically , we iteratively applied PPCA to extract components from the judgments of all but one of the raters and projected the held - out rater 's judgments onto the components . We then assessed the partial Pearson correlation between the component scores derived from each heldout rater 's ratings and those derived from the mean ratings from the other culture , partialing out each previous component . Finally , we tested whether these held - out , statistically independent correlation values were consistently positive for each component using a non - parametric Wilcoxon signed - rank test 85 . ( Note that to calculate the raw group - level out - of - sample crosscultural correlations for each PPC , as shown in Fig . 4b , we averaged the out - of - sample correlations across raters . We then computed partial correlations in the scores on each PPC across cultures , controlling for previous PPCs . Standard errors were computed by bootstrapping across raters . ) See Fig . 3 for results of repeated Monte Carlo simulations validating these methods . Each simulation specifies a sampling distribution that closely matches our actual data after it is projected onto some number of orthonormal components of covariance ( varying from one to the maximum , 29 ) . The results of these simulations confirm that PPCA combined with our leaveone - rater - out approach accurately recovers the number of shared components and yields conservative p - and q - values .	73728390	no
"An important general take - away is that the proponent of knowledge norms can do something much stronger than to merely cast doubt on the arguments of belief - firsters by pointing to disagreement and alternative modeling possibilities such as ambiguous epistemic states . The knowledge - firster can instead argue from a philosophy of science perspective for the re - evaluation in their favor of relevant long - standing disagreements . The argument for this broader lesson draws on Williamson 's picture of knowledgefirst as a paradigm which stacks up well with respect to standard theoretic virtues . As noted in the introduction , taking ' knowledge ' as a primitive enables a simple and highly coherent picture according to which a plausible natural kind ( knowledge ) serves as the common normative standard of belief , assertion , and action . The paradigm enables the explanation of a much broader range of empirical data than could other equally simple accounts , while avoiding "" overfitting "" or the addition of "" epicycles "" to accommodate contrived or unusual cases , as Williamson might put it ."	236251081	no
"The evaluation of pandemic 's economic impact is very important for policy - makers ( Scott et al . , 2020 ) . However , the unprecedented situation introduces high uncertainty . Governments find it difficult to form an appropriate macroeconomic policy response to the circumstances faced with because the social impact of the disease is still difficult to foresee ( Mckibbin and Roshen , 2020 ) . Meanwhile , forecasting requires at least minimal stability of the situation . It is illustrated by the current statistics which is different from the economic forecasts published during the early period of Covid-19 ( e. g. Ng , 2020 ) . Today more than ever can it be ascertained that citizens ' health has direct impact on the countries ' economic welfare ( Mckibbin and Roshen , 2020;Lin , Meissner , 2020 ) . However , this connection is ambiguous . Strict policy of disease control is saving lives but at the same time directly influences economic decline ( Eichenbaum et al . , 2020 ) . What is more , the effect of long - term quarantine may cause a hysteresis of economic consequences , e. g. destruction of supply chains which would cause a massive deceleration of the global economy ( Eichenbaum et al , 2020 ) . According to International Monetary Fund ( IMF 2020a ) , the global economy may shrink by 3 percent , which is more than the economic recession observed during the global financial crisis of 2008 - 2009 . Economic recession may put millions of people in long - term poverty ( Suryahadi et al . , 2020 ) . Small businesses will suffer the most , evidence for which already exists . For example , around 50 percent of workers in the USA work in small business , the majority of which are in retail . By executing the disease control policy , drastic measures were put in place due to which , during the first months of Covid-19 , around 43 % of the sector 's businesses were temporary closed while the employee busyness has decreased by around 40 % ( Bartik et al . , 2020a ) . Similar tendencies are also observed in Europe and the UK . Countries which implemented a strict "" stay - at - home "" policy and left employees at home with only a part of their pay also observed an increased number of unemployed people , especially in small businesses and among those with least income ( Forsythe et al . , 2020 ) as well as increase in income inequality . This is the main aspect by which Covid-19 crisis differs from the earlier economic crisis , when mostly large - scale production , construction and similar businesses stopped while the most impacted were those with the highest income ( Bartik et al . , 2020;Campello et al . , 2020 ) . Nevertheless , it is difficult to objectively evaluate the situation due to contradicting data . For example , job loss statistics are relatively improved by the fact that a part of employees retired early . Due to this reason , higher number of people quitting their jobs rather than becoming unemployed is observed ."	237473259	no
Second , conducting research with Facebook data involves some challenges , which is a potential area of future research on social media . These challenges are ( A ) the role of the algorithms on the visibility of different posts , ( B ) the non - independence of likes and shares , and ( C ) problems to infer causal effects . Regarding challenge ( A ) , the Facebook algorithms cause prominent posts with a higher number of reactions to be promoted more among observers than posts with lower number of reactions . This differential visibility may potentially lead to selection bias ( Elwert & Winship , 2014 ) , as the reactions to a post cause factual exclusion of unattractive posts out of the sample . Although such events are contained in the data , observers are less likely to be able to respond . It is possible , however , that the application of zero - inflation models , which we applied in this study , presents a remedy to this problem , as these models separate unobservable posts from the observable posts .	254385691	no
A domain ontology of electrochemistry can build on existing standards that are widely used and agreed upon in the community . [ 22 ] The International Union of Pure and Applied Chemistry ( IUPAC ) maintains recommendations for terminology . The latest IUPAC recommendations for electrochemical methods of analysis were published in 2020 , [ 56 ] and serve as an extension of the more general Compendium of Chemical Terminology ( also known as the Gold Book ) . [ 57 ] The Electrochemical Society ( ECS ) has created an online dictionary and encyclopaedia of electrochemistry , which contains over 1000 terms and uses hypertext links to couple entries . [ 58 ] The International Electrotechnical Commission ( IEC ) maintains an active international standard governing the vocabulary of electrochemistry , [ 59 ] which is also available as an online digital reference available in a variety of European and Asian languages . [ 60 ] While the terminology recommendations from each of these sources are very similar , there do exist some deviations that should be elucidated in a formal ontology of the electrochemistry domain . Data model ontology An ontological description of a simple data model aimed to make application specific data semantic interoperable .	245111008	maybe
The parameter a ( Eq ( 9 ) ) was estimated using historic temperature data from 1996 to 2010 ( assumed to represent a normal year ) , the area of the buildings S i in m 2 , the energy performance of the buildings for a normal year E i in kWh m Ã2 year Ã1 , and the share of hot water w i . N is the number of years used for calibration ( 15 ) and t here is given in hours . The parameter a was equal to Ã1.7 kW K Ã1 ( for 640 m 2 of heated space , i. e 2.6 W m Ã2 K Ã1 ) .	228975451	no
Superimposing images obtained at different modulation frequencies represents a simplistic image formation approach and demonstrates the complementarity of data obtained at single frequencies ( Fig . 2 and Supplementary   Fig . S6a ) . More generally , multi - frequency amplitude and phase data can be processed for three - dimensional image reconstruction using the Fourier transform based on two approaches : frequency - space representation ( FSR ) and time - space representation ( TSR ) . The FSR arranges data in a three - dimensional matrix , which is denoted as S(x , y , f ) , in which the x - and y - axes correspond to the spatial scanning points and the f - axis corresponds to a vector that contains the measurement ( amplitude and phase ) at each modulation frequency . The TSR arranges data in a three - dimensional matrix , which is denoted as S TSR ( x , y , t ) , in which the x - and y - axes also correspond to the x - y scan pattern and the t - axis is a time - dependent signal obtained via the inverse Fourier transform ( IFT ) , namely , S x ; y ; f Ã° ÃÃ ! IFT S TSR x ; y ; t Ã° Ã , of the collected FD signals ( Supplementary Fig . S6b ) .	56894658	maybe
In India , several studies carried out by a good number of researchers like ; Plocoste et al . ( 2020 ) investigated time series LST trend and PM level . Mahato and Pal ( 2018 ) focused on impact of land surface parameters on land surface temperature regime . Most of the studies reported the increasing trend of LST and PM in the urban and industrial area across the world . Moreover , spatial image data released from European Space Agency ( EPA ) , NASA also reported a growing PM level in the atmosphere in most urban halves of the world . Growing economic activities like intensification in industry , transport , tourism , agriculture , and trade are the majorly responsible for this . Nevertheless , fast - changing land use / land cover , squeezing green and blue space over the terrestrial land , qualitative deterioration of terrestrial and aquatic ecosystems , and weakening of selfregulatory mechanism of the ecosystem are unable to refresh and restore the environment due to release of high - volume pollutants within a very short period ( Du et al . , 2020 ) . A good number of world summits like annual United Nations Climate Change Conference ( UNCOP ) from 1995 till present were conducted ; Intergovernmental Panel on Climate Change ( IPCC ) was periodically conducted with climate change contents reported , but no - good solution was found yet to combat the environmental deterioration . To keep the continuous economic growth , no strict measure was yet taken compromising with production volume .	233713305	no
The business of company M in manufacturing industry involves daily maintenance of engineering equipment at sites . Thus , the primary goal of its transformations in the pandemic period is to ensure operations continue through remote solutions . First , it has implemented AR to safeguard the virtual presence of safety engineers at its maintenance sites all over the globe . The concept of AR was not new to the company before the pandemic , but the company only had limited experience . Since the start of the pandemic , the company has prioritized the roll - out of this technology and scaled up the adoption throughout the company . Second , WFH has been adopted , however , at the cost of efficiency , as IT equipment in manufacturing industry requires specific adjustments to allow remote access and such adjustments are usually not optimal . For example , before the pandemic , most software in company M would only be used on local networks for security reasons and employees manually connect local databases to enterprise resource planning ( ERP ) systems . In the pandemic period , such a manual connection was impossible as engineers could not go to sites to get the offline data . Thus , the company has developed an interface which connects ERP to a part of its offline databases . Due to partial database availability , several standard business procedures of the company have been delayed . Third , the company has adopted IoT at its production sites , that is to collect critical production data and use cloud analytics to turn this data into valuable insights about the efficiency of the operations . It is worth mentioning that the adoption of IoT has already been underway for 2 years in the company , and the pandemic has just accelerated the roll - out of this technology . Fourth , using data on the state of its equipment , the company has adopted ML to find patterns that help predict and ultimately prevent equipment failures .	245617006	no
"Therefore , we propose to monitor the changes in the predictions , which are continually updated with the latest data daily , and focus on the predictions of macro patterns and long - term variables regarding the total pandemic life cycle . Taken together , we propose and advocate the "" predictive monitoring "" paradigm , which synthesizes predictions and monitoring , for heuristic learning of the uncertain and open - ended developments of the pandemic . Predictive monitoring differs fundamentally from the traditionally defined prediction and monitoring paradigms . Table 2 presents a taxonomy ."	231654013	no
If professionals -as operational decision - makers -are seen as autonomous agents rather than just receivers of better information , then the key success factor for data science may reflect both rationales . The alignment between data analysts and decision - makers ( Arnaboldi , 2018;Bhimani and Willcocks , 2014 ) may hold sweet promises . This alignment issue can be viewed as the connection between the supply of data and the demand of information , which is in its nature an organizational rather than a technical issue ( Van der Voort et al . , 2018 ) . The alignment requires to involve decision - makers in the processes of data sciences ( Bhimani and Willcocks , 2014 ) . It also refers to a problem of knowledge . Decision - makers as agents are already knowledgeable in their own right and have their own values and mental models ( Bhimani and Willcocks , 2014;Boisot and Canals , 2008 ) . The agent 's knowledge does not necessarily align with knowledge as derived from data science efforts .	239658990	no
In this work , we demonstrate a transmission - mode alldielectric metasurface platform that can simultaneously and independently manipulate the amplitude and phase for a pair of orthogonal states of polarization at visible frequencies . In contrast to a previous demonstration that only relies on geometric - phase modulation to tune the amplitude and phase for a fixed polarization state 29 , here , by combining geometric phase with propagation phase , the proposed metasurface optics is able to completely decouple any combination of two arbitrary amplitude and phase profiles , and encode their information into two orthogonal polarization states . Various single - layer metasurfaces composed of subwavelength - spaced titanium - dioxide ( TiO 2 ) nanopillars on a fused - silica substrate are designed and fabricated to exhibit the ability of polarization - switchable multidimensional light - field manipulation . Examples of proof - of - concept experimental demonstrations shown here include polarization - switchable nanoprinting , nonuniform cylindrical lensing , and complex - amplitude holography . To the best of our knowledge , this is the first experimental realization of a single - layer metasurface that integrates four independent channels of different optical information for a pair of orthogonal polarization states . This capability is elegantly demonstrated here by incorporating two nearfield nanoprinting images and two far - field hologram images , within the same metasurface . We envision this type of metasurface platform to open new possibilities of creating compact multifunctional optical devices for applications in polarization optics , information encoding , optical data storage , and security .	235190837	no
To verify the method presented above , we apply the calculation to data of Cui and co - workers as they measured the spectral irradiance in absolute quantities with a calibrated spectrometer . [ 30 ] Cui et al . presented iOPV cells with PBDB - TF as donor and IT-4F , ITCC , and PC 71 BM as acceptor materials under illumination with a white LED with a color temperature of 2700 K. [ 30 ] Note that this is a relatively low color temperature for a white LED , that is , one with more photons in the red and less in the blue spectral region . The results are shown in Figure 3 on a double - logarithmic scale . Filled symbols represent the original values of the three samples for illuminances of 200 , 500 , and 1000 lux as provided in ref . [ 30 ] , whereas blank symbols show the results of our calculation . First , we address the normalization of the spectral irradiance to the applied lux levels . The integration according to Equations ( 1 ) and ( 2 ) gives a E v , ref of 46425.97 lux which leads to normalization factors of 0.0043 , 0.0108 , and 0.02154 for the E v , set of 200 , 500 , and 1000 lux , respectively . Note that we apply the calculation to relative spectral irradiance data , although absolute measurements are available in order to prove the applicability to relative data . The integration of the factorized reference spectra f Â· E e , Î» , ref results in input power densities of 60.38 , 150.96 , and 301.91 ÂµW cm â2 for 200 , 500 , and 1000 lux , respectively . The input power densities are shown in Figure 3a and match well with the original absolute data . The integration according to Equation ( 6 ) gives J sc values , which are in good agreement with the original J sc values of Cui and co - workers as well and are depicted in Figure 3b . Only the PBDB - TF : PC 71 BM cell shows a slight deviation with a calculated J sc of 18.63 ÂµA cm â2 to the original value of 18.9 ÂµA cm â2 , which is likely to originate from slight discrepancies in the J sc from the JV measurement and the J sc from Q e , PV . As the V oc and FF are computed by interpolation , a well matching J sc automatically results in a good match of the values for V oc and FF , which can be seen in Figure S2 , Supporting Information . Figure 3c , d shows the resulting output power densities and efficiencies . Apart from a slight deviation of the PBDB - TF : PC 71 BM sample due to the J sc difference , the calculated output power densities and efficiencies are in excellent agreement with the original data .	236547029	no
Drying device ( II ) 3 Total electricity consumption 79.7 Table 3 Life Cycle Inventory data of the process to recover HDPE from MSW at the plant .	225159599	maybe
"Prior research has also highlighted how consumers ' risk perception influences their use of public transportation , such as ride - sharing services or metro trains . ( e.g. , Wang et al . , 2019;Basu & Ferreira , 2021;Garaus & Garaus , 2021 ) . Chernozhukov et al . ( 2021 ) use Google Mobility data to measure the impact of the social distancing policies during the COVID-19 pandemic . Using geo - spatial analyses , a large telecommunication data set is also used to monitor human mobility during the COVID-19 pandemic ( Persson et al . , 2021 ) . We complement this stream of research by using the developed predictive model to forecast consumer mobility in three US cities using publicly available data from Google that reflects "" real - time "" consumer trends . Such data is available for a majority of regions / cities across the globe , and our algorithm could be used to forecast retail mobility , given the data ."	255441206	no
The experimental setup for superresolution PACT is shown in Fig . 1 . A piece of plastic film was used to seal the bottom of the full - ring ultrasonic transducer array , and water was poured in for ultrasonic coupling . The object to be imaged was either submerged in the water or placed just beneath the plastic film after it was lifted . A Ti : sapphire laser ( LS-2145 - LT-150 , Symphotic Tii ; 20 - Hz pulse repetition rate ; 12 - ns pulse width ) was used to excite PA waves . The laser beam was homogenized and expanded by an engineered diffuser ( EDC10 - A-1r , RPC Photonic ) , thereby resulting in a 2 - cm - diameter illumination area on the object . The excited PA waves were detected by a 512 - element full - ring ultrasonic transducer array ( Imasonic Inc. ; 50 - mm ring radius ; 5 - MHz central frequency ; more than 90 % one - way bandwidth ) . Each element has a cylindrical focus ( numerical aperture of 0.2 ; 20 - mm element elevation size ; 0.61 - mm pitch ; 0.1 - mm interelement spacing ) . The PA signals were preamplified by a lab - made 512 - channel preamplifier ( 26 - dB gain ) that was directly connected to the ultrasonic transducer array housing to reduce cable noise . The preamplified PA signals were digitized using four 128 - channel data acquisition systems ( SonixDAQs , Ultrasonix Medical ULC ; 40 - MHz sampling rate ; 12 - bit dynamic range ) with a programmable amplification of up to 51 dB. The digitized data were initially stored in the onboard buffer and subsequently transferred to a computer for data processing .	102347513	no
A first set of solar cells comprises as electron transport layer ( ETL ) C 60 n - doped with tetrakis(1,3,4,6,7,8 - hexahydro-2H - pyrimido[1,2 - a]pyrimidinato)ditungsten(II ) ( W 2 ( hpp ) 4 ) ( chemical nomenclatures in the Experimental Section ) and as hole transport layer ( HTL ) N4,N4â²-bis(9,9 - dimethyl-9Hfluoren-2 - yl)-N4,N4â²-diphenylbiphenyl-4,4â²-diamine ( BF - DPB ) p - doped with C 60 F 36 . As shown in Figure 1 ( top ) , we center the maximum of the optical field in the ZnPc layer for 680 nm , a wavelength close to which ZnPc has its peak absorption ( details in Section SI.3b in the Supporting Information ) . For centering , we adjust the thickness of HTL and ETL for all ZnPc thicknesses x o by means of numerical transfer - matrix - simulations . [ 13 ] As shown in Figure 2 , the measured EQE maximizes for a ZnPc thickness x p between 15 and 18 nm , increasing with Î» . This already indicates â d to be much smaller than the absorption length which for ZnPc is above 100 nm .   measured photocurrent data as function of x o and Î» , we consider the general exciton diffusion equation :	42651708	no
The in - depth characterization of defects , e.g. , the elucidation of defect concentration and spatial distribution , as well as the defect chemistry as a function of both parameters challenges common characterization techniques . For instance , laboratory X - ray diffraction relies on the periodic arrangement of the lattice and only minor changes , oftentimes beyond the resolution of lab X - ray techniques , are expected in the Bragg diffraction pattern of defective MOFs . In contrast to that , experimental techniques that can probe the local structure , e.g. , the analysis of the pair distribution function ( PDF ) or the extended X - ray absorption fine structure ( EXAFS ) , can be used . Such techniques , however , require the use of synchrotron sources and usually go beyond common laboratory techniques ; hence , our structural insight into defects and heterogeneity in MOFs is yet limited . The study by Cliffe et al . from 2014 depicts one of the rare examples , where a combination of several techniques such as ( anomalous ) powder X - ray diffraction ( PXRD ) and PDF combined with computational modeling was used to access the defect chemistry of UiO-66 . [ 14 ] On the basis of their results ( and the insight the authors provide ) , it is no surprise that UiO-66 is presently the model framework within the field . Particularly , the formation of nanoregions with reo topology in UiO-66 , which come with small intensities in the PXRD pattern , have sharpened our perception when analyzing PXRD data related to defective MOFs .	8662842	no
However , it was interesting to observe the perceived readiness level that the respondents had for each individual system . Even with the inability to draw summarising conclusion , observing partial data would still give valuable information about sustainability readiness . Surprisingly , manufacturing process management had a lower sustainability readiness ( m 1 Â¼ 1.5 and s 1 Â¼ 1.2 ) compared to the score for information systems ( m 5 Â¼ 1.75 and s 5 Â¼ 0.94 ) . These results probably derive from a sampling issue connected with the nature of the ECOPRODIGI project , which focus on digital technologies for the maritime industry . Such a focus may have caused the invited respondents to overfocus on ICT - related issues in production . The importance of such technology - related capabilities is expected to increase as a consequence of advances in digital technologies brought by the fourth industrial revolution ( Monostori , 2014;Devezas and Sarygulov , 2017 ) .	229426053	no
Third , the analysis illustrates the specific ways that the concepts ethics , morals , fairness , justice , and democracy participate within the Twitter Occupy Wall Street conversation . Building upon prior research , we distinguish between the use of concepts as stand - alone ethical stance markers and the local use of concepts to amplify the ethical attributes of specific characters . The results show that concepts are important bridges between different characters in that the removal of words terms such as fairness and ethics would fragment the discursive network . This finding is important because it highlights the specific , local ways that the placement of concept terms contributes to the social accountability narrative . Once again , an understanding of the placement of concept terms and the role of concepts in acting as a bridge between characters would not have been possible without the use of large - scale data and social network analysis methods .	252377054	no
To characterize our system , we detect polystyrene latex nanoparticles over a range of radii , and 2.5 nm silica nanoparticles at picomolar concentrations ( Figure 3a ) . We perform the detection in water using microtoroids approximately 80 - 100 mm in diameter , with selected resonant peaks having loaded quality factors ( Q ) of , 1 3 10 5 -5 3 10 6 in water with an input power of 9.3 - 100 mW at 633 nm . These moderate Q - factors are chiefly a result of the optical fiber being positioned in direct contact with the microtoroid in the over - coupled regime 25 . This procedure was chosen to minimize noise due to the optical fiber fluctuating against the toroid during the experiment . Furthermore , we perform these experiments under conditions where we inject fluid toward the toroid with enough sample volume to completely exchange the liquid in our sample chamber three times , before stopping , waiting 30 s , and then recording our data . This approach mitigates noise from the optical fiber fluctuating against the toroid that occurs when a continuous injection is used 19 .	37093521	no
The formation of the SLB platform and the subsequent binding of 1 - 2 tubes were monitored in situ with a quartz crystal microbalance method with dissipation monitoring ( QCM - D ) . The adsorption on the QCM sensor is accompanied by the change in frequency ( Îf ) , while the change in energy dissipation ( ÎD ) provides information on the softness of the adsorbed layer . The formation of high - quality SLB was confirmed by frequency shift of Îf = â24 Â± 1 Hz ( Figure 5 ) , which is in agreement with data reported previously . [ 36,37,42 ] The binding of SAv to SLB yielded a frequency shift of Îf = â25 Â± 1 Hz ( Figure 5 , black curve ) , which corresponds to the maximum coverage of the surface with SAv . [ 42][43][44 ] After the formation of the SAv - SLB in PBS buffer , the solvent was switched to Milli - Q water to accommodate the introduction of the water solution of the 1 - 2 tubes . This liquid phase exchange is characterized by the increase in frequency and decrease in dissipation followed by the fast stabilization of the signal . After washing with water for 10 min , the solutions of tubes were introduced into the QCM chambers . www.advmat.de www.advancedsciencenews.com A solution of 1 ( 500 Ã 10 â6 m ) did not yield any frequency shift ( Figure 5a ) , confirming that in the absence of biotins in the structure , the tubes do not bind to the SLB . For the solution of 1 - 2 with a molar ratio of 300:1 at the concentration of 500 Ã 10 â6 m of 1 , binding was also not observed ( Figure S13 , Supporting Information ) . When the proportion of 2 was increased in 1 - 2 while keeping the same concentration of 1 ( 50:1 , [ 1 ] = 500 Ã 10 â6 m ) , clear evidence of binding was observed as a distinct frequency shift ( Figure 5b ) . Furthermore , owing to accessible biotin groups remaining at the outside layer of the 1 - 2 tubes , the attachment of a next layer of SAv on the tubes layer was accomplished ( Figure 5c ) . Fiber - like patterns observed in fluorescent microscopy images ( Figure 5d ) confirmed the specific binding of 1 - 2 tubes to SAv - SLB . Meanwhile , if tube 1 was introduced instead , no obvious structure and fluorescence was detected ( Figure S14 , Supporting Information ) indicating the absence of nonspecific binding , which is consistent with the QCM result ( Figure 5a ) .	244678183	maybe
"The property requirement also demands that the explanandum ( that b is G ) is an empirical proposition , such that it can serve as a proper object of scientific investigation . Thus , TE is an analysis of topological explanations in the empirical sciences . Insofar as pure mathematics has topological explanations , it is not our concern here . Furthermore , we adopt a broad notion of "" empirical "" in line with recent work on data , measurement , and phenomena . 13 For instance , Helling et al . 's explanandum - ictogenicity - is measured in terms of patients ' dose - response to anti - epileptic medication ."	240459850	no
If we attempt to assess the extent to which this literature can be applied to smart products and things , then we may conclude that theory development for network - embedded business models is needed ( Bankvall et al . , 2017 ) . There is a paucity of theoretical argumentation , especially with respect to an explanation of the consequences of smart things for business models . We may criticize extant literature for failing to address the effects of pervasive connectivity on firms ' business strategies . The levels of connectivity being brought about by the IoE does not simply offer connection to social networks and applications , but enables wholly new forms of ' smartness ' embedded in network constituents due to the interconnection between data streams from both social and physical systems and sources . A major challenge associated with such a shift is how firms develop their existing business model towards a new networked business model that fits best in the IoE context . This implies that the development of a new business model has to deal with path dependency effects as the organization attempts to extend its current strategy and value propositions step - by - step in the direction of the new IoE context ( Wirtz et al . , 2010 ) . Any new theorizing must be able to guide the creation of new business models starting from the context of smart things at a low smartness level right up to fully autonomous , adaptive and self - determining things .	213757082	no
A third , smaller remark is that the authors are not clear about the number of effect sizes per study that were used for each of the meta - analyses . If for anxiety , depression of each of the ER - skills , maximally one effect size per study was observed , there is no problem . If there were for some studies multiple effect sizes , however , this induces dependence in the data that should be accounted for . I guess that if this was the case , the authors used the default procedure in CMA , this is using an average effect size per study . This procedure would be fine , but transparency is needed .	237583058	no
Step 2 -Feature Weighting : For each decomposed 2 - D plane , P ( F i , y ) , the Menger Curvature method , introduced in Section 3.1 , is adopted to obtain the averaged curvature value of the feature F i . Given that a decomposed 2 - D panel ( P ( F i , y ) ) contains m data instances , the Menger Curvature value ( MC i mj ) of data point m j ( 2 j m â 1 ) can be determined by Eq . ( 1 ) . To this end , the mean of MC for F i , denoted as MC F i , is computed as :	231573178	no
The preservation of input data , custom parameters , and order of workflow components is a feature of most workflow frameworks . However , the level of detail at which this information is captured varies significantly between the various workflow frameworks , and as a consequence , also the reproducibility level that the framework can actually guarantee . A crucial element in capturing the complete workflow is the proper description of the utilized software . Separating the standalone software packages wrapped in the framework still is a challenge due to the software version , the underlying platform , compiler settings , and other factors that might influence the computation result and compatibility with the workflow framework itself . In KNIME , for instance , workflow templates link to a specific version of a node . If newer versions for a node are available , the old nodes will be marked as deprecated but still part of the workflow template , and the user has to decide whether to use the newer version of the node . Similarly , calculation nodes in AiiDA always have an input node in the provenance graph , representing the actual executable and machine where the code was run and thus allowing to trace back the code that was used and its run environment . Another solution to the issue is to use software encapsulated in a virtual machine or Docker containers , which make execution independent of the platform where it is run . We expect that a broader support for efficient code containerization also in the context of HPC simulations , and their adoption in major HPC centers , will help to effectively address this issue in the next few years . However , most workflow frameworks also provide the option to incorporate web services or are entirely based on connecting web services like MDStudio ( www.github.com/MD-Studio/MDStudio ) . In this case , the workflow framework can not preserve the state of this workflow element and changes to it . Its discontinuation can either lead to unexpected results or failure of the workflow .	245315824	no
One reason why it can be hard to prove that socially extended wishful speaking has occurred is that certain sorts of communicative patterns which might lead audiences to form ill - established beliefs might occur for reasons other than intentional manipulation of communicative norms ; most obviously , when institutional arrangements fail to incentivise scientists to perform speech acts they ought to perform . Plausibly , this is true of biomedical research more generally ; an unintended result of institutional factors is publication bias , non - publication of negative or null results , which makes it difficult to assess the likely efficacy and safety of various drugs ( Stegenga 2011 ) . Therefore , quite apart from concerns about ghost managed research , we have good epistemological reasons to change biomedical publishing more generally ; for example , through requiring pre - registration of trials or publication of all trial data . It may seem , then , that concerns about ghost managed research are simply part - and - parcel of a larger set of concerns about the epistemic trustworthiness of contemporary biomedicine , and that responding to the latter concerns will automatically solve the former . However , I have tried to show that such cases are ethically problematic , regardless of their socio - epistemic consequences . Why ?	255060787	no
But are we justified in treating as surplus what seems like vital representational structure in some of our most successful theories ? We believe so . To address this question , we have developed a conceptual framework for identifying surplus structure in a theory . The principle we proposed -the PESA -prescribes that the observable structure of a theory be the structure that must be specified in the form of input data in order to uniquely solve the evolution equations . When applied to cosmology , the PESA combined with the empirical adequacy of the standard model of cosmology implies that dynamically similar structure is indeed surplus .	232222968	no
The data that support the findings of this study are available from the corresponding author , [ author initials ] , upon reasonable request .	236215648	yes
We might reason as follows : Let 's assume that the p value , which is the probability of an event ( e.g. , the event e 1 : [ |r | â¥ 0.50 ] , or the event e 2 : [ |r | â¥ 0.10 ] ) , is also a measure of the evidence . Because the two studies are conducted independently of one another , the probability of both events ( say , e 1 in S 1 and e 2 in S 2 ) is the product of their individual probabilities . Therefore , P 1 Ã P 2 should represent the combined evidence . The logic seems unassailable , but there is an obvious problem with this approach . By virtue of being a probability , we have 0 â¤ P i â¤ 1 for all studies i. Thus P 1 Ã P 2 â¤ minimum ( P 1 , P 2 ) , that is , the product of the p values is always smaller than the smaller of the initial p values . If we were to interpret the result of multiplying p values as itself being a measure of evidence , we would have to conclude that the evidence always increases ( or stays the same ) upon consideration of a second study , regardless of the second study 's data . This is clearly wrong . Thus P 1 Ã P 2 can not be interpreted as a measure of the combined evidence .	255063864	no
"Widespread absorption threshold spectra ( large Î» s ) may be very symmetric , such as in Figure 3c , but the integrated photocurrent for the experiment and the sigmoid fitting could be above that for the SQ limit ( see Figure S2c , Supporting Information ) . Thus , one would also say that this is a "" non - ideal "" EQE spectrum . In this case , the irregular distribution of the photon flux makes the region of the EQE spectrum above Î» g Figure 3 . Illustrative EQE spectra for experimentally a ) "" ideal "" and b , c ) "" non - ideal "" cases , and d ) integrated photocurrent for the sub - bandgap range ( integral ( 2 ) from Î» g to â ) assuming sigmoid EQE spectra . Data in ( a ) belongs to an OPV ( adapted with permission . [ 38 ] Copyright 2019 , Wiley ) ; the spectra in ( b ) and ( c ) resemble those reported for a PSC [ 21 ] and a DSSC , [ 24 ] respectively ; and the data ( circles ) in ( d ) correspond to PSCs in the "" Emerging PV reports . "" [ 14 ] The specified photocurrent integrals in ( a - c ) are shown in Figure S2 , Supporting Information ."	233844511	yes
Data Analysis : Data analysis was performed using a customized Matlab program to isolate and fi t the time constant for each pulse as described previously . [ 18 ] In Figure 2 and 4 , the data are then normalized using the following equation : NR = ( Ï no cells -Ï ) / ( Ï no cells -Ï cells ) , where Ï cells refers to the tau value in response to the application of the gate voltage of a barrier forming monolayer , and Ï no cells refers to the tau value in response to the application of the gate voltage of no barrier , with the dataset subsequently normalized to [ 0,1 ] scale , where 1 corresponds to intact cell monolayer and 0 to a disrupted one or absence of barrier monolayer .	17147344	yes
"This situation also give rise to numerous questions , such as "" Where does user privacy begin and end ? "" "" When is mass control of user tracking no longer useful ? "" "" Is geolocation the correct technology to control the COVID-19 ? "" "" Will 2020 be the start of the new era of massive data collection and the intrusion of surveillance capitalism as a global order ? "" "" What data will these kinds of mobile applications collect , and who will the data be shared with ? "" "" How will this information be used in the future ? "" "" Are there legal policies in place to prevent abuse ? "" However , a central question here is as follows : "" What are the limits and options that this new era allows from the point of view of privacy and Big Data collection ? "" Understanding these approximations is important , as the risk of tracking a connected society may cause violations of user privacy . The first step needed to control these surveillance actions is gaining a comprehensive understanding of what data about users are obtained , and how these data can be accessed ( Shilton , 2009 ) ."	233029680	no
Along with the strengths noted above , our study has certain limitations . While based on objective data and a validated model , information on social ties was inferred and contains some degree of error . Approximately 5 % of the hospital 's 26,000 employees had observed connections with a 60 % or greater probability of being true social ties according to the tie prediction model . This could limit the reach of interventions that rely on contacting known employee / co - worker dyads . Another limitation is the fact that the objectively inferred ties did not reveal whether ties or influence were one - sided or bidirectional . While we were able to objectively determine what food individuals purchased , the information in these purchases was incomplete . We could not observe what employees actually consumed , nor could we know about foods purchased by or for others , foods purchased with cash , or foods acquired outside of the cafeteria system . Lastly , our analyses focused on pair - wise relationships only , and did not assess whether peer influence is amplified when groups collectively exert behavioural influence on individuals .	233371463	no
Further , consumer behavior changes may vary based on the social and demographic characteristics of different communities and the rate and extent of transmission in the early stages of the pandemic . Thus , it may be essential to study consumer mobility patterns in distinct geographical areas to understand commonalities and differences in the underlying drivers of consumer mobility , specifically retail mobility ( Clemons , 2008 ) . In this paper , we study the effect of pandemic health metric information and consumers ' perceived risk due to the pandemic on consumers ' mobility decisions in three distinct geographic locations . We use real - time data from Google Mobility , Google Trends , and Twitter to develop a novel prediction algorithm for consumers ' mobility patterns . While Google Trends data have been popular input in several studies to measure public interest , the risk of multicollinearity escalates with the addition of more relevant terms in such studies . Therefore , effective methods must be developed and implemented to maximize the benefit of the information from such data sources . With the developed novel algorithm , our methodology effectively handles multicollinearity and lags in covariates while ensuring that all model - included covariates are statistically significant . These considerations allow the results to be readily interpretable . Consumer mobility is defined as the aggregated , and anonymized movement pattern observed among consumers based on their mobile device location . Further , retail mobility refers specifically to consumer movement trends for retail locations such as grocery stores , restaurants , and shopping centers .	255441206	no
Refer to Web version on PubMed Central for supplementary material .     Representative confocal images of a plane above the nanoneedles and quantification of Dex 10 kDa colocalization with EEA1 and LAMP1 at 24 h. Quantified data represented scatter dot plots with bars representing mean Â± S.D. , N = 1 , n = 3 biological replicates , at least five images per n. Scale bars = 20 Î¼m . e ) Quantification of Tfn , CTxB and Dex 10 kDa localization with their pathway - specific endocytosis carriers and trafficking components ( Tfn with CLC , EEA1 and LAMP1 , CTxB with Cav-1 , EEA1 and LAMP1 and Dex10 with EEA1 and LAMP1 ) . Quantified data presented as scatter dot plots with bars representing mean Â± S.D. , N = 1 , n = 3 biological replicates , at least five images per n. Î¼m . g ) Colocalization of endocytic carrier proteins ( CLC , Cav-1 ) , endosomes ( EEA1 ) and late endosomes/ lysosomes ( LAMP1 ) and their combination ( All ) with Cy3 - siRNA . Values reported as aligned scatter plot of percentages of Cy3 - siRNA pixels overlapping with indicated components of the endolysosomal system ( Mander 's coefficient ) . Lines represent mean Â± S.D. N = 3 , n = 2 for LAMP1 , EEA1 , N = 3 , n = 1 for CLC , Cav-1 . -Five to ten images per sample .	59249544	maybe
18 . P.7 - The authors claim that the SSIs took 20 - 30 minutes ; how was this determined ? Are there data available to determine the mean / median duration of each SSI ?	242291039	no
"With the Consortium 's permission , we refocused our attention from measuring employees ' attitudes to organizational engagement in corporate social responsibility ( CSR ) to measure employees ' perceptions of whether their organization behaves according to the goals of the listed activities . Therefore , the introduction text in part 3 can be read ( with the English translation of Slovenian ' meaning of the text ) as follows : instructions - the following text lists various activities that organizations can do . "" We are interested in your opinion on whether your organization behaves according to the listed activities ' goals "" . We gathered data with this instrument yearly from 2006 on . Every fifth year , we added the original third part to the Slovenian version of the questionnaire for the consortium 's purposes . In this research , we used data from the Slovenian version of the questionnaire , including 2006 to 2016 . We used the data from the second , third , and fourth parts ."	237409895	maybe
Also the costs for mitigating emissions reflect the assumptions made here . The cost estimates scatter over a wide range and can assume very high absolute values if emission savings of electric and plug - in hybrid cars are close to zero ( see Equation ( 7 ) ) . Moreover , mitigation costs become negative if either savings in user costs or savings in emissions are negative , which renders cost estimates ambiguous . If both savings in user costs and emissions are negative , the result becomes positive and depicts the costs accrued by conventional cars for mitigating the emissions from electric and plugin hybrid cars . Given these intricacies , it is important to inspect the emissions mitigation costs and their underlying data carefully before drawing conclusions . Our calculation method yields robust results in cases where an expensive novel technology yields substantial emission savings ( as is the case for electric cars mitigating the tailpipe NO X emissions of diesel cars ; see Fig . 5a ) . However , if costs and emissions of a novel technology are similar to those of the incumbent technology ( as is the case for plug - in hybrid diesel cars replacing conventional diesel cars in Fig . 4c and d , and 5 ) , the results may not be robust .	67863900	no
. Difference in Differences analysis . ( a ) Theory . Establishing parallel trends ( ) and the differential effects ( ) of an intervention on two groups . b ) Data and results . The values from our data , through which we established the effect of mask mandates on paranoia .	236473395	no
We examined several ways to simulate effects of age - related declines in inhibitory mechanisms in the model ( Figure 4C , panels 1 - 4 ) . First , we modified the reuptake rate to be lower ( based on less alpha2A inhibition of NE release ) . This change had no effect on the greater excitation of high salience units under arousal but abolished the inhibitory effect of arousal on low salience units . Moderate GABA impairment also eliminated the inhibition of low salience units under arousal . Combining both of these impairments in one model or making the GABA impairment more extreme led to indiscriminate excitation of units regardless of their salience ( Figure 4C , panels 3 - 4 ) . In summary , these models indicate that impairment of basic inhibitory mechanisms , whether due to decreased function in either GABA or alpha2A receptors or both , could reduce how much arousal inhibits low salience items without affecting how much arousal excites high salience items , as shown in our fMRI data ( Figure 3C ) .	13684714	maybe
Janicka et al . [ 31 ] use double n - type symmetric supercells and find that the charge density profile of the electron gas follows an exponential decay , e âz / Î´ ( where the first TiO 2 layer is at z = 0 and the SrTiO 3 substrate is on the z > 0 side ) . Fitting to DFT data , they obtain Î´ â 1 nm . Due to the imposed symmetry , the geometry used by Janicka et al . [ 31 ] contains five SrTiO 3 unit cells of substrate ( â¼ 2 nm ) . In our work [ 32 ] , we use a stoichiometric n - type interface in a supercell with 11 u.c . of SrTiO 3 , and we find that the conduction electron density profile decays rapidly for the first few unit cells away from the interface , but has a longer , non - exponential tail further into the substrate . Son et al . [ 34 ] have performed the largest simulations to date with 15 to 30 u.c . of SrTiO 3 and also find exponential decay close to the interface that turns into an algebraic decay further into the substrate ( see Fig .    5 of that work ) . Specifically , their calculations show that within 4 nm of the interface , the charge density decays exponentially with Î´ = 1.84 nm . Further into the SrTiO 3 substrate , the charge density profile is found to decay more slowly with the approximate form b/(zâz 0 ) .	28365113	no
A. Testing model performance based on climate data input CFTW was further tested for climate data uncertainty . The model is based on the global climate dataset ERA Interim , which has been evaluated independently in several studies ( Gao , 2013;Thiemig et al . , 2012;Zhang et al . , 2016 ) . This section provides an analysis of model results based on field data input at crop fields and ERA Interim input .	146803893	yes
"There are also higher variances in the sO 2 results within each individual blood vessel obtained by LSF than by DSL , particularly in Fig . 6 g , i. These results clearly indicate the superior robustness and resilience of DSL to variations in experimental conditions and within vessels . Importantly , our DSL models enable direct visualization of the "" en face "" uncertainty maps of the sO 2 predictions in Fig . 7 . The FNN and CNN have similar uncertainty estimations on the sO 2 predictions ( Fig . 7a - f ) , consistent with the previous characterization of Ï at~5 - 7 % ( Fig . 4 ) . Under hypoxia , the sO 2 estimation appears to be inconsistent at the periphery , as indicated by the black arrows in Fig . 6a , d. We attribute this to the extremely poor signal levels at those regions where severe vignetting was present in the raw data ( Fig . S5 ) ."	181990850	maybe
Beyond the differences in metrics across phases , we also discuss some general differences between traditional incumbents and new digital entrants . Specifically , we observe that many traditional incumbents stick to profitability as a financial metric , while many digital firms focus on growth figures ( e.g. , growth in number of users , customers , and sales ) instead of profitability . The primary objective of many digital firms is to achieve growth in the sheer number of users of the digital ecosystem ( e.g. , suppliers , customers , third parties ) to create reinforcing network effects that enable further platform growth . A fastgrowing customer base allows them to accumulate valuable data at scale , which can be leveraged both internally ( within the firm ) , and externally ( selling services to external partners , attaining legitimacy among investors ) . As long as shareholders expect that the firm is able to capitalize on their growing user bases , they are willing to accept ( shortterm ) losses in return for growth .	211424645	no
Despite these advances , the fidelity and quantification of SR - SIM are often challenged 12,13 because the final SR images heavily rely on post - processing algorithms that are prone to reconstruction artifacts 8,14,15 . To acquire SIM images with minimal artifacts , dedicated practical guidelines were recommended for instrument refinement 16 , data acquisition 17,18 , and sample preparation 18,19 . Several studies have been conducted on reconstruction algorithms , including accurate illumination parameter estimation [ 20][21][22][23][24 ] , iterative deconvolution 8,25,26 , and fine tuning of reconstruction parameters 27 . Despite all these efforts , artifacts that limit the implementation of SIM as a daily imaging tool still frequently appear in SIM images . In particular , new structures discovered using SR - SIM need to be interpreted with special care to avoid misinterpretation . Recently , deep learning has shown great potential for SR - SIM reconstruction 28,29 , but the results are closely related to SR images obtained via other methods for training neural network , thus the fidelity is still questioned .	232486236	no
It is worth noting that all our findings are based on variables calculated on data that reflect the business models and work practices established before the pandemic . Further , the INAIL measure of the risk of contagion is based on the features of occupations measured before the COVID-19 outbreak . This is perfectly in line with our attempt of assessing the impact of robotization on worker density and the associated risk of workplace contagion before the spread of COVID-19 . Referring to a more recent period would be both difficult and potentially dangerous . First of all , at the time of writing , there are no recent data available for all the variables . More importantly , however , using recent data would weaken the empirical estimation of the risk-    16 - 18 , 19 , 20 - 21 , 24 - 25 , E , F ; and in List 2 for industries : 19 . Germany is the country at the frontier in List 1 for industries : 13 - 15 , 22 - 23 , 90 , A - B , P ; and in List 2 for industries : P. France is the country at the frontier in List 1 for industries : C. Japan is the country at the frontier in List 1 for industries : 91 ; and in List 2 for industries : 91 . South Korea is the country at the frontier in List 1 for industries : 26 , 27 , 28 , 29 - 30 ; and in List 2 for industries : 26 , 27 . Austria is the country at the frontier in List 2 for industries : F. Belgium is the country at the frontier in List 2 for industries : 29 - 30 . Denmark is the country at the frontier in List 2 for industries : 10 - 12 , 13 - 15 , 16 - 18 , 20 - 21 , 22 - 23 , E. Netherlands is the country at the frontier in List 2 for industries : 90 , A - B. Sweden is the country at the frontier in List 2 for industries : 24 - 25 , 28 , C. mitigation effects of robotization . If the conviction that robots may mitigate the risk of contagion has already created additional incentives for firms to increase the use of robots , this generates a serious reverse causality problem that is absent in analyses ( like ours ) using pre - COVID-19 data . Moreover , as both the epidemic and the conviction that robotization may help reduce the risk of contagion are global phenomena , the foreign stocks of robots might stop being good instruments because in the future all countries will increase robot adoption due to similar contagion - related concerns . Hence , the use of data from 2020 onwards may both lead to greater endogeneity issues due to reverse causality problems , and also invalidate the instrumental variables adopted in works based on data from the pre - COVID-19 period .	237473239	no
The motivation for realizing the value of transparency aligns with well - established reasons for increasing transparency in the context of traditional media organizations ( e.g. via newsroom blogs ) . Specifically , transparency was referenced as a key factor in convincing users of the relevance of new technical features . As one data scientist noted :	237282779	no
Our results show that focusing attention on an item within the spatial layout of working memory involves the brain 's oculomotor system , with consequences that can be traced all the way to the eyes , and that can predict subsequent performance benefits . These findings expand the attentional role of the oculomotor system to the internal space of memory and carry relevant implications for the study as well as our understanding of the neural mechanisms by which our brains flexibly prioritise information in memory to serve adaptive behaviour . van   In the domain of perception , the deployment of spatial attention has previously been shown to increase the propensity of small fixational gaze shifts ( microsaccades ) in the direction of covertly attended locations outside of current fixation27,28 that may be critical for attentional facilitation to occur29 . This has been interpreted as an inadvertent spillover effect17,27 from activating oculomotor brain areas ( such as the Frontal Eye Field and Superior Colliculus ) that are recruited for both spatial attention and gaze . In the context of perception , however , it remains possible that such gaze behaviour reflects the sub - threshold consequence of the urge to look at the attended ( or expected ) item when explicitly instructed not to do so . Here , we demonstrate a similar gaze bias within the context of visual working memory , where there was nothing to look at ( nor expected ) in the direction of the bias . These data therefore not only imply a role for the oculomotor system in focusing attention within the internal space of memory , but also show that such oculomotor engagement leaves peripheral traces ( 17 for discussion of such ' peripheral traces ' ) even when there is no incentive for them .	71144269	no
"Next , in Fig . 2 , we compare the distribution of Israel 's population and its total confirmed case count by each of the three neighborhood 7 In the Ministry of Health the field is called "" neighborhood name "" , while in the Points dataset , the field is called "" EZ_NAME "" . 8 A few neighborhoods were grouped by ministry of Health into aggregated observations ( apparently , due to medical secrecy reasons , since separately those neighborhoods had a small coronavirus cases ) . For these observations , Points data was also aggregated using the comprising neighborhoods ' populations as weights ."	245007305	maybe
There are a few studies dedicated to investigating Twitter sentiment fluctuation during the ongoing pandemic of COVID-19 . Rajput et al . ( 2020 ) present a statistical analysis of the word frequency and sentiments of individual Twitter messages related to COVID-19 posted since January 2020 . Including both Tweets posted by WHO and the general public , their study finds out that most of the Tweets show positive emotions , and only around 15 % exhibit negative polarity . In contrast to this result , Medford et al . ( 2020 ) utilize high - volume Twitter data from January 14th to 28th , 2020 to investigate public sentiments for the COVID-19 outbreak , concluding that around 49.5 % of all Tweets expressed fear and around 30 % expressed surprise . They also find out that the number of negative Tweets increased as the cases of coronavirus surged . Some scholars have also conducted comparative studies of different countries ' response to the COVID-19 . For instance , Dubey ( 2020 ) collected Tweets related to coronavirus from March 11 to March 31 , 2020 from over ten countries . He suggests that people in France , Switzerland , Netherland , and USA expressed greater distrust and anger compared to other countries such as Italy , Spain , and Belgium . Sentiment analysis can be further combined with topic modeling for a more detailed analysis . Xue et al . ( 2020 ) firstly use the National Research Council of Canada Word - Emotion Association Lexicon , which is a list of English words and their associations with emotions , to assign Tweet sentiment by counting the number of words belonging to each emotion category . Then , they apply the Latent Dirichlet Allocation to understand the popular bigrams and sentiments of Tweets . Nevertheless , most of the research around Tweet sentiment change during coronavirus follows statistical methods , or uses the NRC implementation , and not many studies have concentrated on city - level comparisons .	236251116	no
To establish and investigate the functional hierarchical organization of whole - brain activity , we first need to characterize how different brain regions communicate with each other , that is , to compute the directed flow between regions . We characterize the functional interaction between two brain regions , in a given parcellation , by an information - theoretical statistical criterion that allows us to infer the underlying bidirectional reciprocal communication . The NDTE framework was inspired by the work of Brovelli and colleagues , who used and validated a similar transfer entropy framework for neuroimaging data 25 . This framework uses a Gaussian approximation , that is , only second - order statistics of the involved entropies , which means , as shown below , that instead of estimating the probabilities , the method estimates the covariance , which massively facilitates computation . Finally , as also outlined below , we add four key elements to this powerful framework : normalization , multiple timepoints in the past , circular surrogates and aggregation of P values to improve the reliability and robustness of the NDTE framework .	230509029	no
Whilst data is a valuable asset for cities , its collection and processing methods , ownership regime and the purpose of their use raise serious ethical issues , which must be addressed by the SC stakeholders ( e.g. , policy makers , researchers , companies and utilities , etc . ) ( Bianchini and Avila , 2014;Cobb , 2016;Kitchin , 2016 ) . In several cases , the collected data for public benefit was , ultimately , exploited by both public and private organizations for their own purposes ( e.g. , mass control , market dominance , dataveillance , etc . ) , violating the privacy rights of individuals and overshadowing the vision of SC ( Bianchini and Avila , 2014;Cobb , 2016;Greenfield , 2013;Kitchin , 2014;Kitchin , 2016;Townsend , 2013 ) . Excessive zeal and efforts to record and monitor activities within cities , and vulnerabilities of ICT infrastructures have raised numerous security and privacy concerns , and in many cases have annoyed citizens ( Elmaghraby and Losavio , 2014;Zoonen , 2016 ) . Critics argue that the implementation of SC will have negative implications on individuals ' freedom and privacy as they trade off the convenience offered by smart services with the provision of sensitive and personal information ( Ahmed et al . , 2014 ) . Hence , these privacy and ethical issues have a negative impact on the involvement of citizens in SC development , as they feel they are constantly being monitored and their fears about privacy and security are emerging ( Zoonen , 2016;Kirby , 2014 ) .	158903122	no
We collected primary data from the cocoa growers , who were very knowledgeable about the issues at stake . The respondents were either farm owners or farm managers serving as key informants . We based the sampling on farms located in the southern part of Ghana according to the knowledge of the industry regulator . Approval was sought from each informant before each interview . Subsequently , primary data were collected through face - to - face interviews . In most developing and some emerging countries , data collection through mail or email leads to low response rates - hence the need for some other innovative means of data collection through household interviews . The lead author conducted the interviews for study 1 over a period of two weeks and for study 2 a year later for a period of five weeks in the cocoa - growing regions of Central , Eastern , and Ashanti regions of Ghana . The respondents were mostly farm owners who were interviewed in their houses ( sometimes with a farm manager providing corroborative information ) . Study 1 consisted of 105 respondents while study 2 consisted of 444 respondents .	232294507	maybe
The general capacity of human memory has dramatically increased with the help of information and communication technologies . People hardly forget the moments of their lives that are recorded and stored digitally , thereby shifting the perception of memory from being volatile to durable . However , as remembering has become the new standard , it has created opposite needs for memory , namely , to be forgotten ( Mayer - SchÃ¶nberger 2011 ) . Large collections of an individual 's data encompassing communications , shopping , media consumption , and social networks can unravel a mysterious being into rows of personal data ( Richards and King 2013 ) . Individuals have begun to develop a desire for forgetting or being forgotten , as much as for memorizing , because of the potential privacy infringement caused by unforgotten personal data ( Cukier and Mayer - Schoenberger 2013 ) .	231744099	no
"Rather than thinking of gatekeeping and facilitating in terms of competing "" logics "" ( Lewis 2012 ) or some modern reincarnation of the Lippmann - Dewey debate ( Schudson 2008 ) , this article showed how the ongoing datafication of social life allows them to exist along a shared continuum and mutually reinforce each other . The overlap in practical skills and social imaginaries helped making journalism as a professional practice more permeable to outsiders and allowed actors outside the field of journalism to increasingly engage in practices traditionally attributed to journalism , as Rusbridger noted ( see introduction ) . At the same time , data journalists move closer to civil society actors like civic technologists and complement their work ."	149401418	no
Diffraction data were analyzed by XDS , [ 48 ] a software consisting of eight subroutines able to carry out the main data reduction steps ; the process of scaling and correction for absorption effects of the integrated intensities was performed by the XSCALE subroutine . [ 48 ] Structure solution was carried out by Direct Methods [ 49 ] using SIR2019 ; [ 50 ] the partial structure model provided by SIR2019 was completed and refined by SHELXL2014/7 . [ 51 ] All non - hydrogen atoms were refined anisotropically ; the H atoms were positioned via electron density map calculated by difference Fourier synthesis and their fractional coordinates were freely refined . The programs used to prepare material for publication were WinGX [ 52 ] and publCIF ; [ 53 ] the software Mercury [ 54 ] was applied for molecular graphics .	232078560	no
"In addition to daily downloads , our data set contains information on total revenues from downloads . We use these data to calculate the actual price of a paid app on a daily basis ( in cents ) and determine the regular 13 We assessed whether fixed - effects or random - effects correction would be appropriate to control for time invariant differences across applications using the Hausmann test . The results of this test suggested that the fixed - effects model is appropriate in our case . 14 With the help of a Chow test , we assessed whether we can pool the coefficients . The test result suggests estimating separate coefficients for free and paid apps ( F 77,357181 = 14.699 , p < .01 ) . 15 ' Featured List ' is a general term for all curated lists published by the platform . We observe 189 apps ( out of 979 ) featured in 180 different lists . Given the scattered nature of these lists and the low number of featured apps , we decided to classify these lists under top featured lists and other featured lists . The reasoning behind this distinction is that top featured lists are the main lists that are the easiest for users to notice , while others are not . Users are exposed to the top featured lists on the landing page and need to actively search for the other lists . ' Top Overall ' , ' New and Noteworthy ' , or ' Editor 's Choice ' are examples of top featured lists . Other featured lists include category specific or curated lists for special days ( e.g. , Mother 's Day Gift Guide , Apps for Graduates ) . 16 At the time of data collection , Apple App Store top apps charts rolled on a continuous scrolling basis where each screen contained five apps . Therefore , we separated the effect of being visible on the first page ( referred to as ' above - thefold ' ) from that of the second page ( referred to as ' below - the - fold ' ) and the following pages ( referred to as ' below - the-2nd - fold ' ) We think 5 - page - views - byscrolling corresponding to the natural breakpoint at 25 provides us with a comprehensive list of top apps . 17 To illustrate the association between changes in version number digits and the nature of the updates consider an app with the following history : Version 2.3 "" Added History option "" . Version 2.4 "" Added a screenshot option . Now can save the picture in your iPad gallery any time you want . Find this option in game menu "" . Version 2.4.1 "" Updated ABOUT and HISTORY views "" . Version 3 "" Clear option for removing the packages and images , UI changes , New packages at the top of the list in selector , Ability to share packages to your friends ( email , FB , twitter ) , Ability to create own packages "" . The update from Version 2.4.1 to Version 3 is a major update , from Version 2.3 to Version 2.4 is an intermediate update , and from Version 2.4 to Version 2.4.1 is a minor update ."	226318002	maybe
More generally , big data governance incorporates policies , processes and institutions aimed at governing and managing data acquisition , usage / manipulation and storage across the entire lifecycle ( Sunil 2012;Tallon 2013 ) . Both statutory and self - regulatory approaches to governance are evident ( Bollier 2010;Sunil 2012;Celma et al . 2014).While statutory regulation ( e.g. country specific Data Protection Acts ) is often loosely defined around data usage ( Bollier 2010 ) , including aspects of privacy , self - regulation is often concerned with how data are organised and managed ( Cheng et al . 2013;Loshin 2013;Sunil 2012;Tallon 2013 ) including data security considerations .	254382149	no
To further explore the dynamics of charge carriers , perovskite films on various ETLs prepared on quartz substrates were investigated by nanosecond broadband transient absorption ( TA ) spectroscopy . 2D contour plots of the TA data are shown in Fig . 4i - k , and representative TA spectra at different delay times are presented in Fig .   4l - n. All TA spectra feature a negative signal of Gaussian shape around 750 nm . This band is consistent with published data and has been attributed to ground state bleaching ( GSB ) as a consequence of the population of band edge states by charge carriers 66,67 . We note that in the case of SnO 2 QDs , the GSB signal exhibits a smaller full width at half maximum ( FWHM ) . Since the GSB originates from charge filling of band edge states , its width is related to the charge distribution profile 67 . In fact , a narrower FWHM indicates less imperfections , such as defects or traps , which in turn leads to a higher V oc 68 . In addition , SnO 2 QDs / perovskite also exhibit a blue - shifted GSB ( ~3 nm ) compared to the other two samples . This is attributed to an optimized degree of order ( the same underlying mechanism leading to a narrower FWHM of GSB ) and accordingly the suppression of non - radiative centers , as revealed from the decay kinetics in Fig . 4o . Since the GSB originates from the population of bandedge states by charge carriers , investigating decay dynamics provides insight to the underlying charge recombination mechanisms . Here , we find that all decays can be described by single exponential functions with lifetimes of 112.3 Â± 2.5 , 227.3 Â± 2.5 , and 405.1 Â± 4.6 ns ,   respectively . In view of the proposed mechanism 69 , we thus assign the recombination to be of first - order . Considering the weak excitonic binding energy in these perovskite materials , we can further assign the first - order recombination to trap - assisted recombination , that is , Shockley - Read - Hall ( SRH ) recombination . Hence , the increased lifetime indicates that the trap density is the highest in the c - SnO 2 sample , and decreases in the commercial SnO 2 NPs sample , and is the lowest in the ligand - assisted SnO 2 QDs sample . The observation of a decreasing trap density implies that multifunctional terminal groups in the SnO 2 can effectively passivate the interface and improve the film quality , both of which contribute to the solar cell performance . These findings consistently explain the alleviated ( or negligible ) hysteresis and enhanced V OC in the SnO 2 QDs - based device , which are further supported by 2D GIWAXS patterns , ELQE , and spatial confocal PL microscopy as discussed above .	244803585	no
Researchers ( e.g. Dhir et al . , 2021;Kumar et al . , 2021 ) frequently utilise structural equation modelling ( SEM ) as a data analysis approach . However , the two types of SEM ( covariance - based , or CB - SEM , and variance - based , or VB - SEM ) have certain prerequisites related to data , as discussed in recent studies ( e.g. Luqman et al . , 2021 ) . For instance , CB - SEM has certain sample size requirements . In addition , the sample must not include outliers , and the data should be linear , normally distributed , homoscedastic and free from multicollinearity . While VB-   SEM has more relaxed sample - related requirements , it also requires the data to be linear and possess other multivariate characteristics ( Hew et al . , 2019;Talwar , Talwar , Tarjanne et al . , 2021 ) . Consequently , scholars suggest using an ANN approach for data that exhibit both linear and non - linear associations and deviate from other multivariate characteristics mentioned above ( e.g. Leong et al . , 2020 ; . ANN is an artificial intelligence and machine - learning based approach that uses input , hidden and output neurons to generate output in terms of the influence of antecedents on outcome variables . The network of neurons is trained with new information to conduct analysis and generate output . The training process is driven by a two - way ( i.e. forward and backward ) information flow . Multiple rounds of the training process help to minimise errors . In the current study , we applied ANN by dividing the available data into training and testing data to generate output in terms of the relative importance of each proposed antecedent . We used the root mean square error ( RMSE ) values of various models to evaluate the accuracy of the predictions .	245008959	no
"Notwithstanding some important differences , especially concerning the modal nature of HÃ¤ggqvist 's account and the non - modal character of my structure , several similarities exist between our accounts . Both identify the main function of many TEs as inconsistency revealers ( however , notice in ( Î± ) conclusions 5 and 6 are not separated ) . Both are pluralist relative to the cognitive processes . 22 We both reject the ET in its strong reading ( cf . HÃ¤ggqvist 2009 , p. 75 , ft . 48 . HÃ¤ggqvist 22 "" consider the mechanisms resulting in belief in premises of an argument instantiating ( Î± ) when a thought experiment is performed . These may draw on all sorts of cognitive resources : theoretical and other belief , memory , inference , genetically inherited modal expectations , folk physics , and so on . If Nersessian and others are right , they may involve manipulation of mental models . If Brown is right , they may include special faculties of intellectual Schauung . If David Chalmers , Frank Jackson , and an earlier time slice of Stephen Yablo are right , modal claims such as the premises of a regimented thought experiment may be justified by appeal to conceivability . "" p. 72 . however seems to be also rejecting the weaker reading ) . Both accounts "" seem vaguely Popperian in [ their ] emphasis on counterinstances to the target thesis "" . However , and I agree that "" it is a fact that this is what thought experimenters are typically in the business of trying to construct . And this is , in turn , only to be expected . Confirmation is a tricky notion in the best of settings , "" ( p. 64 ) . Indeed , theory choice and confirmation are already tricky , even when new empirical data are generated . As we saw above in Patton 's context of pursuit . When dealing with armchair inquiry - which , by definition , do not produce any new empirical datait is hard , at least for an empiricist , to see how TEs could justify new laws of nature or unambiguously decide in favour of one theory and against another ."	233909749	no
This study used the Gini coefficient to explore the equality of access to food stores in Taipei City ( Figure 4 ) . In the first step , we performed the geocoding and visualization of supermarkets , hypermarkets , and traditional markets using open data .	256000608	no
Currently , the sentiment analysis of Tweets related to COVID-19 has mainly focused on identifying specific emotions ( e.g. , angry , fear , anxiety , etc . ) and top topics . However , not much study has dedicated to investigating the correlations between Tweet sentiment , public health policies and the on - going progress of COVID-19 . Moreover , machine learning methods are not widely used for sentiment analysis in these studies . Our study combined the benefits of Twitter data and machine learning methods - being real - time and of large scale , and thus more accurate , and carried out a correlation study that gave researchers quantified insights into the specific factors that triggered Tweet sentiment changes . Furthermore , most of the existing studies focus on providing an overview of public sentiment change across the globe or concentrate on country - level investigation . Our study seeks to provide a city - level analysis that could be more helpful for local governments to implement policy interventions that take the context of each city into consideration .	236251116	no
We generated bibliometric network data using bibliographic coupling ( Kessler , 1963 ) , where articles are the network nodes and the strength of the link between two articles is determined by the number of cited references that the two articles have in common . The underlying idea is that two articles that share many references are rooted in the same theoretical traditions , share a common perspective , and use similar key concepts . Bibliographic coupling yields a measure for the relatedness of two articles that does not rely on shared terminology . The latter is important given the lack of shared terminology within the literature that studies market innovation . Bibliographic coupling has been used in similar bibliometric mapping studies aimed at identifying research streams related to a specific phenomenon ( e.g. , Van der Have and Rubalcaba , 2016 ) .	225133234	no
"All batteries , by their very nature , degrade with time , so understanding which factors are dominant in this ageing process is critical for developing solutions targeting long cycling lives . Information collected by internal sensors [ 117 ] and sent by optical fibers or Wi - Fi will be used to predict / identify malfunctions , and eventually employ internally injected "" cure solutions "" to regain optimal battery operations . Among the internal parameters of the battery to be monitored during LSF experiments , we can identify three main families : those with safety implications ( e.g. , the detection of gas accumulation inside the cell ) , those linked to the battery lifetime ( temperature and pressure , Li concentration ) , and finally , a beam damage indicator for synchrotron X - rays ( a combination of temperature and pressure could be implemented ) . To date , the few studies reporting on internal sensors and optical fibers describe systems which monitor local temperature fluctuation , but with no additional data sensor . Many other important parameters , taken from the above mentioned three categories , could be monitored at beamlines during operando measurements . For example , pressure sensors could be implemented in solid - state batteries , although care must be taken on correctly disposing sensors within the cell . In general , the internal positioning of an optical fiber/ sensor may cause several physical modifications to the cell , leading to possible variations in local electrochemical response . Sensors placed to capture electrochemical activity transparently will therefore need to be developed . For instance , using the existing current collector , tuned to give additional information about local temperature , pH , pressure , Li concentration , and more , is a promising possible solution for internal , non - intrusive , multi - parameter monitoring . The development of such self - monitoring cells for experimental , and ultimately commercial purposes , coupled with suitably built - in , chemical curation mechanisms activated by the "" intelligent "" battery , will involve long - term , international cooperative projects , but nevertheless presents an obtainable vision of the technology 's future ."	245156434	no
We also measured the PEC cell as a photoanode and provide an overlay with a Pt cathode of the best performing cell ( see Figure S6 , Supporting Information , schematic setup in Figure S7 , Supporting Information ) . The crossover point gives the same result as in Figure 2B , however a photo - anode is less comparable to a PV cell as was used in the analyses above . Furthermore , the current density output in the plateau region corresponds very well to the current density in Figure 2B , therefore the interference of the water layer in front of the PEC cell is most likely low , as discussed above . We assessed the long - term PEC performance of the device ( Figure 2C ) , and tested the hydrogen production by means of gas chromatography ( Figure 2D ) , for the sample with the optimal f c of 5 % . The gas production corresponds well with the observed current density of 5.7 mA cm â2 ( theoretical line in Figure 2D ) . During long - term PEC performance of the device , we monitored the open circuit potential of the anode versus a reference electrode ( Figure 2C ) . In this fully integrated PEC cell it is not possible to directly measure the produced current density which flows through the cell . The PEC cell was tested under day - night cycles of 8 h light on and 16 h light off , thus mimicking the intermittency of the sun , see Figure 2C. Under illumination , the potential of the anode corresponded well to the potential of < 1.6 V of the operating point , as depicted in Figure 2B. Upon switching the light off , the potential of the anode dropped to â1.2 V. This corresponds well to the open circuit potential of dissolved O 2 and H 2 gasses in contact with their respective metallic electrodes within the cell at the anode and cathode . Most importantly , the data in Figure 2C indicates that prolonged activity of the device over a month is possible without noticeable degradation . Hereafter , we tested again ( Figure 2D ) the gas production of the PEC cell , which still agrees well with the theoretical line of 5.7 mA cm â2 . An overall STH efficiency of 7 % was obtained for the stand - alone device .	132976355	maybe
Another audience - centred value related to privacy and data protection is user agency and autonomy . Intrinsically associated with the debate about the relationship between journalism and its audience , this value is related to attributing a more active role in news consumption ( but also news production ) to the audience , by contrast with a view that treats readers as passive recipients of information provided by journalists ( Van Dijck 2009;Milioni , Vadratsikas , and Papa 2012 ) . On the practical level , user agency usually deals with the broadening of users ' engagement with content by giving them more possibilities to express their opinion about it , but also potentially includes enabling more options for selecting what news to read or even influencing its production by the outlet . The effects of ANR deployment on user agency remain an open question ; on the one hand , personalized news delivery based on individual preferences increases agency , but at the same time the limited ability of users to control ANRs can diminish it ( Monzer et al . 2020 ) . Furthermore , the relationship between freedom of expression and the right to receive information is also important in the context of ANR deployment ( Balkin 2004;Eskens , Helberger , and Moeller 2017;Helberger , Karppinen , and D'Acunto 2018 ) .	237282779	no
Ontology for data and hardware related resources and infrastructure .	245111008	no
Due to its broadband response ( Fig . S11 ) , in principle , our proposed transmission dielectric metasurface platform can be designed to generate full - color holograph by leveraging sensitivity of higher order diffraction in metasurface to wavelength and angle 49 . Another alternative approach would be to design a metasurface with spatial multiplexed superpixels , where each superpixel consists of nanopillars that offer multilevel phases for each of the R , G , and B component , enabling realization of polarizationdependent full - color nanoprinting and holograph display . We envision this work to inspire creation of ultracompact flat - profile nanophotonic platforms , and provide new avenues for applications in polarization optics , information security , optical data storage , and multifunctional photonics .	235190837	no
"Some limitations to the current study need to be mentioned . While our corpus aimed to gather a diverse range of professional and academic perspectives , it is inevitable that multiple aspects of personalization were omitted and many questions remained unanswered . Specifically , our findings are confined to documents using the terms "" news personalisation "" and "" filter bubble , "" whereas the discussion of personalization in post - Soviet states also deals with other subjects , varying from more academic ones ( e.g. , echo chambers and selective exposure ) to more industrial ones ( e.g. , specific types of recommender systems and concrete distribution mechanisms ) . Besides varying vocabulary , the lack of a single platform for data collection resulted in corpus imbalance that favoured academic and ( Russian ) IT communities for which we located platforms aggregating a large volume of relevant documents , whereas the more dispersed nature of journalistic platforms resulted in less data retrieved . Furthermore , the use of a single coder analysing documents in all three languages leaves some space for individual bias which might result in occasional misinterpretation on the level of individual documents ( in particular , when attributing them to specific aspects of innovation diffusion ) ."	239186570	no
"The life cycle impact assessment method IMPACT World+ ( IW+ ) v1.30 - 1.48 was selected as it was deemed the most scientifically up - to - date and relevant method for Canada ( Bulle et al . , 2019 ( also called Global Warming Potential ( GWP ) ) , freshwater acidification , eutrophication and ecotoxicity , marine eutrophication , ozone layer depletion , particulate matter ( PM ) formation , photochemical oxidant formation , terrestrial acidification , carcinogenic and non - carcinogenic human toxicity resp . "" cancer "" and "" non - cancer "" ) . As for the endpoint indicators , the damage to ecosystem quality and human health are considered . Both the long - and short - term effects of climate change on these damages are considered in IW+ . Due to the lack of available national data , some IW+ indicators were not considered , such as ionizing radiations , resources ( mineral and fossil ) , land transformation and occupation , as well as water scarcity . Nevertheless , an indicator of water use was calculated , using the data reported by Statistics Canada ( n.d . ) . Water use only accounts for withdrawn water and not released water . It is therefore different from water consumption indicators , which consist of the difference between withdrawn and released water ."	255847212	no
As we have described , battery interface research is a particularly complex domain but has nevertheless seen major progress in the past few years regarding advanced characterizations techniques , simulations / modeling capabilities as well as the application of robotic , high - throughput screening . However , only by intimately meshing these diverse fields will we be able to stimulate the cross - fertilization needed to generate new insights . Towards the goal of combining techniques to unleash the creativity of chemists and engineers in order to solve technologyrelevant interfacial phenomena , large - scale research initiatives such as BATTERY 2030 + are uniquely positioned . [ 217 ] Indeed , they offer an unprecedented opportunity to bring together battery specialists with physicists , data scientists , and engineers , with the common objective of fostering novel approaches fundamental to mastering battery interfaces . Evidently , no single research entity currently gathers all the required competencies at the highest level and , rather than competing in a sterile manner , large research consortiums allow for the consolidation of previously disparate knowledge , thus providing shared tools needed for researchers to thrive and express their creativity . To develop such a transformative approach , an initial maturation step is crucially required , during which the scientific infrastructure is created and benchmarked on the next generation of Li - ion batteries , for which the bottlenecks have been clearly identified ( e.g. , stabilization of Si - containing anode materials and high - potential/ high - capacity Ni - rich and/or Mn - rich layered oxides ) . More problematic and challenging chemistries such as Na - ion , multivalent chemistries , Li - S , solid state or aqueous batteries will then benefit from the development of chemistry - agnostic tools and their integration into a systematic , combinatorial approach . Toward this end , community - wide efforts in which data - driven science serves as a guideline for chemists to develop novel electrolytes or active materials are critical . However , the development of these tools and their inter - communications through an automated workflow can only be achieved by the use of an agreed , community - wide lexicon . The definition and adoption of this so - called ontology - extensively described in a parallel perspective [ 54 ] will thus hold the key to unlocking a fully efficient data transfer synergy between electrochemical testing , characterization , and simulations groups . In conclusion , we foresee a leap forward in our understanding and control over battery interfaces through the use of approaches and techniques such as those described in this perspective , which together represents a necessary departure from our traditional way to approach such complex issues .	245338204	no
I proceed with arguing that it is also practically infeasible to determine the exact degree of interest alignment and competence . The fundamental reason is statistical in nature : the observable data at most allow for the formulation of a degree of confidence in certain values , but do not allow for full certainty . The reason regarding logical indiscernibility above is more severe in that the given observable data do not allow the layperson to distinguish between several scenarios at all . There is no degree of confidence that distinguishes the scenarios discussed above .	235086494	no
The third example may be classified as problematic since it refers to a case in which the management of coordination can be optimized . The example refers to the many research entities , scientific bodies and private organizations which have worked worldwide to finalize and distribute a vaccine for the coronavirus . In such case , the existence of competitive dynamics can bring to partially un - coordinated efforts which may delay the development and global diffusion of the drug . Whereas the finalization and distribution of the vaccine should be a collaborative effort based on experience integration ( fit ) , the partial communication of information on the diffusion of the virus and the lack of data on medical experimentations , can hinder the synergic effort aimed to generate an effective and safe drug for the global population .	231729512	no
Although quantitative research gathers and analyses data using statistical techniques to test a hypothesis , qualitative research seeks to describe , interpret , or develop a theory or conceptual framework around events ( Creswell et al . , 2007 ) . As a result , we used the principal concept of resource orchestration , which was recently proposed to address previously overlooked mechanisms by which international managers can collect , integrate , and leverage resources to support available opportunities and explore potential opportunities to boost the firm 's competitive advantage ( Baert et al . , 2016 ; . Resource orchestration theory contributes to changing the existing international marketing communication method by structuring , utilizing , and leveraging resources and capabilities during COVID-19 ( Barney & Arikan , 2005;Barney et al . , 2011;Barney , Wright , & Ketchen , 2001;Carnes et al . , 2017 ) . The theoretical constructs include information technology resources , capabilities , dynamic capabilities , and environmental uncertainty , which were examined through a series of interview questions .	255566595	no
While repeated volume variations giving rise to a loss of active material is a frequently proposed explanation , this explanation appears unlikely as nanoparticles are known to be able to handle volume expansion effects without breaking . [ 12 ] Previous scanning electron microscopy ( SEM ) investigations of cycled silicon electrodes have likewise failed to detect any significant cracking of the composite electrode or loss of the active material . [ 24 ] It is also not clear why volume expansion effects would give rise to the diffusion - controlled capacity loss effect described in Section 2.2 , especially as the influence of the volume expansion effects should have been very small during the open circuit pauses used in this experiment . The experimental data discussed in Section 2.1 are likewise difficult to explain based on the volume expansion hypothesis as different results were obtained with the same type of silicon electrodes using two different cycling protocols only differing with respect to an additional controlled voltage delithiation step applied on every 10th cycle . The HAXPES results also indicate that no highly lithiated phases remained in the surface region of the electrode after the delithiation step , which could suggest that parts of the electrode material had been made electrochemically inactive during the cycling . Due to abovementioned points , it can be concluded that a loss of active material due to volume expansion effects is very unlikely to be the main reason for the observed capacity losses .	199648051	no
The relationships between perceived neighborhood factors and physical activity of 1623 adults aged 20 to 97 years in King County/ Seattle were examined by Shigematsu et al . ( 2009 ) . They used the validated International Physical Activity Questionnaire and the validated Neighborhood Environment Walkability Scale questionnaire . The results showed that walking was significantly related to almost all neighborhood environment variables ( residential density , proximity to nonresidential land uses , ease of access to nonresidential uses , street connectivity , walking / cycling facilities , aesthetics , pedestrian traffic safety , crime safety , and proximity to recreation facilities ) in the younger people . However , for older people , only proximity to nonresidential uses and recreation facilities were correlated with walking ( Shigematsu et al . , 2009 ) . Troped et al . ( 2011 ) to examine associations between the perceived built environment and physical activity in U.S. women used logistic regression and data from Nurses ' Health Study II in 2005 . Their findings indicated that perceived proximity to shops / stores and access to recreation facilities were important correlates of physical activity for women , irrespective of region or sprawl ( Troped et al . , 2011 ) . Relationships of perceived neighborhood attribute with transport - related cycling and walking in three countries ( USA ( Baltimore and Seattle ) , Australia ( Adelaide ) and Belgium ( Ghent ) ) , with the Neighborhood Environmental Walkability Scale and the International Physical Activity Questionnaire , were examined by Van Dyck et al . ( 2012 ) . Their finding revealed that Proximity to destinations , good walking and cycling facilities , perceiving difficulties in parking near local shopping areas , and perceived aesthetics were positively related to cycling . Besides , perceived residential density , land use mix access , proximity of destinations , and aesthetics were related to walking ( Van Dyck et al . , 2012 ) . Ma and Dill ( 2015 ) by binary logit and linear regression models , examined the relationships between the objective environment ( bikefriendly infrastructure , street connectivity , and accessibility ) , perceived environment ( safety , accessibility , and easy ) , and bicycling behavior based on data from a random phone survey conducted in the Portland , Oregon . Results of their study showed that the perceived environment and objective environment had different associations with bicycling ( Ma & Dill , 2015 ) . JÃ¡uregui et al . ( 2016 ) showed that access to parks , aesthetics , and safety from crime had effects on physical activity among Mexican adults . They used multiple regression models to estimate the association between perceived environmental variables and total moderate to vigorous physical activity ( MVPA ) ; based on 629 data from a population - based study , which was conducted in Cuernavaca , Mexico , in 2011 ( JÃ¡uregui et al . , 2016 ) .	236256030	no
"Despite the divergent views on the best way to integrate transparency into ANR designs , including doubts as to whether users are actually interested in having information about ANR functionality , most interviewees noted that this value is important in the context of individualized news delivery . As one Dutch data scientist observed , the need for transparency is also a transitional phenomenon that is of particular relevance today because the use of ANR is still a rather novel development . By contrast , in the future personalization is expected to be more common and "" everyone will be used to everything being personalized . Then I do not think that it will be very important to explain it per se , because people will have a different state of mind . "" This also creates new responsibilities for the media , however , as a project manager emphasized when observing that , "" In this moment of truth , in which you actually give to us the most valuable thing you have on the Internet [ your data ] , we take that seriously . """	237282779	no
Hemolysis assay was carried out to measure the hemolytic toxicity of the compounds . The results showed , in general , all three compounds had no obvious hemolytic effect ( less than 3.6 % ) at a concentration of 10 Î¼M. Among the three compounds , compound 6 had the lowest hemolysis rate , followed by compound 5 , and compound 4 ( Fig . 4a ) . BC and BB showed slightly higher hemolysis at concentrations of 10 Î¼M ( about 7 % ) . The cytotoxicity of the compounds toward mammalian cells PC12 ( a neuronal cell line ) was also measured by the CCK-8 ( Cell Counting Kit-8 ) assay . It was clear that BC and BB were more toxic than compounds 4 ,    5 and 6 ( Fig . 4b and c ) . The cell survival rates of all three compounds ( 10 Î¼M ) were above 90 % , while the cell survival rates of BC and BB at the same concentrations were only about 40 % . This data indicates that the three compounds had low toxicity to normal mammalian cells .	252843568	no
Here , the ranges of x and y are limited to the size of the pupil of the measured metalens , Ï metalens ( x , y , Î» , f ) is the measured phase distribution , and Ï ideal ( x , y , Î» , f'â² ) is the ideal phase distribution inside the pupil for an ideal lens with focal length f'â². When the focal length of the ideal lens is set to be the same as that of the measured lens , f'â² = f , the wave aberration will be minimal . When f'â² â  f , there will be a defocus aberration . By minimising the defocus aberration , the focal length of the measured metalenses can be obtained ( details are shown in Supplementary Information S10 and S11 ) . Based on this method , the actual focal length values of the metalens under multiple wavelengths of incident light are analysed . Figure 3a shows the actual focal length of the measured PB - metalens as a function of the incident light wavelength . The measured focal length of the PR - metalens has   Fig . 3b . These results reflect that chromatic metalenses have a negative chromatic aberration effect . Compared with the common light - field scanning method to obtain the focal length , this method has the following advantages . ( 1 ) Light - field scanning requires capture of a series of photographs for each depth in the direction of the optical axis . This method only requires one photo of the interference pattern to be taken , which greatly saves time . ( 2 ) The focal length measurement by light - field scanning can only obtain the light - field intensity distribution . The accuracy of determining the focal position is affected by the performance of the optical components , the collimation of the optical path and the nominal NA of the metalens ( this will be discussed in detail later ) . Using the II - PMS , additional aberrations caused by the optical components are removed , and only the phase distribution provided by the metalens itself is retained . ( 3 ) When the measured focal length deviates from the designed focal length , the lightfield scanning method can not provide enough data to analyse the cause of this result . The II - PMS can obtain the phase difference between the fabricated sample and the design , indicating the physical reasons for the focal length deviation .	232172741	no
The relationships between perceived neighborhood factors and physical activity of 1623 adults aged 20 to 97 years in King County/ Seattle were examined by Shigematsu et al . ( 2009 ) . They used the validated International Physical Activity Questionnaire and the validated Neighborhood Environment Walkability Scale questionnaire . The results showed that walking was significantly related to almost all neighborhood environment variables ( residential density , proximity to nonresidential land uses , ease of access to nonresidential uses , street connectivity , walking / cycling facilities , aesthetics , pedestrian traffic safety , crime safety , and proximity to recreation facilities ) in the younger people . However , for older people , only proximity to nonresidential uses and recreation facilities were correlated with walking ( Shigematsu et al . , 2009 ) . Troped et al . ( 2011 ) to examine associations between the perceived built environment and physical activity in U.S. women used logistic regression and data from Nurses ' Health Study II in 2005 . Their findings indicated that perceived proximity to shops / stores and access to recreation facilities were important correlates of physical activity for women , irrespective of region or sprawl ( Troped et al . , 2011 ) . Relationships of perceived neighborhood attribute with transport - related cycling and walking in three countries ( USA ( Baltimore and Seattle ) , Australia ( Adelaide ) and Belgium ( Ghent ) ) , with the Neighborhood Environmental Walkability Scale and the International Physical Activity Questionnaire , were examined by Van Dyck et al . ( 2012 ) . Their finding revealed that Proximity to destinations , good walking and cycling facilities , perceiving difficulties in parking near local shopping areas , and perceived aesthetics were positively related to cycling . Besides , perceived residential density , land use mix access , proximity of destinations , and aesthetics were related to walking ( Van Dyck et al . , 2012 ) . Ma and Dill ( 2015 ) by binary logit and linear regression models , examined the relationships between the objective environment ( bikefriendly infrastructure , street connectivity , and accessibility ) , perceived environment ( safety , accessibility , and easy ) , and bicycling behavior based on data from a random phone survey conducted in the Portland , Oregon . Results of their study showed that the perceived environment and objective environment had different associations with bicycling ( Ma & Dill , 2015 ) . JÃ¡uregui et al . ( 2016 ) showed that access to parks , aesthetics , and safety from crime had effects on physical activity among Mexican adults . They used multiple regression models to estimate the association between perceived environmental variables and total moderate to vigorous physical activity ( MVPA ) ; based on 629 data from a population - based study , which was conducted in Cuernavaca , Mexico , in 2011 ( JÃ¡uregui et al . , 2016 ) .	236256030	no
More precisely , the EC proposal for a Directive sets out as material scope : personal data ( Art 16 TFEU ) , customs cooperation ( Art 33 TFEU ) , agricultural policy ( Art 43 TFEU ) , freedom of establishment ( Art 50 TFEU ) , recognition of diplomas and other formal qualifications ( Art 53(1 ) TFEU ) , transport policy and safety ( Art 91 TFEU ) , transport by rail , road , and inland waterway ( Art 100 TFEU ) , State aid ( Art 109 TFEU ) , internal market ( Art 114 TFEU ) , health ( Art 168 TFEU ) , consumer protection ( Art 169 TFEU ) , tariff ( Art 207 TFEU ) , combatting fraud ( Art 325 TFEU ) . That means that disclosures about wrongdoing relating to any of these could be regarded as ' public interest ' and thus protected disclosures .	233783689	no
Both NO 2 and PM 2.5 are the most anthropogenic activities sensitive pollutants in the atmosphere . It is well established that NO 2 is a traffic emissions tracer pollutant in the lower atmosphere ( He et al . , 2020 ) . Some of the previous studies reported the percentage reduction of NO 2 and PM 2.5 over Europe and the USA , including the south and south - east Asia ( SSEA ) and the middle east ( Bauwens et al . , 2020;Broomandi et al . , 2020;Dantas et al . , 2020;Menut et al . , 2020;Siciliano et al . , 2020;TobÃ­as et al . , 2020;Zalakeviciute et al . , 2020 ) . The present study examined the relative changes of tropospheric NO 2 concentration from hemispheric scale to pollution hotspot cities . The cities were selected based on the lockdown 's intensity ( partial to complete lockdown ) . Over Europe and the USA , there are some cities where lockdown was partially practiced and in some cases , the lockdown was n't implemented . The study aimed to find out the changes of NO 2 and PM 2.5 concentration between complete lockdown , partial lockdown , and no - lockdown cities . A comparison between NO 2 and PM 2.5 changes in these three categories of cities was made with reference to meteorological conditions . As aforementioned pollutants are quite sensitive to anthropogenic activities , city - wise population density and human modification data were also considered to explain the magnitude of pollutions changes . The city environment plays an important role in determining the health conditions of urban populations , however , their relationship is generally ignored . Typically , urban health and social well - being have not been considered in most of the ' canonical ' urban design theories ( BÃ¶ck , 2015;Rice et al . , 2020 ) . In most of the urban design theories , there are six broad sub - categories of urban design , namely , morphological , perceptual , social , visual , functional , and temporal dimensions ( Carmona et al . , 2010 ) which explicitly ignored the health dimension . During the Covid-19 lockdown , urban designers are highly concerned about human wellbeing compared to the pre - Covid-19 period . As such , urban designers can play a vital role in improving the population 's health through their design decisions , and the mechanisms by which it affects individual health and social well - being ( Azzopardi - Muscat et al . , 2020 ) . According to the WHO , ' Health in all policies ' has been initiated as a ' health in all designs ' strategy ( Rice , 2019 ) and therefore , the urban designers need to focus on the health conditions of urban populations .	235382144	no
The advantages and disadvantages of linear architectures have already been discussed at the beginning of the Array architecture section . Pancheri and Stoppa 18 implemented a 64 Ã 4 linear SPAD array ( overall size of 1660 Ã 104 Î¼m 2 in 0.35 Î¼m CMOS technology ) targeted for FLIM . The four SPADs in each column were connected to the same read - out channel , creating macropixels to reduce the influence of the single SPAD dead time ( ~50 ns ) . This increased the photon throughput of a 15.8 Ã 63.2 Î¼m 2 macro - pixel . The chip also featured four time - domain gates that were connected to four separated counters , enabling the construction of on - chip histograms of the photon - arrival times with four bins and data compression . This sensor was later used 65 for spectrally resolved FLIM ( sFLIM or Î»FLIM ) , a setup that enables the separation of molecules by both the fluorescence emission wavelength and the fluorescence lifetime 66 . An example of a corresponding tissue image is shown in Fig . 3d , e. The Î»FLIM system simplifies the discrimination of different fluorophores and enables the simultaneous study of donor and acceptor molecules .	202670835	no
Telemedicine involves the use of information and communication technology ( ICT ) to securely transfer medical data and health information , through messages , sounds , and photographs , and in other forms , which are used to prevent and diagnose illnesses , to provide care and to monitor patients during recovery ( Robinson et al . , 2003 ) . Healthcare providers can use telemedicine to combine all services and thus may be able to provide quicker diagnosis and to improve the efficacy and appropriateness of care ( Hilligoss et al . , 2019 ) . This tool can be used for many health purposes related to three core service categories - diagnosis , care , and rehabilitation services . Diagnosis services are used to transfer diagnostic information on patients . Although healthcare providers can not use telemedicine in isolation to conduct a full diagnostic procedure , they can use it to support the diagnosis and treatment process and to obtain valuable insights . Conversely , care services can be provided only once a diagnosis has been made and enable the healthcare provider to make therapeutic choices and assess prognostic trends . Rehabilitation services consist of therapy programs offered at home or at nursing centers , which are provided to people eligible for therapy because they are vulnerable , infants or elderly , or have a disability or medical condition ( Chen et al . , 2017;Sanders et al . , 2012 ) . In this regard , the ongoing COVID-19 pandemic has highlighted the importance of timely diagnosis , care , and rehabilitation , which are the main purposes that telemedicine can be used for effectively . Telemedicine services are classified into the two macro categories of specialized telemedicine and teleassistance ( Cobelli , 2020 ) .	234818228	no
"The future of air pollution monitoring technology is low cost , chemically specific , sensitive , weather protected , mobile sensor arrays capable of being worn or attached to existing infrastructure ( Fig . 1c ) . When used together , such sensors could form an early warning network through a "" crowdsourced "" map of outdoor pollutant levels . These sensors would have low power consumption and would be able to provide continuous , long - term , live monitoring of pollutant measurements in dynamic and harsh environments . Additional considerations , such as data storage , management , dissemination , and privacy , would also need to be addressed . These sensors could provide an abundance of hyper local air quality information , such as data related to household chemical use or air pollutants in car passenger cabins . The data obtained could be linked to indicators of health and be used to quickly inform the public as to their risk for illnesses , such as asthma , bronchitis , cancer , and Alzheimer 's ."	52134436	no
stations , ( v ) workplaces , and ( vi ) residential places . These data have been constructed by comparing visits and lengths of stays at certain places relative to a baseline ( Google Mobility , 2021 ) . The retail & recreation cate - gory provides data on mobility trends for places such as restaurants , cafes , and shopping centers . Grocery & pharmacy category provides data on mobility trends for sites considered to be essential trips , including grocery markets , drug stores , and pharmacies . Similar subcategories of related locations are grouped within parks , transit stations , workplaces , and residential places ( Google Mobility , 2021 ) . The use of such types of consumer mobility data is also in vogue in the extant literature ( e.g. , Persson et al . , 2021 ) .	255441206	no
The second goal of the workshops was to make the tacit knowledge of the inspectors and data analysts explicit in a business concept . The inspector workshop started with a broad brainstorm on possible risk factors . At first , the inspectors came up with the most obvious risk factors . It can be hypothesized that these factors are a result of explicit knowledge , as they are commonly known within the organisation . However , after a few minutes , the inspectors began to connect their ideas with ideas written down by other inspectors . This led to new insights and less obvious risk factors began to manifest . It can be hypothesized that these risk factors are derived from tacit knowledge , because the inspectors did not previously realize that they possessed knowledge on those risk factors . Thus , during the brainstorm phase in the workshop , both tacit and explicit knowledge of inspectors became explicit . The same happened during the data analysts workshop . They did a broad brainstorm on possible data sources that could be used to add the risk factors to the model . At first , the data analysts came up with the more obvious data sources . After a while , they formed connections with other data sources and they came up with more ' out - of - the - box ' ideas . Thus , during both the data analysts and inspector workshop , tacit knowledge became more explicit and has been shared .	239658990	no
The survey tested housing and tenure security and adequacy using several metrics . It included a simple measure of overcrowding by asking for number of residents and number of bedrooms in the household . This question was supplemented by questions about resident 's level of comfort using and occupying their home during isolation measures . Housing security was tested using questions about length of rental lease , and   whether respondents leased from a landlord or sub - let from a housemate . The survey also included a question about levels of confidence about rental legal rights . Affordability was tested by asking for salary and weekly rental or mortgage payments . The final section of the survey related to the support mechanisms or resources that respondents accessed in response to COVID-19 . Respondents were asked if they received government payments , support from their employers , friends , a charity organization , housemates or family , accessed their personal resources through savings or superannuation or sought a personal loan or mortgage relief . We generated a proxy for social support by asking respondents the degree to which their family , family , government , friends , neighbours and charities supported them throughout COVID-19 . We also adapted a survey instrument from Sherbourne and Stewart ( 1991 ) to test the frequency with which respondents accessed emotional and pragmatic support from networks . Finally , the survey investigated experiences of rental renegotiations in Victoria and captured data about whether rent was reduced , by how much and why or why not this negotiation proceeded .	237663595	no
For the DPP polymers , the electrochemical band gap , defined as E g , SWV î q(E ox , SWV â E red , SWV ) , is larger than the optical band gap ( E g , opt ) determined from the onset of absorption in thin films ( Table 1 ) . Figure 4 reveals that the electrochemical gap and optical gap are strongly correlated . The dashed line in Figure 4 represents a fit with a fixed slope of unity to the data E g , opt = E g , SWV â ( 0.44 Â± 0.02 ) [ eV ] . For most DPP polymers , the optical and electrochemical band gaps adhere to this relation ( R 2 = 0.72 ) , but exceptions are evident , especially for 2PyDTP ( 8) and to lesser extent for 2Py3 T ( 6 ) , 5 T ( 15 ) , TDTPT ( 18 ) , and SDTPS ( 19 ) . If we view E g , SWV as the single - particle gap ( sometimes called the transport gap ) , the dashed line in Figure 4 indicates that the effective singlet exciton binding energy is â0.44 eV , quite independent of the specific polymer ( apart from the exceptions noted ) . The average effective binding energy , determined empirically as E b = E g , SWV â E g , opt , amounts to 0.44 eV and reflects a combination of fundamental effects ( such as Coulomb and exchange interactions ) and experimental effects ( such as the presence of electrolyte ions in the oxidized or reduced films that may affect the absolute and relative values of the redox potentials ) . We also note that the actual E b value will depend on how the optical and electrochemical gaps are determined . We used the onsets of the absorbance spectrum and the square - wave voltammogram as determined by the crossing of tangent in the inflection point and the baseline . Hence , the value should be treated with caution . The value of the singlet exciton binding energy in semiconducting polymers has been subject to intense discussions , as it has been notoriously difficult to agree on the method how it can be determined experimentally . Many - body theoretical calculations of the excitonic properties of conjugated polymers that include the interchain screening of the Coulomb interaction by using the bulk dielectric constant have revealed binding energies of 0.4 - 0.6 eV for a number of homopolymers , [ 48 ] consistent with the present result for donor - acceptor DPP polymers . For smallmolecule organic semiconductors , the singlet exciton binding energy is often much larger . [ 37,[49][50][51 ] It is of interest to consider why polymers 2PyDTP ( 8)     holds for two other polymers that have an electron - rich DTP unit , i.e. , TDTPT ( 18 ) and SDTPS ( 19 ) , but for which the thienophene-2,5 - diyl and selenophen-2 - yl units that flank the DPP unit are more electron rich that the pyridine-2,6 - diyl unit in 2PyDTP ( 8) . For 2Py3 T ( 6 ) , the lower E b = 0.31 eV is a result of the combination of an electron - deficient 2Py - DPP-2Py segment as in 8 with an electron - rich 3 T ( terthiophene ) segment . 3 T is more electron rich than 1 T and 2 T units in 2PyT ( 1 ) and 2Py2 T ( 2 ) , but less than DTP in 2PyDTP ( 8) . Finally , 5 T ( 15 ) has the longest electron - rich segment , combined with DPP , in which case the centers of positive and negative charge densities of a CT - like absorption are more spatially separated . In summary , the effective binding energy for the DPP polymers defined as E b = E g , SWV â E g , opt amounts to about 0.44 eV for most DPP polymers , but can be significantly smaller when electronically distinct units are alternating along the chain .	104323766	no
Data were collected over 12 sessions ( eight interviews and four focus groups ) involving 17 participants across the six company cases from different industry sectors . Table 2 shows the companies involved in developing the model , the number and role of participants , and the data collection methods . Observation of Companies A , B , C , and F took place during study visits , either at the factory or shipyard . Notes and pictures were taken to document processes and work in progress . Secondary data from the company 's website , white papers and press releases were used when relevant . In Companies C , D , E and F , data were gathered from focus groups . If gathering multiple participants in one session was not possible , then individual in - depth interviews were carried out . Two rounds of model development occurred : one in Australia ( Companies A , B and C ) , and one in Europe ( Companies D , E and F ) . In the first round , the SMMM was used as a mediating object for interviewing . Codes were generated inductively ( Miles et al . , 1994 ) and grouped in categories . The initial data collection used ten interview questions focused on identifying the core capabilities connected to the company 's sustainable manufacturing strategy . The questions enabled participants to connect the concepts of business strategy and core capabilities with corporate sustainability . A summary of key discussion points was sent to the participants for feedback to check the accuracy of the data collected .	229426053	no
In this study , the methodology applied to estimate GHG emissions from agriculture is the Tier 1 method of the IPCC ( 2019a ; 2019b ) . The nitrogen pollution is estimated from leaching and runoff from crops , and from the nitrogen excreted by livestock . The biophysical information for each crop and irrigation system are taken from literature reviews and fertilization practices in Spain published by the Spanish Ministry of Agriculture . Emission factors and the data used in the estimation of GHG emissions are taken from IPCC ( 2019a ; 2019b ) . We assume also that the NO 3 -N loads reaching watercourses are 40 % of all nitrogen loads at the source of pollution , and the NO 3 -N loads reaching the Ebro river mouth represent only 10 % of all nitrogen loads at the source of pollution . This is based on the results of Lassaletta et al . ( 2012 ) , which indicate a high level of retention in the basin ( 90 % ) . The environmental damage of agricultural activities is the sum of the cost of GHG emissions and the cost of nitrogen pollution into watercourses , and are given by the expression :	240139964	no
However , these questions are only part of a broader issue of legitimacy . Data science is becoming more contested because of issues of accountability , fairness , and legitimacy . On a more positive note , the contestation of data science can be seen as a maturation of the field . Obviously , any practice or method has its strengths and weaknesses , and for more mature practices , these strengths and weaknesses are better known . If we consider this , combining the strengths of data science with the wisdoms of the work floor to gain knowledge is full of promises .	239658990	no
The resulting gravimetric and volumetric capacities of AlCl 3 : EMIMCl ionic liquids are 48 mAh g â1 , 63 Ah L â1 and 19 mAh g â1 , 24 Ah L â1 for r = 2 and r = 1.3 , respectively . Hence , to achieve an optimal energy density , not only must the highest capacity of the cathode ( C c ) be addressed , but a concomitant increase in r must also be included . As a reference point , we analyzed all available literature on aluminum GDIBs and identified that the highest experimental energy density of â65 Wh kg â1 was reported for an AlCl 3 : EMIMCl anolyte with r = 2 , a graphitic capacity of 142 mAh g â1 , and a corresponding discharge voltage of 1.79 V ( see Table 2 ) . We note that most of reported data in the literature were obtained with r = 1.3 . At this lower value of r , the energy density does not exceed 30 Wh kg â1 .	201214362	no
Fieldwork took place in 2014 - 2015 in two stages : the first stage was in Bishkek , Kyrgyzstan and the second stage in Ekaterinburg , Russia . Additional interviews were gathered by Skype or email during 2016 ; and then during 2019 . 43 interviews were collected ; 22 on Kyrgyzstan and 21 on Russia . The primary data from in - depth semistructured interviews were supported through fieldwork observations and document analysis , which allowed to minimise potential bias ( Cassell , 2009 ) .	244241829	no
Several websites are available which provide the updated record of COVID 19 cases in India primarily maintained by the governmental or non - government organizations . For this study , we obtained the daily confirmed district - wise COVID 19 cases for 103 days period of March 4th , 2020 to June 14th , 2020 , from the website https://howindialives . com / gram / metrics.php . The data sets have been prepared by collecting the information from various central and state government sources , and have been verified before utilizing in this study .	231965779	yes
The Autoregressive Integrated Moving Average Model ( ARIMA ) is a method of establishing a mathematical model through curve fitting and parameter estimation ( Zhang , 2003 ) . This model is mainly for stationary non - white noise sequence data , and generally uses a specific mathematical formula to make the data meet the calculation conditions ( Morimune and Miyazaki , 1997 ) . In the process of transforming a non - stationary time series into a stationary time series , the ARIMA model is a model established by regressing the dependent variable only on its lag value and the present value and lag value of the random error term . This reflects that the ARIMA model has the characteristics of simple operation . Its modeling only needs endogenous variables and does not need to resort to other exogenous variables . At the same time , the ARIMA model also has its application limitations . First of all , the model has strict requirements on the stability of the data . Stationarity can be divided into two categories : strong stability and weak stability . In the process of practical application , strong stationarity is too ideal and theoretical , and weak stationarity and unevenness need to be dealt with by difference tools . If the data after the difference is still not stable , then this set of data series could not be executed . Secondly , the ARIMA model essentially can only capture linear relationships , not non - linear relationships . The overall flow chart is shown in Fig . 3 .	236294095	no
Second , social media can serve as tools to track and predict a pandemic due to their capability for real - time surveillance of disease outbreaks ( Al - Garadi , Khan , Varathan , Mujtaba , & Al - Kabsi , 2016 ) . Compared with traditional disease surveillance systems , monitoring pandemics using social media data can be faster ( Signorini , Segre , & Polgreen , 2011 ) and less expensive ( Al - Garadi et al . , 2016 ) . For example , in China , Sina Weibo data provide an opportunity to detect the transmission of contagion , and the results from analysing these data are in accordance with those of the Chinese Center for Disease Control and Prevention ( CDC ) ( Huang , Zhao , & Zhang , 2013 ) . Additionally , data from social media can be used to predict infection cases during pandemics . Most studies demonstrated that social media data could predict official data up to one week in advance of its release by health agencies and centres ( e.g. , US CDC and UK HPA ) ( Al - Garadi et al . , 2016 ) . For example , Shen et al . ( 2020 ) revealed that reports of symptoms and diagnoses of COVID-19 obtained by analysing posts related to COVID-19 on Weibo significantly predicted daily case counts up to 14 days ahead of official statistics . Thus , social media can help government and health organizations facilitate timely actions to decrease unnecessary mortality ( Li & Cardie , 2013 ) .	238478271	no
The tomographic reconstruction based on the Wolf transform and the Rytov approximation directly maps multiple 2D measurements into the 3D Fourier space . Therefore , any missing information in measurements directly deteriorates the final reconstruction . However , the LT - SSNP is an iterative reconstruction scheme . The iterative reconstruction begins with an initial guess ( usually based on the Rytov approximation ) , and the initial solution is updated based on the calculated error gradient by using the forward model . In addition , prior knowledge about the sample is imposed on the current guess during the iterative process . Therefore , even if the measurements are underdetermined due to missing measurements , the learning approaches can fill in some of the missing information . This idea was validated by reducing the number of illumination angles used for each method . The experimental data used for this investigation were ODT images of a pair of HCT116 human colon cancer cells . These cancerous epithelial cells contain information in small structures relative to the size of the cell and highlight the importance of reconstructions that can capture these fine details . Reconstructions were performed by using Rytov , linear tomography 20 , and the LT - SSNP by using different numbers of projection angles ( 45 , 24 , 12 , and 4 ) uniformly spaced in the range from 0 to 360 Â° . The linear tomography method uses the same iterative reconstruction scheme as the LT - SSNP , except with single scattering as the forward model . For the quantitative analysis , we also compare the structural similarity index ( SSIM ) 33 for reconstructions from compressed measurements with the full measurement case , namely , 360 angles at the focal plane . The results , plotted in Fig . 7 , show a dramatic improvement in the reconstruction quality for linear tomography and the LT - SSNP because the two methods iteratively fill up empty components introduced from missing measurements but using different forward models . In the case of the HCT116 cells , Rytov produces fairly good reconstructions that reveal intracellular structures with 360 full projections , despite the underestimation due to the missing - cone problem . The Rytov reconstructions , on the other hand , rapidly deteriorate as the number of illumination angles decreases . Compared with Rytov and linear tomography , the LT - SSNP is more robust in the number of projections , providing reconstructions with only four scanning angles with nearly the same quality as reconstructions by using the full 360 - angle data , as confirmed by the SSIM in Fig .   7b . We believe that the LT - SSNP can benefit from both the iterative scheme and an accurate forward model . In addition , we further tested the compression using the cell phantom , which has higher RI contrasts ; the results have been added to the supplementary material .	202509934	maybe
Our findings in Table 5 mostly support our hypotheses . Table 5 reveals that Environment Score and Environment Award have a significant impact on disclosure of the number of species protected in companies that operate in developing environments compared with their counterparts that operate in developed countries . These findings are supported by the legitimacy theory expectation that companies from The table reports the effects of assurance , environment award , presence of partnership and green Industry on the number of reported species in firm 's annual report in each year . The data consists 599 firm - year observations of top 200 firms listed in Global 500 firms for the year 2012 , 2014 and 2016 . nSpecies - coded from 0 to 4 - 0 if the number of species is 0 , and 1 - 4 if the number of species is in the range of 1 - 99 , 100 - 199 , 200 - 299 , 300 and more respectively . Green industry is a dummy equal to 1 if the industry belongs to green industry and 1 if it is in red or amber industry . Natural logarithm of total assets as a proxy for firm size is used . Column 3 reports Zero - inflated Poisson ( ZIP ) regression . Robust standard errors are reported in parenthesis * * * Denotes 1 % , * * denotes 5 % and * denotes 10 % significance level   ( Hassan et al . , 2020b;Tagesson et al . , 2009 ) . Similarly , we find that assurance has a significant positive effect on disclosure of the number of species protected in companies that operate in developing environments , compared to their counterparts operating in developed countries . Overall , the results support our claim that institutional context has a moderating effect on the relationship between Environment Score , Environment Award , Assurance , and disclosure of the number of species .	233210919	no
Third , the interviewees stated that the development of technology for telemedicine , mobile - based smart services , and consumer - oriented services should all be accelerated through the integration of innovative technologies ( e.g. , robotics , big data , IoT , and cloud - based ambient computing ) . Additionally , they remarked that digital healthcare , an area not directly managed by medical staff , should be equipped with different forms of digital therapy products ( e.g. , devices , software , and mobile application software ) . The interviewees also remarked that the challenges of COVID-19 should be transformed into opportunities to further innovate the healthcare industry in Korea , especially government regulations in dealing with pandemics , hospital facilities that are specifically designed to treat virus patients , and medical staff development for infectious diseases ( Lee and Lee 2020b ) . We summarize the opportunities and challenges that the pandemic has brought to the healthcare industry in Table 2 .	232055750	no
Cross - population comparison of AM using UKB data . We estimated GPD for six traits in the UKB GWAS data : T2D , CAD , light - PA and yoghurt consumption as traits with significant AM signatures in the Japanese , and adult height and obesity ( BMI ) as gold standard controls for AM ( Fig . 4 ) . We robustly replicated the GPD estimate for adult height in the European - ancestry population as a sanity check ( Î¸ height in UKB = 0.030 and 0.030 for the current and previous studies 18 , respectively ) . The GPD estimate of BMI in our work was slightly higher than in the previous study ( Î¸ BMI in UKB = 0.0079 and 0.0001 for the current and previous studies 18 , respectively ) . It is noteworthy that the GPD estimates for adult height were relatively higher than those for BMI in both European - ancestry and Japanese populations ( that is , Î¸ height in EAS = 0.0073 and Î¸ BMI in EAS = 0.0067 ) . However , the GPD estimate for adult height was not as high in Japanese compared with the European - ancestry cohort . This result was consistent with previous epidemiological reports 5 , in which the correlation of height between spousal pairs in Western countries was higher than those in non - Western regions . We note that height was one of the traits with the strongest positive natural selection among Europeans 29 , whereas it was not in the Japanese 27,28 . The GPD estimates of T2D , CAD , light - PA and yoghurt consumption were higher in Japanese than in European - ancestry populations ( Î¸ T2D in EAS = 0.018 versus Î¸ T2D in UKB = 0.003 , Î¸ CAD in EAS = 0.014 versus Î¸ CAD in UKB = 0.002 , Î¸ light - PA in EAS = 0.012 versus Î¸ light - PA in UKB = 0.002 , Î¸ yoghurt in EAS = 0.010 versus Î¸ yoghurt in UKB = 0.001 ) . This result suggests a population - specific effect of AM .	252466144	no
Array cameras , which are an effective solution to increase the aperture area and overcome the optical aberrations of single - lens cameras , have been extensively studied for highperformance imaging 1 - 13 , including wide - field high - resolution imaging [ 3][4][5 ] , high dynamic range imaging 5,14 , and high frame - rate imaging 5 . By strictly following the uniform sensation principle in which each pixel has the same instantaneous field of view , as in a single camera , a large array camera was first proposed for high spatial / temporal resolution and wide field - of - view ( FoV ) videography 5 . However , the system was bulky , and the video stitching algorithm was not robust enough to support a large number of cameras and irregular arrangements . The recent multiscale optical design 3,4,15 adopted a customized objective lens as the first - stage optical imaging system . The secondary imaging system used multiple identical microoptics to divide the whole FOV into small overlapping regions . It substantially reduced the size and weight of gigapixel - scale optical systems . However , the volume and weight of the camera electronics in video operation was more than 10Ã greater than that of the optics 3 . Moreover , this system required a delicate structured array camera design , raising challenges with the complex optical , electronic , and mechanical designs . Laborious calibration and massive data processing were also needed 4,7 .	231956726	no
"In a series of papers published between 2011 and 2021 , Napoletani et al . put forward the thesis that there is a particular kind of methodology that differs from those underlying classical scientific methods 3 and makes it possible to find significant correlations across huge datasets . According to these authors , certain scientific methods , when applied to phenomena that are not even tentatively understood , can represent instances of what they call ' agnostic science ' . One paradigmatic example of such a method that might be agnostic in this sense , is machine learning . A comparison of two usages of machine learning , the PageRank algorithm and the microarray method , illustrates how it can be applied to both , phenomena that are understood and those that are not . Napoletani and his co - authors argue that the PageRank algorithm , which provides a hierarchical classification of websites , represents a way of applying a machine learning algorithm to a well - understood problem that possesses a foreseeable solutionstructure ; because the result of this application is an increased understanding of the problem and its solution , this usage does not count as an example of agnostic science . Conversely , the microarray method , which classifies messenger ribonucleic acid ( mRNA ) molecules according to their function as co - occurrent with specific diseases , involves the application of machine learning to a problem that is known to exist , but for which we lack any insight regarding its structure and for which predicting an outcome is infeasible ; as Napoletani et al . ( 2021 , p. 45 ) argue , "" [ the ] mechanism that leads from a certain distribution of mRNA molecules to the manifestation of a certain disease is [ â¦ ] rarely understood . In addition , it is also unclear which specific mRNA molecules are relevant in particular diseases "" . Consequently , although it provides us with meaningful correlations , the microarray method does not increase our understanding of the problem and its solution - structure is not transparent . That is , ' agnostic science ' according to Napoletani et al . refers to whether we gain any understanding of a phenomenon when applying big data and machine learning methods in science , while Anderson 's notion of ' agnostic science ' is that these methods can be applied without any prior expert knowledge or theory . Thus , the importance of expert knowledge in applying these methods will have different ramifications for the different notions of ' agnostic science ' . We will return to this discussion in Sect . 6.1 ."	256060110	no
Third , Netflix also references audience data to deflect criticism . Here , the case of Marco Polo is particularly instructive . The first ten - episode season of this big - budget historical epic cost a reported ninety million dollars and was widely understood to reflect Netflix 's global ambitions ( Steel , 2014 ) . Billed as the streamer 's response to the success of HBO 's Game of Thrones ( 2011 - 2019 ) , the show was savaged by American television critics who found it to be a ' disappointment ' and ' dramatically inert ' ( Genzlinger , 2014;Van Der Werff , 2014 ) . A month after Marco Polo 's premier and just 2 weeks after the second season renewal was announced , CEO Reed Hastings told an interviewer the show was ' a massive success ' that had ' been super popular with the audience ' ( Stenovec , 2015 ) . The second season , with a budget of more than 100 million dollars , premiered in July 2016 . Discussing Marco Polo 's performance later that year , Sarandos told an industry roundtable that the show was ' hugely popular all throughout Asia and Europe ' ( The Hollywood Reporter , 2016 ) . Given Netflix 's subscriber - based economic model , he explained , the series ' lack of popularity with American audiences and its harsh reception by television critics was ' really irrelevant because it 's doing exactly what it was supposed to do ' . In these instances , the practice of discussing but not releasing audience data allows Netflix to deflect the criticism most networks face regarding an underperforming big - budget project . Instead of being forced to answer for low ratings and unmet expectations , anti - transparency policies ensure that executives can claim success or redefine the parameters of success without be challenged . Of course , claiming success and succeeding are two different things . In December 2016 , Netflix canceled Marco Polo after just two seasons taking a reported $ 200 million loss on the project ( Goldberg , 2016 ) .	236221457	no
The existing literature on aggregating evidence for causal hypotheses accords well with the witness schema . One might interpret the key questions as follows : How should individual ' witness reports ' be delineated to ( at least approximately ) preserve independence and how should the reliability of these reports be assessed ? What algorithm should be employed for aggregating the reported causal conclusions ? Consider an example report amounting to a statistical reject / accept result concerning some causal claim . This is effectively a witness report that has some degree of reliability . Indeed , there is a preoccupation in the literature ( in particular , the ' hierarchy of evidence ' literature associated with the ' evidence - based medicine / policy ' movement ; see Brendan et al . 2014 for an overview ) with how to assess the reliability of study results given the design in question ( the sample size , the controls for bias , etc . ) , and furthermore with how to aggregate the results , for instance , whether supposedly more reliable study types should ' trump ' others or whether they should all play a role in determining the final causal conclusions . 5 Most evidence hierarchies place statistical meta - analyses near the top . 6 One might worry that the witness model does not account for this kind of conglomerate evidence , where the effect size measures from different studies ( perhaps the difference in efficacy of two treatments ) are combined in sophisticated ways . By way of response : There are two ways one might reconcile statistical meta - analysis with the witness schema . The first is to see meta - analysis as an instance of the general schema , with a particular choice of algorithm for aggregating the witness reports , and limited to a certain kind 4 In the Bayesian setting , the witness reports are mere indicators of the truth . 5 For instance , the hierarchy introduced by the UK National Institute for Health and Care Excellence ( NICE 2006 ) places meta - analyses , systematic reviews of randomised controlled trials ( RCTs ) , and RCTs above case - control or cohort studies , non - analytical studies such as case reports , and expert opinion . In addition to worries about undue privileging of RCTS , a major criticism of the evidence hierarchies is that mechanistic evidence and expert opinion are distinguished from correlational evidence and relegated to the bottom of the hierarchy ( see Brendan et al . 2014 ) . The claim is that mechanistic evidence for causation is rather complementary to statistical evidence ( see the Russo - Williamson thesis , Russo and Williamson 2007 ) . This criticism does not necessarily undermine the witness schema . Instead , one can draw a lesson of caution from this debate regarding what counts as independent witness - style evidence . In particular , one might contend that evidence of mechanisms and evidence of probabilistic - association can not be treated as separate ' witnesses ' . 6 As per the NICE hierarchy ( see previous footnote ) . of evidence ( generally the fine - grained effect - size results of RCTs ) . 7 The second is to treat an individual meta - analysis as itself a single study or witness report , perhaps a very reliable one if it is based on considerable data from multiple experiments ( but see Stegenga 2011 for doubts about the reliability of meta - analyses ) . The latter route is attractive because in practice there are many meta - analyses at hand that account for some , but not all , of the raw statistical data that could serve as potential input for assessing a causal hypothesis . 8 In general , the above discussion underscores a point made above , namely that the witness schema , while offering some useful constraints , is nonetheless a very flexible model for evidence aggregation . Clearly a lot depends on how the evidence is divided into independent witnesses and assessed for reliability . That is , it is apparent that a lot of the difficult questions in negotiating evidence are shifted to the ' pre - processing ' of the evidence , and away from the final aggregation task . So , the general dictates of logic - here spelled out in terms of a witness model - can provide a basic framework for evidence aggregation , but further substantial aspects of the process are inevitably left unspecified . That is not to say that these further details of identifying , weighing and aggregating evidence can not in large part be automated via an explicit algorithm . How much automation is a good idea is of course the question that remains unanswered .	255060743	no
We believe that a more structured data collection on frequent failures and repair rates may be generally useful to understand which components of a given product group are more prone to fail , and which are more challenging to repair . In particular , the components identified to be more unlikely to be repaired represents a discriminating factor when it comes to define when an appliance can be used again or should go to EoL processes . The data collection , if performed at the moment of the initial diagnosis and during the repair service is not necessarily time consuming , and can be done by any repair operators . Statistical analyses may bring the necessary knowledge to identify existing hot - spots , but professional repair operators should record a series of key parameters in a structured way . As a result , a structured knowledge on repair services can be useful ( also for EoL operators ) to collect spare parts from appliances at the EoL , to be stored for future reuse .	128352956	no
Recent developments such as brightfield holography 18 and phase staining 21 digitally introduce alternative contrast mechanisms to digital holography , which were not possible before the deep - learning - based data - driven approaches were developed . These advances demonstrate the powerful potential of coherent imaging systems that are combined with deep - learning - based statistical image transformations to modify standard image formation , reconstruction and analysis workflows employed in a QPI . We envision that these latest developments will serve as a catalyst to accelerate the translation and widescale adoption of holography and coherent imaging techniques in biomedical and clinical applications . Regarding life - science - related applications , live cells can be imaged label - free with low phototoxicity at higher frame rates by using these emerging deep - learningpowered methods and then digitally postprocessed to provide multimodal transformations to other contrast mechanisms for visualization and/or automatic classification or segmentation .	202510468	no
Inspired by the alternative perspectives on ethical relations offered by feminist theory , we wished to focus on aspects of whistleblowing disclosures that are typically overlooked in extant research - and discussions of business ethics more broadly . These include tangible impacts that affect the bodily capacity for survival : financial resources including changes to income and expenditure as a result of speaking out , costs of attaining necessary care for mental health and physical impacts , the time costs of speaking out , the capacity to earn a living , attaining support through modes of belonging and access to the infrastructures that can help cope with these experiences to better enable survival for self and loved ones . We collected quantitative evidence on these aspects . Our study is among the first attempts to measure and quantify the tangible costs of disclosure for people who find themselves having to leave their current role as a result of speaking out . Our findings are supplemented by qualitative survey responses from whistleblowers , which provide useful background detail while not forming a substantive part of our data .	245516492	no
The EF LCIA ( EF2017 ) method ( EC , 2017 ) was adopted for the impact assessment phase . The assumptions made to map the environmental data of statistical sources ( DF ) or the emissions and resources of the environmental extensions of Exiobase v3 ( CF - TD ) with the list of elementary flows of the LCIA method applied , i.e. EF2017 , was a key aspect in the quantification of the environmental impacts . Beylot et al . ( 2019 ) details this mapping for the CF - TD . The characterization factors were those of the EF reference package 2 ( EF 2.0 ) ( EC - JRC et al . , 2018;Fazio et al . , 2018 ) . Although the 16 EF impact categories were assessed ( ESM 1 ) , only 14 out of them ( i.e. , excluding ozone depletion ( ODP ) and ionizing radiation ( IR ) ) were considered for the general results due to limitations of the Exiobase database ( top - down approach ) . The 14 categories assessed were Climate change ( CC ) , Human toxicity , non - cancer ( HTOX_nc ) , Human toxicity , cancer ( HTOX_c ) , Particulate matter (   the relevance of adopting the 16 EF categories is later discussed , compared to the limited use to 14 EF categories when employing the Exiobase database . Regarding HTOX_nc , the characterization factor for the zinc emissions from USEtox ( Rosenbaum et al . , 2008 ) was reduced to 2 % , according to the procedure adopted in the IMPACT World Ã¾ method ( Bulle et al . , 2019 ) . Characterized values were normalized at the global level , referring to global impacts calculated by Crenna et al . ( 2019 ) , and at EU-28 level for sensitivity purposes , by using the CF - TD results as reference . The EF2017 weighting factors   were applied to obtain a single score CF .	198689284	maybe
Influenza prototype diseases wreck humankind under low daily temperature and with humidity up to 70 % ( Park et al . , 2020 ) . Initially , investigations explicated COVID-19 transmission decreased with an increase in temperature ( TobÃ­as and Molina , 2020 ) . Another study that involved 429 cities suggested that temperature may have a strong relation to COVID-19 infection and transmission , which collected data for only 16 days ( Jan 20 ~ Feb 4 ) ( Wang et al . , 2020d ) . Using these climatic correlations with COVID-19 cases data ( Jan 20 to Feb 29 : 2299 COVID-19 death counts ) in Wuhan , temperature and humidity proved to have an impact on mortality , and increased temperature showed a slight decline in the rate of death . A positive association with COVID-19 daily death counts during the diurnal temperature range ( r = 0.44 ) and , a negative association for relative humidity ( r = â 0.32 ) was observed . Additionally , investigation of daily COVID-19 cases association with daily average temperature and relative humidity in 30 Table 1 Stages of vaccine development and testing ( T. N. Times , 2020 ) .	236247702	no
We studied an MSI involved in the UK based project ' Peatland tipping points ' , 2 which investigated how changes in climate and land management affected peatland ecosystems in the UK . We drew our data from a workshop through which the stakeholder collaboration took place , allowing us to observe micro - level interactions in real time and to account for the influence of design characteristics on frame deliberation . The aim of the workshop was for scientists to work with stakeholders to identify options for managing and protecting peatland ecosystems and upland rural communities in the North Pennines after Brexit , taking into account the peatland ecosystem as well as related social and cultural practices such as recreation , sheep grazing and grouse shooting ( also see Reed et al . , 2017bReed et al . , , 2020 . By the end of the workshop , stakeholders had to jointly decide on recommendations for ( a ) what environmental land management options to be included in the governmental peat management payment scheme , and ( b ) what ' fair price ' ( Kenter , 2020 ) should be paid for those . The workshop was also a forum for uttering disagreements with the current scheme and inform other stakeholder groups and policymakers on difficulties and local issues regarding the scheme . The workshop and project results fed into a policy brief to the UK government . Stakeholders ' decisions and feedback could make a difference to what practices would be supported or prohibited , which was personally significant to some of the stakeholders , as detailed later on .	233565674	no
Future research could analyze whether the potential credibility problem of voluntary initiatives with weak review and enforcement mechanisms materializes into a substantial problem in practice . This requires investigating whether stakeholders do actually identify inactive late signatories and whether they act accordingly to scrutinize free - riding . While we analyzed the implementation of the UN PRI on the firm level with third - party ESG data , survey - based research projects may improve the understanding for the perceived credibility of the initiative by various stakeholders . Such analyses can be closely linked to our research by asking different stakeholders to assess the perceived credibility of initiators of the UN PRI as well as of late signatories . Future research could also analyze whether the stricter requirements of the UN PRI after 2018 have helped to avoid free - riding by new signatories as documented in our study .	244651817	no
Forced by the lack of data on the sustainability of complete post - Li - ion-(including Al , K , Mg , Ca , and Zn ) technologies , establishing the sustainability of materials that are proposed to replace Lithium is not possible , however , a partial comparison among these different metals can be made by overlooking the cell components ( anode , cathode , and electrolyte ) that seriously impact the green metrics . So , by limiting the sustainability analysis to metals , Lithium has dramatically high SRS , comparable to Cobalt that is worldwide known as a Critical Raw Material ( CRM ) . [ 39 ] The factors that negatively impact on the SRS score of Lithium are the recycling , the global supply concentration , and the substitutability , being the latter identified as a major bottleneck also for other metals . With respect of recycling issues , a literature survey offered very different scenarios , [ 40 ] pointing out the importance of a critical Life Cycle Assessment ( LCA ) analysis of lithium ( and related technologies ) before drawing any definitive conclusion . The only critical score for sodium is the recycling that , however , could not be considered as a real hotspot due to its large availability ( 2.36 % in the Earth Crust ) ; on the other hand , Al has negative scores only with respect to substitutability . [ 41 ] The environmental impact of different metals was thoroughly investigated recently by means of different metrics such as Cumulative Energy Demand ( CED ) , Global Warming Potential ( GWP ) , and Yearly Global CO 2 Emission ( YGCE ) . [ 42 ] On one hand , CED measures the total energy usage during the whole life cycle of a given material and it includes both the direct and indirect energy usage ( also associated with material consumption ) ; [ 43 ] on the other , GWP is the heat absorbed as CO 2 equivalent by any greenhouse gas generated throughout the production process ( from mining to end - of - life / recycling ) and delivered in the atmosphere . Of course , when dealing with metals , these indicators strongly depend on the final utilization of the materials and they are expected to change if large scale use is proposed . Having Lithium as a reference ( CED = 125 MJ kg â1 , GWP = 7.1 kg CO 2 -eq / kg and IGCE = 3.07 kg CO 2 -eq / kg ) , the other metals under scrutiny for new batteries , generally have milder values : Mg , Zn , and Ca have very low CED ( 18 , 52.9 , and 5.8 MJ kg â1 , respectively ) GWP ( 5.4 , 3.1 , and 1.0 kg CO 2 -eq / kg , respectively ) and YGCE ( 1.05 and 0.98 kg CO 2 -eq / kg , for Mg and Ca respectively ) . Zinc , on the other hand , has comparable YGCE values to Li . Quite unexpectedly , Al has slightly higher values for all the metrics , CED = 131 MJ kg â1 , GWP = 8.2 kg CO 2 -eq / kg and IGCE = 9.47 kg CO 2 -eq / kg ) . Of course , these values are referred to the production of pure metals starting from naturally available sources and they could be meaningfully downsized by considering appropriate recycling and end - of - life use . Based on these , the most promising candidate to replace Li is Ca . Similar data on alkaline metals ( such as Na and K ) are still missing , thus the comparison is incomplete . This lack of available data is further pointing toward the necessity of a comprehensive analyses of different materials in the coming future .	236329656	no
"The "" global project "" ( Reese 2015 ) of non - profit civic tech organizations is to enable forms of participatory culture in as many different contexts as possible by developing "" eco - systems "" of data infrastructures and tools ; intended to help citizens to be more informed , active , and engaged ( Baack 2018a ) . Participatory culture is based on the idea that more participation leads to better outcomes and thus aims to create a more "" engaged , representative , and collectively intelligent society "" ( Lewis 2012 , 848 ) . Civic tech 's roots in participatory culture are most explicit in the frequent use of the term "" empowerment "" among civic tech organizations across countries . Civic technologists understand empowerment in terms of accessibility and convenience : by providing services that make engagement with , and monitoring of governments easier and less time - consuming , they aim to increase the level of participation , which in turn would make decision - making processes by governments more representative . Data play an essential role in implementing this vision of participatory culture , as the availability of data that is granular and complete is a prerequisite for many civic tech applications that provide more convenient access to information ."	159434250	no
This paper began with the surprising observation that creativity is a concept explicitly invoked by members of the ATLAS and CMS collaborations in their descriptions of the conditions for a measurement of the self - coupling of the Higgs . This broad notion was one of being able to do more , i.e. improve with respect to the learning aims of the investigators , from transformations to the model of the measurement process rather than expected improvements such as increases in the available data . Due to the very low predicted signal , in the case study explored , this notion translated to a condition for knowledge production . Whilst model - based accounts of measurement of knowledge have recently been very successful in pointing to the epistemic role of models of measurement processes in accounting for standardisation and the stability of measurements ( Mitchell et al . , 2017 ) , this case focused on the transformations to the model of the measurement process .	238769264	no
Theoretical framework of a data - collection technology Privacy	233029680	no
The development of data journalism has traditionally been aided by actors outside the newsroom , who often educate data journalists in using tools and accessing data ( Aitamurto et al . 2011;Appelgren 2016;Appelgren and Nygren 2014;Usher 2016 ) . For this special issue , Cheruiyot , Baack , and Ferrer - Conill ( 2019 ) studied a subset of these actors : the civic technologists . Based on the three researcher 's expertise , they did this in an African and a European context and found that the goals of civic tech are not the simple diffusion of Western ideas but rather a negotiation of local and national origins with global issues ( Cheruiyot , Baack , and Ferrer - Conill 2019 , 13 ) . The two practices that civic tech and journalists share are those of facilitating and gatekeeping , with facilitating being about enabling others to take action themselves and gatekeeping being about highlighting information that is deemed publicly relevant . Journalists are closer to a gatekeeping than a facilitating role , where civic tech instead is more prominent . Civic technologists thus reach their goal of engaging people in important issues . By doing so , they influence data journalism practices by introducing friction between journalistic and civic goals .	210943398	no
This section presents the data and the methodology used to predict mobility as a function of consumers ' perceived risk . Prior research has identified that perceived risk plays a vital role in consumer behavior . Based on the stay - at - home order issued by the state and county governments , one significant behavioral change relates to their mobility decisions . Therefore , due to individuals ' perceived risk , individuals may restrict or change their mobility for different activities . We first describe the risk perception dimensions and then discuss data sources that map onto these dimensions .	255441206	no
To quantitatively test this qualitative reasoning and to rule out any experimental artifacts , we have performed numerical calculations using the discontinuous Galerkin time - domain method 42,43 for the bare gold nanoantenna arrays and nanoantenna arrays with a linear dielectric . Our approach self - consistently takes the light propagation at the SH frequency into account and therefore includes SHG reabsorption , emission shaping and the near - to far - field transition . We described the optical response of the metal by the state - of - the - art hydroynamic Maxwell - Vlasov theory 44,45 , which takes both surface and bulk contributions into account . Its linear limit corresponds to the Drude free - electron model , for which we have chosen a plasma frequency v pl 5 1.33 3 10 16 rad s -1 , a collision frequency v col 5 8 3 10 13 rad s -1 , and a background dielectric constant e ' 5 9.84 . The refractive index of the glass substrate was taken as n 5 1.46 . The geometric parameters of the nanoantennas were adapted from the SEM micrographs shown in Figure 1c and 1d , respectively . The length of the nanoantennas was 350 nm per arm in the case of the bare gold nanoantennas and 325 nm in the case of the hybrid nanoantenna . The width and height were approximately 40 nm . The gap had a width of 60 nm and the size of the dielectric nanoparticles was chosen such that they scarcely touched the nanoantenna arms . The nanoantennas as well as the dielectric nanoparticles were modeled with a surface roughness of approximately 3 nm root mean square by a random   Figure 3 ( a ) Normal - incidence optical extinction ( one minus the measured intensity transmission ) spectra for x - polarized light ( left axis , continuous lines ) as well as the SHG intensity ( right axis , connected data points ) for an array of bare gold nanoantennas ( dark yellow ) and an array of nanoantennas with ZnS nanoparticles ( red ) , both located on sample 1 . ( b ) The same as in ( a ) but for an array of bare gold nanoantennas ( dark yellow ) and an array of nanoantennas with LaF 3 nanoparticles ( blue ) , both located on sample 2 . The SHG intensity spectra are both cases normalized to the maxima of the corresponding bare gold nanoantenna arrays .	52130980	no
Besides economic and political implications , it is also worth examining how COVID-19 and quarantine measures triggered the swing of public sentiments . Thus , we conducted this study amid COVID-19 , aiming to help scientists , policymakers , and other stakeholders to better understand the emotional impact of the COVID-19 ( -like ) pandemic across cities , and to further evaluate in a concrete and quantitative way on how the threat of infectious disease , economic paralysis , political intervention , and scientific effectiveness should be dealt with in a rapidly changing world . Since Twitter is one of the major social platforms where people self - document and share emotions about their daily lives ( Bogers & Bjorneborn , 2013;Liu et al . , 2010;Miller et al . , 2019 ) , it was selected as the main source of data for this study . This study has three major contributions : ( a ) We investigated public sentiment during COVID-19 using Twitter data analyzed with advanced machine learning methods , which allowed a large - scale analysis of an ongoing pandemic ; ( b ) We combined sentiment analysis with Spearman 's rank correlation , which helped offer insights into the reasons behind sentiment changes ; ( c ) This study provided a comparative analysis across cities and time during the pandemic , which was more concentrated and in - depth than at the national level .	236251116	no
Data availability - The data that support the findings of this study are available on request from the corresponding author ( EMR ) .	3792998	yes
In our analysis , we aim to measure the global economic impact of the coronavirus outbreak by investigating the reaction of the main economic indicators to the pandemic level . Therefore , we propose a frequency approach , which allows us to disentangle the short - and long - term effects . The empirical literature proposes various approaches to this . However , to take into account the time - varying behavior of the economic indicators during this period of turmoil , we adopt the continuous wavelet transform ( CWT ) . This approach allows us , contrary to other frequency methods ( e.g. , Fourier transform ( FT ) and spectral analysis ) , to consider nonstationary time - series models through its continuously resized window properties . 1 More specifically , CWT has several advantages compared to other wavelet approaches ; in particular , CWT can avoid the data length restriction imposed by discrete wavelet approach . 2 This CWT method allows us to estimate the reaction of the main economic indicators to the health shock of the coronavirus . In other words , we aim to assess whether the coronavirus health shock has affected the fundamental drivers of the economic system . Therefore , investigating the reaction of the main economic indicators to coronavirus shocks through a nonlinear relationship , and distinguishing between short - and long - term dependence , might be an interesting study for economic interpretations and policy implications .	232162521	no
The number of data taken into account can vary considerably . In a simple network , each food concept is paired with just one kind of data , e.g. , when nutrients are the only determinant of a healthy food . In a reductionist framework , the explanatory role of some data is reduced to the explanatory role of some more basic data , e.g. , when nutritional data are reduced to those about the molecular composition of food ( StrÃ¶hle & DÃ¶ring , 2010 ) , or when a collection of eating habits is reduced to data about the economic relations that sustain them . In a more complex , multi - layered network , instead , food concepts are explained by different sets of data , e.g. , food security ( roughly speaking , the possibility of access to nutrient food ) roots out on data regarding nutritional intake , economic , social , and environmental conditions . Data gathering is surrounded by controversies . A chief one concerns their neutrality . As Biltekoff et al . ( 2014 ) efficiently sum up , purely quantitative data gathering tends to be presented as neutral with regard to other non - quantitative food externalities , including habits , conventions , beliefs , rituals , and taste . Yet , scholars demonstrated several hidden assumptions that underscore quantitative units of measure . These include : politics of the body and endorsed ideologies ( Mudry , 2009 ) ; implicit biases of scientific research ( Nestle , 2013 ) ; the dubious status of the basic components of the concepts that should be collected , e.g. , whether nutrients or whole foods are to be measured ( Jacobs & Tapsell , 2007 ) ; which specific population is taken into account for collecting data ( Pogge , 2016 ) .	238810809	no
Our study has some limitations . As anonymity and confidentiality was promised to the organisations , a deeper analysis of other contextual factors affecting organisational innovativeness in particular organisations ( e.g. in the form of a case study ) was not possible . Therefore , we acknowledge that the findings obtained from the two organisations are not generalizable to all public sector organisations . To increase our knowledge about the effects of ethical organisational culture on organisational innovativeness , a sample should be increased to include more public organisations from each country or / and the results have to be compared to data from the private sector . It is very likely that the virtues and their effect on innovativeness will differ . Findings from a considerably different socio - cultural context or from other organisations in Nordic and post - Soviet societies could also provide data for more generalisable conclusions . Using mixed methods ( Riivari 2015 ) , i.e. carrying out a quantitative study with qualitative methods such as interviews with managers of organisations , document analysis or participant observation , could also contribute to more generalisable results .	254384477	no
The optical absorption data from ZnSnN 2 samples grown under the different conditions are shown in Figure 1 . The absorption onsets vary between 1.33 and 2.38 eV. The absorption coeffi cient , Î± , rapidly increases to 5 Ã 10 4 cm â1 ( 2.5 Ã 10 9 cm â2 for Î± 2 ) above each onset , a value typical of direct band gap semiconductors . The plot of Î± 2 versus photon energy exhibits approximately linear behaviour , again consistent with a direct band gap . The features below the sharp onset are due to Fabry - Perot oscillations associated with the 120 - 165 nm thickness of the ZnSnN 2 fi lms . The free electron densities of the samples , determined by Hall effect measurements , were found to vary between 1.3 Ã 10 19 and 1.1 Ã 10 21 cm â3 . The measured electron mobility was in the range 7 - 12 cm 2 V â1 s â1 for all samples . The free electron density did not vary with temperature , indicating the presence of unintentional degenerate n - type doping . The absorption spectra are therefore expected to be infl uenced by conduction band fi lling , the well - known Burstein - Moss effect . [ 9,10 ] That is , transitions between the band extrema do not occur - only direct transitions from the valence band to the states at or above the Fermi level within the conduction band contribute to the absorption spectra .	56418268	maybe
Regarding key regions , Figs . 8 and 9 show that the real data are lower than the predicted data , indicating that the COVID-19 pandemic contributed more to the PM 2.5 improvement in key regions than in other cities in China . Fig . 11 shows that the reduction in key regions in February and March were extremely significant ( 30.2 Î¼g / m 3 and 9.6 Î¼g/ m 3 respectively ) . Some previous studies have also proved that . For instance , one study found that the total number of avoided premature deaths associated with PM 2.5 reduction during the lockdown was estimated to be 42.4 thousand over the Yangtze - River - Delta region , with Shanghai , Wenzhou , Suzhou , Nanjing , and Nantong being the top five cities with the largest health benefits .	237424987	no
"O'Hara ( 2016 ) reaches a similar conclusion . She questions the extent to which the existence of a ' two speed ' market can actually be fair . In other words , at what point does the advantages that the HFTs firms have such as ultrafast computers , colocation , and proprietary data feeds , become unfair ? O'Hara explains why perfect coordination in the market , where information reaches all the traders at the same time , is unlikely to be attained "" and so neither is perfect fairness "" ( 2016 , p. 145 ) . According to O'Hara , a less idealistic approach to justice should take into account the different needs of the various kinds of traders , respecting the principle of ' reasonable discrimination ' . However , the author acknowledges that "" putting your needs above those of others is unethical "" ( 2016 , p. 146 ) , and therefore , it is not as straightforward as it might seem that a two - tier market may be justified by the differences among the traders . On the contrary , some ethics scholars do not consider spoofing and quote stuffing unethical , and suggest a more positive interpretation . For example , Cooper et al . ( 2016 ) argue that as in the game of poker , these forms of misleading behavior should also be accepted in the financial markets . The authors claim that these practices are part of an ' evolutionary process ' through which only the best firms survive , eventually leading to a general benefit for society . Furthermore , they state that effectiveness should be the aim of markets , and therefore the regulatory over - focus on the ethics of intent misses the point ( see also Cooper et al . , 2020 ) ."	237716093	no
Despite the success and adoption of the CRISP - DM framework , there has been relatively little critical analysis of the assumptions and the design context which underlies the framework . The sharpest criticism of CRISP - DM may well be that the framework sets up the analyst to work alone , without the necessary tools and cross - disciplinary expertise needed to achieve outcomes in a real - world data or statistical practice ( Salz , Shamshurin , & Connors , 2017 ) . What literature has been published has been of two kinds . One strand of literature cites the framework as an integral part of surveying domain knowledge ( c.f . Esfandiari et al . , 2014 ) . A second strand of literature is comparative in nature ; it proposes and tests alternatives in an effort to build new frameworks ( c.f . Sharma , Osei - Bryson and Kasper , 2012 ) .	239658990	no
"The research gap identification involves reviewing the literature on various aspects of e - commerce and consumer rights protection issues spanning two decades . An objective review of 36 highly rated ( Scopus / Web Services / ABDC Ranking or the like ) e - commerce related publications from over 100 articles published in the last 20 years   suggests that the vast majority of earlier studies in this field have been conceptual / theoretical and generic . Regarding the legal framework of e - commerce and consumers ' rights protection , six current papers exclusively in the Indian context were available for analysis and review . The observations are that while the focus on consumer privacy and rights protection concerns is too general , the legal framework 's scrutiny has limited its scope . A review of selected studies on trust and consumer rights protection in e - commerce , as shown in Table 3 , reveals that application aspects , particularly legal issues , are lacking . Indian experience in e - commerce consumer rights protection through jurisprudence is nascent . Review studies show the research of a combination of management and law - related analysis in e - commerce and consumer rights protection is lacking . This scenario showed a gap in exploring a more comprehensive research opportunity in the Indian context . While e - commerce and electronic transactions have evolved as a global trend , it is noteworthy that Indian customers are still reluctant to place complete confidence and trust in commercial online transactions . Compared to conventional offline customers , online customers face greater risk in cyberspace because they negotiate with unknown vendors and suppliers . 16 The common issues 17 related to e - commerce are data privacy and security , product quality , uncertain delivery , no / low scope of replacement , the jurisdiction of filing complaints , and inconceivable terms and conditions ( Lahiri , 2018 ) . "" Country of origin "" of the product is a significant issue in e - commerce , particularly in cross - border transactions ( Bhattacharya et al . , 2020 ) . The inadequacy of the Consumer Protection Act , 1986 and other associated laws has surged the insecurity and lack of trust among online customers . The significance of digital payments pursued by the Government of India 's essential demonetisation policy-2016 has pushed for online transaction security and consumer protection in e - commerce activities . Therefore , the Consumer Protection Act , 2019 18 replaced the Consumer Protection Act 1986 and became effective with effect from 20 July 2020 , 19 while on 7 July 2020 , the Consumer Protection ( E - commerce ) Rules , 2020 20 came into force to address the e - commerce challenges . Nevertheless , it was evident that to attract additional investment and to engage with the global market , India , as an emerging country , had to gain the confidence of e - consumers . can be sent via email , messaging services , social networks and text messages to potential customers , raising issues of privacy and trust Act is silent on privacy & trust but Rules ensure customers ' protection from unsolicited correspondence can include an opt - in provision for permission to send messages Purchase Electronic contracts : Contract terms Marketplace e - commerce entities have to display information relating to return , refund , exchange , warranty and guarantee , delivery and shipment and modes of payment prominently to its users at the appropriate place on its platform Confusion on seller location and status Marketplace e - commerce entities would provide a consumer information regarding the seller from which he bought product , principal geographic address of its headquarters and all branches and name and details of its website for effective dispute resolution Cooling - off period :"	235784924	no
Italy , USD / CNY for China , and the DXY 6 index for the USA . All variables are expressed in terms of returns , calculated as the difference of the logarithm prices between the date ( t ) and ( t â 1 ) . All these data are extracted from the Bloomberg database from December 31 , 2020 , to assess the effect of the first wave of COVID-19 . The literature on the measures of the pandemic 's evolution presents some consensual proxies , namely mortality ( Zeylke and Bauchner , 2020 ) , newly confirmed cases ( Ashraf , 2020;Zhang et al . , 2020 ) , and excess deaths ( Woolf et al . , 2020 ) . This latter proxy has been criticized as it might be a biased estimation . Therefore , we retain , in our analysis , two proxies to measure the pandemic 's evolution : the daily growth in deaths related to COVID-19 ( hereafter , GD t ) and the daily growth in confirmed cases ( GC t ) , measured as the relative growth rate of the cumulative sum of deaths and cases between day ( t ) and day ( t â 1 ) , respectively . These data were obtained from the Johns Hopkins Coronavirus Resource Center .	232162521	maybe
Since mono - digestion of broiler manure is impractical due to the high nitrogen and dry matter content it was assumed that the manure is transported to a close by biogas plant , where it is codigested without any prestorage together with wetter feedstock ( e.g. liquid cow manure ) and feedstocks with a higher C / N ratio ( e.g. energy crops ) . However , since the focus was on the impacts associated with the broiler manure , these feedstocks were not modelled explicitly . Emissions from biogas plant operation were derived similar to the methodology and data of Effenberger et al . ( 2016 ) . Biogas was assumed to be used in a cogeneration unit with pilot injection engine to produce heat and electricity . The energy generation was calculated from the CH 4 production in the digester ( and the poststorage in the case of a closed storage ) , and with an electrical efficiency of the CHP of 38 % and thermal efficiency of 44 % . Electricity produced was assumed to replace energy generation according to the German energy mix , and thus negatively accounted with a carbon intensity of 0.588 kg CO 2eq per kWh , while for the energy consumed by the biogas plant a factor of 0.615 kg CO 2eq per kWh ( Moro and Lonza , 2018 ) was used . These values account for upstream emissions from extraction , refining and transport , as well as for trade between countries and losses in the grid . 40 % of the generated heat were assumed to be used externally , which is in line with the current situation in the German state of Lower Saxony ( Kralemann et al . , 2018 ) , to replace heating with natural gas . For the substituted natural gas use , losses of CH 4 of 2.3 % during production and transmission were also accounted for ( Alvarez et al . , 2018 ) . For the construction of the biogas plant an emission factor of 0.015 kg CO 2eq per kWh electrical energy production was assumed , ignition oil consumption was considered with 3.75 kg / h and engine oil usage with 0.0004 kg / kWh ( Effenberger et al . , 2016 ) . CH 4 was assumed to leak from the digester , the closed post - storage tank and the CHP unit ( 1 % of the produced gas at each stage ) . Furthermore , NO x emissions from the CHP were considered with 1000 mg / m 3 exhaust gas ( Aschmann et al . , 2007 ) . Liebetrau et al . ( 2010 ) showed that the methane emissions from the co - generation unit can range quite significantly between 0.17 and 3.72 % . The sensitivity analysis considered these two variants in addition to the default value of 1 % . Also considered was a variant of open digestate storage , and one where the share of thermal energy use was reduced to 0 % .	228984842	no
The contribution analysis has shown that , aluminum strips and polyester / nylon blends used in raw material processing , and water consumption in mask production for disposable masks , as well as cotton fabric used in raw material processing and detergent in the use phase for reusable cotton masks , were identified as the key factors contributing most to CF among the four types of face masks . However , the above parameters are of high variability and uncertainty due to monitoring errors , the diversity of processing techniques and the inconsistency of historical data series . Sensitivity analyses were therefore performed to fill these limitations by assessing the effects of changing the base case of these parameters . Each parameter was varied independently of all other parameters by Â±10 % from its base value , so that the extent of their impact on the base case could be assessed . Fig . 9 illustrates the results of the sensitivity analysis .	255373604	no
where C s is the specific capacitance exhibited by the working electrode in Faradays per gram ( F g â1 ) , V 1 and V 2 are the potential limits of the voltammogram essentially ÎV is the potential difference between V 2 and V 1 in volts ( V ) , Î½ is the voltammetric scan rate ( V s â1 ) , and m is the material ( MoO 2 ) mass in grams . The determined capacitance values are shown in Table 2 . The specific capacity is shown to be inversely proportional to the scan rate , which is due to ions , at lower scan rates , penetrating   Table 2 also shows a comparison of the unmodified G / AME , and MoO 2 -G / AMEs clearly demonstrating the electrochemical decoration improve the capacitance . GCD tests can also be used to evaluate the performance of the supercapacitors , these being the preferred method for DC testing . The GCD process is measured by the responsive potential with respect to time unlike CV , which evaluates data correlating with electrochemical phenomena arising at the electrode / electrolyte interface . The GCD measurement is completed in two steps : 1 ) a constant current charges a supercapacitor first , and then 2 ) the supercapacitor is discharged in a specific voltage range or charge / discharge time . Capacitive analysis of GCD was performed using a symmetrical two - electrode approach , such as the one described above ( an electrode spacing of 5 mm was utilized ) . Figure 2B shows three charge / discharge cycles of the G / AME again , utilizing the â1.4 V deposition potential held for 300 and 600 s to produce the G / AME - MoO 2 . The capacitance of the systems was calculated using Equation ( 1 ) where the well - documented correlation between current and capacitance is again observed , as shown in Figure 2C , D where high currents are observed to reduce the capacitance . In this case , the reduction is significant and results in an order of magnitude change in the performance , this is largely due to the filler quantity of the electrode and the relatively high resistance having a significant impact on the performance at the higher currents . Of note , Figure 2C shows the comparison of the G / AME with that of different electrochemical modification strategies ( potential and time ) where the MoO 2 -G / AMEs prepared by â1.4 V , 600 s give rise to the optimal capacitive response . Last , Figure 2D compares the    Table 2 where significant improvements are observed when using ionic liquids over that of conventional aqueous media . The inspection of Table 1 shows that the improved capacitance in ionic liquid is due to the wider electrochemical window that is not possible in the aqueous media . The capacitance output of the MoO 2 -G/ AMEs is compared to prior literature which demonstrates an excellent performance of 1212 F g -1 ( @1.48 A g -1 ) . Note that the various electrolyte and cell configurations do not allow direct comparisons to be feasibly made . Furthermore , the capacitive stability was explored via 1000 GCD cycles , with the resultant plots being shown in Figure 3 . It can be seen that the consistency of performance of the devices remains , in the most part , over 80 % , with the one exception being the MoO 2 modification at â1.4 V for 300 s , indicating there is a potentially less direct binding to the surface , and the MoO 2 is liberated from the surface during testing . It should be noted that all electrodes perform similarly to the unmodified G / AMEs , indicating that there is no inherent loss in cycling reliability after the surface modification is made . Overall , the optimal electrochemical decoration in terms of capacitive output and stability is clearly the electrochemical decoration of MoO 2 using a potential of â1.4 V held at 600 s.	235564605	maybe
The model was specifically implemented in C by the investigators and model outcomes were analyzed in R ( version 3.6.0 ) . Should the manuscript be accepted , all data and codes will be provided on GitHub .	235609133	maybe
One of the most exciting recent developments in laser dynamics is the pursuit of neuromorphic configurations with a view to novel data and information processing . See for example 94 and references therein . Biological neurons interact and process data via trains of excitable pulses . The excitable responses of optically injected semiconductor lasers are analogous but are many orders of magnitude faster . This speed , allied with the ubiquity , ease of control , and compact size of semiconductor lasers , has led to intense efforts to employ them as artificial neurons . QD lasers have started to feature prominently in such studies . In the GS only regime , several excitable regimes have been identified and studied 17,20,21 . However in this review , we wish to discuss efforts that utilise dual state mechanisms .	244745725	no
Foursquare API provides access to various capabilities , such as location search and venue details . The API has two different types of endpoints , i.e. , regular and premium , each providing access to various information . It uses two forms of authentication , i.e. , Userless Auth and User Auth . The former is used for server - side applications , while the latter uses OAuth 2.0 to provide authorized access to the API . In this work , we have used the Userless Auth authentication form . This authentication type requires the consumer key 's Client ID and Secret instead of an access token in the request URL . Various information , such as location data , i.e. , street address , postal code , longitude , latitude , and distance , can be fetched . We found around 60 parks across Dublin ( Fig .   2 ) and aggregated them at the postal district level . Some examples of such distribution are presented in Table 1 . The API also provides access to information about each venue 's level of popularity , i.e. , the counts of users who have liked a venue . We used such capability to assess the popularity of all parks detected . Each observation ( i.e. , park ) includes a unique string identifier , the postal district it belongs to , and the number of likes . The pseudo - code for the procedure is presented in Algorithm 1 . Given the procedures described in the algorithm , the number of likes for each park is revealed (   	235829512	maybe
Reviewer # 1 : In this study , the authors investigated genetic factors underlying thickness and volume symmetry of the human cortex by carrying out a genome - wide association study and subsequent follow - up analyses . They report 21 genomic loci that were significantly associated of which most were new findings . The carry these genomic loci forward into in silico follow - up analyses integrating different types of data . This is an interesting article that sheds new light on a brain phenotype that is associated with a wide variety of outcomes . Their provide consistent evidence of involvement of the cytoskeleton using gene - mapping and gene - set testing . I have several comments , questions and suggestions to improve the current version of the manuscript :	232244943	no
Experimental studies also do not provide a completely consistent insight . In a recent experimental study on the energy alignment at pentacene / C 60 interfaces , it was shown that the HOMO - LUMO gap at the interface varies from 1.50 eV for a face - on orientation to 0.75 eV for an edge - on arrangement of the molecules . [ 62 ] This is consistent with earlier work in which it was shown that interface energies of sexithiophene depend on the orientation of the molecules with respect to the interface . [ 63 ] On the other hand , the HOMO - LUMO gap at the interface between diindenoperylene and C 60 was found to be identical to that based on the HOMO and LUMO energies of the pristine materials . [ 54 ] In their review , Koch and coworkers conclude that predicting the interface dipole is difficult , [ 23 ] but from a more recent study on blends of five commonly used conjugated polymers with PCBM one can infer that the vacuum level shift scales with E HOMO , D . [ 7 ] The vacuum level shift ( Î ) and E HOMO , D from ref . [ 7 ] are collected in Table S2 and Figure S6 in the Supporting Information . A fit gives Î = ( 0.33 Â± 0.09)E HOMO , D + ( 1.76 Â± 0.43 ) [ eV ] . Although the number of data points ( 5 ) is limited and the correlation ( R 2 = 0.88 ) is not perfect , the vacuum level shift indeed decreases with more negative E HOMO , D . Because Î increases the offset between E HOMO , D and E LUMO , A at the donor - acceptor interface , it increases the V oc for donors with a low oxidation potential . In fact , when the slope of 0.33 is added to the slope of 0.75 found in our work , a total slope of 1.08 emerges , which is ( probably somewhat fortuitously ) identical to the slope of 1.08 recently found by Vandewal and coworkers between qV oc and E CT . [ 10 ] In summary , both theoretical and experimental studies suggest that different molecular orientations can give rise to differences in E CT at the donor - acceptor interface , amounting up to several tenths of an electron volt . While such deviations can explain the difference between a slope of 0.75 and a slope of 1 , over the â1 eV range of HOMO energies ( Figure 2 ) , they do not give a rationale for the result that V oc ( and hence E CT ) would change in gradual fashion with the HOMO energy , which is suggested by the small scatter ( < 0.1 eV ) in the experimental data with respect to the fit ( Figure 2 ) . Possibly , the formation of an interface dipole at the DPP polymer - PCBM interface , [ 23 ] which one can expect to be dependent on the HOMO level of the donor , explains the slope of less than 1 found in a plot of V oc versus E ox . SWV ( Figure 3 ) .	104323766	maybe
To study the returns and volatility connectedness of the top three cryptocurrencies ( Bitcoin , Ethereum and Ripple ) , the fiat currencies of the euro , GBP and Chinese yuan and the RavenPack Coronavirus Media Coverage Index ( MCI ) , the time - varying parameter vector autoregression ( TVP - VAR ) methodology developed by Antonakakis and Gabauer ( 2017 ) is applied . Some of the main advantages of this methodology are ( 1 ) that it adjusts immediately to events , ( 2 ) that there is no loss of observations , ( 3 ) that there is no need to arbitrarily choose the size of the rolling window because it adjusts automatically and ( 4 ) that it can also be used for low - frequency datasets . All these advantages of the time - varying parameter vector autoregression ( TPV - VAR ) methodology are very necessary when studying the effects of the COVID-19 crisis as the data series are somewhat short . Specifically , we apply this methodology to estimate the connectedness between these variables and the coronavirus media coverage index to analyse the degree to which the returns and volatilities of these variables have been affected by the COVID-19 pandemic crisis .	236449955	no
The objective behind the statement of the three hypotheses H4a , H4b and H4c is to explore the consequences of power imbalance and opportunism . H4a states that power imbalance is associated with reduced financial performance . We found support for H4a ( Î² = â 0.24 , t = 2.65 , p < 0.01 ) ( Table 5 ) . H4b states that the effect of power imbalance on reducing financial performance is stronger for non - cooperative members than for cooperative members . To test H4b , we conducted a multigroup analysis based on data from study 2 . The results of the multigroup analysis ( Table 6 ) showed significant differences ( Î²1 -Î²2 = 0.40 , p < 0.001 ) between both groups , such that the effect of power imbalance on reducing financial performance is stronger for the non - cooperative members ( Î² = â 0.15 , p < 0.01 ) than for cooperative members ( Î² = 0.25 , p < 0.01 ) . Concerning H4c , buyer / agent opportunism was found to be associated with reduced supplier financial performance ( Î² = â 0.08 , t = 1.64 , p < 0.05 ) ( Table 6 ) .	232294507	no
A prerequisite to fitting the data was the acquisition and subsequent image subtraction of the dark current of the photodiode and CCD camera and glare . Then , since the targets are finite and the lateral intensity data are used in the analysis , an exhaustive field correction methodology was developed to account for image field intensity inhomogeniety . As data at different focus positions were collected repeatedly , a focus metric 27 was applied to determine the relative focus positions and enable alignment of the sample plane in the vertical direction . Since the focus metric has 625 nm uncertainty , the data - sets were interpolated in 4 nm intervals for best focus alignment . Lateral positions were also aligned using correlation algorithms , necessary for theory to experiment comparisons during parametric fitting .	29896319	no
"These data suggest that , in Hup and Yuhup , only the words for numbers from one to five are fully associated with consolidated cardinal values . The other "" numerals "" are still seen just as phrases that accompany tallies . This suggestion is corroborated by a closer look at the level of lexicalization of candidate numerals . The phrases that originated the words for four and five are already lexicalized as true numerals . In Hup , four is hi - bab'nÃ­ , whose etymology is analysed by Epps as "" ( fact)have.sibling / accompany.nmlz . "" It is interesting to note that the word ends with a nominalizer ( nmlz ) , which converts the original phrase into a noun or , more precisely , a numeral . This clearly shows that Hup speakers see the cardinal value corresponding to four as an independent concept . In Yuhup , four is bab - nÃ­ - w'Çp , whose etymology is analysed by Epps as "" has - sibling - quantity . "" Here the use of the suffix -Çp ( quantity ) is what shows that Yuhup speakers are referring to the cardinal value of four , and not to the gesture or to the idea of having a sibling . The word for five in Hup has a few variants . One variant is not a word , but the phrase "" one hand "" ( Ä³ayÇp d'apÇh ) . But there is also another variant that displays a process of lexicalization through phonological reduction : Ä³aedapÇh . The Yuhup word for five has only one variant - cÃ£h - pÃµh - w'Çp - where the suffixÇp shows that speakers are referring to the cardinal value of five . In contrast to the words for one to five , the phrases that accompany tallies for values above five present several variants and do not show signs of lexicalization . To give just one example , Epps ( 2006 , p. 271 ) identified the following variants in Hup for the phrase accompanying the gesture for six : cÃ£p cob cakg'et Ä³ayÇp "" other finger stands up one "" Ä³ayÇp cob cakg'Ät "" one finger stands up "" cÃ£p cob popÇg "" other finger red - big (= thumb ) """	236393433	no
Editor 's Comments 1 . You will see that both Reviewer # 1 and # 2 raise concerns over aspects of the data analysis , regarding missing data handling and the use of a linear regression , respectively . We believe that in both of these cases it will be necessary to carry out additional analyses , as suggested by the reviewers , to resolve these important concerns .	242291039	no
A relevant question related to the completeness of the model is : to which extent does the readiness score translate into an actual alignment between sustainability strategy and operations in production systems ? Organisational behaviour ( e.g. , corporate culture , leadership style ) has a significant role in effective strategic alignment . Aspects of governance emerged during the interviews and were consequently included in an intermediate version of the model . Unfortunately , there was insufficient empirical data and literature data to substantiate all the four readiness levels on governance affecting sustainability performance . Further research is needed to explore this area empirically .	229426053	no
"Consider the scheme of an EPR - Bohm - type experiment . A large ensemble of two - particle systems is prepared "" in the singlet state "" by means of a physical procedure P s . In each run of the experiment a member of this ensemble is analyzed : a particle pair is emitted , one particle flying to the left , the other one to the right , and at remote places we measure the spin of the particles along chosen directions . Let a and b denote the events of measuring spin along directions a and b in the left and right wings of the experiment respectively . A and B denote the corresponding "" spin up "" outcomes in the detectors on the two sides . Empirical data are the relative frequencies of measurements a and b , and of the corresponding "" spin up "" outcomes A and B , over the ensemble of runs - for varying measurement directions a and b. On the basis of this observed statistics , one can calculate the conditional probabilities of sort p(A|a â§ P s ) , p(B|b â§ P s ) , and p(A â§ B|a â§ b â§ P s ) , defined by Bayes 's rule . 1 The minimal interpretation consists in the identification of quantum probabilities ( 3)-(4 ) with these conditional 2 probabilities of macroscopic measurement events :"	244072974	no
Behavioural Data - Response times ( RT ) were defined as the time to make a correct response . We explored graphically all of the data in MATLAB . Specifically , we examined the distribution of the data using histograms , and normal probability plots . Any response time in the top one percentile ( i.e. , Î± = 0.01 ) of a participant 's data was identified using a Grubbs ' Test and removed .	3792998	no
This activity includes the cycle from data preparation to evaluation as depicted in figure 3 . Data has been prepared for the risk model . This means that the relevant data has been selected and that the quality of the data has been checked and improved . Now the risk model can be constructed . As a model the decision - tree has been chosen . The tree starts with a conditional node at the top , which contains all cases . Then , the decision tree used conditional rules to split the cases into separate branches , based on the amount of risk each branch contains . The decision tree has calculated which variable is the best to split the cases on , based on the risk associated with the cases . Each of these branches can be followed by another branch . In this way the tree created a hierarchy of risks .	239658990	no
In addition , Google Trends data have been widely used to inform epidemiological studies . Ahmad et al . ( 2020 ) presented a study to assess the predictability of COVID-19 incidence using Google Trends data on internet search interest of certain gastrointestinal symptoms and terms . The study stated that these internet search data could be useful for predicting COVID-19 cases in the United States . Similarly , Asseo et al . ( 2020 ) used taste and smell loss - related search terms to track the cases in the United States and Italy and discussed the benefits and limitations of using Google Trends data in disease surveillance . Internet search data are also useful for improving forecasts for certain infectious disease activities , for improving surveillance , and supporting real - time decisions . In earlier studies , Google Trends data have been used in forecasting influenza activity and predicting related outcomes ( Araz et al . , 2014;Yang et al . , 2015 ) . Kandula et al . ( 2019 ) used Google Trends data to forecast influenza - associated hospitalization in the United States and suggested that these web - search data can provide important real - time information and improve the accuracy of forecasts for hospitalizations .	255441206	no
We explain employment expectations using as explanatory variables the Google Trends index related to COVID-19 and some control variables : unemployment rate ( % ) , according to ILO definition and harmonized index of consumer prices ( HICP , where 2015=100 ) . The data for control variables and employment expectations are provided by Eurostat . Seasonally adjusted data were used for all the variables .	237473259	maybe
Ethical Approval This paper uses publicly available data and was conducted in compliance with the Declaration of Helsinki ( 2013 ) on research ethics .	233783689	no
Similar to entrepreneurial journalists in the European contexts we studied , for some of our African interviewees , advocacy and activist approaches took center - stage in their data practices , and in some cases , this appeared to cause tensions with journalistic goals , as they tried to combine practices of facilitating with gatekeeping in various ways . For example , a respondent from Africa Check described activism as complementary to the truth - telling mission of journalism :	159434250	no
"Prior research has also highlighted how consumers ' risk perception influences their use of public transportation , such as ride - sharing services or metro trains . ( e.g. , Wang et al . , 2019;Basu & Ferreira , 2021;Garaus & Garaus , 2021 ) . Chernozhukov et al . ( 2021 ) use Google Mobility data to measure the impact of the social distancing policies during the COVID-19 pandemic . Using geo - spatial analyses , a large telecommunication data set is also used to monitor human mobility during the COVID-19 pandemic ( Persson et al . , 2021 ) . We complement this stream of research by using the developed predictive model to forecast consumer mobility in three US cities using publicly available data from Google that reflects "" real - time "" consumer trends . Such data is available for a majority of regions / cities across the globe , and our algorithm could be used to forecast retail mobility , given the data ."	255441206	maybe
Block function : components which are involved in data transmission . This is a critical and necessary feature for IoT edge devices . Many protocols and technologies exist for IoT communication such as ZigBee , NB - IoT , LoRa , Bluetooth and WiFi [ Samie et al . , 2016 , Lethaby , 2017 . Each one comes with different trade - off in terms of range , data rate , and power consumption .	233740019	no
The distinction between data and phenomena introduced by Bogen and Woodward ( 1988 ) was meant to help accounting for scientific practice , especially scientific theory testing . Their article and the subsequent discussion is primarily viewed as internal to philosophy of science . In this paper , we apply their distinction to the general technique of conceptual modelling , a widespread methodology that is also employed in philosophy . Distinguishing between data and phenomena will allow us to shed some light on a number of philosophical and metaphilosophical issues : it provides for a stance from which one can assess the status of empirical methods in philosophy , and it helps to distinguish between good and bad uses of the technique of conceptual modelling in specific arguments employed in analytical philosophy .	12017797	no
The BoM of the battery cell components and the type of data source ( i.e. primary or secondary ) used in the cell modelling are shown in Table 4	128181737	maybe
Although research on news coverage of election campaigns has been ongoing since the 1940s ( Patterson , 1980 ) , the coverage of referendums in the news is comparatively an under - researched area ( De Vreese and Semetko , 2004a : 714 ) . This article uses frame analysis , a method that has made a substantial contribution to our understanding of election coverage , to look at the way the 2014 Scottish referendum on independence from the United Kingdom was represented in a range of Scottish newspapers . Drawing from the analysis of the specific case and reflecting on previous studies of campaigns on other topics and national contexts , it addresses the following question : did the press coverage of the referendum generate different frames compared to those of election campaigns , as would be justified by the different nature of these political events ? The findings have implications both for our understanding of referendums as mediated events and for evaluating the performance of the news media in explaining what a referendum is about . This latter is particularly significant because the media are for most people a key source of information on politics , and how they define referendums matters ( Wettstein , 2012 ) . Despite the dramatic decline of the print press internationally and in Scotland specifically ( Dekavalla , 2015 ) , it remains a significant part of the ' relay race ' of discourses in the public sphere ( Garton et al . , 1991 : 100 - 103 ) , whereby print , broadcast and online media co - create the mediated public debate and re - represent political discourse on different platforms . The 2014 referendum has been hailed as an occasion where grassroots groups reinvigorated the debate on social media and challenged the dominance of traditional news platforms ( Law , 2015 ) , but these accounts also recognize that the press and broadcasting remained important ' in setting the parameters of official political discourse as well as registering the ways in which social media replicate the established patterns of political discourse as much as it threatens to dislodge them ' ( Law , 2015 : 7 ) . Newspapers may have had a relatively restricted print readership , but they were read by political elites and by contributors to broadcast and online media , they often became themselves direct or indirect contributors to online conversations , while the material dominating the debate on ' old ' media was also the main material for discussion on social media ( Paterson , 2015 : 23 ) . For this reason , newspapers are worth studying , as they remain a component of this multiplatform debate . A discussion , however , of how newspaper coverage was interpreted and used by other parts of the public sphere , or by voters in their decision - making process , would require a wider range of data , and the influence of the coverage on the outcome of the referendum falls outside the scope of this article .	29267727	no
The indicator function , I(Îµ i.tâ 1 ) , is equal to 1 if Îµ i.tâ 1 < 0 , and 0 otherwise . The dynamics of Qfor the ADCC model are given as : where A , B , and G are n Ã n parameter matrices and z â t is a vector of zerothreshold standardized errors , which are equal to z t when below 0 , and 0 otherwise . Q and Q â are the unconditional matrices of z t and z â t , respectively . To test these models and their relevance for our research question , we construct a daily dataset collected from different sources . The next sub - section presents the data and describes their proprieties .	233549739	no
Interestingly , our findings offer empirical support to Freeman 's ( 1994 ) seminal work in which he rejects what has been referred to as the '' separation thesis . ' ' Freeman ( 1994 ) describes stakeholder theory as '' one of many ways to blend together the central concepts of business with those of ethics . Rather than take each concept of business singly or the whole of '' business '' together and hold it to the light of ethical standards , we can use the stakeholder concept to create more fine - grained analyses that combine business and ethics ( â¦ ) '' ( p. 409 ) . In fact , our findings suggest that respondents belonging to different stakeholder networks , such as business groups and community groups , share a common sense that using purely legal or economic reasoning will often lead to neglecting aspects related to social or ethical concerns . In fact , from a stakeholder viewpoint , there is no evidence in the findings of this study that a differentiation between different types of business responsibilities is useful or supported . On the contrary , such an approach seems to anger respondents particularly form a community perspective and is also seen as '' out of date '' and unhelpful by many business respondents . As such , theories in CSR and ethics lag behind this much more holistic view of business evidenced in the findings of this study by holding on to a legal or regulatory debate in the CSR literature ( Mackey et al . 2007;Mueckenberger and Jastram 2010;Russo and Perrini 2010;Svendsen and Laberge 2001 ) . Interestingly , this call for more integrated management theory corresponds with a debate in the management literature on the purpose of business ( Alexander and Douthit 2016;Hsieh 2015;Nichols 2014 ) as well as with reviews in CSR and ethics literature on the holistic nature of stakeholder expectations ( Aguinis and Glavas 2012;Gond et al . 2011;Liston - Heyes and Ceton 2009;Lucea 2010;Matten and Moon 2008;Orlitzky et al . 2015 ) . Our study starts to integrate aspects that can be seen to relate to legal , economic , ethical , and social aspects of business by presenting a process , outlined in Fig . 1 and discussed in the managerial implications below , that is developed from our empirical data to form a stakeholder perspective . As such , it may be seen as a first step toward developing a more integrated approach to management theory and practice .	158680894	no
In these models the social influence inherent in the network structure means that groups tend towards consensus . Typically enough actors gather data about the best option that the entire group eventually ends up accurately believing that it is , indeed , best . But in many versions of these models communities can also fail to form a good consensus . Zollman assumes that actors in his models myopically choose whichever option they currently believe is most successful . This might correspond to a gambler playing the bandit arm she likes best , or a scientist generally testing the theory they find most promising , or a doctor prescribing only the medication she thinks most efficacious . In some cases , a string of misleading data can lead an entire community to prefer a suboptimal option . Once the entire group focuses on this option , they stop testing other ones and settle on a poor consensus . Zollman ( 2010 ) gives a case study exemplifying this latter possibility . In the early 20th century , scientists debated whether stomach acid or bacteria was the primary cause of peptic ulcer disease . A highly influential study by Palmer ( 1954 ) convinced the research community that bacteria could not live in the stomach , resulting in a consensus on the acid theory . This research was flawed , but was only finally overturned by the work of Warren and Marshall ( 1983 ) .	237459907	no
( 2)-(4 ) ] allows us to gain insight into the roles of the various terms in the observed temperature dynamics . The cooling crystal temperature ( T x ) initially drops rapidly with the slope given by â âÎ· c ( T c ) P abs ( T c ) /C x ( T x ) before the radiative load ( from the chamber ) and conductive load ( through the link ) slow down this process , as shown in Figure 7a . The coldfinger , however , initially experiences a small temperature increase due to the small fluorescence leakage Î² l at a rate given by âÎ² l Î· ext P abs ( T c ) /C f ( T c ) before cooling from the crystal reverses this process in a time scale approximated by Ï â K l ( T c ) /C l ( T c ) , as shown in Figure 7b . Beyond this point , both the crystal and cold - finger continue to cool and reach the steadystate condition with a temperature difference Ã°T f Ã T x Ã final % 2P link load = K l Ã°T l Ã , where P link load denotes the total heat load power ( parasitic and useful ) carried through the link . The data used in Figure 7 and the corresponding fits were obtained for N rt = 1 ( one laser roundtrip ) . The parameters obtained from these fits are Î² l â0.2 % , Î· c ( T c ) â1.2 % at Î»=1020 nm ( corresponding to Î· ext â0.992 ) , Î± b â2.1Ã10 â4 cm â1 , and Ïµ x % Ïµ l % 0:38 . The values for Î· ext and Î± b are in close agreement with previously measured values for this 10 % Yb 3 + -doped YLF crystal . Î² l also agrees with the calculated value from the raytracing model . T c was fixed at 283.15 K , which is the final measured temperature of the clamshell . With the above parameters fixed , the model predicts a final coldfinger temperature T f = 135.0 K with a temperature drop of ÎT = T f âT x = 6.8 K across the link when the number of roundtrips is increased to N rt â¥30 , as expected in the Herriott cell arrangement . Considering the simplicity of our model , these calculated values are in excellent agreement with our observed values of T f = 134.9 K and ÎT = 6.1 K ( Fig . 6a ) . The above calculations assumed a negligible heat lift ( P lift = 0 mW ) in comparison to the existing radiative and fluorescence loads . Furthermore , the measured initial slope of 0.31 K / mW ( Fig . 6b ) is in good agreement with âT f /âP lift â 0.31 K / mW obtained from the model calculations . In a final experiment , the laser - cooled HgCdTe sensor was used as part of an FTIR spectrometer and the infrared absorption spectrum of a sheet of low - density poly - ethylene ( LDPE ) was measured ( Fig . 8) . This is the first demonstration of a sensor cooled by solid - state optical refrigeration used as part of a practical device . Figure 8 shows the absorbance spectrum of the same sample measured with an equivalent HgCdTe sensor cooled with liquid nitrogen to 77 K. The bandgap energy E g = hc / Î» of this HgCdTe sensor corresponds to a cutoff wavelength of Î» = 16.7 Âµm . The primary noise source is due to statistical fluctuations of the thermally activated dark current within the detector element . The dark current I d is proportional to the number of carriers that are thermally excited across the bandgap and thus varies approximately as I d âexp ( âE g /k B T f ) , with the corresponding noise amplitude varying as ffiffiffiffi I d p	52135802	no
"To evaluate these research hypotheses , we collected not only data from Google but also search statistics from the ECDPC ( European Centre for Disease Prevention and Control ) and the OECD , and data on new cases and new deaths and other information required for control from 37 OECD member countries . The time period subject to analysis was the period from February 1 , immediately following the WHO 's declaration 3 Although the WHO 's announcement was made on March 11 , we analyzed the RSV as of March 12 . Because the standard time varies by country , and we also needed to consider the time of the release of WHO 's announcement , we judged that March 12 would be the date that best reflects the public 's response . Furthermore , we also considered that there were many countries in which the highest value of RSV ( 100 ) was reached on March 12 , or in other words , in which the RSV showed a rapid increase , as shown in Table 2 . that COVID-19 's risk assessment at the global level was high , to May 11 , which is two months from March 11 , the date on which the WHO assessed COVID-19 to be a pandemic ( WHO , 2020 ) . Table 1 describes the variables included in this study , our sources and related references ( OWID , 2020 ) . 4 Here , we collected search information from 37 OECD countries via Google Trends , and since the data was collected by country , all search data was collected as daily relative search volume , that is , a normalized value based on the search volume on the day with the highest domestic search volume during the data collection period ( with its value set as 100 ) ( Jun et al . , 2018 ) . Note that Google Trends provides RSV for "" coronavirus , "" considered the thesaurus equivalent of COVID-19 ( Google_Trends , 2020 ) . In the case of non - English speaking countries , statistics were also processed with the word "" coronavirus . """	232282755	maybe
For each of the S&P 500 firms , we follow previous event study practice , searching for announcements in the leading news agencies PR Newswire and Business Wire ( Barua & Mani , 2018 ) . Our data collection spans the period between December 2019 and October 2020 , sufficiently capturing the first and main wave of the pandemic in the U.S. For the keyword search string , we combined the firm name with variations of COVID-19 or Corona , to establish a relation to the pandemic , and with variations of keywords such as disrupt , impede , countermeasure , response , decline , suspend or react , to ensure a causal - reactive relationship between the COVID-19 crisis and the firm response . The keyword search led to a total of 6926 article texts . In a first step , we screened all headlines and excluded articles that were captured by our search string , but were no firm announcements . Examples include analyst reports , trading forecasts , and market outlooks . We further eliminated all duplicate articles that referred to the same COVID-19 response announcement . This first step left us with 802 potential announcements of firm responses to the COVID-19 crisis . In a second step , we then screened the full announcement texts , applying the following exclusion criteria to the 802 remaining announcements :	255571157	maybe
Our DFT calculations confirm this understanding . Figure 5a , Li extraction ) but also in Li x NiO 2 ( whose Ni 3 + /Ni 4 + -redox reservoir is large enough to cover full Li - extraction ) ( Figure S12 , Supporting Information ) . Gray and red data points represent the formation energies of the structures without ( black ) or with ( red ) condensed O - species developed upon ab - initio molecular dynamic ( AIMD ) simulation at 1500 K ( see the Experimental Section for details ) . We observe short OîO bonds with the bond length of â1.45 Ã ( peroxide ) or â1.29 Ã ( superoxide ) when performing AIMD ( at 1500 K ) for highly Li - extracted DRX structures ( Figure S13 , Supporting Information ) .	234686321	maybe
In this study , we aim to measure the global economic impact of COVID-19 on the main cluster economies . The outbreak of COVID-19 began at the end of 2019 in China and later spread to other countries , such as the USA , beginning March 2020 . Therefore , assessing the impact of this crisis on the economic system imposes a restriction on the data frequency used . In other words , we are constrained by the daily frequency of the main economic indicators . Interestingly , we analyze the stock market 's performance , measured by stock market returns , and we investigate investor fear sentiment dynamics based on implicit volatility , meaning the investor market 's expectation of 30 - day forwardlooking volatility . The currency market is a macroeconomic indicator of the behavior of the economy as a consequence of the constraints on trade , product and service transactions , and the mobility of capital flows .	232162521	no
Comparison specifications . Lastly , these analyses were supplemented by a comparison specifications section , putting into context the effects found in the SCA . To do so , we performed a literature review to select four variables in each dataset that should be positively correlated with psychological well - being , four that should be negatively correlated with psychological well - being and four that should have no or little association with psychological well - being . A SCA was run for each of the variables and the mean of the technology use variables present in the dataset , graphing their specification curves . These methods provide a way for researchers to transparently , openly and robustly analyse large - scale governmental datasets to produce research that accurately depicts associations found in the data for both academia and the public .	58006454	no
"Investigating multi - component systems composed of three or more elements with a desired structure and properties is very challenging . Traditionally , the development of new materials is generated from a single experiment ( "" trial and error "" and "" directed research "" ) at a time ; this process results in high cost , long manufacturing and analysis time , and exponential growth as the complexity of the material increases . However , the vast compositional space of multi - component systems , such as HEMs , hinders selecting suitable material candidates for many different applications . [ 7,8,10,62 ] Therefore , significant efforts have been dedicated to developing combinatorial synthesis approaches ( aided by artificial intelligence ) and theoretical predictions to hunt specific materials of interest for industry and academic research . [ 63,[64][65][66][67][68][69 ] A synergy among experimental , theoretical predictions , and artificial intelligence will significantly aid the development of multicomponent materials for targeted properties . A common trend in the workflows [ 64,67,[69][70][71][72 ] presented in different fields suggests a path toward developing autonomous and automated protocols , as depicted in Figure 5 . The workflow starts with combinatorial synthesis methods , automated characterization techniques ( with or without a feedback - measuring loop ) , automated data analysis , creating a material database or material library , and selecting materials of interest . The complete workflow can be closed by selecting samples of interest for further synthesis and characterizations . [ 73 ] However , without theoretical predictions or computational approaches , the workflow can be considered a fast "" trial and error "" approach ."	240481156	no
Risk perception is broadly defined as evaluating the subjective probability of a negative outcome and its consequences ( SjÃ¶berg et al . , 2004;Menon et al . , 2008 ) . Prior research suggests that risk perceptions have two dimensions , susceptibility and severity ( El - Toukhy , 2015 ) . Susceptibility refers to the likelihood of experiencing a health risk , whereas severity refers to the seriousness of the risk ( Brewer et al . , 2007 ) . The local and national cases and death data due to the pandemic publicized by the media and captured in the Pandemic Impact metrics provide consumers with a measure of the pandemic 's prevalence in their local communities , impacting their risk perceptions in terms of their susceptibility to the pandemic . Further , such risk assessment by consumers affects their decision to search for information ( Maser & Weiermair , 1998 ) . Information search for pandemic - related paraphernalia captures the risk perception in terms of severity . Moreover , mortality data may also directly affect consumers ' perceptions of the severity of the risk associated with the pandemic . Therefore , in our empirical analysis , we incorporate the effect of both these dimensions of risk perception on mobility .	255441206	no
When less limescale deposit is present the electricity usage of household appliances with heating elements decreases while the Table 3 Inventory data of all softening techniques when reducing the hardness of 1 m 3 water by 1,0 mmol / L.   ( Hofman - Caris et al . , 2016;Evides , 2019;de Ridder et al . , 2019 ) . Original data was provided for softening depth of 0.91 mmol / L and is adjusted to softening depth of 1.0 mmol / L assuming a positive linear relation ( except for water losses ) . b In the PR , the efficiency of the softening chemical ( NaOH ) is 83 % ( Hofman - Caris et al . , 2016 ) . In the WSR this is only 58 % ( Dits , 1995;Evides , 2019 ) . c Evides (   expected lifespan increases . Similar to Godskesen et al . ( 2012 ) , the domestic appliances affected by the softened water were identified as washing machines , coffee machines , kettles and dishwashers . Godskesen et al . ( 2012 ) determined the electricity usage and lifespan of household appliances based on hardness of 3.62 mmol / L , 2.54 mmol / L and 1.45 mmol / L. For central heating systems , boilers and scaling in hot water pipes no data on the effect of scaling could be found . Thus , any potential energy - saving effect and lifespan increase due to softening could not be taken into account . The data provided by Godskesen et al . ( 2012 ) , is adjusted to the water hardness in our two scenarios in two steps . First , we interpolate the data to obtain the data for 2.4 mmol / L. Secondly , as we argued that with a hardness of < 1.5 mmol / L the amount of limescale deposit is negligible , the electricity consumption and lifespan of the household appliances for 1.4 mmol / L and 0.0 mmol / L are set to the same values presented by Godskesen et al . ( 2012 ) , at 1.45 mmol / L.	222117836	maybe
The inclusion and exclusion criteria were pre - established before any data collection , and are :   6 . Untreated severe depression ( depression of greater than or equal 20 on the Geriatric Depression Scale ) 7 . Acute illness 8 . History of , or current , alcohol abuse 9 . Significant visual impairment that would inhibit ability to participate in study , with distance vision > 20/40 10 . Drug induced or inherited Parkinson 's Disease 11 . Significant camptocormia 12 . Any medical condition which the investigator determines would compromise the safety for the subject .	13928352	no
There was no significant correlation between passenger volume changes before and during the pandemic and the daily passenger volumes of the MTR station on weekdays , whilst a significant correlation ( p = 0.027 ) was observed on the weekend before and during the pandemic . This implies that Hong Kong citizens intentionally avoided going to densely crowded public places during the COVID-19 pandemic ( Fig . 4a ) . In the pandemic week , there was a greater reduction in MTR use at the weekend than for weekdays , however , the correlation was not very significant ( p = 0.082 ) . No such trend was seen before the pandemic ( Fig . 4b ) . The number of passengers at Quarry Bay station during the pandemic week , a business district , decreased by approximately 68 % compared to that of the non - pandemic week ( Fig . 4b ) . In the nonpandemic week , the borders and amusement areas have 10%-70 % more visitors on Sunday than during the rest of week . The detailed spatial distribution of daily MTR ridership is shown in Fig . S6 . Fig . 5 shows that the modularity of the MTR network and the proportion of the population flow within communities on weekends are both higher than those on weekdays , with the exception of the CNY holiday . These data suggest that people travelled more locally ( within communities ) on weekends . After CNY , both figures tended to decrease overall , possibly suggesting that increasing awareness of the pandemic led people to reduce unnecessary travel , whilst daily commutes for work , which normally occur across communities , were not heavily influenced . The detailed network information is found in Fig . S5 .	231880553	maybe
"Public opinions could also influence the design of public policies . A classic study conducted by Page and Shapiro ( 1983 ) examines public opinions and policy data of the U.S. from 1935 to 1979 , and finds out that very often public opinions cause policies to change , and could influence policies more than policies affect opinions . Therefore , an analysis of public sentiment could provide valuable insights into how policies should be implemented . For instance , Chung and Zeng ( 2016 ) have collected Tweets related to U.S. immigration and border security policies , extracted the sentiment and emotion of Tweets , and helped policymakers build a "" social - media - based public policy informatics "" system that could identify key opinion leaders and community activists ."	236251116	no
and excitation density at which the data is evaluated with decay times TPL , HLI LS Ï varying from tens of ns to tens of Âµs within our experimentally accessible range ( see grey data points in Figure 7 ) . Note that for the highest values of ÎE F , also Auger recombination might contribute to the decay time . This result highlights the importance of comparing data at equal charge - carrier density or quasi - Fermi level splitting [ 80 ] and to identify - e.g. , from differential decay time versus quasi - Fermi level splitting plots - whether the decay in a certain range is consistent with radiative or with some type of SRH recombination . In this context , the radiatively dominated region ( light blue ) can be identified by the exponential slope being proportional to âexp ( â ÎE F /(2k B T ) ) . The part of the data showing the smallest slope of decay time with ÎE F ( light green ) is indicative of recombination that is approximately linear in electron and hole density , which should be SRH recombination in the bulk and at interfaces .	239883912	no
Data were shown as mean Â± standard error of the mean . The statistical analysis of the data was analyzed using GraphPad Prism 8.0 . Comparisons for normally distributed data with two groups were analyzed by two - tailed unpaired t - tests . Comparisons for normally distributed data with three or more groups were tested by one - way ANOVA . Mann - Whitney tests were applied to determine statistical significances of data with the non - normally distribution . Statistical differences for all tests were considered significant at p < 0.05 .	237441205	no
Hydrogen and Oxygen Measurements : Oxygen was analyzed in the headspace of the anodic compartment of the PEC cell using an Ocean Optics fl uorescence oxygen probe ( FOXY - R ) . The probe was inserted through a tightly sealed septum and continuous O 2 readings ( O 2 partial pressure ) at 1 s intervals were made throughout the experiment . For electrocatalytic O 2 production with FTO|TiCo OEC , a potential of 2.0 V versus RHE was applied between 0.5 and 6.5 h of the experiment with the fi rst 0.5 h as control with no applied potential . For PEC O 2 production by nanoBiVO 4 |TiCo OEC in a three - electrode system , the cell was operated at an applied potential of 1.23 V versus RHE in the dark during the fi rst 0.5 h ( control experiment ) , followed by 1 h under standardized light illumination ( 100 mW cm â2 ) and another 0.5 h in the dark ( control experiment ) . For O 2 quantifi cation in PEC cell I , an applied bias of 0.8 V was applied in the dark during the fi rst 0.5 h ( control experiment ) , followed by 1 h under illumination and another 0.5 h in the dark ( control experiment ) . In the case of tandem PEC cell II , the cell was operated at an applied bias of 0.6 V with the same dark - light - dark intervals . The control experiment is used for determining leakage of O 2 from the atmosphere into the cell and the resulting data were corrected for the derived rate of O 2 leakage . The total amount of O 2 evolved was determined as the sum of O 2 measured in the headspace using the ideal gas law plus dissolved O 2 in the solution calculated by Henry 's Law .	98368654	no
The concept of an ANN - driven intelligent metasurface obtained by integrating a programmable metasurface with deep learning techniques is illustrated in Fig . 1 . As shown in Fig . 1b , the designed reflection - type programmable metasurface is composed of 32 Ã 24 digital meta - atoms with a size of 54 Ã 54 mm 2 , and each meta - atom is integrated with a PIN diode ( SMP1345 - 079LF ) for electronic control . More details on the designed meta - atoms and programmable metasurface are provided in Supplementary Figs . 1 , 2 . With reference to Fig . 1b , our intelligent metasurface has active and passive modules of operation . In the active module , the metasurface system includes a transmitter ( Tx ) to emit RF signals into the investigated region through Antenna 1 and a receiver ( Rx ) to detect the echoes bounced back from the subject through Antenna 2 . In the passive module , the system has two or more coherent receivers to collect the stray Wi - Fi waves bounced back from the target subject . Figure 2 schematically illustrates three building blocks of the data flow pipeline . In Fig . 2 , the microwave data collected by the intelligent metasurface are instantly processed with an imaging CNN ( the first CNN of the intelligent metasurface , called IM - CNN-1 for short ) to reconstruct the image of the whole human body . More details on IM - CNN-1 are given in the Methods section and Supplementary Fig . 3 . Then , a well - developed Faster R - CNN 47 is adopted to find the region of interest ( ROI ) within the whole image , for instance , the chest for respiration monitoring and the hand for sign - language recognition . Afterward , a modified Gerchberg - Saxton ( G - S ) algorithm is implemented to come up with the optimal digital coding sequence for controlling the programmable metasurface so that its radiation wave is focused onto the desired spots , as presented in Supplementary Information . After receiving the command from the host computer , the programmable metasurface will adaptively focus the EM waves onto the desired spots to read the hand signs or physiological state . As such , not only can unwanted disturbances be excluded effectively , but the SNR of echoes from the local body parts of interest can also be remarkably enhanced by a factor of 20 dB , improving the subsequent recognition of hand signs and vital signs ( see Supplementary Figs . 6 , 7 ) . We develop the other CNN ( IM - CNN-2 ) to process the microwave data to recognize hand signs . In addition , human breath is identified by time - frequency analysis of the microwave data . More details on IM - CNN-2 and the respiration identification algorithm are given in Supplementary Fig . 4 . Several sets of representative results are recorded in Supplementary Videos 1 , 2 .	203610414	maybe
"However , as data journalism matures , diversifies , and moves from the margins to the centre of journalism practice , academic interest seems to be shifting from ontological , epistemological and identity issues to a need to understand data journalism 's "" rituals of meaning - making "" ( Broersma 2010 , 16 , 19 ) and its impact on society . This requires that we look at data journalism as both a socio - discursive practice and the material product of that practice . Because meaning is not created in a vacuum , but constructed through the encounter of producer and audience , there is a demand to investigate how the "" imagined audience "" ( Litt 2012 ) factors in the production of data journalism artefacts . "" Imagined "" connotes a certain lack of control on the producers ' part , their control being relinquished the moment a data journalism story is published . We argue that a more useful concept to explore in an era of increased audience quantification and measurement is that of the constructed audienceor the various ways newsroom audiences are conceptualised and configured in the encoding process . "" Constructed "" , in this context , refers to the ways data journalism producers try to predict , during the design process , what user experience ( UX ) pathways have the potential to generate audience engagement ."	156033788	no
The relationship between economic growth and energy consumption is considered an urgent issue because the relationship between the two implies many important policy implications ( Chiou - Wei et al . , 2008;Wang , Q. and Wang , L. , 2020 ) . Energy is indispensable for the functioning of the global economic system ( Haider and Adil Masudul , 2019;Mahmood and Ahmad , 2018 ) . Many production and consumption activities use energy as a necessary input . At the same time , economic growth may lead to more energy consumption ( Lee and Chang , 2005;Wang and Zhang , 2020 ) . With the growth of global economy , international trade has developed rapidly ( Shahbaz et al . , 2017;Wang and Zhang , 2021 ) . According to the data collected from the World Development Indicators database , the share of global imports and exports of goods and services in GDP increased from 38.53 % in 1991 to 59.65 % in 2014 ( The World Bank , 2020 ) . Through increased trade flows , the world economy is increasingly integrated ( Trung , 2019 ) . The deepening of globalization makes the economic fluctuations of countries not only limited to their own borders , but may also spread to other parts of the world . Therefore , the spillover effect between countries can not be ignored in the relationship between economy and energy consumption , especially for major economies like China .	231875597	no
The data used in this paper come from China Electricity Council ( 2020 ) . With the pandemic from severe to mild , China has gradually shifted from industry closure to industry recovery , and the process of social restart has also begun . Thus , electricity consumption in 2020 is significantly different from previous years . Fig . 2 shows China 's electricity consumption over the period 2015 - 2020 . The black line in the figure represents the historical value from 2015 to 2019 , and the yellow line represented the value in 2020 . The black curve displays that China 's petroleum consumption presents an overall upward trend with seasonal characteristics in history . The electricity consumption in 2020 shown by the Yellow curve indicates a trend of decreasing first and then rebounding quickly . These data characteristics , which are different from those in previous years , further confirm the obvious impact of the pandemic on China 's electricity consumption .	236294095	maybe
Publication bias is a critical issue in meta - analyses . We took the necessary measures to avoid bias at the data collection and coding stage , and statistical tests are available to detect publication bias . The commonly used tests to detect publication bias are Rosenthal ( 1979 ) Fail - safe N andDuval andTweedie ( 2000 ) trim - and - fill method . As reflected in Table 2 , the Fail - safe N suggests that 31,391 studies reporting null results are required to bring the overall results of this meta - analysis to a point of non - significance . The results for Duval and Tweedie ( 2000 ) trim - and - fill method indicate that the number of missing studies due to publication bias using estimator R 0 is 23 . The funnel plot presented in Fig . 2 shows our sample distribution along with 23 imputed studies .	244672081	no
Vis - OCT ( Figure 1 ) uses a supercontinuum light source ( SuperK , NKT photonics ) with a working bandwidth from 520 nm to 630 nm . The illuminating power on the cornea was measured to be 0.8 mW , which is within the ANSI laser safety standard ( Supplementary laser safety standard calculation ) . Briefly , we used a free - space interferometry configuration to minimize the dispersion , where the probing beam was collimated and split by a cube beam splitter into the reference and sample arms . The beam in the sample arm was steered by a pair of galvanometer mirrors to scan the focal point across the retina . The two beams from the reference and sample arms recombined at the beam splitter and were collected by an optical fiber . The fiber delivered the light to a home - made spectrometer that collected the interference spectral fringes by a line - scan CCD camera ( spl2k , Basler ) . The full - width - halfmaximum ( FWHM ) of the spectral coverage was â¼85 nm , giving us 1.7 - Î¼m axial resolution . The lateral resolution was estimated to be 15 Î¼m in the retina . Two scanning protocols were performed . Protocol 1 raster - scanned a 20 Â° squared retinal area with 256 Ã 256 pixels in each direction at a 25 kHz A - line rate . Protocol 2 used dual circle scanning that scanned two concentric circles centered at the optic disk with 4096 pixels in each circle at a 70 kHz A - line rate . The dual circle scan pattern was repeated eight times and the results were averaged to remove motion artifacts and pulsatile flow pattern . Protocol 1 was used for sO 2 measurement and microvascular imaging . Protocol 2 was used for blood flow measurement , which requires much denser scanning . For visualizing the microvasculature , the mean intensity projection of a slab at depth range from 150 Î¼m to 200 Î¼m with respect to the retinal surface was taken to capture the microvasculature . The system schematic ( Supplementary Fig . S1 ) , scanning , data acquisition protocols , and data processing ( Supplementary Fig . S2 ) are explained in detail in the Supplementary Information .	17028996	maybe
Briefly , a 532 - nm nanosecond - pulsed fiber laser beam was coupled to a single mode optical fiber . A 1310 - nm continuous diode laser with a 40 Î¼m coherence length was used to interrogate the reflected light from the sample with a spot that was co - focused with the excitation beam . The collimated interrogation beam passed through a polarized beam splitter ( VBA05 - 1550 , Newton , New Jersey , USA ) to direct vertically polarized light through a Î»/4 zero - order wave plate ( Thorlabs Inc. , Newton , NJ , USA ) into a beam combiner ( BC ) . Then , it was scanned across the samples via a 2D galvanometer scanning mirror system ( GVS012 / M , Thorlabs , Inc. ) along with the excitation beam . The scanning mirrors were driven by a two - channel function generator ( AFG3022B , Tektronix Inc. , Beaverton , OR , USA ) . The scanning light was then focused tightly using a 0.4 - numerical - aperture objective lens ( M Plan Apo NIR 20X , Mitutoyo , Kawasaki - shi , Japan ) . The light reflected back through the wave plate was converted from circular to horizontal polarization and then reflected at the polarizing beam - splitter interface , directing the maximum possible intensity of reflected light to a 150 - MHz bandwidth InGaAs photodiode ( PDA10CF , Thorlabs , Inc. ) . The output of the photodiode was amplified using an RF amplifier ( 5900PR , Olympus , Center Valley , PA , USA ) with a band pass filter ( 1 - 50 MHz ) and 26 dB gain and then digitized using a four - channel , 12 - bit PCI digitizer ( CSE1242 , Gage Applied , Lockport , IL , USA ) at a sampling rate of 200 million samples per second . A two - axis mechanical scanning system was used for imaging larger fields - of - view . Photoacoustic remote sensing P Hajireza et al lateral sample movement down to a 1.25 Î¼m step size , while maintaining scanning mirrors in a fixed position . The scanning region size was limited by the onboard capture card memory , though multiple captures or data streaming could be implemented to extend the imaging range to the full reach of the motor stages . Images which were captured using the galvanometer scanning mirror system used fixed fast and slow scanning rates of 65 and 0.25 Hz , respectively . Large field of view images were formed using 2axis mechanical scanning and were performed with a 2.5 Î¼m step size at a 2.5 KHz acquisition rate . For example , to produce a 4 Ã 4 mm scan , roughly 17 min were required . The pulse repetition rate of the excitation laser was fixed at 40 KHz for all of the images shown in the manuscript . Figure 3a demonstrates PARS imaging of~7 Î¼m carbon fiber networks at~1 mm depth in water . This depth is significantly greater than the 40 Î¼m coherence length of the probe beam , such that any local optical interferometry of reflected light between the target and surface signals was rejected . This large field of view image was captured using~1 nJ excitation pulse energy and~4 mW interrogation power on the sample using the mechanical scanning method Photoacoustic remote sensing P Hajireza et al explained in the previous section . The signal - to - noise ratio ( SNR ) , defined as the average of the maximum amplitude projection pixels in a region of interest over the standard deviation of the noise , was quantified as 60 Â± 3 dB. A representative PARS signal as a function of time is shown in Figure 3b . This was acquired by imaging a single carbon fiber at a depth of approximately 0.25 mm in a 20 % intralipid scattering medium ( reduced scattering coefficient of~10 cm â 1 at 532 nm wavelengths , similar to previous work 43 ) . The photoacoustic signals were recorded coincident with the laser excitation pulse . Only a 75 ns time delay between PA signals and excitation laser pulses was observed , which is consistent with the group delay of the analog filters of the RF amplifier . When a carbon fiber target was positioned at different depths below a water surface , no additional time - of - flight was measured . This demonstrated that signals were associated with initial pressures rather than propagation - delayed surface oscillations . Such signals were only present when an absorbing target was imaged , eliminating concerns of pump - beam contamination in the photodiode signal . More information about time - of - flight measurements is given in Supplementary Information , Section 2 . In addition , to demonstrate that PARS image contrast was due to transient modulations associated with excitation pulse absorption and not inherent scattering , a set of experiments were performed as shown in the Supplementary Information , Section 3 . Figure 3c demonstrates the power spectral density of PARS signals from a single 7 Î¼m carbon fiber placed at 0.25 mm depth in a 20 % intralipid scattering medium . The â 3 dB ( blue line ) and â 6 dB ( green line ) bandwidth are measured as 54 and 65 MHz , respectively . These measurements were acquired without an amplifier and with only a 25 KHz analog high - pass filter and a 1 MHz digital high - pass filter . Representative time domain signals are shown in Supplementary   Figure 1b . Fourteen hundred A - scan signals from the carbon fiber were averaged for the bandwidth calculation . These time domain signals were windowed with a 300 ns length hamming function around the signal and then zero padded to 200 samples , prior to conversion to frequency domain .	52131320	no
Based on the significant accumulation of lithium in the electrodes indicated by the electrochemical data , the ICP - AES results and in the HAXPES spectra for the lithiated electrode , it could also be expected that the Li z Si peak should be seen in the delithiated spectra . No such peak can , however , be seen in these HAXPES spectra in Figure 4 . While this could indicate that the Li z Si concentration , within the about 30 nm thick surface region probed in the HAXPES measurements , was too low after the 6.25 - hour delithiation step , this explanation is unlikely since the spectra were recorded about seven days after the delithiation experiment . There should consequently have been sufficient time for lithium to diffuse from the internal parts of the electrode to the ( delithiated ) electrode surface . However , as this would generate a surface region in which all the probed silicon atoms had analogous lithium environments only one photoemission peak should be seen , in good agreement with the experimental results . The small shift in the Li x Si peak toward lower binding energies with increasing cycle number hence constitute additional support for an increased lithium concentration in the delithiated electrodes .	199648051	no
Digital coherent technology is also a pivotal element for optical communications including data center and access networks 45 . In principle , a coherent system is capable of retrieving both the amplitude and the phase information of optical signals , however at the price of a relative sensitivity to the phase noise of the transmitter and local oscillator 46 . In order to maintain a stable heterodyne detection , narrow linewidth semiconductor lasers are required 47 . At 40 Gbit/ s , the required linewidth is to be of 240 kHz , 120 kHz , and 112 kHz for 16PSK , 16QAM , and 64QAM , respectively 48 . Apart from the coherent technology , low noise oscillators are also needed for optical atomic clocks , frequency synthesis , high - resolution spectroscopy and distributed sensing systems [ 49][50][51][52 ] . In such applications , it is important to use semiconductor lasers featuring both low frequency noise ( FN ) and relative intensity noise ( RIN ) 53 . Indeed , the RIN degrades the signal - to - noise ratio ( SNR ) and the biterror rate ( BER ) hence affecting the performance of a high - speed communication system 54,55 . Although a low RIN floor can certainly be achieved by increasing the bias current of the laser source , it goes with an unwanted extra energy consumption . In radar applications , the RIN has also to be closed to that of the shot noise level over a bandwidth ranging up to 20 GHz hence showing the importance of generating coherent states of light for low - noise oscillators 56 . To meet these goals , QD and QDash lasers are strong candidates because they feature a low population inversion factor and reduced amplified spontaneous emission ( ASE ) noise 57 .	236505289	no
"One group of studies highlight the benefit to firms that are able to employ the dynamic capabilities necessary to take advantage of smart things ( Teece , 2012 ) . Within organizations , smart things may complement the capabilities of employees thereby enhancing the overall ability of the firm to efficiently and effectively operate , particularly if the smart technology helps people to free up time for the tasks they are best able to carry out ( Marinova , de Ruyter , Huang , Meuter , & Challagalla , 2017 ) . Other studies highlight how smart things may endow firms with new abilities for flexible adaptation , explaining how organizations rapidly adapt to changing circumstances in order to profit from new opportunities or avoid damaging threats ( Drnevich & Croson , 2013;Teece , Pisano , & Shuen , 1997 ) . These scholars posit that the type of digital data available in the IoE offers rich new opportunities for enhancing this flexibility , whereby a "" superadditive "" effect can boost the data 's value when it is used by organizations with a high level of flexibility ( Drnevich & Croson , 2013 ) ; having more data makes having a given amount of flexibility more valuable , and vice versa ."	213757082	no
The strongest form of pre - registration involves both registering the study ( with a commitment to make the results public ) and closely pre - specifying the study design , primary outcome and analysis plan in advance of conducting the study or knowing the outcomes of the research . In principle , this addresses publication bias by making all research discoverable , whether or not it is ultimately published , allowing all of the evidence about a finding to be obtained and evaluated . It also addresses outcome switching , and P - hacking more generally , by requiring the researcher to articulate analytical decisions prior to observing the data , so that these decisions remain data - independent . Critically , it also makes clear the distinction  	6326747	no
Through a multiple linear regression model , we correlated the share of users who abandoned PT during 2020 , with income equality variables , PT service characteristics , quality of service aspects and pandemic severity data . Empirical findings revealed that the presence of income inequalities resulted in lower abandonment rate , which could mirror the behaviour of captive users . Simultaneously , regarding PT trip characteristics , results imply that PT vehicle transfers and waiting time are the two most critical trip segments as per user opinion , for continuing or not using PT modes . Additionally , results confirm our initial hypotheses that : ( a ) in cities with higher pandemic impact ( as per number of deaths ) users were deterred to use PT and ( b ) improved disinfection in vehicles could contribute to sustaining ridership . Based on the empirical findings of the regression model analysis , specific policy implications can be derived . The methodology of this paper aims at identifying the key factors that influenced travel behaviour , in terms of abandonment of PT , during the COVID-19 era . These factors may highlight suitable measures , which can be followed by PT and governmental agencies , towards maintaining PT ridership during pandemic and post - pandemic circumstances . At first , the proper and frequent disinfection of vehicles could enhance the perception of safety to PT users and convince them to select PT . Likewise , changes in the PT network , towards the direction of providing more direct trips , can contribute to limited interaction between passengers and thus minimize the possibility of infection . In the same sense , PT operators should ensure that waiting facilities ( bus stops , metro platforms , etc . ) adhere to the health and safety protocols ( clean surfaces , proper ventilation , etc . ) , in order to build confidence among users that PT is not a hotbed of COVID-19 contraction . Furthermore , in regions with higher income inequalities , operators should expect a comparatively lower decrease in PT ridership and thus , the application of PT preferential treatment measures ( dedicated bus lanes , traffic signal priority , etc . ) ( Pulichino & Coughlin , 2005 ) would increase commercial PT speeds and ultimately improve PT service frequencies so as to address crowding events .	255826268	no
This study compiled and analyzed the data from several sources to present an informed set of best practices on how to safely conduct a public hearing during the pandemic . For the first data set , nine counties in the state of Florida were analyzed by evaluating the current number of COVID-19 cases reported , broadband availability for the region , and public hearing strategies these counties have implemented . For the second set , a recent survey of citizens throughout Florida regarding how the COVID-19 pandemic has affected their county and municipality 's public hearing process was examined .	242496299	no
The recent acceleration in developments by various conventional and non - conventional actors resulted in a growing attention for the area WSK , exemplified by the 2019 ABN AMRO Circular Economy Award being granted to WSK . Moreover , the municipality started reassessing the policy - document of 2012 in 2019 ( Photo 5 ) . Table 1 provides a detailed , structured overview of the social entrepreneurs in WSK , related to the data of the parameters .   	230551072	maybe
The case of the promise of green 5 G is significant because , whilst 5 G has been widely established to be far more energy efficiency than 4 G , anticipated dramatic increases in mobile data trafficat least in part driven by 5 G -could potentially counteract efficiency improvements resulting in an overall increase in network energy consumption . This of course occurs amidst the backdrop of increasing urgency in efforts to mitigate the worst effects of climate change , which include commitments on the part of many telcos to adhere to various climate targets . The realisation of the promise of green 5 G is therefore a matter of great significance , as are the ways that the promise of green 5 G -like all successful promises and expectationsdirects research and innovation efforts towards particular technologies and approaches and away from others . This case is also interesting from the perspective of the sociology of expectations because , notwithstanding some exceptions ( e.g. Kriechbaum et al . , 2021 ) , most work that has employed this conceptual approach has focused on cases where technologies are in the early stages of their development . The present study is different in this regard because 5 G 's commercial roll out began during the time period covered by our research .	254302320	no
Figure 2e , the change in rate of sorption over long times in Figure 2d shows the most deviation between model and data due to the difficulty in describing the dynamic absorption process . The model for 50 wt% MnCl 2 /SiO 2 was also used to describe pure MnCl 2 ( Figure 2b ) by removing the first term ( adsorption ) and re - fitting the kinetic constants . When applied to the first four cycles of absorption for pure MnCl 2 , the model indicates a decrease in surface area of several orders of magnitude ( Figure S4 , Supporting Information ) , thus confirming the surface area measurements ( Table 1 ) and suggesting the surface area of used MnCl 2 may in fact be much lower than measurable .	233828232	no
where p I = âL BB âË q I are the generalised momenta of the system . This condition can be satisfied by going to a reduced description where the centre - of - mass position ( and velocity ) has been removed from the system . Such a description can be obtained , for instance , by defining the centre - of - mass variables Q I = q I â q cm , where q cm = I m I q I , and then eliminating one such variable in terms of the others ( the choice is arbitrary ) . In such a reduced description , the variable q cm no longer appears . This indicates that , in BB theory , changing the centre - of - mass position ( and velocity ) , even in a time dependent way , has no effect on the variables satisfying the dynamical constraints ( 7 ) . Importantly , satisfaction of these constraints reduces the 24 Corollary VI states that this is also the case for isolated systems undergoing arbitrary linear accelerations . number of independently specifiable initial data for the system by 6 : the centre - of - mass position and velocity , which are underdetermined by the equations of motion of the BB system . The largest , well - posed autonomous system that satisfies ( 7 ) is therefore 6 dimensions smaller than the original Newtonian system . Moreover , when the dynamical constraints ( 7 ) are satisfied , it is easy to see that the original Lagrangian transforms in such a way that	232222968	no
To derive the data set of the studies for the analysis , we first used keywords accounting , education , and ethic * 1 as a search engine in the Web of Science . In total , 385 articles matching all three keywords were found in July 2020 . Next , we limited the search to the following science categories : business finance , business , education educational research and ethics , which scaled the list of relevant articles down to 273 . Third , we defined article as a document type ( after which 205 articles remained ) and English as a document language ( after which 192 articles remained ) . To prevent any omission of the relevant articles , we also ran searches with different combinations of keywords , including teaching , accountant and similar , all resulting in comparable sets of articles .	235401332	yes
Our sample consists of companies that are included in the 2004 SiRi ( Sustainable Investment Research International ) database , which holds sustainability profiles of companies included in the MSCI World Index . As this index includes the 1500 largest ( by market capitalisation ) equities in the world , our sample represents large corporations from developed markets . SiRi is an international network of socially responsible investment research organisations collecting a range of CSR information of companies for their customers , which are mainly institutional investors . 2 The network members use the collected information also for their local databases and other investment services . The SiRi data have been used in prior research ( van Nimwegen et al . 2008;Prior et al . 2008;Surroca et al . 2010 ) . In addition , the local databases of some of the SiRi members - among which Kinder Lydenberg Domini ( KLD ) , Michael Jantzi Research Associates , and Pensions and Investment Research Consultants - have been extensively used in previous studies . The SiRi database is broadly considered a reliable and high - quality information source on CSR data . The companies that are profiled in the database are all large public companies .	254384414	yes
Nguyen ( 2020 ) suggests a framework for COVID-19 detection using data obtained from smartphones sensors such as cameras , microphones , temperature , and inertial sensors . In Italy , as well as in many other countries around the world , the machine - learning method is used to learn and obtain knowledge about disease symptoms based on collected data . This approach offers an inexpensive and fast method for coronavirus detection compared to the traditional medical kits or professional scanners , because data inferred from the smartphone sensors can be used efficiently in different individual applications . For example , Rao and Vazquez ( 2020 ) recommended a method to collect people 's travel history and their common sign using a phone - based online interview . The collected data can be analyzed with machine learning algorithms to study and estimate the threat of infection ; thus supporting early recognition of high - risk cases for isolation . It reduces the spread of the virus to vulnerable people . Allam and Jones ( 2020 ) suggest the use of AI and data sharing regulatory procedures for better global understanding and management of urban health during the COVID-19 pandemic . For example , additional benefits can be obtained when AI is integrated with IoTs devices installed in many smart cities for early outbreak detection . AI methods demonstrate great efficiency in supporting decision makers in the virus containment process when health data are collected and shared across and among smart cities .	234046079	no
The introduction of digital technologies has led to drastic changes in the field of journalism . One example of such a change is the deployment of algorithmic news recommenders ( ANRs ) that affect online news consumption habits ( Moeller et al . 2020 ;) by transforming news delivery by offering users personalized news selection ( Moeller et al . 2018;Bastian et al . 2020 ) . Combining AI - driven techniques with data about content ( e.g. topic ) and audience features ( e.g. user 's age ) , ANRs learn users ' news preferences to predict what content might be interesting for them ( Karimi , Jannach , and Jugovac 2018 ) or even to help them achieve their epistemic goals ( Sullivan et al . 2019 ) .	237282779	no
In this paper , we focus on this problem in the medical context . Evidence aggregation in medicine can involve a host of data from different sources , such as observational studies , randomized controlled trials , meta - analyses , and expert judgment , which often confirm conflicting hypotheses . Throughout this paper we refer to aggregation procedures involving evidential input of this sort , i.e. , high volume , highly diverse and potentially conflicting evidence , as ' large - scale ' evidence aggregation .	255060743	no
By decreasing the starting pH , an increase in the transport of protons is expected , and therefore a decrease of the built - up pH gradient . We tested different electrolyte composition of Na 2 SO 4 and H 2 SO 4 , keeping the overall sulfate concentration at 1 m. Figure 3D shows the results of the pH change over time , with different starting compositions as stated by the specific concentrations of H 2 SO 4 . For comparison , results for a nonporous device are shown as well , for which the anode and cathode compartments were connected by a salt bridge . These   results corroborate those of the wireless PEC device of Reece et al . , who concluded that a pH gradient between the cathode and anode compartments was the reason for the observed rapid loss of performance . [ 7 ] Upon lowering the starting pH , a longer period of time was required before depletion of protons in the cathode compartment became evident . Even for 0.9 m Na 2 SO 4 and 0.1 m H 2 SO 4 a pH increase of 0.3 units was measured after 20 min . Not until a pure electrolyte of 1 m H 2 SO 4 was used , a stable pH over time was observed , as is seen in Figure 3D. The importance of the implementation of micropores in the device is further underscored by the change in pH observed for a nonporous device operated in 1 m H 2 SO 4 . After only 20 min of operation , already a substantial increase in pH was observed . This observation agrees with the findings of Modestino et al . [ 13 ] Our results indicate that the produced / consumed ion needs to be the major charge carrier when the build - up of a gradient is to be prevented . We tested also lower concentrations of H 2 SO 4 in the absence of Na 2 SO 4 ( data not shown ) , but in this case the lower electrolyte conductance became problematic .	132976355	no
with R 2 = 0.85 and R 2 = 0.77 , respectively . The standard error found for the slope in Equation ( 7 ) suggests that the data can also be reasonably fitted with a slope of 1 . In this case , Deming regression gives a slope of 1.07 ( Figure 8) . Hence , our results can not be interpreted as Adv . Energy Mater . 2019 , 9,1803677    evidence for a slope deviating from unity . A similar conclusion was recently reached by Wang et al . for ten different conjugated polymers where the slope was â(1.03 Â± 0.13 ) and the offset was â(4.54 Â± 0.08 ) eV. [ 40 ] The spread in the data around the best - fit line in Figure 8 can be partially attributed to the experimental uncertainty of the data points : about Â±0.05 eV for E HOMO , SWV and about Â±0.10 eV or in some cases slightly more for E HOMO , UPS . We note that deviations larger than these error margins can not be explained on the basis of an exceptionally large uncertainty in the analysis of the UPS spectra or SWV data . The largest deviation from the best fit is obtained for polymer 9 ( 2TzDTP ) for which Figure 6 shows that E HOMO , UPS is more negative than the expected value based on V oc . Equation ( 7 ) places Fc / Fc E + at â4.59 eV versus the vacuum level . Using this value , we have determined the SWV HOMO energies ( E HOMO , SWV ) in Table 1 . We can also use this value to determine the LUMO energy level of PC 61 BM using the redox potentials measured with SWV ( Figure S3 , Supporting Information ) . Using the experimental value of E red , SWV = â0.98 V versus Fc / Fc + and Fc / Fc E + = â4.59 eV , we find a E LUMO , SWV = â3.61 eV for PC 61 BM , which is in fair agreement with value of â(3.84 Â± 0.04 ) eV found by Yoshida . [ 52 ] Of course , UPS and SWV are not expected to yield in all cases the same value of the HOMO energy . Most importantly , the ionization energies probed are electrostatically screened to different extents , due to the different local environments in which the ionized molecules reside . In UPS , the signal originates predominantly from molecules at the surface , where the screening due to the polarizability of the environment is weaker than that in the bulk . [ 30 ] The signal as probed by voltammetry of molecules in solution is influenced by the screening by the metal electrode and by the electrolyte solution . [ 36 ] In the case of voltammetry on thin films , it is not well known to what extent the ionization process takes place at the outer film surface , in contact with the electrolyte , or in the bulk of the thin film . In any case , also the presence of the electrolyte and the metal electrode will affect the redox potential . Additional complications include 1 ) the effect of the vacuum surface or the interface with the electrolyte on the energetic disorder , 2 ) the different roles of molecular relaxation during the excitation , and 3 ) the different roles of possible surface or bulk contaminants . These effects may also depend on the specific material properties .	104323766	no
Researchers ( e.g. Dhir et al . , 2021;Kumar et al . , 2021 ) frequently utilise structural equation modelling ( SEM ) as a data analysis approach . However , the two types of SEM ( covariance - based , or CB - SEM , and variance - based , or VB - SEM ) have certain prerequisites related to data , as discussed in recent studies ( e.g. Luqman et al . , 2021 ) . For instance , CB - SEM has certain sample size requirements . In addition , the sample must not include outliers , and the data should be linear , normally distributed , homoscedastic and free from multicollinearity . While VB-   SEM has more relaxed sample - related requirements , it also requires the data to be linear and possess other multivariate characteristics ( Hew et al . , 2019;Talwar , Talwar , Tarjanne et al . , 2021 ) . Consequently , scholars suggest using an ANN approach for data that exhibit both linear and non - linear associations and deviate from other multivariate characteristics mentioned above ( e.g. Leong et al . , 2020 ; . ANN is an artificial intelligence and machine - learning based approach that uses input , hidden and output neurons to generate output in terms of the influence of antecedents on outcome variables . The network of neurons is trained with new information to conduct analysis and generate output . The training process is driven by a two - way ( i.e. forward and backward ) information flow . Multiple rounds of the training process help to minimise errors . In the current study , we applied ANN by dividing the available data into training and testing data to generate output in terms of the relative importance of each proposed antecedent . We used the root mean square error ( RMSE ) values of various models to evaluate the accuracy of the predictions .	245008959	no
where CF prod ( x ) is the carbon footprint of a single product ( kg CO 2 -eq ) , and a single product here refers to a mask ; x is the specific stage in the product life cycle , x = 1 - 5 , representing raw material extraction , industrial manufacturing , distribution and transport , consumer use and end - of - life disposal respectively ; AD prodi ( x ) is the activity data of GHG emission source i for the specific life cycle stage x ( the unit varies with the emission source ) ; EF i , j is the emission factor of GHG j emitted by source i , i.e. , the amount of GHG j emitted per unit of source i ( the unit varies with the emission source ) ; GWP j is the global warming potential of GHG j ( dimensionless ) ; m is the number of GHG emission sources ; n is the number of GHGs . The total CF of the products can thus be calculated by multiplying the number of products and washes defined by the functional unit . The calculation methods of disposable and reusable products are described in Formulas ( 2 ) and ( 3 ) respectively :	255373604	no
DUTY , D 1 m / D 6 Figure 3 . The diffusion resistances of 6.6 m-(pyramids , first row to the reader ) and ACN - solvated 1 m EMIM - BF 4 ( boxes , second row ) electrolytes in model carbons C micro , C meso , and C hierarch . Green tags represent corresponding DUTY - factors for EMIM - BF 4 illustrating the extent to which the ionic diffusion increases upon dilution from 6.6 to 1 m , that is , D 1 m / D 6.6 m. For comparison , data obtained on 1 m TEA - BF 4 /ACN in ref . [ 11 ] are represented as cylinders ( third row ) . Results for the cations and anions are color - coded according to the legend ( cations - orange , anions - blue ) . The impact of confinement on the pore diffusion is representatively divided according to the range of diffusion resistances as follows : low ( < 10 ) , moderate ( 10 - 100 ) , and high ( > 100 ) .	236550603	maybe
"We collect data for the 12 - week period from 3rd March 2020 to 29th May 2020 for our analysis . This time frame is chosen because the World Health Organization ( WHO ) classified the COVID-19 outbreak as a pandemic on 11th March 2020 . This led all state and county governments to issue a stay - at - home order . Around the third week of May 2020 , there was a shift in government policy , allowing businesses to reopen in a phased manner , albeit with restrictions . Furthermore , the stay - athome order was modified to a "" safer at home "" order ."	255441206	no
"Opacity problems generate mismatched communication and uncertainty in interactions between collaborators which make it very difficult to coordinate practices in productive ways . In other cases the problems might be less directly due to a lack of technical insight into one another 's practices and more due to the fact that the conceptual and methodological distance between the cognitive domains is very large . As mentioned philosophers often identify such divides , and sometimes propose ways , in theory at least , to bridge them . However sometimes there might be no straightforward way to translate or link models or concepts from the different domains , without solving very complex problems neither domain is well - adapted to solve with its current sets of practices . Importantly it may require significantly restructuring practices in those domains in ways which conflict with the way practices in those domains have been designed and optimized . In such cases domain specificity becomes a particularly intransigent obstacle . One particular such problem in economics / ecology collaborations is the problem of scale . Most experimental work and models in ecology are of relatively small scale compared to those in economics ( working over limited spatial regions , with limited numbers of variables ) . This fits the range at which experimentation can be manageably carried out , and thus the range over which reliable models can be produced . Such models can guide individual land - use decisions , such as harvesting strategies for resource management . On the other hand economics usually works with larger - scale models relevant for regional , national or international policy formation built using observational data ( Vermaat et al . 2005 ) . It at these levels that there is a demand for policy relevant contributions from ecology to economic models . Unfortunately there are no simple reliable ways of scaling up models produced in one limited context to another larger context . As Stevens et al . ( 2007 ) put it , scaling up requires the addition of assumptions that introduce further error , while requiring complex arguments that reduce "" the transparency of results and makes them difficult to explain to non - specialists ( Carpenter 1998 ) "" . On the other hand scaling up experiments to a large - scale is not only an enormously expensive option but such experiments become difficult to control and replicate . Arguably ecology has settled on its scales of experimentation and model - building because they fit well these practical and epistemic constraints . There is no easy pathway to transforming the field . The result however is that ecological models and economic models are for the most part not in scale alignment , and thus lack conceptual compatibility . There is likely no easy way to resolve this incompatibility . 9 At certain scales of economic analysis economics and ecology can be in temporal and spatial scale alignment . For example in the field of resource management and harvesting for individual land or resource users , such problems connecting model variables can be much more straightforward . However even here conceptual problems of these kinds may arise ( MacLeod and Nagatsu 2016 ) . For instance economic optimization readily requires growth models that are valid outside the physical situations used to build the model . Optimization algorithms survey factual as well as counterfactual possibilities . However this requires a usually larger range of validity than most models in the domain of resource management are usually constructed to achieve . Most are built using statistical regression techniques , and are valid only for the domain encompassed by the data used in their construction . In ecology the models that can provide better reliability are called process - based models . Process - based models attempt to model the causal processes underlying ecological growth . This enables reliable model predictions outside the range of data used to build the models and over longer time - scales , both essential factors in economic optimization . However such models require considerably more work and expertise ( particularly computational and biological expertise ) to produce requiring longer time frames . Knowledge in particular of the relevant processes which determine a system 's response to future climate conditions is "" extremely limited "" and difficult to produce ( Cuddington et al . 2013 , p. 9 ) ."	36385693	no
Major Concern : Handling of Missing Data . As is common in research in this area , there was a high percentage of missing data . This makes the choices about how to address this problem especially important . The authors applied only one technique and therefore could not provide sensitivity analyses that would , in my view , provide a more robust understanding of the data . The claims they make about the effectiveness of their SSI are strong and bold , which puts more pressure on them to show that their effects are robust ( or not ) when applying different techniques to handle their missing data . The approach they chose - multiple imputation of all participants who were randomized - may artificially inflate the power of their tests . Of the 2452 participants who were randomized , 398 did not complete their condition , and 686 did not complete the follow - up measure . ( It is unclear to me if this 686 figure includes the 398 who did not finish their condition , or if it means that 686 of those who finished their condition did not complete the follow - up measure ) . Regardless , it appears that about 25 - 45 % of the sample either a ) did not complete their intervention , b ) did not fill out their follow - up measure , or c ) both . When rates of missing data are this high , the technique(s ) used to address missing data can meaningfully change a study 's findings and the way that those findings are interpreted . The authors implemented the Amelia II algorithm in R to impute missing data . Although they state that this approach is more conservative than other approaches , such as listwise deletion and last - observation - carried - forward analyses , this is true only under certain conditions . Those conditions may have obtained in this dataset , but there is no way to know this from what they report . Many multiple imputation approaches take the pattern that is observed in the available data and essentially apply that pattern of findings to the missing data . This is partially why these approaches are only considered valid if there is reason to believe -or evidence in support of -a claim that the data are Missing at Random . Missingness in the present dataset are extremely unlikely to have resulted from random processes . In particular , rates of dropout across the conditions differed substantially ( from 10 % in ABC to 20 % in Personality ) and significantly ( per a chi square test ) . The authors should address this limitation . Possibilities include implementing at least two alternative approaches to missing outcome data , such as :	242291039	no
The method used to develop a data - collection technology used and collect data has been analyzed Source : The authors . In addition , different categories of keywords divided into the types of methodology approach used in the reviewed articles were defined . As explained above in the description of the literature review process , these included technical , theoretical , experimental , and data - based methods .	233029680	no
"The CFTW is programmed in Python 2.7 . It estimates crop water use and the main components of the soil water balance combining the single crop coefficient approach presented in the "" FAO irrigation and drainage paper No . 56 crop evapotranspiration "" ( Allen et al . , 1998 ) with global datasets for soil , crops and climate . Adjustments to crop phenology , soil water balance simulations and management options have been made to increase accuracy , represent current knowledge or to enhance usability . The adjustments are described in the following section 3.1 and summarised in Fig . 1 . Finally , model and data are integrated on - line and accessed via a user - friendly interface at https://coolfarmtool.org using any internet browser ."	146803893	yes
"First , research on the effect of ( in)consistency in CSR communication ( e.g. , Kim & Choi , 2018;Scheidler et al . , 2019;Skard & ThorbjÃ¸rnsen , 2014 ) and on the role of greenwashing or symbolic CSR ( De Jong et al . , 2018;Donia et al . , 2019;Nyilasy et al . , 2014 ) focuses on different types of inconsistencies . That is , studies vary according to the source of information where ( in)consistent information is provided from . On the one hand , companies provide CSR information , but inconsistencies arise as the information on a same or similar issue ( e.g. , CSR ) provides differing or even contradicting signals . For instance , there could be an imbalance between the extent companies pursue external versus internal CSR initiatives ( Scheidler et al . , 2019 ) or a ( mis ) fit between pre - versus post - crisis CSR initiatives ( Kim & Choi , 2018 ) . In these cases , previous results indicate that inconsistencies are detrimental to stakeholder reactions ( e.gKim & Choi , 2018;Scheidler et al . , 2019 ) . On the other hand , inconsistencies may result from different information provided by different source , for instance , when the company communicates about its CSR initiatives in a different way than third parties do or objective data is showing ( e.g. , Nyilasy et al . , 2014;Skard & ThorbjÃ¸rnsen , 2014 ) . The study by Nyilasy et al . ( 2014 ) , for instance , indicates that if a company exhibits high environmental performance , green advertising results in more unfavorable brand attitudes than no advertising . Our study provides indications in the same direction , since we found a dampening effect of CSR performance on the relationship between CSR communication and the ( average ) affective evaluation of CSR - related messages . Based on the arguments provided by Nyilasy et al . ( 2014 ) , observers of CSR - related messages may start being skeptical about the "" true "" environmental / CSR performance when a company with high CSR performance strongly promotes its CSR performance for marketing purposes . Differences in the findings of the effect of inconsistencies provide a future research opportunity to further investigate how attributions about inconsistencies differ depending on the source and type of information ( objective vs. subjective ) that CSR communication is provided by ."	254385691	no
Although our study leverages unique data , the results must be interpreted considering limitations that present opportunities for future research . First , coding the posts on whether they had a CSR content or not was based on text mining to identify combination of terms that are indicative of CSR posts . While this procedure is objective , it results in an imperfectly accurate classification of posts . It can be expected that both false positives ( i.e. , posts misclassified as containing CSR content ) and false negatives ( i.e. , failures to identify true CSR posts ) exist . From a measurement theory viewpoint , these misclassifications represent random measurement error which downward biases the effect sizes . As our effect sizes were not only significant but also substantial , the download bias was apparently not so substantial that it led to the inability to find effects . On the contrary , it can be expected that because of the error , true effect sizes are even larger . As a future research implication , we suggest the application of modern forms of supervised text mining algorithms ( Foster et al . , 2016 ) not only to enhance a most accurate classification but also to estimate the amount of accuracy versus measurement error .	254385691	no
In a second step , by means of multiple correspondence analysis ( optimal scaling ) , we represent in a 2 Ã 2 dimensional space the most important hazards , shocks and stresses identified by the 100 RC participating cities . Our hypothesis is that hazards and acute shocks cluster together and differentiate from the long - term stresses and disaster risk drivers ; if such a hypothesis is confirmed , then it will be possible to discriminate between urban resilience and urban sustainability depending on the types of hazards , shocks and stresses . Statistical data analysis was performed with IMB SPSS , Version 20 .	255901035	no
Apart from time series models , the research work of artificial neural networks was also deepening , and great progress had been made . There were numerous researches on this subject by related scholars . Di Piazza et al . ( Di Piazza et al . , 2020 ) studied an artificial neural network ( ANN)-based model for short - term simulating of hourly wind speed , solar radiation , and electricity demand . The simulation analysis proved that the method could coordinate the good prediction performance in the short term with a very simple network structure . RodrÃ­guez et al . ( 2018 ) proposed an artificial neural network ( ANN ) to simulate photovoltaic generators . Dumitru and Gligor ( 2017 ) established an architecture based on a feedforward artificial neural network and simulated the daily average wind energy in Southeast Europe . Using Iran 's monthly available data from 1996 to 2006 , Azadeh et al . ( 2013 ) used an artificial neural network ( ANN ) method to simulate the consumption of renewable energy in consideration of environmental and economic factors . Neto and Fiorelli ( 2008 ) . Pino et al . ( 2008 ) used an artificial neural network to simulate the next day 's electricity price in the Spanish energy market . Moreira et al . ( 2021 ) used an artificial neural network ( ANN ) to estimate the photovoltaic power generation in Minas Gerais , Brazil , with an average absolute percentage error of 4.7 % per week . Khwaja et al . ( 2020 ) used integrated machine learning based on artificial neural networks ( ANN ) to perform short - term power load forecasting in New England . Islam et al . ( 1995 ) developed a new type of artificial neural network ( ANN ) to simulate electricity load and energy in the next 24 months . The artificial neural network model has also been applied to the simulate of European electricity load ( Behm et al . , 2020 ) and wind power generation ( Zafirakis et al . , 2019 ) . In addition , combination models related to artificial neural networks are also common in practical applications ( Zainuddin et al . , 2019 ) .	236294095	no
The electrochemical and elemental analysis data strongly indicate that silicon electrodes suffer from capacity losses due to diffusion controlled lithium trapping and that the imbalance between the lithiation and delithiation charges is further increased by continuous SEI formation required to maintain a constant thickness of the SEI layer . Although it is generally difficult to detect the trapped lithium using delithiated electrodes that only have been cycled for a few cycles , it should be possible to detect the trapped lithium at later stages in an extended cycling experiment . Figure 4 shows hard X - ray photoelectron spectroscopy S1s spectra for a pristine silicon electrode as well as a silicon electrode analyzed after the lithiation and delithiation steps on the first , 25th and 50th cycles , respectively ( the latter electrode was cycled using the standard constant cycling protocol discussed in Section 2.1 ) . For the pristine electrode , two distinct peaks were observed due to the presence of silicon oxide and bulk Si , respectively . After the first lithiation , a new peak due to the Li - Si alloy emerged at lower binding energies ( see the yellow Li z Si peak in Figure 4 ) in addition to the silicon peak . In the spectra for the cycled electrode , the silicon peak was denoted Li x Si to indicate that the electrode also contained some residual lithium yielding a shift toward lower binding energies . [ 23 ] The latter shift should , incidentally , be coupled to the shift in the redox potential of the electrode to lower potentials expected for an increasing lithium concentration in the electrode ( see Section 2.1 ) . After 25 and 50 cycles , the Li - Si alloy peak had clearly increased in size , indicating a build - up of residual lithium at the electrode surface that should not be present in the absence of the lithium - trapping effect . The latter is very important , as this is , to the best of our knowledge , the first HAXPES evidence for the lithium - trapping effect . By comparing the positions of the peaks in Figure 4 with those reported in our previous work involving step - by - step lithiation of silicon , [ 23 ] it can be seen that the spectra for the 25th cycle match those previously obtained using a lithiation capacity of Adv . Energy Mater . 2019 , 9,1901608   2000 mAh g â1 . In addition , the spectra for the 50th cycle suggest a lithiation degree corresponding to a lithiation capacity between 2000 and 4000 mAh g â1 . Here it should be noted that the experimental data indicate that the silicon electrode should have had a total capacity ( i.e. , lithiation capacity + accumulated capacity loss ) of 2055 and 2463 mAh g â1 after 25 and 50 cycles , respectively . It can , therefore , be concluded that the HAXPES results indicate that the lithium concentration in the electrode increases during the cycling in agreement with the electrochemical data and the lithium - trapping hypothesis .	199648051	no
"W k is normally used to estimate the "" correct "" number of clusters K via the elbow method . On the other hand , the gap statistic uses null reference distributions . These are each constructed by finding the range in the M -dimensional space of the samples and generating N data points with a uniform distribution ."	126166955	no
The rest of this paper first highlights relevant literature on deliberative democracy , PCSR , parentalism and corporate remediation . The following section analyses the case of Mariana in Minas Gerais state , Brazil . After a description of the methodology and data analysis , the paper presents the rich narratives gleaned from interviews under the different themes of parental power retention , resistance to parentalism and the moral justification of parentalism via an MSG arrangement . The final section features a discussion , further research avenues and a conclusion .	254384500	no
Poor community economic welfare Poor community economic welfare by firms impedes social sustainability . Competition among suppliers to reduce cost To get orders from the buyers , suppliers compete among themselves to reduce cost risking social sustainability . Zorzini et al . ( 2015 ) Confrontational relationship between Third party auditors often give adverse report regarding violations of code of conduct so they can revisit and receive another fee . Huq et al . ( 2014 ) psychological tension . Suppliers feel that they are forced to measure , monitor , and report sustainability indicators that are not relevant for their own business . For example , overtime is a critical issue in developing countries , where the minimum wages are very low . Workers often have to work overtime so that they can earn decent money ( Xiao et al . , 2019 ) . Many suppliers do not buy employee insurance as their proft is very low . If they buy employee insurance , their profits will go down further and they will not be able to survive ( Xiao et al . , 2019 ) . Resistance to adoption of new work practices , process changes , learning new skills , sharing of sustainability related operations and process data with the buyers are all considered behavioural tensions ( Tura et al . , 2019 ) . Rezaee ( 2018 ) reported that tensions can occur in various dimensions of social and environmental sustainability as the corporates find that the non - financial social and environmental sustainability may take away funds . Often , managers give greater priority to economic goals than to sustainability goals . Sometimes suppliers who wish to comply with sustainability norms become phased out because of cost related reasons ( Xiao et al . , 2019 ) . Sounndararajan et al . ( 2019 ) proposed the concept of collective stakeholder orientation in the context of global supply chain . They claim that this would enable participants to seek and share value , to share responsibilities , make voluntary and sustainable collaborations , seek collective ownership of the responsibilities , and provide mutual benefit to all participants overcoming their differences . A summary of sustainability tensions is given in Table 8 .	224923046	no
For the banks , a key driver is generation of customer loyalty and new accounts through cash - back offers for existing and new customers . The cash - back schemes are funded solely by merchants in exchange for commercially valuable insights generated from the detailed payment - card data the banks hold . Benefits for merchants include ( a ) a comprehensive sector analysis of their market share ; ( b ) grouping of their existing and potential customers into different categories ( e.g. ' high value loyals'-big category spenders who are loyal to the merchant or ' switcher prospects'-low - tomedium spenders that do not currently spend with that merchant ) and ( c ) targeting existing and prospective customers using various offer strategies .	254382149	no
Dye sensitized and perovskite solar cells may be considered to be in a similar situation even though at differing levels of maturity . Common aim of all these technologies under development is to understand what induces changes foremost in the electrical properties of the PV devices but also to the mechanical , the physical and chemical properties of the various layers and interfaces under ambient factors such as light , temperature , humidity and oxygen . This is done with a combination of electrical , optical , morphological , mechanical and chemicallysensitive techniques and associated modelling . Compared to OPV , the perovskite fi eld is still in its infancy , [ 15 ] but many considerations of the OPV can be applied to this new fi eld . There are signifi ca nt differences , though . Most notable is the chemical stability of the perovskite [ 16 ] which can decompose into PbI 2 and/or other components which are detrimental to the stability of output power . The photoactive layer is susceptible to moisture , oxygen , UV light and temperature with water being a major culprit for catalyzing decomposition . [ 17 ] Whereas perovskite devices do not typically contain a photoactive blend system as used in OPV , the morphological and crystalline structure of the perovskite layer [ 18 ] does play a huge role in the performance and stability of these devices . The top hole conductor also has a strong bearing on performance both at the cell level [ 19 ] and at the module level . [ 20 ] Perovskite solar cells can be found in two main architectures that both deliver high effi ciencies : with and without a mesoporous scaffold ( typically made of titania or alumina ) . Early signs [ 21 ] show that the presence of a mesoporous or nanostructured scaffold maz have a signifi ca nt positive effect on device stability both at the cell [ 22 ] and module level . [ 23 ] Furthermore , perovskites have been shown to suffer from measurement induced hysteresis , [ 24 ] which needs also to be considered when designing measurement and stability protocols for this type of device . Recently , outdoor fi eld data have also been reported [ 25 ] on hole - conductor - free PSCs based on a triple - layer architecture employing carbon as a back contact as well as heat exposure for 3 months at 80 - 85 Â° C , which are encouraging . [ 26 ] Dye solar cells [ 27 ] are electrochemical devices , so the differences regarding stability are even more substantial . [ 28 ] The glaring one is the presence of a liquid electrolyte . It needs to be contained inside the cell chamber , which puts an onus on effective encapsulation , which not only needs to keep oxygen and moisture out since these can cause chemical changes to the electrolyte together with UV light [ 29 ] and the dye or its detachment , which makes hydrophobic dyes more stable , [ 30 ] but also keep the corrosive electrolyte from seeping out ( this limits the current sustaining capabilities of the cells and can corrode the silver contacts of a module ) . Thus , effective encapsulants and barriers are required together with electrolytes with high boiling point solvents [ 31 ] and stabilizing additives . [ 32 ] The task is more severe when developing devices on fl exible substrates . [ 33 ] Solid or quasi solid state DSSCs with polymeric hole transporters or gel electrolytes have also been developed to increase stability . [ 34 ] Electrochemical reactions occurring in reverse biased dye solar cells [ 35 ] ( as would happen to a shaded cell in a module ) can also lead to device failure if severe . [ 36 ] Thus , stability is achieved via a combination of stable materials and effective encapsulation .	97325601	no
Even more interesting is the data detected on the use of the social networks WhatsApp ( 80.7 % ) and Facebook ( 75.5 % ) . These social networks seem to be the most used tools to disseminate news considered interesting on COVID-19 ( Table 15 ) .	236296201	no
The functional units ( FUs ) employed for analysis in this study are masks used by 100 individuals over a period of 1 month . Reusable cotton masks are discarded after 6 days of use ; in other words , they can withstand up to 5 washes while maintaining their protective properties , as recommended by the surveyed factories . Despite the fact that there are many different brands of reusable masks on the market that may vary in the maximum numbers of washes ( TESTEX Community Mask Label , 2022 ) , with some reportedly able to withstand up to 30 washes ( Forever Family , 2022 ) , due to limited research conditions and survey funding , production data were only available for masks that could be washed up to 5 times . Given that the cost people pay for them ( retail price : CNY 7 per mask ) is quite low relative to disposable masks ( retail price : CNY 0.35 per medical and surgical mask and CNY 2.5 per KN95 ) , we developed an evaluation model based on the number of washes in Section 2.4.2 to reduce the uncertainty associated with low settings for the number of washes .	255373604	no
In this event study setting , we analyze the seriousness in the implementation of the initiative 's principles by considering the abnormal shifts in ESG ratings of the signatories after signing the UN PRI . We define the signing of the UN PRI by a firm as a firm - specific event and organize our data in event time . The estimation period ends in the year before the signature year of the respective firm . The event window for a certain firm represents the period of being a signatory , i.e. , we keep a UN PRI signatory in the treatment group until the year of its delisting or the last year in our analysis . For each UN PRI signatory , the control firm is the matched non - signatory based on the GM applied in the year before the date of signing .	244651817	no
As summarized above , most studies analyzing social data related to COVID-19 focused on changes in the public 's emotional states such as anxiety , sadness , or stress , in response to governments ' lockdown policies to stem the spread of the infectious disease . While the studies reviewed above also researched the effects of the pandemic declaration , our study differs in that we focused on changes in the public 's search patterns in response to the outbreak of disease and their subsequent behavior instead of focusing on changes in the perceived emotional state of the general public . What distinguishes this study is that we explain the serial process leading from risk awareness to information searching , testing , and confirmed cases through the analysis of changes in RSV .	232282755	no
The R - square value is R 2 = 0.94 . It is noteworthy that the slope that emerges from the fit is less than unity . An alternative way of fitting is the Deming regression , [ 47 ] which is a technique for fitting a straight line to 2D data where both    Table 1 ) is determined by the intercept of the tangent through the inflection point at the edge of the square - wave voltammogram and the baseline . Table 1 . SWV redox potentials and HOMO energies from UPS and DFT for DPP polymers .	104323766	no
Our discussion should help bring into sharper focus the important role of vagueness in grammar . In particular , if it turns out to be right that the main determinant of the mass / count distinction is vagueness , then the interface of grammar with the conceptual system has to be somewhat reassessed . Under the view that Universal Grammar ( UG ) is , essentially , a lexicon together with a recursive computational apparatus , vagueness would n't just play a role at lexical interfaces with extralinguistic systems , but it would shape some aspects of the computational apparatus itself . More specifically it would have a rather direct and perhaps surprising impact on the morphosyntax of number . Another way to put it is that the non lexical component of UG ( unlike other conceivable computational devices ) is pre - wired to handle vagueness ; if one views UG as the structure of a ' language organ ' , one can readily speculate on why a computational system that is capable of handling efficiently vague information would be a better fit with our environment that a system that is n't . 1 I will be taking the notion of vagueness pretty much as given and adopt a ' supervaluation ' approach to it , 2 in the particular version developed by Veltman ( 1985 ) , also known as ' data semantics ' . In adapting to my goals a supervaluationist approach , I will try to remain neutral between ' indeterministic ' vs. ' epistemic ' stands on vagueness , even though my own bias towards the former may sometimes seep through . 3 I also wo n't have anything to say on issues pertaining to higher order vagueness .	16023507	no
"Response : We appreciate this concern raised by the reviewer . It is true that we could not examine whether changes in ER skills are caused by changes in depression / anxiety symptoms or vice versa . In accordance with another Reviewer 's suggestions , we made changes to the statistical approach in our revised manuscript , removing meta - regression analyses , which we believe has simplified our approach as well as avoided potential suggestions that we are able to appropriately examine mediation with the data extracted . We reviewed our Introduction and Discussion sections to ensure that our inability to make causal claims in the current investigation were highlighted . For example , we removed words such as "" mediation "" throughout the Introduction ( p.3 - 6 ) and only suggested these techniques for future directions given limitations to the current investigation ( p. 12 - 13 , 18 ) ."	237583058	no
Given the unreliability of pre - theoretical intuitions , what seems more plausible , I submit , is that pre - theoretical intuitions constitute only a starting point for logical theorizing . Logical theories do not simply capture pre - theoretical intuitions , but rather improve on them . In other words , logical theories are ameliorative , rather than representational . In the two final Sects . ( 6 and 7 ) of this paper , I draw on Carnap 's ( 1950Carnap 's ( , 1963 view of scientific and logical theorizing as explicative and on Haslanger 's ( 2012 ) account of ameliorative philosophical analysis , accounts in which theory choice is pragmatic , to argue that what determines theory choice in logic are , first , the investigative aims of the theorist and , second , data about logical theories themselves ( e.g. , meta - theorems ) showing whether a given theory can satisfy the pursued aims .	238769910	no
"In order to test Hypotheses 2 to 5 , the independent variables needed to be reasonable measures of prior CSR and CSiR performance by a firm . In order to determine the level of CSR and CSiR performance , we used KLD ESG data by MSCI - a data set with annual snap - shots of the environmental , social , and governance performance of publicly listed US firms , and one of the most widely used sources of CSR data in current research ( Cheng et al . , 2014;Flammer , 2013;Godfrey et al . , 2009;Kruger , 2015 , etc . ) . KLD STATS assigns scores against CSR performance of firms across seven key ESG stakeholder domains : community , corporate governance , diversity , employee relations , environment , human rights , and product . Under each of these domains , there are multiple indicators of CSR strengths and concerns , specified separately , against which KLD STATS issues a binary score . Good / bad actions are recorded as "" 1 "" representing the presence of a strength / concern and "" 0 "" indicate the absence of an action . Summing up total strengths and total concerns across all seven CSR domains provides composite scores for aggregate CSR strength and concern ."	237756669	yes
With respect to statistical procedures , we conducted HarmanÂ´s single factor test ( Malhotra et al . , 2006 ) , which is one technique to identify common method variance , and its use has been evidenced in many survey - based studies with similar objectives ( e.g. Marodin et al . , 2018;Tortorella et al . , 2020b;Saurin et al . , 2020 ) . Results for this test indicated that 22.5 % of the variance was represented by the first factor , which suggests that common method variance was not likely to be a problem because most of the variance was not loaded into one factor . Because this is an exploratory method and not a statistical test , we complemented this analysis by running a Confirmatory Factor Analysis ( CFA ) , which provides a chi - square test so that it is possible to judge whether the model fits the data or not ( Williams et al . , 2010 ; RodrÃ­guez - Ardura and Meseguer - Artola , 2020 ) . Results for the CFA model confirmed that no single factor emerged , indicating common method variance issues could indeed be disregarded .	237706348	no
"In the "" Multivariate genome - wide association analysis ( mvGWAS ) "" section of Results ( page 5 ): "" A multivariate approach had the dual advantages of achieving data reduction and increasing statistical power compared to running 42 separate univariate GWAS . """	232244943	no
To perform a comparative assessment of the socioeconomic impacts between the first and second COVID-19 waves , we used a sample from January 13 , 2020 to September 21 , 2020 . The different data series show different patterns as follows ( see Fig . 1 ) . The US and Chinese stock markets experienced a significant drop during the COVID-19 pandemic . By contrast , the two measures of US economic uncertainty ( VIX and EPU ) show a sharp rise around the start of the COVID-19 pandemic . The higher values represent more uncertainty or fear for both the S&P 500 and the overall economic situation , their rise coinciding with the rising numbers of COVID-19 infection cases and deaths globally . Using these daily series , we calculated the daily returns as follows :	233549739	no
The remainder of this review is structured as follows . In Section 2 , the review begins with a summary of the Semantic Web and introduces W3C concepts related to data interoperability . Section 3 provides an overview of the ontology field by introducing fundamental ontological concepts , an example of a widely used top - level ontology , and a review of current efforts to develop relevant domain ontologies . Section 4 reviews the status of dedicated battery domain ontologies , focusing on two on - going initiatives . Section 5 elaborates on the applications of ontologies in battery research and development , and Section 6 discusses the challenges and outlook for future development . This review may contain terms and phrases that are unfamiliar to some readers new to the field of ontology . The Supporting Information contains a glossary of terms in Table S1 , Supporting Information .	245111008	no
In addition , Google Trends data have been widely used to inform epidemiological studies . Ahmad et al . ( 2020 ) presented a study to assess the predictability of COVID-19 incidence using Google Trends data on internet search interest of certain gastrointestinal symptoms and terms . The study stated that these internet search data could be useful for predicting COVID-19 cases in the United States . Similarly , Asseo et al . ( 2020 ) used taste and smell loss - related search terms to track the cases in the United States and Italy and discussed the benefits and limitations of using Google Trends data in disease surveillance . Internet search data are also useful for improving forecasts for certain infectious disease activities , for improving surveillance , and supporting real - time decisions . In earlier studies , Google Trends data have been used in forecasting influenza activity and predicting related outcomes ( Araz et al . , 2014;Yang et al . , 2015 ) . Kandula et al . ( 2019 ) used Google Trends data to forecast influenza - associated hospitalization in the United States and suggested that these web - search data can provide important real - time information and improve the accuracy of forecasts for hospitalizations .	255441206	no
Proposition Macro 3 : At higher levels of smartness , industry sectors will succumb to the ' Winner Takes All ' pattern of power centralization unless new institution arrangements emerge to enable data sovereignty solutions .	213757082	no
"Across the contexts we studied , peripheral actors to data journalism promote a vision of public or citizen - oriented journalism through creating guidelines , training kits and tools to be used by aspiring citizen journalists . The approach can sometimes put them at odds with more traditional authoritative journalistic stances . In the European context , tension has been shown in relation to entrepreneurial journalism , whose actors "" combine , complement , and interweave seemingly opposing practices and values , moving beyond the traditional / alternative [ journalism ] divide "" ( Wagemans , Witschge , and Harbers 2018 , 12 ) . Our data confirms that more citizen - oriented forms of journalism are primarily promoted by entrepreneurial journalists in the European context . The aforementioned nonprofit Correctiv , for example , made training ordinary citizens the methods and techniques of journalism a central part of its mission . One of its projects that best illustrate this approach is the "" CrowdNewsroom "" , a platform where the crowd ( i.e. , registered users ) should not only help collecting or verifying data but is also actively involved in the production process of news . Some of our interviewees who work in entrepreneurial journalism organizations explicitly aim to introduce practices from civic tech to journalism . As one of our interviewees in Germany put it , data journalism for him is "" applied civic tech "" ( Co1 ) . As an interviewee stated : "" we do n't publish stories , we publish the tools we developed to understand the data ourselves "" ( Ts1 ) ."	159434250	no
With rare events , organizations may not have relevant prior experiences to draw inferences and aid decision - making . The Covid-19 pandemic represents such a rare event . Responding to rare events requires organizations to mobilize and adjust existing resources quickly as well as develop new capabilities ( Henningsson et al . , 2021 ) . Further , rare events ( such as the Covid-19 pandemic ) are usually characterized by less available data ( Oehmen et al . , 2020 ) . For example , in the case of the Covid-19 pandemic , retailers may not have accurate epidemiological data on transmission and may have to use other heuristics , such as consumer mobility patterns , to optimize retail decisions . During the early days of the COVID-19 pandemic , due to potential and actual social distancing policies , including mandated lockdowns or potential lockdowns , consumer trends were disrupted , which also affected retail activities globally ( OECD , 2020 ) . As the epidemic growth showed geographic variation , some states , e.g. , New York ( NY ) , observed early surges in hospitalizations and early long - term state - wide lockdowns . Meanwhile , other states , e.g. , Nebraska ( NE ) and Texas ( TX ) , observed increased cases and deaths sometime later than NY . These geographic variations in cases and deaths also produced varying demands on certain items , such as hand sanitizer and masks , as well as varying mobility patterns , including retail activity patterns .	255441206	no
We recall that the database of repair services monitored in 2016 ( and thus reporting the age of the device ) was less populated compared to the 2009e2015 database , and uncertainty may be introduced by a number of factors . However , we could identify which components or recurring failure modes can be often observed when relatively young ( e.g. less than 10 years old ) appliances are diagnosed . Nonetheless , the limitations identified for this subset of data demand for a further analysis with a more comprehensive database .	128352956	no
Lotz is at pains to stress that none of these features on their own are unique . Vertical integration has long been a prominent strategy in the media business ( Evens and Donders , 2018 ) ; there are also historical precedents of television purely funded through subscription ; niche targeting is not new either , though what is new is the depth and granularity of consumer data available to SVoD companies ( Jenkins , 2016 ) ; finally , ancillary technologies for viewing ( VCRs , DVD players , DVRs ) as well as pay - per - view services on pay - TV have long made non - linear viewing possible , although these viewing forms remained peripheral before the Internet ( Johnson , 2019 ) . It is the combination of these features into a single business proposition that makes Netflix ( and SVoD more generally ) a new and disruptive phenomenon . The seeming strong transnational character of Netflix ( and , to a lesser extent , of other multi - territory SVoDs ) and the availability of significant amounts of investment capital ( Evens and Donders , 2018 ) , can be added to the mix of ingredients that make SVoD a powerful business proposition ( Lobato , 2019 ) .	234299322	no
Examples of typical cyclic voltammetry scans and long term stability tests of the 0.25 cm 2 photoelectrochemical tandems are found in Figure 5c , d , respectively . The data for all tandems can be found in Figures S22 - S25 of the Supporting Information .	103057921	yes
This study has proposed a method that estimates almost real time ( monthly ) CO 2 emissions based on proxy variables related to energy production and comsumption for each AACC in Spain . The method is flexible enough so that each AACC can forecast the shortterm effect of implementing diverse energy policies in the CO 2 emission levels . The method has been shown capable of capturing the effects of changes in regulation and of sudden events such as the COVID-19 pandemic . The model can also be used to product a set of economic recovery scenarios after the pandemic , in which the participating variables can be estimated , to benchmark the effects of different energy policies in the emissions of CO 2 . The advantage of a data - centric policy definition is that , if the hypotheses about the predictors are revealed to be wrong , the scenarios might be updated with actual values whenever possible and policies can be dynamically improved .	233916124	no
The combined STEM and XRD data reveal that , in addition to the grain growth seen in SEM analysis , the aerosol treatment also leads to an improvement in microscale uniformity of the MAPbI 3 films . Impurity phases such as PbI 2 are reduced , compositional uniformity increases throughout the film , and crystallites grow and increase their preferred orientation , all of which contribute towards the observed improvements in device performance .	237802796	no
These regimes are representative of the part of the original data with the lowest signal to noise ratio ,	231846789	no
"Besides , basic particulars do not have a direct cognitive value ( green - situations are not "" data "" that can be expressed with the resources of ordinary language ) , but represent , so to speak , the boundary conditions that regulate the meaning of words and that govern the material rules of inference that we use in our ordinary speeches . 16 Our talk about complex particulars , on their side , do not have a direct link with the "" data "" they intend to express , but they rather summarize normative ties that connect different situations of usage . Talking about "" blue "" ( epistemic level ) implies a complex of particular situations that makes it possible for us to learn pattern governed behaviors , namely , to spend the word correctly in the great variety of possible standard and non - standard situations ."	238831543	no
As these are only components of a holistic index , and because our theorization throughout most of the paper concerns all our aspects of CSR , these findings must be interpreted with caution . For example , community may not be significant because of very limited variation in the measure of community CSR ( 90 % report no strengths , 97 % no concerns ) . The MSCI ESG KLD data only cover a limited number of items on community strengths and concerns ( our data show a range from â 1 to 2 , and most firms list none ) . In addition , community - related CSR in the database mainly concerns donations which are often to national funds or foundations rather than local communities , and local initiatives such as volunteer programs are rare ( only about 1.2 % of our sample firms report volunteer programs ) ; hence , the community - related CSR ratings may not accurately measure firms ' CSR efforts in their communities .	235459410	maybe
The NO 2 , SO 2 , CO , AOD , and LST data used in the study were acquired during Jan 01 to May 15 for the years 2019 and 2020 . The datasets were obtained and processed using the Google Earth Engine ( GEE ) API ( Gorelick et al . , 2017 ) . The land use land cover compositions of the study sites ( Fig . 2 ) are derived from the Copernicus Global Land Service : Land Cover 100 m ( Buchhorn et al . , 2019 ) .	233532496	yes
These organisations receive funding from international bodies such as Bill and Melinda Gates Foundation and the International Center for Journalists ( ICFJ ) , but also generate revenue from small - scale commercial data projects .	158951976	no
The main one is around uncertainty . The uncertainty is not played well , but actually there is a lot of uncertainty in the results ( Extended data Figure 3 ) . I will suggest to add a section in the manuscript describing the different uncertainties and ideally linking it with Supplementary Figure   1 to 5 where some of the countries are really lacking in data . In addition , a section on uncertainty could clear the results , where in my view some statements does not take into account uncertainty ( for example when describing EBF in South Africa ) .	235336555	no
Area socioeconomic status indicators are presented in Table 1 . These indicators were obtained with analysis in GIS using geospatial data processed by Kalogirou ( 2010 ) based on census data from Hellenic Table 4 Regression models examining how the built environment relates to personal relationships satisfaction before and during COVID-19 . All coefficients shown are standardized . The models are adjusted for individual sociodemographic variables : age , gender , unemployment , cohabitation status , citizenship , income , education level , presence of children in household , religiosity , and disability . The models are also adjusted for area socioeconomic status : mean household income , proportion of immigrants , and unemployment rate . * * p < 0.01 . * * * p < 0.001 . a p < 0.10 . * p < 0.05 .	238530423	no
After computing and mapping PM 10 , validation of the map was done using Tem - top airing-1000 air quality monitor ( measuring range 0e999 mg / m 3 , resolution 0.1 mg / m 3 ) derived field data at 80 sites for pre - lockdown period . However , it was not possible to validate maps of lockdown phase using all those sites due to assess limitations . Field measurements from only three sites including the monitoring station of CPCB were taken for validating the map . Pearson 's correlation coefficient was computed between the data derived from PM 10 image and field data .	233713305	no
These studies exemplify the reasons for why inconsistent causal hypotheses can be supported with statistical models of observational data and how mechanistic evidence can help resolve the controversy . The two case studies are representative of the reasons why data researchers obtain inconsistent results . The disagreement between Cornaglia ( 2006 , 2013 ) and Abrevaya and Puzzello ( 2012 ) results from different but plausible methodological decisions . Hence , one is unable to resolve the controversy by arguing that one of the two inconsistent results is an effect of using inappropriate ( from the perspective of statistical methodology ) statistical techniques what implies that an additional source of evidence is required for the resolution . Furthermore , the discussion of economic models representing addicts ' decision process shows that mechanistic evidence can also be divided , i.e. , economists can disagree in regard to which of a few hypothesized mechanisms actually produces the phenomenon . It allows for drawing a lesson that the quality of mechanistic evidence needs to be carefully assessed . Considering that the sources of mechanistic evidence in economics and medicine are different , the case study is a good ground for discussing approaches to evaluating the quality of mechanistic evidence stemming from mathematical models . Still another reason for analyzing the case study of the controversy regarding the influence of excise tax on smoking is that taxation changes not only cigarette purchases but also smoking intensity what exemplifies the view of Kelly et al . , ( 2014 ) that social and biological mechanisms of diseases are often intertwined . The question regarding the influence of concise tax on smoking intensity falls within the research interests of not only econometricians but also epidemiologists ( e.g. , Caraballo et al . , 1998;Falba et al . , 2005;Shiffman & Scholl , 2018 ) , and therefore , I hope , the lesson from the case study can be useful not only for economists but also convince medical researchers to endorse the guidance of evidential pluralism and the movement of EBM + ( see Parkkinen et al . , 2018 ) . The problem of inconsistent causal hypotheses supported with statistical models is not specific to economics but troubles all disciplines using observational data , with epidemiology being the prime example ( Broadbent , 2013;Tatsioni et al . , 2007 ) .	236249427	no
Participants ' emotion ratings can be represented on two different timescales , an absolute timescale and a normalized timescale . The absolute timescale binned participant 's ratings to the nearest 10ms window , and represents individual trajectories through the emotion space on the dARM . However , because trials were self - paced , some trials took longer than others . As a consequence , the absolute timescale results in fewer datapoints at longer time windows ( Supplementary Figure 12 ) . Therefore , for the main analysis participants ' data were normalized to 101 time bins , where 1 represents the start of a trial and 101 represents when the participant made their rating .	236219670	maybe
& _ i , t = Ã 0 + Ã 1 Female_Managers i , t + Ã 2 LA&HR_Perf i , t + Ã 3 Size i , t + Ã 4 ROA i , t + Ã 5 Leverage i , t + Ã 6 Internacio i , t + Ã 7 Cash i , t + Ã 8 DLoss i , t + Ã 9 Accruals i , t + Ã 10 Cov_Ana i , t + Ã 11 B_Indep i , t + Ã 12 CSR_Comm i , t + Ã 13 B_Women i , t + Ã 14 DLawsuits i , t + Ã 15 NCSRPI i + + Ã 16 ICSRPI t + Ã 17 Country i + Ã 18 Industry i + Ã 19 Year t + it + i Fig . 1 Research model determined according to the availability of a company 's corporate reports on their website , which was necessary to determine , through content analysis , the information disclosed in relation to LA&HR . Table 1 depicts the frequencies that determine the composition of the sample by sector , country and time period . Although distribution over time is fairly homogeneous , there is a geographical bias in favour of countries such as the USA information available to estimate the proposed empirical models , the final sample of analysis was an unbalanced data panel consisting of 5693 observations from 1243 companies for the period 2013 - 2017 . The period selected was ( LA ) and human rights ( HR ) considered in the definition of the dependent variable .	238721332	maybe
Thus , the right to be forgotten , a recent solution to reduce the cultural lag regarding individual privacy , should also be based on social consensus . This right 's primary purpose is to provide a legal foundation for individuals to manage their personal data when such data manipulations do not harm public interests ( European Parliament 2016 ) . Social consensus can resolve the cultural gap that has emerged from the difference between the speeds of technology and regulation in the context of individual privacy . Accordingly , scholars have investigated cross - border and cross - business arbitration proposals to enhance privacy rights in terms of legal clarity , empirical applicability , and the balance between multiple rights ( Shahin 2016;Malgieri and Custers 2018 ) . Unfortunately , there is little understanding of why people want to be forgotten , which must be the basis of this right 's design and implementation ( De Hert et al . 2018 ) . It is hard to determine whether existing forms of implementation of the right to be forgotten reflect the voices of information providers because these forms are usually developed by information controllers ( Chenou and Radu 2019 ) . Explorations into determining the need and the right to be forgotten online are necessary to form specifications of this right . Furthermore , understanding such needs are important for balancing the interests of various stakeholders of personal data ( Tavani 1999 ) . Therefore , in this study , we aim to answer the following research questions : ( 1 ) Why do people want to be forgotten online ?	231744099	no
This study was constructed as following steps . First , we tested on different machine learning models , including NaÃ¯ve Bayes , Logistic Regression , Convolutional Neural Network ( CNN ) , and Long Short - Term Memory ( LSTM ) , and tried different text representation such as bag - ofwords and pre - trained word vectors . Secondly , we applied the optimal LSTM model on the collected Tweets and analyzed the sentiment change of different cities across time . Finally , we used Spearman 's rank correlation to investigate the relationship between Tweet sentiment , quarantine measures , and COVID-19 statistics such as new case emerges , hospitalization , and deaths in three cities - New York City , Los Angeles , and London , where we collected sufficient and quality Tweets to drive the machine learning based sentiment analysis . Since Tweet sentiments and the spread of the pandemic may vary by city , a comparative study across cities could allow researchers to incorporate city - specific features , such as the demographic distribution , economic indexes , and accessibility of public transportation , to dig deeper into the reasons behind the possible correlations found . Also , as pandemic quarantine measures could have huge impacts on the daily life of residents , such policies are often issued on a city , or even district level . Thus , a city - bycity comparison could help policymakers better distinguish the response of different residents and design more differentiated measures to prevent the spread of epidemics . The rest of the article was structured into the following sections . Section 2 ( Literature review ) reviews relevant research related to sentiment analysis and Twitter data usage . Section 3 ( Method ) introduces the methodology for Tweet collection , data preprocessing , machine learning classifiers for sentiment analysis , and the ranking rule for Spearman 's correlation . Section 4 ( Results ) presents the data summary and correlation analysis . Section 5 ( Discussion ) explores how the results of this study could be interpreted considering the difference in population density and infrastructure across cities . Section 6 ( Conclusion ) outlines the contributions , limitations , and implications of this study .	236251116	no
To tackle this potential issue of endogeneity , we run additional regressions based on the 2 - Stage - Least - Square ( 2SLS ) estimator . Particularly , we instrument the log of the number of robots per 1000 workers in Italy with the same variable for Japan and South Korea . The purpose of using these instruments is to capture the exogenous technological differences across industries that lead to different uses of robots in the production process . We chose Japan and South Korea because they have among the highest robot adoption rates , provide reliable and readily available data on employment by industry , and are not part of the European Union and so less likely to be influenced by factors shaping robot adoption in Italy as well . We will show that these instruments are informative and , given that we have more instruments than endogenous variables , we will also provide some evidence that the instruments are valid .	237473239	no
When examining the distributions of the data , many of the variables are highly skewed ( for example , the 5 - item technology use measures in the MTF ) or questionably linear ( for example , the 3 - item happiness measure in the MTF ) . We opted to treat these variables as continuous so that our analyses and results would be directly comparable to those of previous studies 10,31 . Data distribution was assumed to be normal throughout the analysis , but was not formally tested for each specification .	58006454	no
We incorporate location - specific COVID-19 case and death counts into our analyses , as well as counts for the US as a whole . Such data represent immediate indicators of COVID-19 severity and are likely the factors driving Google searches for masks , hand sanitizer , and disinfectants . Although case fatality rates and the prevalence are epidemiologically better indicators of the severity and the transmissibility of the virus spreading in communities , at the time of the study , news outlets were presenting both the number of deaths and the confirmed cases separately , which were driving the public perception about the risk associated with COVID-19 . Therefore , for each state and city considered in the study , daily cases and death counts are obtained from New York Times data repository and used . 3 Fig . 4 shows the COVID-19 daily cases and deaths at the three locations of interest as a time series .	255441206	yes
For investigating the effectiveness of travel restrictions on COVID-19 transmission in China , we compared the population flow among 43 major cities ( including Wuhan ) during the same observation period in 2019 ( 12 January 2019 - 8 March 2019 ) and 2020 ( 1 January 2020 - 23 February 2020 ) . This data was extracted from Baidu Inc. ( Baidu Migration Map - Big data on Spring Migration ) . Fig . 3 showed the daily population inflow and outflow indexes of Wuhan and other top ten cities ( 4 first - tier cities , three transport hubs , and three developed coastal cities in southern and eastern China ) with highest average daily population inflow and outflow indexes . In Fig . 3 , the grey dotted line represented the day of Chinese Lunar New Year ( 6 February 2019 , 25 January 2020 ) . Because the spring migration was set according to the lunar calendar , we identified the observation periods in 2019 and 2020 according to the same lunar dates . Before the Chinese Lunar New Year , that was historically the peak period for spring migration with the increasing daily population outflow indexes of Wuhan and other top ten cities in 2019 and 2020 ( Fig . 3c ) . However , in 2020 , the average daily population outflow indexes of these cities were more than 1.1 times that in 2019 , especially in Wuhan ( 1.2 times ) . After the Chinese Lunar New Year , that was also historically the peak period for traveling and returning to work , with the increasing daily population inflow indexes of Wuhan and other top ten cities just in 2019 . Travel restrictions and large - scale control measures were implemented in China from 23 January 2020 , which caused a rapidly decreasing daily population inflow and outflow indexes of these cities . During this period , the average daily population inflow and outflow indexes of these cities were 30 % of that in 2019 , especially in Wuhan ( only 9 % ) .	231808069	yes
As the adverse events investigated in prior related studies are one - time events , most of these studies use a crosssectional sample . To show the consistency of our results with these studies , in Panel C of Table 12 , we restructure our panel data into a cross - sectional sample and rerun the regression . Here , Don_Dum ( Don_Amt ) represents the likelihood ( the total amount ) of donations during the sample period , and Confirm is calculated as the natural logarithm of the total number of confirmed cases in the province where each firm is headquartered during the sample period . We also include industry and province fixed effects in the regression . Overall , consistent with the main results , firms in the most affected areas are reluctant to make donations during the pandemic .	231985056	no
Metal - oxygen batteries and ( aprotic ) lithium - oxygen , in particular , have also been the topic of intense research for more than two decades following the work from Abraham and Jiang in 1996 . [ 161 ] Driven by an alluring theoretical specific energy of â3.500 Wh kg â1 , notable progress has been achieved in unraveling the fundamental mechanisms for both surfacebased [ 162 ] and solution - mediated mechanisms . [ 163 ] However , mass - market commercialization remains elusive due to parasitic processes occurring at the reaction productâelectrolyte , productâcathode , electrolyteâcathode , and electrolyteâanode interfaces . [ 164,165 ] The formation of highly reactive superoxide , Li 2 O 2âx species , and singlet oxygen in particular [ 166,167 ] poses a key challenge for the realization of commercially viable Li - O 2 batteries and accelerated procedures for identifying mitigating strategies like suitable singlet oxygen quenchers or oxygen blocking SEI [ 168 ] are needed . The methodological toolkit developed in BATTERY 2030 + and related initiatives offer an opportunity to accelerate the identification and implementation of approaches like BIG - BMS , [ 4 ] where multisensory data ( gas , pressure , etc . ) from the embedded sensors ( e.g. , developed in SENSIBAT , INSTABAT , and SPARTACUS ) is fed to the deep learned spatio - temporal Battery Interface Genome ( BIG ) models [ 54 ] for the preemptive launch of self - healing additives ( HIDDEN and BAT4EVER ) like singlet oxygen - quenchers . The BIG - BMS models can be trained to predict the onset of such critical events by using autonomous computational workflows developed to predict anionic redox processes , peroxo - species , and formation of molecular oxygen in Li - rich compounds . [ 169 ] Lowering the charging potential through the use of redox mediators ( RM ) has also shown promise toward limiting the degradation processes , [ 170,171 ] but the underlying physical principles still need to be fully understood . [ 165 ] The search for more efficient RMs [ 172 ] can be accelerated by molecular embeddings , [ 173 ] enabling inverse design . Other concepts like aqueous lithium - oxygen [ 174 ] dual - carbon electrode architectures , [ 175 ] Na , [ 176 ] K , Mg , Al , and Zn - oxygen would also benefit from the integrated framework outlined above .	244639571	no
We confirmed that the first difference is needed in the unit root test and took the difference and analyzed the VAR model ( proceeding to 24   15 During the analysis period in Germany and France , test data were obtained only on a weekly basis , and therefore we did not perform any statistical reviews . In the case of the United States , which was the only country for which daily data was available , the correlation between RSV and new tests was not significant in the VAR model . This is because daily new tests tended to increase almost linearly during the analysis period . 16 In Table 9 , for cross correlation , only the lags with the highest correlation are displayed . For Granger causality , from among the analysis results of up to 24 lags , only the values for the interval with the lowest p - value and values for additionally significant intervals are presented .	232282755	no
Hourly data were only used for the validation step . TROPOMI - based NO2 and SO2 data were compared with TAQMS ground - measurements for three test sites ( urban , urban - traffic and suburban ) in the city of Istanbul . To evaluate MODIS AOD 470 nm data , we applied AERONET data ( AOD440 and AOD500 ) with a time tolerance of Â±0.5 h. Since AERONET does not provide AOD 470 nm , the mean value of AERONET AOD 440 nm and 500 nm values were calculated for AOD 470 nm retrieval relevant to MODIS AOD 470 nm ( Equation ( 1 ) ) . . 3 . The monthly images of tropospheric NO2 column density over Turkey .	238664729	yes
between data - independent confirmatory research that is important for testing hypotheses , and data - contingent exploratory research that is important for generating hypotheses . While pre - registration is now common in some areas of clinical medicine ( due to requirements by journals and regulatory bodies , such as the Food and Drug Administration in the United States and the European Medicines Agency in the European Union ) , it is rare in the social and behavioural sciences . However , support for study pre - registration is increasing ; websites such as the Open Science Framework ( http://osf.io/ ) and AsPredicted ( http://AsPredicted . org/ ) offer services to pre - register studies , the Preregistration Challenge offers education and incentives to conduct pre - registered research ( http://cos.io/prereg ) , and journals are adopting the Registered Reports publishing format 52,53 to encourage pre - registration and add results - blind peer review ( see Box 3 ) .	6326747	no
There are several limitations of this study that could be addressed in future works . First , the effects of internet slang ( such as LOL ) and more complicated Emojis could be taken into consideration to improve the accuracy of sentiment prediction . Second , future works could remove robotic / official accounts for better representation of valid individuals ' sentiments . Considering that the proportion of such accounts were usually small relative to the overall data size , these accounts were not removed in this study . Finally , this study only showed the polarity of Tweet sentiments , but it did not show what specific sentiments were expressed , for instance , anger , sadness , happiness , etc . It was also worth noticing that while Twitter sentiments provided us important insights on public sentiments , the sentiments exhibited on social media platforms did not necessarily equal to people 's real emotions in life .	236251116	no
A unified information exchange structure , such as the one presented in Fig . 9 , is warranted for an accurate data sharing across various stakeholders for better pandemic response . For example , it has been reported that there was a mismatch in COVID-19 data reporting from the trusted sources such as CDC and WHO ( Sokol , 2020 ) . A comprehensive and accurate information exchange among different entities is necessary for a cohesive response to the pandemic through collective intelligence where information systems and analytics techniques would be required to mediate the communication ( Secundo , Shams , & Nucci , 2021 ) . If the information generated from one stakeholder is seamlessly transferred to all the other stakeholders through a unified system , this can result in a better response through collaboration and creation of novel pandemic solutions . For instance , the readily available information from public such as self - reported health data , location , etc . and healthcare providers such as hospital resources ( beds , ventilators , PPE kits , etc . ) can be used by government agencies to devise better policies , which can collectively also inform healthcare research .	236296279	no
"Appelgren 's investigation of interactive features and signs of personalisation in data journalism emphasises the "" filtering "" , curatorial function of journalism as one "" naturally making decisions for the audience "" ( 2017 , 3 ) . A data journalistic project , Appelgren observes , is "" a choice architecture provided by journalists and developers , where the design nudges people to explore the storyline "" ( 6 - 7 ) . Appelgren notes that while the early examples of data journalism used to have a high level of interactivity , there is evidence that this has now been replaced by "" an illusion of interactivity "" and a more author - driven , paternalistic design approach offering "" only limited possibilities for the audience to make choices "" ( Appelgren 2017 , 14 ) . In a rare scholarly attempt to understand the rationale for the rather constrained audience agency offered recently , Young , Hermida , and Fulda ( 2018 ) found that the trend towards limited interactivity might be explained by journalists ' experience of a low audience interest in sophisticated interactivity , offered by audience analytics . Drucker et al . point out that only an estimated 10 - 15 % of website visitors use the interactive features of data - driven stories ( 2018,226 ) ."	156033788	no
Using the questionnaires completed by the individual respondents , we first describe two key trends observed in the data focusing on : ( i ) the type of COVID-19 driven shocks experienced on average in the sample ; and ( ii ) the individual characteristics associated with experiencing a shock .	237663595	no
Physical destruction refers to the physical removal of the hardware where the information is stored . It is an expensive option that is sometimes used by companies to remove sensitive information ( Svantesson , 2015 ) . As concerns voluntary access , here it was classified as optional ( i. e. obtaining of information is based on optional adjustments for the user ) and required ( i.e. when using an application that uses this technology requires access to the data ) . Another type of voluntary access is compulsory , which includes technologies or applications that can not be used or installed without generating access to the data ; in such cases , granting access to user data is compulsory .	233029680	no
On 15   The listserv data includes 206 posts made between January 2018 and May 2019 . The data provides insights into the strategies of lobbying and the dynamics of collaboration between unions and civil society organizations . It should not be surprising that the conversations on the listserv at times suggest differences in interests and agendas . However , in this paper we focus on two issues the campaigning platform fought for : ( 1 ) the material scope of ' public interest ' , and ( 2 ) the three - tiered approach to protected disclosure . I present a chronology of that struggle for each of these topics in turn .	233783689	no
A further explanation for the implicitness of Latin American interviewees might have been the high levels of insecurity found in many countries . Argentina , Chile , Colombia , Mexico , and Peru have all experienced prolonged bouts of terrorism and kidnapping of affluent people for ransom . This is likely to discourage people from seeking high public profiles . The periods of left - wing and anti - business governments in many countries may also encourage discretion . There might be a fear of public retaliation from being accused of whitewashing , using their foundation for sketchy purposes , such as tax evasion , or provoking government intervention in their operations ( Turitz & Winder , 2005 ) . It is noteworthy that some of them were unwilling to quantify the scale of their foundation activity . While large foundations in South Asia often provide detailed data on their operations , the work of many foundations in Latin America is discrete , and often even basic statistics are not public .	237212641	no
The general willingness of consumers to take part in protests was controlled for by measuring the trait action willingness , by asking if they had joined an anti - firm protest during the previous year ( with multiple answer options , as well as a ' yes , other â¦ ' option ) . These data were transformed into a dichotomous variable for the analysis .	254384444	no
Having outlined the distinction between behaviour and symptoms I now develop a conceptual understanding of symptoms . To do this I consider the distinction between data and phenomena .	255068141	no
The cross - checked field notes 5 were added to the dataset for subsequent analysis . Our own input into the data can not 1 3 be ignored . Initially , our observations were unobtrusive and interactions with field actors at these events were limited , but as our attendance became regular , organizers became interested in our project , which led to collaborative relationships that included presenting our findings in one event in 2019 . We conducted 15 semi - structured interviews with UK construction field actors . Our sampling size and selection approach were purposive ( similar to Islam & Van Standen , 2021 ) . This meant that the strategy of data collection was driven by reaching data saturation ( the point at which subsequent interviews do not provide any additional insights ) . As per our research interests and theoretical underpinnings , our aim was to obtain a broad representation of participants from the different subgroups of field actors ( Table S1 in the Supplementary Appendices ) , not only businesses . One of the authors , who had established contacts working on modern slavery in a professional role , facilitated introductions to four practitioners . To avoid accessing the views of a particular network of the field , we did not follow a snowballing approach . Rather , we used the attendance at the field - configuring events ( above ) to purposefully approach additional interviewees based on their subgroup membership . Seven interviewees were representatives of construction businesses , a dominant group in the field , all of which were subject to section 54 of the MSA . Since we used multiple data sources ( including the naturalistic observations and extensive secondary data ) and the interviews per se were not intended to capture interactive framings , we are confident that the sample size is sufficient for our analysis . Lasting an hour on average , the interviews were intended to elicit perceptions of how the framing of modern slavery and industry actions were emerging and evolving , and to confirm our understanding of the frames identified . The interviews were recorded and transcribed for subsequent analysis . We requested participants ' feedback on preliminary findings in order to ensure the accuracy of our interpretations .	244953396	no
Validation is the process of determining whether the simulation model is a useful or reasonable representation of the real system ( Pritsker et al . , 1997 ) . Absolute validation is usually impossible because the simulation is at best an approximation of the real system , and the most definitive method is to compare the output data from the simulation with the actual data from the existing system using formal statistical analyses such as confidence intervals ( Kumar and Shim , 2006 of this study , we calculated the confidence intervals of the simulation outputs at 95 percent confidence interval ( a Â¼ 0.05 ) and compared them to the actual values provided by the Hospital . We also verified the architecture of the simulation model with staff in the Linens Department before the simulation runs and showed the simulation results to the Hospital staff after the simulation runs to ensure that the simulation results are reliable .	154267117	no
We computed summary effect sizes for power and status differences in observers ' distrust and report the results of a meta - analysis combining data from all four studies with entered means , standard deviations , and sample sizes for the four studies . For all analyses , we obtained effect sizes by calculating the standardized mean differences ( Cohen 's d ) for the relevant groups ( Goh et al . , 2016 ) . We conducted both fixed and random effects meta - analyses using the metafor package in R ( Viechtbauer , 2010 ) .	244772733	no
â¢ When rates of missing data are this high , the technique(s ) used to address missing data can meaningfully change a study 's findings and the way that those findings are interpreted . The authors implemented the Amelia II algorithm in R to impute missing data . Although they state that this approach is more conservative than other approaches , such as listwise deletion and last - observationcarried - forward analyses , this is true only under certain conditions . Those conditions may have obtained in this dataset , but there is no way to know this from what they report .	242291039	no
"In contrast , the findings from the PRIMs model corresponding to the myopic types ( based on the formulas Îº 1 P and Îº 3 P of Sect . 4.2 ) do not fit the reaction time data at all : in general , the real participants use much more time ( mean around at least 7000 ) than the "" virtual participant "" who uses the myopic strategy does ( mean around 4000 ms ) . A great advantage of computational cognitive models in an architecture such as PRIMs is that one can also make predictions for future experiments . We will make one such prediction now . Currently , together with Aviad Heifetz and Eric Jansen , we are in the midst of a set of experiments in The Netherlands , India and Israel , based on games that are variations of those of the experiments of Ghosh et al . ( 2015b ) , with the same centipede - like trees as those in Figs . 3 and 4 but different payoff structures . In particular , the new truncated game 1 corresponding to game 1 of the current paper has new payoffs ( 1 , 2 ) after c , ( 3 , 1 ) after e , ( 1 , 4 ) after g , and ( 6 , 3 ) after h ; and the new truncated game 3 corresponding to game 3 of this paper has payoffs ( 1 , 2 ) after c , ( 3 , 1 ) after e , ( 1 , 4 ) after g , and ( 6 , 4 ) after h. We predict that also for these games , participants whose choices fit the own payoff strategy as well as the myopic one , are still more likely to reason following the own payoff strategy , as shown by their reaction times : we predict that they will be slower on Game 1 than on Game 3 ."	641997	no
"Although the tests on the variable selection and the rewriting history bias suggest that our results based on the Asset4 ESG ratings are robust , we conducted our analyses using ESG ratings from another ESG rating agency , Vigeo Eiris . Vigeo Eiris ESG ratings measure the degree to which firms take into account and manage material ESG factors . Firms with higher ESG ratings are better at managing relationships with their stakeholders on a scale from 0 to 100 . To generate ratings , Vigeo Eiris analyzes and scores up to 38 distinct ESG criteria that are framed within 40 industry specific models . In each industry framework , the 38 generic ESG criteria are assigned a weight that reflects the sector specific materiality of the analyzed criterion . Each criterion has a defined set of so - called "" Principles of Action "" . These determine the active content of the analysis and articulate the actions that Vigeo Eiris would expect a high - performing firm to undertake in this dimension . These principles are derived from universally recognized norms and standards emanating from organizations such as the United Nations , the International Labour Organization , and the Organisation for Economic Cooperation and Development . Within the rating process , qualitative and quantitative data , management and performance data as well as self - reported and third - party data are used ."	244651817	no
Major Concern : Handling of Missing Data â¢ As is common in research in this area , there was a high percentage of missing data . This makes the choices about how to address this problem especially important . The authors applied only one technique and therefore could not provide sensitivity analyses that would , in my view , provide a more robust understanding of the data . The claims they make about the effectiveness of their SSI are strong and bold , which puts more pressure on them to show that their effects are robust ( or not ) when applying different techniques to handle their missing data .	242291039	no
One of the most used ways to collect massive data is through the Internet ( Qi et al . , 2020 ) , mobile applications ( Salo and Makkonen , 2018 ) , and geolocation ( Luceri et al . , 2018 ) . Mobile applications are small systems installed on users ' smartphones that perform specific tasks ( Libaque - SÃ¡enz et al . , 2020 ) . To install such application on their mobile devices , users must accept the privacy policy and terms of use of these applications . Privacy policy terms should specify how the data will be handled , who will have access to them , which part of the data will be accessed via an application , who the data will be shared with , and whether the data will be sold to third parties or destroyed it ( Choi et al . , 2018;Fengzhe et al . , 2011 ) .	233029680	no
Supply risk is often assessed through product concentration , by - product dependency and political country risk , among others ( Figure 3 ) . [ 48 ] While lithium and cobalt are both largely concentrated in South America and the DRC , respectively , companies located in China are largely responsible for the refinement of these raw materials for battery material production . [ 68,69 ] China has significantly increased investment into cobalt mining activities overseas in order to provide a domestic and steady downstream supply of raw materials . Chinese dominance of both raw and battery materials may lead to supply shortages if critical materials are leveraged in diplomatic disputes or reserved for their domestic use . [ 69 ] Therefore , country - level disruption to South American countries , the DRC or China could result in a significant impact on global lithium and cobalt supply resulting in high supply risk . [ 48 ] In addition to lithium and cobalt , environmental policies appearing throughout South East Asia banning raw ore exports or suspending nickel extraction in certain regions may pose a notable risk to nickel supply . [ 70 ] Increased insight into the environmental , social and governance ( ESG ) impacts of critical metal mining ( see Environmental , Social and Governance Impacts Section ) has led to increased consciousness toward responsible sourcing , which may further restrict resources available for use . Tesla has demonstrated the need for a secure supply chain by securing the supply of both Ni and Li as these metals pose the greatest risk within their nickel - rich chemistries . [ 47,70 ] Helbig et al . attempted to quantify the supply risk associated with a selection of metals used for battery applications . [ 72 ] From this study , it was determined that Li and Co posed the most significant supply risk ( 54 % risk ) . Risk to Li supply was largely impacted by lack of sufficient recycling opportunities , whereas high Co risk was a result of political instability and byproduct dependence . From the data presented , Ni ( 50 % ) and Mn ( 52 % ) show similar supply risk scores , with Ni risk largely dependent on supply reduction . Mn , on the other hand , shows a high score , despite its high natural abundance , due to its lack of substitutability . Ti was also evaluated , due to its use in lithium titanate anode materials ( Li 4 Ti 5 O 12 ) , and was shown to have a lower supply risk ( 43 % ) . This work highlights the need to include Mn into supply considerations . Furthermore , understanding the impact of increased demand for Ti may be interesting for understanding the future implications of moving to alternative chemistries .	240517510	no
We extracted the numerical values directly from tables and text in the selected documents , or from figures by using the Web - PlotDigitalizer version 4.2 ( Rohatgi , 2019 ) . We also collected information about historical data and input parameters for each study ( e.g. changes of recycling market shares , technological market penetration , investment levels , taxation rates , and price elasticities ) . Further information on the selected literature is available in worksheet selected_literature in the file data_source.xlsx of the Supplementary Materials .	224930176	yes
Different methods have been developed to investigate environmental efficiency ( the ratio of the target environment output to the actual environment output ) or CEE . For instance , Charnes et al . ( 1978 ) first proposed the data envelopment analysis ( DEA ) model , which has been widely employed in research on environmental and energy efficiency ( Dyckhoff and Allen , 2001;Qin et al . , 2017;Zhou et al . , 2017 ) . Charnes and Cooper ( 1985 ) combined the DEA with window analysis and proposed the DEA window analysis to estimate the dynamic effect of data . The fuzzy DEA model was proposed by Ignatius et al . ( 2016 ) to evaluate CEE in 23 European Union ( EU ) countries . Slack - based measure ( SBM ) DEA model was applied by Choi et al . ( 2012 ) to calculate the efficiency and potential CO 2 emissions reduction ( PCR ) ( the slack of CO 2 emissions ) in China . The average PCR was 56.1 million tons in each province , and the CEE in eastern China is better than that in other regions in China .	158288388	no
The high - capacity pad configuration combined with internal reactant storage provides a particularly effective solution with performance and capacity that exceed those of the premixed   reactant experiment . The operational energy density of the prototype device , based on the electrical energy generated from the discharge data in Figure 5 normalized by the mass of the stored reactants , is estimated to be 32 Wh kg â1 . This value compares favorably to other recently reported biodegradable batteries , [ 7,8 ] albeit further improvements are needed to reach the level of conventional primary batteries such as Li - ion batteries . An important advantage of the present device configuration , in terms of energy density , is that the reactants are stored in the dry , solid state . Compared to an equivalent redox flow battery with the same reactants stored in liquid electrolytes , the operational energy density is â7Ã higher . This feature is particularly important for the portable applications intended for the battery . Figure S2 ( Supporting Information ) shows the Coulombic electroactive material utilization calculated from the discharge curves of the battery prototypes in Figure 5 as the fraction of active species converted by the battery during discharge until the cut - off voltage ( in this case 0.5 V ) is reached . The batteries with an intermediate absorbent pad thickness operated under a high load show the highest active material utilization among the tested conditions . Interestingly , under these conditions , the device with internally stored reactants achieves a higher utilization ( 13.3 % ) than the corresponding device supplied with premixed reactant solutions ( 8.9 % ) , which could be due to reactions already taking place in the dissolved active species before coming into the battery . This indicates yet another advantage of the proposed PowerPAD flow battery configuration with onboard reactant storage in terms of reactant utilization , although further optimization is required to fully exploit its potential in this regard .	99044966	no
"We then explored the data of our earlier experiment with Heifetz about the games that was presented first in Ghosh et al . ( 2015b ) . In the current article , we moved beyond the question whether participants in general use forward induction reasoning and instead first explored two ways of segregating the participants into groups to see whether and how they can be divided into reasonable "" player types "" . The first way to construct a typology was based on latent class analysis , which turned out to divide the players into three classes according to their first decisions in the game : Random players , Learners , and finally Expected players who make decisions consistent with forward induction . This typology appeared to be reasonable , because the three levels correspond with increasing gains in the games and with increasing time spent on decisions . The second way of constructing a typology was based on the participants ' answers to a question about their opponent , classified according to levels of theory of mind : the resulting types are Zero - order , First - order and Second - order . This typology was also validated by increasing levels of theory of mind turning out to correspond to increasing monetary awards and increasing decision times . The logical language was then used to describe different reasoning strategies and reasoning types that were displayed by the participants during the experiment , including the types discussed previously ."	641997	no
Conceptualization , J.H. and S.L. ; data curation , N.Y. and J.H ; formal analysis and writing - original draft preparation , J.H. and R.L. ; writing - review and editing , S.L. and J.H. All authors read and approved the manuscript .	235915166	no
To model the monthly electricity consumption from 2015 to 2019 , this sub - section mainly focused on the prediction process and accuracy of each model . According to statistics from the China Electricity Council , the value of electricity consumption in the past five years was shown in Table 1 . The data conveyed the following information points . First , China 's electricity consumption had shown a slow upward trend in the past five years . Specifically , the annual growth rate in recent years was 18 % , 22 % , 21 % , 5 % , and 15 % . Second , there were apparent seasonal changes between monthly data . Summer and winter usually reached small peaks of electricity consumption during the year .	236294095	maybe
This is an longitudinal observational study . We controlled for a wide range of sociodemographic characteristics , maternal health and baseline values of the outcome variables wherever data were available , with the aim to make the comparison groups exchangeable .	146115927	no
A final , broader future concept is to plan for a smart city . While the term smart city has varying definitions , the overall idea is that a smart city will make use of information communications technologies ( ICT ) , investments from human and social capital , and collaborative innovations designed to improve the quality of life for its citizens ( Errichiello & Demarco , 2020 ) . Ideally , by making use of intensive development and improved technologies , the smart city will one day help its citizens become more resilient and prepared to face any crisis by using a network of computers , artificial intelligence solutions , big data , and the internet of things ( Errichiello & Demarco , 2020 ) . For example , with a smart city , remote working , e - learning , telemedicine , etc . can all be easily accessible so should there be another pandemic , there would only be minimal disruption to a person 's life . The pandemic has already acted as a catalyst to improve ICTs everywhere , and this can lead to the development of a smart city and rapid urbanization . All this can be achieved with the proper considerations .	242496299	no
Collecting COVID-19 case data within cities proved challenging . For disaggregated COVID-19 data at the urban scale , there are no global patterns , no standard dashboards , no unified reports , and therefore the sources vary from official agencies to educational institutions , nongovernment organizations ( NGOs ) , and even to media portals . These problems have been highlighted by the World Health Organization in its COVID-19 strategy update report ( WHO , 2020b : 13 ) , which stresses the challenges involved in accessing disaggregated global data due to a lack of standardized data architecture and harmonized public health reporting mechanisms .	244923305	no
In EC - AFM and related SPM techniques the structure of the battery being studied is , in the vast majority of cases , much simpler than that of a real battery , discarding the closely and multiply stacked / wound parallel anode , separator / electrolyte , cathode layers found in cylindrical , prismatic , or pouch cells for a single working electrode that is well geometrically separated from any others , making enough space for the scanning probe . It is also common to utilize a three electrode system , introducing both a simple counter and reference electrode , as opposed to a second complex ' active ' ( e.g. , a metal oxide based cathode ) electrode , despite the fact that this will exclude any influence of the redox processes at this electrode on the electrochemical environment . The complex working electrode itself is also commonly replaced with a relatively flat analogue , highly unrepresentative of most battery electrodes , but often deemed necessary due to the perceived vertical height limitations with AFM . Finally , although many other differences exist on a case - by - case basis , it is usual to utilize a vast excess of electrolyte in these studies , in comparison to the ' lean ' electrolyte conditions in many modern batteries , necessary to fully submerge all the electrodes and the probe . These simplified conditions are beneficial for expanding our understanding of the basic mechanisms occurring during battery electrochemical processes , in particular at the electrode / electrolyte interface ( pseudo 2D ) . However , it excludes contributions from more complex phenomena in 3D , such as electrode strain , electric field distribution , the nature of the conductive network and ionic transportation and more , all of which we must understand to help improve batteries . Hence it is essential that the data collected to date is critically appraised , considering the degree to which it can truly be used to expand our understanding of processes within real batteries .	237552462	no
Given the average salary in each broad sector , the LHC premium declared by interviewees , and the above - assumed shares of students finding a job in each sector , we have computed a job effect component of the human capital formation benefit . Considering that the difference Figure 3 : Top : types and number of people benefitting from training at the LHC , historical data and forecasts . Centre : estimation of future average salaries ( left ) ; current employment sector of CERN alumni ( right ) . Bottom : perception of skill improvements due to the LHC experience ( left ) ; percentage impact on salary due to the LHC experience estimated by current students ( light green ) and past - students ( dark green ) ( right ) .	84176509	no
Firms are subject to multiple crises over time . From a scope perspective , most crises only relate to the affected firm itself or to a specific region ( Wenzel et al . , 2020 ) . For example , the global ridehailing firm Uber experienced a data breach in 2018 , exposing private data related to 600,000 Uber drivers ( Al - Muslim , 2018 ) . The resulting crisis negatively affected financial performance and reputation , leading to a rework of Uber 's data privacy and internal data access policies . Analogously restricted to the scope of single firms , Raithel and Hock ( 2021 ) , for instance , investigate the match between product crises and product recall responses .	255571157	no
which is identical to those observed by Suenobu et al . for LaNi 5 powder before and after hydrogenation . [ 22 ] Figure 4b shows the magnitudes of the Fourier - transformed EXAFS data of these samples obtained by the Fourier analysis . A most strong peak appeared on the Ni edge at about 2 Ã , corresponding to mainly Ni - Ni and partially Ni - La distances . The decrease of this main peak height after charging is attributed to either decreasing of the coordination number or increasing of the static disorder induced by hydrogen . It indicates the chemical hydrogenation of MH particles by reduced mediators . Furthermore , both XANES and EXAFS spectra of the discharged MH sample changed back to that of pristine one , suggesting the reversible hydrogenation / dehydrogenation of MH particles in the external reservoir during the charge and discharge processes .	244360866	no
The shares of vehicles before the lockdown were estimated based on the total number of registered vehicles in each category in the city extracted from Automobile Club d'Italia ( http://www.aci.it/ ) , and the hourly flow extracted from a report by 5 T S.r.l . on vehicular mobility in the Piedmont region ( 5 T and Regione_Piemonte , 2019 ) . For the lockdown period , the share of each category in the hourly traffic flow in both working and non - working days was considered in the simulation . Since no data on the share of each of the 44 specified categories in the hourly traffic flow of Turin was available , and this type of data could not be extracted from the recorded traffic flow , an estimation for the share of these vehicles in the traffic flow was made . The data regarding the circulating vehicles was estimated based on the average number of kilometers traveled , and the data regarding the registered vehicles were considered in order to verify the consistency of the disaggregation into categories .	236179718	yes
We used a Monte Carlo simulation study ( MuthÃ©n & MuthÃ©n , 2002 ) to evaluate the necessary sample size to get good enough fit indices ( i.e. , RMSEA , CFI , TLI , SRMR ) . Figure 2 shows that in samples from 100 employees or more , apart from SRMR , the fit indexes have no clear turning point in which increasing sample size would improve the quality of the fit of the model ( assuming the best model found in Study 2 as the true data generating process ) . For SRMR , sample sizes larger than 198 participants will more likely	235671763	maybe
Further , the negative impact of COVID-19 on the economy , daily life , and social activity , created psychological difficulties . Previously for the SARS outbreak , due to quarantine , high rates of depression and anxiety among people were visible . This pandemic also created psychological issues including depression , frustration and stress while survey was conducted with 1182 individual in New Delhi , India which included different age groups and genders ( Chaturvedi et al . , 2021 ) . In London 70,000 adults data between 23rd March and 9th August , showed in the early stage of lockdown depression and anxiety was present , which reduced later , may be because of the adaption with circumstances ( Fancourt et al . , 2021 ) . Similar outcome was also found in Germany ( Bendau et al . , 2021 ) . Using 500 adult samples from nationwide , the USA community showed the positive impact of COVID-19 on daily life associated with health anxiety , financial worry , and social support , and a negative association with loneliness , due to self - isolation and no social life was prominent ( Tull et al . , 2020 ) . In the Greek population , insomnia was prevalent for women and people living in an urban area . Financial pressure , changes in social life , and the daily routine increased health issues during a virus outbreak ( Voitsidis et al . , 2020 ) . Depression , anxiety , and PTSD symptoms were prominent among the USA young adults , age between 18 and 30 years , with high levels of COVID-19 - specific worry and loneliness ( 898 participants from April 13 , 2020 , to May 19 , 2020 ) ( Liu et al . , 2020a ) . Based on different published reports , due to economic hardship , isolation , quarantine suicide rate   increased during this time . In some cases , unavailability of food and alcohol was also a reason for suicide . Six different couples committed suicide in Bangladesh , India , and the USA for various reasons such as public harassment , fear from COVID-19 , and financial constraint ( Griffiths and Mamun , 2020 ) . Suicide for financial distress was higher in economically hard countries ( Rajkumar , 2020 ) . Increasing levels of domestic violence , which includes physical , emotional , and sexual abuse increased ( Roesch et al . , 2020 ) in Brazil ( 40%-50 % ) , and in Spain , Cyprus , UK , and Singapore helpline received 20 % , 30 % , 25 % , 33 % higher call respectively because of the domestic violence ( Bradbury - Jones and Isham , 2020 ) . Domestic violence tripled during February 2020 compared to February 2019 in Hubei , an increase of 30 % in France , and 25 % in Argentina were observed since they initiated a lockdown in March 17 and March 20 respectively ( Boserup et al . , 2020 ) . Lockdown adversely affected the life of refugee in Uganda because of the insecurity in income while gender - based and sexual violence and anxiety increased ( Bukuluki et al . , 2020 ) .	236247702	no
The main objective of this paper is to develop and evaluate a threestep methodological framework that can be used to identify knowledge gaps and provide new insights into development directions of a welldefined technological field . Although we aim at wider applicability , in this paper , the framework is developed and demonstrated with respect to wind catchers ; a sustainable natural ventilation system for buildings . This topic was specifically chosen because it is manageable in scope and size ( i.e. the veracity of the results can be checked ) , yet has experienced a complex development history , is an active field with mixed research methods , and has a non - trivial future outlook . This paper uses a combination of existing methods : life - cycle analysis , text mining and cluster analysis , but combines them in a novel way that has not been described before . Given the importance of the impact of textual data on the accuracy of text mining , a sensitivity analysis is also carried out for three cases , when ( i ) title , ( ii ) title , abstract and keywords , and ( iii ) full - text of the papers are considered as the textual data . This evaluation is based on the methodology of the research papers . This paper continues by describing the development of a methodological framework for science foresight on the basis of life - cycle analysis , text mining and cluster analysis ( Section 2 ) . The sensitivity analysis is also presented in this section . Characteristics of wind catchers , the topic of the application study , are introduced in Section 3 . In Section 4 , this methodology is applied in the case of wind catchers , to describe the status of research in this field , predict future trends and identify knowledge gaps in order to identify possible opportunities for new research and development activities . In Section 5 , a reflection on the methodological framework and its potential in future studies is given .	65495165	no
Between November 2013 and January 2016 , we conducted 53 depth interviews held in the offices of participants or in coffee shops in Bucharest , generating approximately 58 h of data . Most multinationals have their headquarters and related CSR departments in Bucharest , 1 3 but they implement CSR projects across the country . Five participants were interviewed twice ( in 2013 , and then in late 2015 , or early 2016 ) following up on accounts provided about changes in their position , or job , or ongoing projects . Position titles included : corporate responsibility manager , corporate communications manager , community affairs manager , president , director , executive director , fundraising manager , community strategy or relations manager , programme coordinator . Industry sectors included : automotive , FMCG , retail , construction , banking , tobacco , technology , and non - profit organizations that support community , health , environmental , minority groups , human or animal rights issues ( see Table 1 ) .	237363721	no
Probably the environment is the only sector that got an immensely positive impact form this COVID-19 scenario . International energy agency reported that global coal use was 8 % lower in the first quarter in 2020 . Due to the Locked down , transport , industry , and all non - essential sectors were closed , which reduced emission significantly . NASA ( National Aeronautics and Space Administration ) and ESA ( European Space Agency ) published recent data ( Fig . 9 ) declaring that compared to last year , NO 2 emission reduced by 30 % ( Dutheil et al . , 2020 ) . The decline in PM2.5 was significant in the US , UAE , Italy , and Spain , in the month of March , due to cumulative lockdown ( Chauhan and Singh , 2020 ) . Noticeably , in China , the overall air quality improved as NO 2 reduced by 22.8 Î¼g / m 3 , PM 2.5 decreased by 1.4 Î¼g / m 3 particularly in Wuhan ( Zambrano - Monserrate et al . , 2020 ) and by 18.9 Î¼g / m 3 in 367 other cities ( Lal et al . , 2020 ) . However , some cities also witnessed the air quality index over 100 . These reductions accounted for lowering the particle loadings ( Wang et al . , 2020f ) . Air quality showed improvement near the Yangtze River Delta ( YRD ) region , which is one of the economic city - clusters in Eastern China . However , the percentage of PM 2.5 attributed to residences and long - range transport . Additionally , 44 cities of northern China marked 69.5 % reduction in human mobility improving the air quality as SO 2 , PM2.5 , PM10 , NO 2 , and CO decreased by 6.76 % , 5.93 % , 13.66 % , 24.67 % , and 4.58 % , respectively ( Bao and Zhang , 2020 ) . In 2017 , the energy sector in Italy ( industry and transport ) contributed 80 % of the total country GHG emissions . COVID-19 related lockdown caused an overall 20 % reduction of GHG emission , lower than emissions of March and April in 2015 - 2019 ( Rugani and Caro , 2020 ) . In Milan , Italy , partial lockdown restricted the people movement , and total lockdown terminated industry and transport activities . Reduction of PM10 , PM2.5 , BC , benzene , CO , and NOx level was observed because of a decrease in road transport ( Collivignarelli et al . , 2020 ) . In Barcelona , PM10 reduced by 31 %   and NO 2 by 50 % ( Baldasano , 2020 ) . Initially , Madrid and Barcelona contributed 55 % and 56 % of NO 2 emission from traffic . However , due to the COVID-19 scenario - based lockdown , since March , Barcelona and Madrid ( Spain ) , emitted 50 % and 62 % less NO 2 respectively ( Baldasano , 2020 ) . In the continental USA , PM2.5 reduced during the lockdown , especially in urban counties and wherever non - essential businesses were closed ( Berman and Ebisu , 2020 ) . During the lockdown period ( March 19th to April 14th , 2020 ) , reduction in PM2.5 , NO 2 , and CO concentration by 21 % , by 35 % , CO by 49 % , was noticed in Almaty , Kazakhstan ( Kerimray et al . , 2020 ) . Sao Paolo Brazil also encountered a reduction in CO and NO 2 emission by 64.8 % , and 77.3 % ( Nakada and Urban , 2020 ) . Further , PM10 , NO 2 , and SO 2 emissions decreased by more than half during the COVID-19 lockdown period in SalÃ© City , Morocco ( Otmani et al . , 2020 ) . India , every year battles more than 350,000 new cases of childhood asthma and 16000 premature death attributed to air pollution , mostly NO 2 and PM ( 2.5 - 10 Î¼m ) generated from fossil fuels and transportation sector ( CREA , 2020 ) .	236247702	no
The data includes all ET cases in 2015 - 2018 that claimed Public Interest Disclosure and went to a preliminary hearing or beyond in England and Wales . Public Interest Disclosure claims are categorised as open track claims and claimants had to pay a Â£ 250 lodging fee and a Â£ 950 hearing fee . Fees were introduced to shift the cost burden of the ET system onto those who use it and to discourage vexatious claims ( Dickens , 2014 ) . Despite the desire to reduce the number of vexatious claims , research shows that success rates of claims have fallen since fees were introduced , suggesting that genuine cases were put off going to ET as much as vexatious claims ( Tetlow , 2017 ) . However , due to a landmark case taken by Unison in late July 2017 , fees were ruled to be unlawful and the fee system was scrapped .	245506098	no
It would hence be necessary to expand further the evaluation of the socio - economic impact of RIs to other large - scale facilities , including those in applied science . An example of the latter is a recent study of the CNAO particle accelerator for hadron therapy ( Pancotti et al . 2015 ) , which uses , in the context of medical research , the same methodology we apply here . The proportion and scale of the costs and benefits may be different elsewhere , but we believe that the main ingredients of a CBA of research infrastructure are well represented in the LHC case ; hence replication can be attempted if data are available . Further studies on a range of different facilities , in different science and technology domains , and in different countries , are needed to confirm our intuition .	84176509	no
Each test was repeated at least three times in the present work . The data were presented as the means Â± standard deviations . Statistical analysis was performed using one - way analysis of variance .	252843568	maybe
Again , black box AI in respect to the extent of data capture , data quality , model specification , among other things , complicate the judgments of non - maleficence and the decision of whether to rely on algorithmic predictions for both customers and companies . While the perspective on algorithm - driven decision - making focuses on decision outcomes , the autonomy principles rather entails the process view of decision - making .	235213894	no
More broadly , recent technological advances are transforming retailing ( Shankar et al . , 2020 ) , and understanding the drivers of consumer mobility data can enable organizations to further optimize technology - driven tools to manage market disruptions . Our method is scalable to include more risk perception indicators to predict retail mobility , which could be a starting point toward developing actionable retailing strategies . Although we do not focus on the impact of retail mobility on specific retail strategies , we believe that the outcomes from our predictive model could be used as strategic inputs to optimize several retail decisions , such as staffing , inventory , and location - based online and in - store advertising decisions .	255441206	no
We have considered five types of ESR : CERN doctoral students ; CERN technical students ; CERN fellows ; users under 30 years ; and users between 30 and 35 years . The sources of data are the yearly reports of CERN Personnel statistics from 1995 until 2013 . We have estimated the number of incoming students year by year for each type and average stay , based on past data available at the CERN Human Resources Department and from interviews with staff . Future incoming student flows have been extrapolated from past trends and checked with CERN . The HR Department records all types of students and post - docs , but we need an apportionment of these flows to the LHC . We have computed such apportionments with data from the Collaborations and additional interviews at CERN , leading to the following estimates : 30 % of the total flows ( for the period 1993 - 1998 ) ; 50 % ( 1999)(2000)(2001 ) ; 70 % ( 2002 - 2007 ) ; and 85 % ( 2008 - 2025 ) . The resulting figures have then been attributed to each of the five types , based on the historical distribution , in order to derive the flow of annual incoming students over the years 1993 - 2025 .	84176509	maybe
Of the 219 articles coded , 61 were found to contain either cognition , sensemaking or managerial interpretation as a key conceptual focus ( 34 cognition ; 22 sensemaking ; 5 managerial interpretation ) . Originally only two articles were located with a focus on managerial interpretation . Due to the low numbers of articles being returned a second separate review was completed examining the articles which referenced the original Sharma article from the year 2000 . Of the 966 articles which cited Sharma ( 2000 ) in Scopus , 299 articles came from the journals considered in this review . The abstracts of each of these 299 articles were then reviewed to establish whether they were in fact about managerial interpretation or whether it was a minor citation within the text . Only two of the articles contained the complete term ' managerial interpretation ' in their abstract , title or key words in addition to containing content on a sustainability - related topic ; however , the simplified term ' interpret ' identified 14 articles . The sustainability - related topic verification resulted in five remaining articles of which two were already contained in the data set . This process resulted in an additional three files which were included in the review .	236495231	no
Privacy levels according to type of data collection and user privacy .	233029680	no
The functional units ( FUs ) employed for analysis in this study are masks used by 100 individuals over a period of 1 month . Reusable cotton masks are discarded after 6 days of use ; in other words , they can withstand up to 5 washes while maintaining their protective properties , as recommended by the surveyed factories . Despite the fact that there are many different brands of reusable masks on the market that may vary in the maximum numbers of washes ( TESTEX Community Mask Label , 2022 ) , with some reportedly able to withstand up to 30 washes ( Forever Family , 2022 ) , due to limited research conditions and survey funding , production data were only available for masks that could be washed up to 5 times . Given that the cost people pay for them ( retail price : CNY 7 per mask ) is quite low relative to disposable masks ( retail price : CNY 0.35 per medical and surgical mask and CNY 2.5 per KN95 ) , we developed an evaluation model based on the number of washes in Section 2.4.2 to reduce the uncertainty associated with low settings for the number of washes .	255373604	no
"The growth rate in air transportation volume in our sample is even higher than the global average for international tourism referenced   ( Recchi et al . , 2019 ) . The association between these figures with our global cities sample is explored using two indicators developed by Sun et al . ( 2017 ) namely the "" International Ratio "" and the "" Global Direct Reach , "" applied to data gathered from FlightRadar24 for 2020 . Both indicators were calculated based on consolidated information for each city , considering airports within 1.5 h driving distance from the city center . Table 2 lists the airports included in each city as well as both indicators . The average value of the International Ratio equals 0.51 , on a scale from 0 to 1 , meaning that in average 51 % of the total flights serving airports associated with our global cities sample , are international flights . The Global Direct Reach resulted in an average of 62 countries with direct connections from each global city , a figure that is 637 % higher than the average of the total dataset including almost 3000 airports . The latter indicator when grouped according to the GaWC classification of Alpha , Beta , and Gamma cities shows that the first tier of global cities reaches an average of 88 countries with direct connections ( Global Direct Reach ) , the second tier of cities connects to an average of 63 nations , and finally , 57 direct connections are the average among airports in the third tier . These results indicate a clear connection between globalization , represented by the GaWC ranking , and the degree of international hypermobility expressed by the Global Direct Reach indicator ."	244923305	no
"To the extent that the associations we measured reflect social influence , this research has implications for the design of public health and policy interventions to prevent obesity that may be realized using ubiquitous and readily - available data linking individuals to one another . Social influence could be leveraged to target particular individuals or social connections to promote healthy eating or disrupt unhealthy eating . Furthermore , the physical environments where social interactions occur could be designed to target pairs of people ( or larger groups of purchasers ) making food choices . For example , healthfulness could be encouraged by offering two - for - one sales on salads ( or other healthy foods ) for pairs of purchasers . Lastly , quantifying the social transmission of food choice behaviour could allow policy - makers and researchers to develop interventions and policies that efficiently target specific groups of people for increased population effect 31,32 . Eating together is an example of a public health scenario that likely involves a large "" network multiplier "" effect 33 . If food choice is "" socially contagious "" and an intervention improves healthy eating in a particular group , the benefit of that intervention will accrue not only to that group , but to individuals socially connected to group members , as well . This more complete capture of benefits will provide greater incentives for stakeholders to adopt health - promoting interventions . Though our findings do not prove the existence of social influence in food choice , they are consistent with such an explanation and together with these implications highlight the value of additional work to test peer - based strategies for promoting healthy eating ."	233371463	no
"Public opinions could also influence the design of public policies . A classic study conducted by Page and Shapiro ( 1983 ) examines public opinions and policy data of the U.S. from 1935 to 1979 , and finds out that very often public opinions cause policies to change , and could influence policies more than policies affect opinions . Therefore , an analysis of public sentiment could provide valuable insights into how policies should be implemented . For instance , Chung and Zeng ( 2016 ) have collected Tweets related to U.S. immigration and border security policies , extracted the sentiment and emotion of Tweets , and helped policymakers build a "" social - media - based public policy informatics "" system that could identify key opinion leaders and community activists ."	236251116	no
Finally , it is worthy to highlight the importance of a circular economy with respect to recycling and the steps of reuse and remanufacturing . Manufacturing and recycling steps are closely related . Accordingly , the digitalization and enhancement of the production processes may clarify and give key insights on how to develop concepts for a reuse of certain battery cells or a remanufacturing , for example , of battery modules and finally a safe and sustainable recycling process . Recent proposals call for the establishment of a Battery Identity Global Passport ( BIGP ) to support battery recycling . The BIGP is envisioned as a digital asset that accompanies the battery over its lifetime , from manufacturing to recycling , and should provide to recyclers the necessary information about the materials that are included in the cell , so that it can be processed in a tailored recycling process . In this scenario , battery manufacturers will likely be asked to mint the BIGP for their cells , which again underscores the need for common data structures to support interoperability , not only internally within a gigafactory , but across the entire battery value chain .	245112757	no
The SiRi global profiles that were used contain over 350 data points and are structured according to the following research themes : community , corporate governance , customers , employees , environment , contractors / human rights , and business ethics . The themes correspond to the following stakeholder groups : the community , shareholders , customers , employees , environmental stakeholder groups , and human rights groups . Due to this stakeholder orientation , the database is considered to be an appropriate tool for the purpose of this study . The sources , on which the profile content is based , are not limited to annual reports , but also include special - purpose reports ( environmental reports , sustainability reports , and personnel reports ) , consultation of NGOs and governments , the media , one - to - one meetings with company representatives , and questionnaires .	254384414	maybe
Risk perception is broadly defined as evaluating the subjective probability of a negative outcome and its consequences ( SjÃ¶berg et al . , 2004;Menon et al . , 2008 ) . Prior research suggests that risk perceptions have two dimensions , susceptibility and severity ( El - Toukhy , 2015 ) . Susceptibility refers to the likelihood of experiencing a health risk , whereas severity refers to the seriousness of the risk ( Brewer et al . , 2007 ) . The local and national cases and death data due to the pandemic publicized by the media and captured in the Pandemic Impact metrics provide consumers with a measure of the pandemic 's prevalence in their local communities , impacting their risk perceptions in terms of their susceptibility to the pandemic . Further , such risk assessment by consumers affects their decision to search for information ( Maser & Weiermair , 1998 ) . Information search for pandemic - related paraphernalia captures the risk perception in terms of severity . Moreover , mortality data may also directly affect consumers ' perceptions of the severity of the risk associated with the pandemic . Therefore , in our empirical analysis , we incorporate the effect of both these dimensions of risk perception on mobility .	255441206	no
"Although many positive effects were anticipated , the negative effects of the right to be forgotten were also expected . Many respondents were concerned about abusing the right , which could result in social problems such as allowing ( ex- ) criminals to delete their records and facilitating information concealment and privatization . This concern was reflected in statements such as : "" The original content should be saved because of concerns for social issues such as crimes , "" "" This will make it easy for politicians and companies to privatize or conceal information , "" "" If this makes it easy to delete , this might be more abused , "" and "" It enables abuse by certain companies or organizations without my consent . "" Moreover , the respondents thought that the right to be forgotten could lead to manipulation of the press and the mass production of The content includes private information "" "" Because it contains a sensitive issue "" "" The mind or facts have changed between the time of writing and revising "" Social reputation "" It is embarrassing to me "" 197 ( 25.89 % ) 187 ( 21.42 % ) "" It contains content that is harmful to me "" "" It might catch up with me in the future "" "" I am concerned about misleading information / opinions to others who see my post "" Control over further processing "" I do not think I can control it "" 78 ( 10.25 % ) 106 ( 12.14 % ) "" I want to know how my content is used , but I do not think this is possible "" "" It is out of control due to illegal archiving services "" System / process "" The reliability of the service is low "" 33 ( 4.34 % ) 60 ( 6.87 % ) "" The service does not provide means or options for control "" "" It is difficult to find the deletion request procedure . There is no way to contact the uploader . There is no immediate request method , such as by telephone "" Sociality "" There are people with similar experiences around me "" 31 ( 4.07 % ) 19 ( 2.18 % ) "" I see that similar things are deleted or changed by others "" "" Other people have asked me to revise or delete content "" Others "" To improve what I have written "" 9 ( 1.18 % ) 2 ( 0.23 % ) "" I have something to fix â¦ "" Total 761 ( 100 % ) 871 ( 100 % ) Fig . 1 An abstraction process of motives for deleting / revising personal data Fig . 2 Positive effects of the right to be forgotten on online content generation false information ( e.g. , fake news and rumors ) , with diminished responsibility for information distribution . For example , "" It enables artificial image [ or reputation ] manipulation through the misusage of RTBF , "" "" It can lead to mass production of false information , "" and "" It can be used to conceal facts . "" Additionally , they expressed the recklessness of content uploads , for example , "" It encourages free registration and deletion , and increases the possibility of indiscriminate data registration [ i.e. , content uploads ] "" and "" It is likely to be a more senseless posting because the content can be easily removed because of the guarantee of the right . "" Skeptics were also concerned about reduced freedom of speech and limited content variety . Such respondents expressed their concerns as : "" Strong claims or content postings with the possibility of controversy will be reluctant , "" "" The greater the awareness of the right to be forgotten , the more cautious is the content posting , "" "" I think over time , only refined and simplified content will remain , "" and "" It may cause longterm negative effects to the diversity of Internet content . """	231744099	no
To validate the model , we showed the performance of the model in fitting real case data and predicting out - of - sample cases using the model calibrated on the period before . Specifically , we split the study period into two parts : the first 12 weeks as the learning set for fitting and calibrating the model ; the balance of the time ( 4 weeks ) as the testing set for predicting the confirmed cases . We first fit the model taking the weekly contact networks in the first 12 weeks as the input and obtained the values of model parameters . Due to the delay in case testing and reporting , our model implemented on the contact network in any week was fitted on the cases in the following week by minimizing the root mean square error ( RMSE ) . Hence , we define the loss function as :	233025194	no
The paper is laid out as follows . To begin , we review the literature on cross - sector social collaboration . Building on core concepts from two research traditions , the life - world ( SchÃ¼tz 1967 ) and reciprocity theory ( Sahlins 1972 ) , we derive five conditions for lasting corporate - SE collaborations . In the methodology we explain QCA and our set - theoretic approach . We next employ fsQCA to analyze dyadic data from corporate - SE collaborations . The results are then reported , and we use the literature on cross - sector collaboration , life - worlds and reciprocity to examine the plausibility of our findings . Our contributions to theory are explained , and the paper concludes with suggestions for future research .	234030256	no
For the first dimension of capabilities , we define reactive smart things as having the ability to immediately adjust to a changing environment . Adaptive smart things have the longer - term ability to adjust their behavior to changes , such as by learning from historical data or usage patterns . Autonomous smart things have the ability to act independently , without direct intervention from human agents . Cooperative smart things have the ability to interact with other constituents of the IoE in order to jointly work towards a unified objective . The final smartness capability from Rijsdijk and Hultink ( 2009 ) is multifunctionality which refers to the ability to support and combine several functions in a single device . However , due to the other dimension for our taxonomy , connectivity , we no longer see the relevance of focusing on multi - functional things when a set of connected , uni - functional , things can amount to the same . As such , we drop multi - functionality from our taxonomy . Therefore , we utilize four smartness capabilities that denote how smart things can be reactive , adaptive , autonomous and collaborative . It may be clear that each of these capabilities is a technological achievement in its own right , a fact highlighted in our earlier discussion of enabling technologies , but it is in their combination that the highest levels of smartness may be achieved .	213757082	no
Further , the negative impact of COVID-19 on the economy , daily life , and social activity , created psychological difficulties . Previously for the SARS outbreak , due to quarantine , high rates of depression and anxiety among people were visible . This pandemic also created psychological issues including depression , frustration and stress while survey was conducted with 1182 individual in New Delhi , India which included different age groups and genders ( Chaturvedi et al . , 2021 ) . In London 70,000 adults data between 23rd March and 9th August , showed in the early stage of lockdown depression and anxiety was present , which reduced later , may be because of the adaption with circumstances ( Fancourt et al . , 2021 ) . Similar outcome was also found in Germany ( Bendau et al . , 2021 ) . Using 500 adult samples from nationwide , the USA community showed the positive impact of COVID-19 on daily life associated with health anxiety , financial worry , and social support , and a negative association with loneliness , due to self - isolation and no social life was prominent ( Tull et al . , 2020 ) . In the Greek population , insomnia was prevalent for women and people living in an urban area . Financial pressure , changes in social life , and the daily routine increased health issues during a virus outbreak ( Voitsidis et al . , 2020 ) . Depression , anxiety , and PTSD symptoms were prominent among the USA young adults , age between 18 and 30 years , with high levels of COVID-19 - specific worry and loneliness ( 898 participants from April 13 , 2020 , to May 19 , 2020 ) ( Liu et al . , 2020a ) . Based on different published reports , due to economic hardship , isolation , quarantine suicide rate   increased during this time . In some cases , unavailability of food and alcohol was also a reason for suicide . Six different couples committed suicide in Bangladesh , India , and the USA for various reasons such as public harassment , fear from COVID-19 , and financial constraint ( Griffiths and Mamun , 2020 ) . Suicide for financial distress was higher in economically hard countries ( Rajkumar , 2020 ) . Increasing levels of domestic violence , which includes physical , emotional , and sexual abuse increased ( Roesch et al . , 2020 ) in Brazil ( 40%-50 % ) , and in Spain , Cyprus , UK , and Singapore helpline received 20 % , 30 % , 25 % , 33 % higher call respectively because of the domestic violence ( Bradbury - Jones and Isham , 2020 ) . Domestic violence tripled during February 2020 compared to February 2019 in Hubei , an increase of 30 % in France , and 25 % in Argentina were observed since they initiated a lockdown in March 17 and March 20 respectively ( Boserup et al . , 2020 ) . Lockdown adversely affected the life of refugee in Uganda because of the insecurity in income while gender - based and sexual violence and anxiety increased ( Bukuluki et al . , 2020 ) .	236247702	no
"The observations and focus groups enabled the researchers to identify the most relevant informants for the study . This study followed a grounded theory methodology in which the theory is grounded in the data and , most importantly , "" in the informants ' experience and their understanding of that experience "" ( Gioia , 2021 , p. 22 ) . Therefore , while multiple data sources were used ( see Table 2 ) , the heart of this research lies in the semi - structured interviews conducted with "" knowledgeable agents "" ( Gioia et al . , 2013 , p. 17 ) of the network ."	255592313	no
"In order to evaluate the blame validation and true self accounts described earlier as potential explanations for the findings of Studies 1 - 3 , Study 4 ( N=608 ; see Methods , Study 4 , Participants ) examined two psychological phenomena that could possibly be mediating people 's tendency to endorse genetic explanations less readily for antisocial behavior than for prosocial behavior . In particular , we tested whether the difference in genetic attributions for antisocial and prosocial behavior was consistent with mediation by differences in ascriptions of responsibility ( as would be predicted by the blame validation view ) and/or by differences in judgments of the extent to which the behavior reflected who the actor truly was ( as would be predicted by the true self view ) . Study 4 was identical to Study 3 , except that there was no manipulation of the presence or absence of a genetic explanation , and participants rated Jane 's level of responsibility for behavior and the extent to which her behavior reflected "" who she truly is , "" in addition to rating their genetic attributions ( see Methods , Study 4 , Stimuli and Procedures ) . We initially analyzed the data from Study 4 using a 6 ( situation ) Ã 2 ( condition : antisocial vs. prosocial ) ANOVA . This revealed a main effect of condition on genetic attribution ratings , replicating the results of We evaluated the two mediation hypotheses using the PROCESS procedure ( version 3.2 ) for SPSS with 5,000 bootstrap samples . 42 Figure 3 illustrates the results of this analysis . In particular , there was a significant indirect effect of condition on genetic attributions through responsibility ratings ( unstandardized B=.06 , 95 % percentile bootstrap CI [ 0.01 , .11 ] ) , consistent with the notion that participants ' motivation to hold Jane responsible for harmful behavior mediated their tendency to rate her behavior as less genetically influenced when she acted antisocially than when she acted prosocially . However , the indirect effect through "" true self "" ratings was not significant ( unstandardized B<.0001 , 95 % percentile bootstrap CI [ â.02 , .02 ] ) , suggesting that the extent to which participants considered Jane 's pattern of behavior to reflect who she truly was did not mediate their differential willingness to make genetic attributions for her prosocial and antisocial behavior . The data from Study 4 are presented as a box - and - whisker plot in Supplementary Figure 4 ."	198983723	maybe
Most data on softening is provided for different degrees of softening . Similar to Godskesen et al . ( 2012 ) and van der Bruggen et al . ( 2009 ) , it is assumed that the required electricity and auxiliaries ( except membranes ) and produced co - products have a positive linear correlation to the softening depth .	222117836	maybe
"Typically the probabilities figuring in this distribution are treated as unknown , and statistical data - analysis is conducted to learn something about them . There does not seem to be a generally accepted terminology for these probabilities figuring in a statistical model : I shall term them "" Formal Probabilities . """	26826884	no
The authors declare that they have no conflict of interest . NestlÃ© and its partner companies were by no means involved in the design , data analysis or financing of the research .	234832730	no
This data screening eliminated 1.4 % of the overall data . More than 272 million records of passenger movement through the MTR were considered valid . Passenger flow from time point A to time point B is defined as the number of passengers leaving the MTR station between A and B. To filter regular daily commutes from these movements , we defined consecutive round trips between the same two stations as regular commutes . We defined the pandemic and non - pandemic weeks to analyse the local travel behaviour during and before the COVID-19 pandemic . Between January 1 and March 31 , pandemic week ( March 25 to 31 ) is defined the week when the most weekly confirmed COVID-19 cases were reported . The non - pandemic week ( January 6 to 12 ) is a week without either holidays or any reported COVID-19 cases , and is regarded as a control group . We used the effective reproduction number R t ( Appendix A ) , to indicate the severity of virus transmission .	231880553	no
Our study has certain limitations that should be considered . The trends in health and well - being before and during the COVID-19 pandemic are analyzed for the context of Greece . Similar studies from other contexts will enrich the current findings . Future studies measuring health and well - being trends during later COVID-19 lockdowns would be particularly useful . Pathways between built environment characteristics and health and well - being outcomes need to be investigated in more detail in future research to provide insights into possible causal links . This study has used self - reported measures of health and wellbeing . In future studies , objective health and well - being indicators could be assessed for their relation to the built environment in cities during COVID-19 . The sample of the study is subject to biases common for questionnaire surveys and non - probability sampling . Health and well - being indicators were evaluated with univariate variables representing distinct concepts , thus a composite measure of health and/or well - being is not possible . These univariate variables are stable and reliable ( Lucas & Brent Donnellan , 2012 ) ; datasets with latent variables might have nevertheless produced even more reliable estimates . This study has assessed separate models for each health and well - being variable , while future studies could also explore connections between these health and well - being variables with more complex statistical techniques . The study was based on retrospective quasi - longitudinal data on health and well - being outcomes before and during COVID-19 . Individual recall might be imprecise and subject to biases compared to prospective longitudinal designs . Furthermore , due to the short interval between the before and during COVID-19 time points , individual sociodemographic characteristics were assessed only once . Measurements of these variables in two time points might have provided greater accuracy to the results .	238530423	no
"Fragility . Among the four instantiations of the concepts of healthy food , HF2 appears as the most fragile . As mentioned above , the diversity of meanings that could be attributed to "" naturalness "" affects the concept of healthy food through Synthese ( 2021 ) 199:12225 - 12249   all the dimensions - to the point that a comparative table for the family of HF2 could be easily imagined . A potential element of fragility can be found in HF4 , in the data and methodologies dimension : many different disciplines converge under the label of nutritional ecology , with their own methods , taxa , and concepts . Such interdisciplinarity is a resource only when a methodological integrated framework is at play ( Raubenheimer et al . , 2009 ) . Furthermore , each of the four instantiations tends to underestimate the role that unhealthy eating plays in relevant social occurrences , both formal and informal . Unhealthy foods may in fact enable experiences that provide highly desirable values , such as family or community identity , crucial for human psychological health ( e.g. , celebrations with specific cakes , see Barnhill et al . , 2014 ) . In this respect , each of the four instantiations could be marked with fragility since they do not include in their ontology specific food entities relevant for human well - being and they do not consider the aim of health in its multifactorial composition . 18 Polarization . Both HF1 and HF4 focus on the fine - grained layers of molecular interaction . The idea that diet affects physiology is at the very core of both positions but in substantially different ways . HF1 promotes the calculus of input - output , in which the body is the machine where transformation happens , and food is the measured input associated with projections on our body image and health - eat fewer calories to lose weight , take more vitamins to contrast aging . HF4 is not about knowing food components to create the right equation within the body - machine , but rather about how food affects our phenotype through mechanisms of attachment and removal of chemical marks to our DNA . In other words , it is about how food rules and shapes the metabolic equation ( Landecker , 2011(Landecker , , 2013b . Two polarized concepts of metabolism and the human body are entailed in HF1 and HF4 : clinical research targeting nutrition - related disease , for instance , would likely encounter some obstacles if both concepts are at play simultaneously within the research teams . As shown in Sect . 1.1 , another kind of polarization occurs between HF1 and , for instance , HF3 ."	238810809	no
Over the past several decades , complex forecasting methods have been developed to improve sales forecasts in the retail industry . As Ma & Fildes ( 2021 ) have stated , retail forecasting has focused on sales forecasting . However , no method dominates for all types of products and time periods . Therefore , the performance of the predictions is hugely dependent on the data available , products under study , and the geographic trends in which the demand emerges . In addition to testing various techniques to find the most accurate forecasting method specific to the product and the business , newly emerging data sources can definitely provide value in studying the retail industry 's demand and sales phenomenon . Brea et al . ( 2020 ) underscore the significance of these new data sources during uncertain times , especially when a pandemic hits . Incorporating these data ( e.g. , mobility and , more specifically , retail mobility data ) requires a systematic approach to analyzing the timing of information and the optimal lags with the outcomes of interest . As demonstrated in this study , machine learning and forecasting techniques used in the retail industry can address this challenge .	255441206	no
Having outlined the distinction between behaviour and symptoms I now develop a conceptual understanding of symptoms . To do this I consider the distinction between data and phenomena .	255068141	no
Convenience sampling was used because of its relevance to the research topic rather than the representativeness of how the respondents are selected ( Flick 2009 ) . Given that our research topic concerns each individual 's need to be forgotten in a general online environment , our sample should consist of individuals familiar with online services and experienced in uploading content on the Internet . Therefore , we collected half of the data from social networking service platforms and the other half by investigating the perceptions of part - and full - time MBA students , government employees , office workers , and students to consider a wider range of ages and occupations . For the first half , we uploaded the post collecting responses mainly on the timeline and group page on Facebook , and additionally , on Twitter and online communities . For the rest , we requested part - and full - time MBA students to participate in the survey during our lecture , and transferred the request to our acquaintance for completing the insufficient samples via KakaoTalk , a dominant instant messenger in Korea similar to WhatsApp .	231744099	no
Panel D in Fig . 4 displays the evolution of price elasticity over time . Consistent with the low - price elasticities reported for US Apple App Store ( e.g. , Ghose & Han , 2014;KÃ¼bler et al . , 2018 ) , we find that a 10 % increase in price lowers downloads by 1.41 % on average . The magnitude of price elasticity declines with the passage of time : downloads become less sensitive to price changes as the app matures . As to the effect of discounting on downloads , displayed in Fig . 4 Panel E , we find a 13.20 % increase in app demand in response to a 10 % temporary reduction in price . The increase in app demand in response to a discount is more than double what has been reported in other studies ( e.g. , Ghose & Han ,    Notes : * indicates p < .1 , * * indicates p < .05 and * * * indicates p < .01 . We use Monday as the baseline while dummy - coding days of the week variable . All models include other controls , which are not shown here to conserve space . 20 Though major updates findings are consistent with expectations directionally and magnitude wise , there is substantial uncertainty around the estimatesdue to the scarcity of major updates released in the last half of the data . Hence , we refrain from drawing strong conclusions about their effects .	226318002	no
To better understand the impacts of the lockdown on environmental conditions , we grouped the data into five periods : P1 e Earlier ( Jan and Feb ) ; P2 e Pre - Lockdown ( March 01 to March 22 ) ; P3 e During Lockdown ( March 23 to April 15 ) ; P4 e Partial Loosening ( April 16 to April 30 ) ; and P5 e Limited Lockdown ( May 01 to May 15 ) . Table 1 presents a summary of the averaged / change statistics for NO 2 , CO , SO 2 , AOD and SUHI segregated by the key sectors -megacities , major cities , industrial areas , gas fields , power plants and cement plants .	233532496	no
Such digital technologies are rapidly supporting the efficiency of the healthcare ecosystem . The time for new digital technologies theories invites scholars to deepen their analyses regarding to the use of digital technologies for solving the global crisis of healthcare management . Several scholars proposed different approaches and technological tools . For example , Cappelle et al . ( 2011 ) developed a GIS - based methodology in estimating of epidemiological contact rates . Hirsch , Winters , Clarke and McKay ( 2014 ) investigated the global positioning system ( GPS ) as opportunity to measure , describe , and compare mobility patterns in elderly health , assuming that this technology can become a powerful tool to accurately describe the interaction of people within a particular geographic space . Koylu , Delil , Guo , and Celik ( 2018 ) investigated the patient mobility system through a data - driven approach ; Munyaneza et al . ( 2014 ) analyzed the same topic focusing on GIS . Young et al . ( 2013 ) investigated the role of AI through the machine learning approach connecting it to the epidemiology landscape .	234046079	no
Moovit data are available at the city level . Moovit covers 87 major cities worldwide , spanning across four ( 4 ) continents ; North America ( New York , Miami , San Francisco , Washington , etc . ) ; South America ( Brasilia , Buenos Aires , Santiago , Bogota , etc . ) ; Europe ( London , Paris , Berlin , Rome , etc . ) and Asia ( Singapore , Bangkok , Jakarta , Kuala Lumpur , etc . ) . For the present study , we utilized five ( 5 ) PT service attribute variables ( Variables 7 - 16 in Table 1 ) , that pertain to the years 2019 ( pre - pandemic ) and 2020 ( pandemic ) . These five ( 5 ) variables are regularly estimated by Moovit and they are closely related to PT quality of service :	255826268	maybe
The DT of a manufacturing process aims to efficiently monitor and remotely manage the physical item , using data analytics and intelligence tools and technologies . It allows programming maintenance schedules , load balancing , and predicting failures and disruptions , in which the operational parameters of machine sensors or machine components must be rectified or adapted continuously in the operation stage of the manufacturing process . Additionally , using advanced ML algorithms and data analytics , the integration of the real - time streaming sensor data with other operational inputs to create an operational data - driven DT will be facilitated . This operational DT will provide a more holistic and dynamic virtual representation of the whole manufacturing system , end - to - end processes , and operations . Thus , these analytics are important to be combined with a DT to reduce system downtime , improve production efficiency , and perform predictive quality maintenance .	245112757	no
Note that the Google mobility data compare mobility for the reported date to a baseline day . The baseline day represents a normal value for that day of the week calculated as the median value from the 5 - week period , Jan 3 -Feb 6 , 2020 . Thus , consistent with our data source , we are interested in predicting retail mobility relative to the baseline . Fig . 3 shows the time - series representation of the Google mobility values for the various categories across three cities .	255441206	no
Environmental impacts from electricity . Time series of electricity mixes , such as the ones provided by national energy agencies or as compiled from these agencies by Electricity Map , 5 provide the composition of the electricity mix at any given point in time . With these time series , only the carbon intensity of the electricity is usually computed . However , to perform a complete LCA ( i.e. including all environmental impact categories ) , this is not sufficient . The LCA database Ecoinvent ( Weidema et al . , 2013 ) provides complete life cycle inventories ( LCI ) , but its market processes for national grid mixes are usually given as annual averages and the underlying assumptions that generate various system - models are not easily changeable ( Cox et al . , 2018 ) . In this paper , to keep the LCA complete and at a high time resolution , we combined hourly production data in Sweden with Ecoinvent processes for each technology represented in the Swedish mix . This required a correspondence table because the two data sources did not share the same classification ( see SI ) .	228975451	maybe
We tested our hypotheses using an online survey with employees working for organizations in public and private sectors in five countries : South Africa ( N = 124 ) , Russia ( N = 161 ) , China ( N = 109 ) , the US ( N = 158 ) , and Germany ( N = 139 ) . We chose these countries based on a combination of their corruption 1 ( Transparency International , 2018 ) and societal inequality ( Coefficient of Human Inequality , UN , 2018 ) indices . Thus , Germany has low corruption levels and low inequality ; Russia has very high corruption and low inequality ; South Africa has very high inequality and medium levels of corruption ; and China and the US have medium levels of inequality and corruption , with China slightly higher on both counts ( see Table 1 ) . These countries were also chosen for their diversity in terms of their historical and political landscapes ( see Appendix table 4 ) , meaning that they are likely to differ in their attitudes and practices concerning inequality in the workplace and in society in general , generating adequate variability for any general patterns to become visible in the data .	238408791	no
"The promise of empowering communities through direct communication , although significant , also needs to be taken critically . Cooper ( 2015 ) points out that these optimistic accounts of community inclusion are often "" wishful thinking "" on behalf of media and NGOs , as digital voices mostly include white , middle class , and privileged groups . Big crisis data reflects the "" digital divide "" , as it contains and can further amplify the geographical ( North / South ) , economic , social , and political contexts of the people producing it ( Burns 2015;Madianou 2015 ) and can therefore be unrepresentative or biased ( Aitamurto 2016;IFRC 2013;Murthy 2013 ) . Crises are never the same , but neither are the affected societies themselves , as technological inclusion , pressures from political systems , levels of social trust , and cultural values vary considerably . Asymmetries in social power , such as class , race , and gender , directly impact the presence or absence of digital voices from these groups during crises ( Madianou , Longboan , and Ong 2015 ) . Over - reliance on digital voices in humanitarian response can amplify social inequalities and result in "" second order disasters "" ( Madianou 2015 ) where social media further diminish recovery opportunities for low - income groups and systematically exclude them from aid distribution ."	56090375	no
But recommendations could also be used in a completely different way : precisely because they are data - driven , recommenders can also take each individual 's different ideas , beliefs and opinions and use them as points of departure , suggesting alternative viewpoints that the individual has not yet thought of . Interestingly , personalisation could become a critical feature of a deliberative recommender , as it allows particular individuals to be challenged and exposed to ideas and opinions that they would not have come across on their own . Thus , news recommenders ' democratic role may be not only to inform users but to educate them and nudge them to broaden their horizons and make them practised in tolerance . Recommenders could expose the reader to extra , in - depth background material . They could present different perspectives alongside each other , and also make the user aware of what her current place is in the ideological spectrum . They could become an important instrument for fostering critical reflection and open - mindedness .	197796153	no
In this section , we examine the results of the Google Mobility models , beginning with retail mobility and followed by grocery and pharmacy mobility . Two results are presented with each type of mobility : predictive performance results and analytical results . The predictive performance results show the training and testing performance of each model . As we have mentioned , the test set consists of the last seven days of our data -May 23rd to May 29th ( inclusive ) .	255441206	no
Using the framework of media industry studies , this article examines industrial discourses related to Netflix 's audience data under conditions shaped by the company 's anti - transparency policy . Until late-2018 , executives used discussions of proprietary audience data to position the platform outside of the traditional television industry , to critique traditional industry players , and to deflect criticism . During this period , the company presented the popularity of its original series as axiomatic . As Sarandos explained in 2014 , ' You know in the culture that Orange Is The New Black [ ( 2013 - 2019 ) ] and House Of Cards are enormous hits ' ( Patten , 2014 ) . This discourse , enabled by the platform 's subscriber - based revenue model , supported Netflix 's broader efforts to position streaming as linear television 's inevitable replacement . Although these dynamics remain largely unchanged , by early 2019 , selective releases of audience data for what are presumably the service 's most popular series became standard practice . Although Hastings has described this willingness to publicize any data as part of the company 's efforts to ' grow up a little ' ( Goldbart , 2019 ) , Netflix 's use of non - standard metrics remains a point of contention within the industry . Setting aside questions of whether selective data releases represent a move toward meaningful transparency ( they do n't ) , this research has several significant implications for scholars concerned with video streaming services .	236221457	no
The fragile bargain in the form of a contract that the ' old ' market makers pursued ( with the exception of NASDAQ and OTC markets ) in order to gain an advantage in return for some obligations that they more or less fulfilled , has been entirely transformed by HFTs ' entrance . This structural positional advantage of the ' new ' market makers still persists , even though it is not assured by a contract but rather by the possibility of exploiting a number of services such as co - location and data feeds , and that de facto enable them to access information and orders of other investors faster than other players . In return for this structural advantage ( for which they pay high fees ) , HFT market making firms in contrast with the old market makers , do not have any positive and/or negative obligations . The greater freedom of HFT market makers , allow them to ( 1 ) operate the highest number of trades in as short time as possible ; ( 2 ) to maintain a very low inventory in order to close the day with a flat position .	237716093	no
A final conclusion from this review is that a rigorous , complete cradle - to - grave LCA of multiple battery technologies can be made more tractable by the production of consensus - based scenarios to address some of the major sources of uncertainty for these analyses . Specifically , scenarios that capture critical raw material availability , the geographic distribution of near - and long - term sources , and any expected shifts in extraction / processing methods would reduce reliance on sub - standard data sources and enable easier crosscomparisons between different battery studies . The same is true for the battery use - phase ; most LCA researchers and practitioners do not have the resources and subject matter expertise to develop detailed scenarios for battery cycling , operating temperatures , and SOC , nor can such a scenario easily be translated to expected shifts in capacity fade , efficiency , and lifetime . However , if a collection of experts were able to devise a set of scenarios that reflect the most likely use cases for batteries in transportation and stationary applications , these would be widely used and further improve the ability to compare studies and externally validate results . Ambitious harmonization projects are not unheard of [ 128 ] and , through a partnership between systems analysis experts and technology experts , the community can ensure that future analyses of battery technologies further our understanding of their impacts on the environment .	237792009	no
This study is the first attempt to monitor and analyze the effects of the first wave COVID-19 lockdown period as well as on air pollution using satellite - derived air pollutants and their relationships with various parameters in Turkey at a national level . The analyses in this study show that air pollution variation due to human activity can be monitored most effectively through NO 2 concentration using satellite imageries . In this way , GEE provides a powerful and very effective platform for researchers to analyze these parameters . Processing Sentinel-5P data in this platform , it is found out that NO 2 concentration significantly decreased during the first wave lockdown period of COVID-19 outbreak . The further analyses of the results with other parameters , shows that the transportation and industrial activities played the key role in decreasing the NO 2 level . As for the summer time after the lockdown , agricultural and touristic activities caused to higher NO 2 levels . Thus , as a future work , the authors plan to investigate the relationship between air pollutants and with various parameters such as traffic density , touristic and agricultural statistics as well as with fatality cases of COVID-19 outbreak on the city level in Turkey .       ( Rume and Islam , 2020 ) .	238664729	no
A commitment to investing in domestic drama is supposed to be a key differentiator for the PSMs in this case study , with drama strongly associated with local content , cultural identity and diversity , which in turn underpins the legitimacy of public funding from licence fees ( UK , Italy ) , government grants ( Flanders ) , and indirect production support from subsidies ( e.g. the Flanders Audiovisual Fund 's Media Fund ) and tax credits . In spite of PSM public statements about being dwarfed financially by US SVoD players like Netflix , BBC , RAI and VRT remain by far the largest investors in domestic fiction in their respective markets . VRT is the biggest producer and commissioner of scripted TV in Flanders , participating in eight out of 13 scripted series ( including soaps and web series ) aired in 2018 . In 2019 , VRT channels broadcast 12 out of 23 scripted television series ( based on second author 's own data ) .	234299322	no
There are more than a billion people globally who use Google Maps every month ; further , the mobility data are not limited to Google Maps users on mobile devices , but also comes from users of more than five million active apps or websites using Google Maps Platform core products everyday . Hence , we believe the mobility data provided by Google should accurately reflect average mobility trends across counties . We used the Mobility Reports data from February 15th , the first day the data are available , to the week ending on April 26th , by which time most states had begun to issue specific masking and distancing policies that made reducing mobility less necessary and thus a less accurate indicator of social responsibility .	235459410	maybe
Hypotheses 2 and 3 predict positive effects of team accountability on team performance and effort . Hypothesis 2 does not receive strong support . Our data find that accountability is positively related to subsequent team performance , but is not a statistically significant predictor when added to a model that includes midpoint performance ( Î² = 0.17 , R 2 = 0.41 , ÎR 2 = 0.01 , n.s . ) . The strongest predictors of team performance are previous performance ( Î² = 0.36 ) and effort ( Î² = 0.43 ) . In support of Hypothesis 3 , we found team accountability is associated with a significant increase in team effort ( Î² = 0.51 , R 2 = 0.29 , ÎR 2 = 0.12 , p < 0.01 ) .	244401758	no
The functional units ( FUs ) employed for analysis in this study are masks used by 100 individuals over a period of 1 month . Reusable cotton masks are discarded after 6 days of use ; in other words , they can withstand up to 5 washes while maintaining their protective properties , as recommended by the surveyed factories . Despite the fact that there are many different brands of reusable masks on the market that may vary in the maximum numbers of washes ( TESTEX Community Mask Label , 2022 ) , with some reportedly able to withstand up to 30 washes ( Forever Family , 2022 ) , due to limited research conditions and survey funding , production data were only available for masks that could be washed up to 5 times . Given that the cost people pay for them ( retail price : CNY 7 per mask ) is quite low relative to disposable masks ( retail price : CNY 0.35 per medical and surgical mask and CNY 2.5 per KN95 ) , we developed an evaluation model based on the number of washes in Section 2.4.2 to reduce the uncertainty associated with low settings for the number of washes .	255373604	no
We provide detailed conceptual framework behind each of these four proposed effects in the next section on theory and hypotheses , followed by section on data and methodology . We then go on to provide evidence in favor of all our hypotheses , and we conclude with the theoretical and practical implications of our findings in the final discussion section .	237756669	no
In the Supporting Information a detailed analysis of a range of published data is shown ( Figures S3 - S9 , Supporting Information ) , where the necessary data was available . In about 65 % of the studied data the efficiency stated in the publication and calculated with our method are in good agreement , which means deviation is only about 1 % ( in total ) . In the other 35 % of the evaluated data the stated and the measured absolute efficiency is deviating > 3 % in total , in worst cases > 8 % in total , which emphasizes the need of establishing low light measuring protocols . The deviations can have the following reasons : First , inconsistencies in the theoretical input powers ( calculated with the relative LED spectra normalized to 200 lux ) and the given input powers in the references imply that the illumination is not measured precisely . Therefore , the performance parameters are measured at an arbitrary point of illumination . If the lux meter for instance underestimated the illumination and the measured points would be on a slightly higher illuminance in reality , this error propagates to all performance parameters . Consequently , the J sc of the apparent 200 lux would seem higher , because in reality it might have been measured at say 210 lux . A detailed discussion can be found in the Supporting Information . Second , as stated in ref . [ 59 ] , the theoretical J sc ( J cal in the ref . [ 59 ] ) should be consistent with the JV measurement , which is not the case for many publications . This inconsistency indicates that either the Q e , PV or the LED spectra are of insufficient accuracy . Consequently , an overlap of calculated data points and original data can not be achieved , because our calculation is based on the integrated J sc from the quantum efficiency whereas most publications work with the JV measurement data . Additionally , we remark to check the correct calculation of the efficiency , because in some data the simple equation Î· = J sc V oc FF / P in does not hold true or it is not clear from which parameters the efficiency is calculated . If all data is measured precisely at a defined illumination , theoretical values and the original data must match well . Therefore , this method also gives the chance to validate low light measurements and editors or reviewers can judge whether some data credibly reports a certain efficiency under a certain illumination condition . Note that optical neutral density ( ND ) filters , which may be used to achieve sufficiently low light intensities , have ( unlike what the name suggests ) a wavelength - dependent transmission which varies mostly at the edge of the visible spectrum . Thus , in particular the region Î» > 700 nm becomes problematic , because at these wavelengths many organic solar cells for indoor applications will still absorb light well . The spectral dependencies of ND filters will cause changes in the spectra if used in low light set - ups and will therefore affect P out but more importantly P in at 200 lux and the efficiency .	236547029	maybe
This article explores how the IoE will impact on the business world , with a specific focus on the business model . Strategic theory following the service - dominant logic ( Vargo & Lusch , 2017 ) , posits that the products and things people buy are simply carriers of competences and functionality that form a service that users apply in the context of their use situation . We have discussed how this situation will change as the IoE leads to increasing levels of smartness in the things that we buy and use . Even though the dynamics of these changes are mainly driven by technical progress such as interconnectivity , big data , artificial intelligence , and semantic interoperability , organizations and institutions also have important roles to play in influencing the way the IoE will change societies .	213757082	no
There are many useful simulation tools for manufacturing system development . However , data exchange among different engineering phases and tools remains challenging due to the lack of a generally accepted data format . It potentially causes the random error generated by repeated data entry ( Hoffmann et al . , 2010 ) . Switching from virtual commissioning to semi - physical commissioning is difficult because the control functions should be connected to the physical system via the physical interface ( Lee and Park , 2014 ) . As shown in Fig . 4 , a digital twin system ( DTS ) has been developed based on the open - source jMon - keyEngine kernel ( Java language ) , which is an upgrading of our formerly - proposed digital twin system that developed based on the free - to - use Unity3D kernel ( C # language ) ( Leng et al . , 2020 ) . Different from the conventional offline simulation , the digital twin system interoperates the hardware equipment with digital models through establishing the channel between the virtual / physical controllers and the execution engine so as to control both the physical equipment and the cyber model . The digital twin system is used to conduct semi - physical simulation - based commissioning in a distributed environment . The digital twin implies synchronization among the physical system , simulation model , and execution engine of a smart manufacturing system ( Lu et al . , 2020 ) . The synchronization between simulation models and physical equipment is realized by a mapping between the hardware Programmable Logic Controller ( PLC ) and soft PLC through industrial communication . Moreover , it is driven by remote data from physical equipment distributed geographically based on high - speed sampling ( Hoffmann et al . , 2010 ) . Therefore , the electric and mechatronic hardware - in - theloop commissioning of OA - FSMS can be done parallel in the digital twin system , resulting in lower debugging costs .    5 provides an overview of the integration framework and function modules of the digital twin system , which includes four layers : infrastructure , data logic , visualization , and application . Firstly , the infrastructure layer includes a database , programming environment , networking , and 3D engine . It synchronizes the cyber model and physical object to form the hardware - in - the - loop simulation model . It includes the objectification of equipment model ( e.g. , loading / unloading and storage devices ) , moving trajectory , sensing devices , control script , and communication standard . Secondly , the data logic layer integrates the hardware - in - theloop simulation model and control system for translating the upper - level production instructions into lower - level controller scripts / codes deployed to the physical equipment and feeding back the in - situ production information on time to the upper - level production control systems . By setting up the shared data structure , macro object , and instruction database , the communication channel between the digital twin system and the external planning system is established so that the instructions generated by the external planning system can control the operation of the device , and the results can be fed back to the external planning system in real time . Thirdly , the visualization layer includes the fusion of the 3D model and real - time data for supporting the tracking of system operation status . This layer includes a refined - parameter model library to support the rapid commissioning of process , operation , storage , and assembly . Fourthly , the application layer majorly includes the process compilation , multi - view synchronization , and   performance analysis . The process of commissioning is to continually call the model in the library and deploy it to the semi - physical simulation engine according to the established planning scheme . In the digital twin system , the digital model is consistent with the physical equipment in appearance , structure , behavior , state , kinematics , and dynamics ( e.g. , collision detection , motion trajectory , friction force , gravity , resistance , velocity , acceleration , and inertia ) ( Leng et al . , 2020 ) , which provides the runtime for manufacturing system commissioning . The OA - FSMS could be rapidly defined and customized in a drag - and - drop manner by combining the easy - to - use visual modeling and redevelopment IDE ( integrated development environment ) tool . An open data interface is established in the digital twin system to enable users : 1 ) to manually or automatically import control scripts , 2 ) to modify some functions in the process , and 3 ) to monitor the data flow in the breakpoint debugging manner , which significantly facilitates error troubleshooting . By supporting a drag - and - drop manipulation , the digital twin system enables the quick reconfiguration of the complex OA - FSMS model , together with its motion schemes and control scripts .	235511748	no
Diffusion tensor fitting was then used to obtain fractional anisotropy ( FA ) maps for 604 each participant . All participants ' FA data was aligned into a common space using 605 the non - linear registration tool FNIRT , using a b - spline representation of the 606 registration warp field . The mean was then taken across all FA maps to create an FA 607 averaged image . This map was then ' thinned ' to create a mean FA skeleton , which 608 was then thresholded at FA > 0.2 , keeping only the major white matter tracts . Each    2 ) Non - brain tissue was removed ( FSL BET ) .	203853259	no
This study was constructed as following steps . First , we tested on different machine learning models , including NaÃ¯ve Bayes , Logistic Regression , Convolutional Neural Network ( CNN ) , and Long Short - Term Memory ( LSTM ) , and tried different text representation such as bag - ofwords and pre - trained word vectors . Secondly , we applied the optimal LSTM model on the collected Tweets and analyzed the sentiment change of different cities across time . Finally , we used Spearman 's rank correlation to investigate the relationship between Tweet sentiment , quarantine measures , and COVID-19 statistics such as new case emerges , hospitalization , and deaths in three cities - New York City , Los Angeles , and London , where we collected sufficient and quality Tweets to drive the machine learning based sentiment analysis . Since Tweet sentiments and the spread of the pandemic may vary by city , a comparative study across cities could allow researchers to incorporate city - specific features , such as the demographic distribution , economic indexes , and accessibility of public transportation , to dig deeper into the reasons behind the possible correlations found . Also , as pandemic quarantine measures could have huge impacts on the daily life of residents , such policies are often issued on a city , or even district level . Thus , a city - bycity comparison could help policymakers better distinguish the response of different residents and design more differentiated measures to prevent the spread of epidemics . The rest of the article was structured into the following sections . Section 2 ( Literature review ) reviews relevant research related to sentiment analysis and Twitter data usage . Section 3 ( Method ) introduces the methodology for Tweet collection , data preprocessing , machine learning classifiers for sentiment analysis , and the ranking rule for Spearman 's correlation . Section 4 ( Results ) presents the data summary and correlation analysis . Section 5 ( Discussion ) explores how the results of this study could be interpreted considering the difference in population density and infrastructure across cities . Section 6 ( Conclusion ) outlines the contributions , limitations , and implications of this study .	236251116	no
"To study the entanglements between data journalists and civic technologists , I took inspiration from practice - focused research paradigms that try to avoid "" any apriorisms about the roles and practices of the multiplicity of actors "" ( Domingo , Masip , and Meijer 2015 , 54 ) . A focus on practices has been suggested by a number of researchers to avoid a priori delineation of actors based on predefined categories . Instead , it encourages researchers to be open to the full range of "" what people are doing and how they categorize what they are doing "" without predefining their actions in categories like "" consumption "" "" whether or not that is how actors see their actions "" ( Couldry 2004 , 125 ) ."	149401418	no
The fifth category of apps in our dataset is symptoms monitoring , and such apps are used for surveillance and research . These apps typically require users to share their personal information such as health data , including symptoms , disease - related experiences and voice samples of a cough and breathing sounds with healthcare providers , public health agencies and researchers . Users share their health data to receive personal recommendations , and the authorities use the data for monitoring . Various users actively engage with these apps to share their personal health data with health agencies and thus provide active information	236296279	no
A summary of the modelling work conducted in this study is provided in Figure 2 . The model calculates the PV production starting from the climatological data and applying the algorithms concerning solar position , solar decomposition and transposition , and the solar shading . Crop yield is calculated by feeding the crop yield model with PAR and other key climatological and agricultural parameters . Photosyntetically active radiation ( PAR ) absorbed by the crop is calculated by considering the diffuse and beam components of the PAR and considering the shadings produced by the bifacial PV modules rows on the ground . The model developed in this study is based on the modelling and optimization framework of the open - source code OptiCE ( OptiCE , 2021;Campana et al . , 2017 ) .	233033702	no
A battery ontology was recently proposed by the German battery research cluster ProZell to target knowledge - based life cycle engineering . [ 64 ] They adopted a single - ontology approach for the whole system and has BatteryDataObject as central term , which refers to the Battery being handled , the current LifeCyleStage , the origin of the data object , AnalysisMethod used and TargetInfluence . This ontology is designed to capture life - cycle - oriented information , but also contains basic battery descriptions connected to the BatteryDataObject through the Battery which hasComponent Component . Although it is publicly described , the ontology itself is not yet openly available .	245111008	maybe
